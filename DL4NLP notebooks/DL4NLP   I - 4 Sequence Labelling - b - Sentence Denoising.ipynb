{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "\n",
    "\n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "    <font color=orange>I - 4 </font>\n",
    "    Sequence Labelling\n",
    "    \n",
    "  </div> \n",
    "\n",
    "<div style=\"\n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 20px; \n",
    "      margin: 10px;\">\n",
    "  b. Sentence Denoising\n",
    "  </div>\n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. <font color=orange>**Sequence Labelling**</font>\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. Text Classification\n",
    "\n",
    "2. Sequence to sequence\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "1. Abstractive Summarization\n",
    "\n",
    "2. Question Answering\n",
    "\n",
    "3. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "A top-quality Github repository discussing Sequence Labelling is found [here](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Sequence-Labeling)<br>\n",
    "\n",
    "We consider as Sequence labelling task a **Sentence Denoising** problem, which consists in transforming a noisy sequence of words into a correctly formed sentence. Training follows a denoising objective known as _Cloze task_ , which is used :\n",
    "\n",
    "- For the BERT model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.5.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_DL4NLP = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_DL4NLP + '\\\\lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG news\\\\train.csv\", sep = ',', header = None, error_bad_lines = False)\n",
    "df_AGnews_tst = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG news\\\\test.csv\" , sep = ',', header = None, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn.columns = ['index', 'title', 'description']\n",
    "df_AGnews_tst.columns = ['index', 'title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    return s\n",
    "\n",
    "def cleanSentence(s) :\n",
    "    s = s.lower()\n",
    "    s = re.sub('[\\.!?]+ ', ' . ', s)\n",
    "    s = s.replace('%', ' % ')\n",
    "    s = re.sub(' [0-9]*\\.[0-9] ', ' FLOAT ', ' ' + s + ' ').strip()\n",
    "    s = re.sub(' [0-9,]*[0-9] ', ' INT ', ' ' + s + ' ').strip()\n",
    "    \n",
    "    for w in ['\"', \"'\", '”', '“', '/', '(', ')', '[', ']', '<', '>', ':', ','] : s = s.replace(w, '')\n",
    "    return s\n",
    "\n",
    "def trueWord(w) :\n",
    "    return len(w)>0 and re.sub('[^a-zA-Z0-9.,]', '', w) != ''\n",
    "\n",
    "def tokenize(s) :\n",
    "    s = normalizeString(s)\n",
    "    s = cleanSentence(s)\n",
    "    s = nltk.tokenize.word_tokenize(s)\n",
    "    s = [w for w in s if trueWord(w)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce label by 1 to make is starts from 0\n",
    "sentences_trn = [tokenize(s1 + ' . ' + s2) for s1, s2 in zip(df_AGnews_trn[\"title\"].values.tolist(), df_AGnews_trn[\"description\"].values.tolist()) if tokenize(s1) != []]\n",
    "sentences_tst = [tokenize(s1 + ' . ' + s2) for s1, s2 in zip(df_AGnews_tst[\"title\"].values.tolist(), df_AGnews_tst[\"description\"].values.tolist()) if tokenize(s1) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "word2vec = Word2Vec.load(get_tmpfile(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_skipgram_gensim.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences_trn, \n",
    "                     size = 100, \n",
    "                     window = 5, \n",
    "                     min_count = 5, \n",
    "                     negative = 20, \n",
    "                     iter = 25,\n",
    "                     sg = 1,\n",
    "                     workers = multiprocessing.cpu_count())\n",
    "word2vec.train(sentences_trn,\n",
    "               epochs = 25,\n",
    "               total_examples = word2vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#word2vec.save(get_tmpfile(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_skipgram_gensim.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder\n",
    "from libDL4NLP.misc    import Highway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence denoising Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDenoiser(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden_dim = 100, \n",
    "                 n_layer = 1, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(\n",
    "            emb_dim = self.word2vec.out_dim, \n",
    "            hid_dim = hidden_dim, \n",
    "            n_layer = n_layer, \n",
    "            dropout = dropout, \n",
    "            bidirectional = True)\n",
    "        self.out       = nn.Linear(self.context.out_dim, self.word2vec.lang.n_words)\n",
    "        self.act       = F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index = self.word2vec.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, \n",
    "                                    ignore_index = self.ignore_index, \n",
    "                                    weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def predict_proba(self, words):\n",
    "        embeddings = self.word2vec.twin(words, self.device) # dim = (1, input_length, hidden_dim)\n",
    "        hiddens, _ = self.context(embeddings)               # dim = (1, input_length, hidden_dim)\n",
    "        probs      = self.act(self.out(hiddens), dim = 2)   # dim = (1, input_length, lang_size)\n",
    "        return probs\n",
    "\n",
    "    # main method\n",
    "    def forward(self, sentence = '.', color = '\\033[94m'):\n",
    "        def addColor(w1, w2, color) : return color + w2 + '\\033[0m' if w1 != w2 else w2\n",
    "        words  = self.tokenizer(sentence)\n",
    "        probs  = self.predict_proba(words).squeeze(0) # dim = (input_length, lang_size)\n",
    "        inds   = [probs[i].data.topk(1)[1].item() for i in range(probs.size(0))]\n",
    "        new_ws = [self.word2vec.lang.index2word[ind] for ind in inds]\n",
    "        print(' '.join([addColor(w1, w2, color) for w1, w2 in zip(words, new_ws)]))\n",
    "        return\n",
    "\n",
    "    # load data\n",
    "    def generatePackedSentences(self, sentences, \n",
    "                                batch_size = 32, \n",
    "                                mask_ratio = 0.15,\n",
    "                                max_sentence_length = 50,\n",
    "                                tol = 10,\n",
    "                                seed = 42) :\n",
    "        def maskInput(index, b) :\n",
    "            if   b and random.random() > 0.25 : return self.word2vec.lang.getIndex('UNK')\n",
    "            elif b and random.random() > 0.10 : return random.choice(list(self.word2vec.twin.lang.word2index.values()))\n",
    "            else                              : return index\n",
    "            \n",
    "        def maskOutput(index, b) :\n",
    "            return index if b else self.ignore_index\n",
    "        \n",
    "        def splitLongs(words, threshold = 50, tol = 10):\n",
    "            news = []\n",
    "            for i in range(0, len(words), threshold) :\n",
    "                if len(words)-i-threshold > tol : \n",
    "                    news.append(words[i : i + threshold])\n",
    "                else : \n",
    "                    news.append(words[i:])\n",
    "                    break\n",
    "            return news\n",
    "        \n",
    "        packed_data = []\n",
    "        random.seed(seed)\n",
    "        # prepare sentences\n",
    "        #sentences = [self.tokenizer(s) for s in sentences]\n",
    "        sentences = [[self.word2vec.lang.getIndex(w) for w in s] for s in sentences]\n",
    "        sentences = [[w for w in words if w is not None] for words in sentences]\n",
    "        sentences = [s for S in sentences for s in splitLongs(S, max_sentence_length, tol) if len([w for w in s if w != self.word2vec.lang.getIndex('UNK')]) > 1]\n",
    "        sentences.sort(key = lambda s: len(s), reverse = True)\n",
    "        # collect packs\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            # prepare mask\n",
    "            mask_xl = [[i for i, w in enumerate(p) if w != self.word2vec.lang.getIndex('UNK')] for p in pack]\n",
    "            mask_xs = [random.sample(m, k = int(mask_ratio*len(m) +1)) for m in mask_xl]\n",
    "            # prepare input and target packs\n",
    "            pack0    = [[ maskInput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xs)]\n",
    "            pack1_xs = [[maskOutput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xs)]\n",
    "            pack1_xl = [[maskOutput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xl)]\n",
    "            lengths  = torch.tensor([len(p) for p in pack0]) # size = (batch_size) \n",
    "            # padd\n",
    "            pack0    = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index)) \n",
    "            pack1_xs = list(itertools.zip_longest(*pack1_xs, fillvalue = self.ignore_index))\n",
    "            pack1_xl = list(itertools.zip_longest(*pack1_xl, fillvalue = self.ignore_index))\n",
    "            # turn into torch variables\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))   # size = (batch_size, max_length)\n",
    "            pack1_xs = Variable(torch.LongTensor(pack1_xs).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            pack1_xl = Variable(torch.LongTensor(pack1_xl).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            # store pack\n",
    "            packed_data.append([[pack0, lengths], [pack1_xs, pack1_xl]])\n",
    "        return packed_data\n",
    "    \n",
    "    # fit model\n",
    "    def fit(self, batches, \n",
    "            iters = None, \n",
    "            epochs = None, \n",
    "            lr = 0.025, \n",
    "            unmasked_ratio = 0,\n",
    "            random_state = 42, \n",
    "            print_every = 10, \n",
    "            compute_accuracy = 'xs'):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens,_  = self.context(embeddings, lengths = batch[1].to(self.device)) # dim = (batch_size, input_length, hidden_dim)\n",
    "            log_probs  = F.log_softmax(self.out(hiddens), dim = 2)                    # dim = (batch_size, input_length, lang_size)\n",
    "            return log_probs\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            total   = np.sum(targets.data.cpu().numpy() != self.ignore_index)\n",
    "            success = sum([self.ignore_index != targets[i, j].item() == log_probs[i, :, j].data.topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0)) \\\n",
    "                           for j in range(targets.size(1)) ])\n",
    "            return  success * 100 / total\n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, unmasked_ratio, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs  = computeLogProbs(batch[0]).transpose(1, 2) # dim = (batch_size, lang_size, input_length)\n",
    "            targets_xs = batch[1][0].to(self.device)               # dim = (batch_size, input_length)\n",
    "            targets_xl = batch[1][1].to(self.device)               # dim = (batch_size, input_length)\n",
    "            loss       = (1-unmasked_ratio)*self.criterion(log_probs, targets_xs) \\\n",
    "                       + unmasked_ratio    *self.criterion(log_probs, targets_xl)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            if compute_accuracy == 'xs': \n",
    "                accuracy = computeAccuracy(log_probs, targets_xs)\n",
    "                error = float(loss.item() / np.sum(targets_xs.data.cpu().numpy() != self.ignore_index))\n",
    "            elif compute_accuracy == 'xl': \n",
    "                accuracy = computeAccuracy(log_probs, targets_xl)\n",
    "                error = float(loss.item() / np.sum(targets_xl.data.cpu().numpy() != self.ignore_index))\n",
    "            else : \n",
    "                accuracy = 0\n",
    "                error = float(loss.item() / np.sum(targets_xs.data.cpu().numpy() != self.ignore_index))\n",
    "            return error, accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, unmasked_ratio, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer,unmasked_ratio, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566019"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser = SentenceDenoiser(device = device, # torch.device('cpu'),\n",
    "                            tokenizer = lambda s : s.split(' '),\n",
    "                            word2vec = Word2VecConnector(word2vec),\n",
    "                            hidden_dim = 100, \n",
    "                            n_layer = 3, \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.AdamW)\n",
    "\n",
    "denoiser.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = denoiser.generatePackedSentences(sentences_trn, \n",
    "                                            batch_size = 16,\n",
    "                                            mask_ratio = 0.15,\n",
    "                                            max_sentence_length = 50,\n",
    "                                            tol = 10,\n",
    "                                            seed = 42)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 39s (- 50m 0s) (100 1%) loss : 14.075  accuracy : 6.2 %\n",
      "1m 17s (- 49m 15s) (200 2%) loss : 13.148  accuracy : 8.3 %\n",
      "1m 58s (- 49m 16s) (300 3%) loss : 13.123  accuracy : 8.1 %\n",
      "2m 39s (- 49m 7s) (400 5%) loss : 12.763  accuracy : 8.5 %\n",
      "3m 20s (- 48m 44s) (500 6%) loss : 12.333  accuracy : 9.3 %\n",
      "4m 5s (- 48m 56s) (600 7%) loss : 11.947  accuracy : 10.1 %\n",
      "4m 45s (- 48m 11s) (700 8%) loss : 11.452  accuracy : 11.7 %\n",
      "5m 26s (- 47m 35s) (800 10%) loss : 11.010  accuracy : 12.8 %\n",
      "6m 7s (- 46m 50s) (900 11%) loss : 10.712  accuracy : 13.5 %\n",
      "6m 48s (- 46m 16s) (1000 12%) loss : 10.407  accuracy : 14.0 %\n",
      "7m 30s (- 45m 37s) (1100 14%) loss : 10.175  accuracy : 14.6 %\n",
      "8m 10s (- 44m 50s) (1200 15%) loss : 10.007  accuracy : 15.1 %\n",
      "8m 49s (- 44m 3s) (1300 16%) loss : 9.797  accuracy : 15.7 %\n",
      "9m 29s (- 43m 19s) (1400 17%) loss : 9.570  accuracy : 15.8 %\n",
      "10m 12s (- 42m 47s) (1500 19%) loss : 9.292  accuracy : 16.4 %\n",
      "10m 53s (- 42m 8s) (1600 20%) loss : 9.255  accuracy : 16.2 %\n",
      "11m 34s (- 41m 26s) (1700 21%) loss : 9.108  accuracy : 16.7 %\n",
      "12m 15s (- 40m 48s) (1800 23%) loss : 8.841  accuracy : 17.3 %\n",
      "12m 56s (- 40m 6s) (1900 24%) loss : 8.864  accuracy : 17.2 %\n",
      "13m 36s (- 39m 23s) (2000 25%) loss : 8.673  accuracy : 17.3 %\n",
      "14m 16s (- 38m 40s) (2100 26%) loss : 8.506  accuracy : 17.1 %\n",
      "14m 57s (- 37m 59s) (2200 28%) loss : 8.441  accuracy : 17.9 %\n",
      "15m 37s (- 37m 17s) (2300 29%) loss : 8.361  accuracy : 18.4 %\n",
      "16m 15s (- 36m 30s) (2400 30%) loss : 8.374  accuracy : 18.2 %\n",
      "16m 58s (- 35m 54s) (2500 32%) loss : 8.151  accuracy : 18.1 %\n",
      "17m 39s (- 35m 13s) (2600 33%) loss : 8.191  accuracy : 18.3 %\n",
      "18m 19s (- 34m 31s) (2700 34%) loss : 8.119  accuracy : 17.9 %\n",
      "18m 59s (- 33m 50s) (2800 35%) loss : 7.946  accuracy : 18.5 %\n",
      "19m 38s (- 33m 5s) (2900 37%) loss : 8.019  accuracy : 17.8 %\n",
      "20m 17s (- 32m 23s) (3000 38%) loss : 7.856  accuracy : 18.7 %\n",
      "20m 58s (- 31m 42s) (3100 39%) loss : 7.732  accuracy : 19.0 %\n",
      "21m 39s (- 31m 2s) (3200 41%) loss : 7.812  accuracy : 18.9 %\n",
      "22m 20s (- 30m 22s) (3300 42%) loss : 7.714  accuracy : 18.5 %\n",
      "23m 0s (- 29m 42s) (3400 43%) loss : 7.714  accuracy : 18.4 %\n",
      "23m 40s (- 29m 0s) (3500 44%) loss : 7.566  accuracy : 19.4 %\n",
      "24m 20s (- 28m 19s) (3600 46%) loss : 7.488  accuracy : 19.7 %\n",
      "25m 0s (- 27m 37s) (3700 47%) loss : 7.476  accuracy : 19.5 %\n",
      "25m 39s (- 26m 55s) (3800 48%) loss : 7.396  accuracy : 19.8 %\n",
      "26m 18s (- 26m 13s) (3900 50%) loss : 7.314  accuracy : 20.1 %\n",
      "26m 58s (- 25m 32s) (4000 51%) loss : 7.397  accuracy : 19.2 %\n",
      "27m 39s (- 24m 52s) (4100 52%) loss : 7.202  accuracy : 20.2 %\n",
      "28m 20s (- 24m 12s) (4200 53%) loss : 7.153  accuracy : 20.1 %\n",
      "28m 59s (- 23m 31s) (4300 55%) loss : 7.238  accuracy : 19.8 %\n",
      "29m 39s (- 22m 50s) (4400 56%) loss : 7.138  accuracy : 20.1 %\n",
      "30m 20s (- 22m 10s) (4500 57%) loss : 7.109  accuracy : 19.5 %\n",
      "30m 59s (- 21m 28s) (4600 59%) loss : 7.185  accuracy : 20.4 %\n",
      "31m 38s (- 20m 47s) (4700 60%) loss : 7.005  accuracy : 21.4 %\n",
      "32m 19s (- 20m 7s) (4800 61%) loss : 7.090  accuracy : 20.1 %\n",
      "32m 59s (- 19m 26s) (4900 62%) loss : 6.970  accuracy : 21.2 %\n",
      "33m 38s (- 18m 45s) (5000 64%) loss : 7.013  accuracy : 20.2 %\n",
      "34m 16s (- 18m 4s) (5100 65%) loss : 7.015  accuracy : 20.5 %\n",
      "34m 56s (- 17m 23s) (5200 66%) loss : 6.907  accuracy : 20.2 %\n",
      "35m 35s (- 16m 42s) (5300 68%) loss : 6.809  accuracy : 20.8 %\n",
      "36m 15s (- 16m 2s) (5400 69%) loss : 6.852  accuracy : 20.9 %\n",
      "36m 55s (- 15m 21s) (5500 70%) loss : 6.845  accuracy : 20.4 %\n",
      "37m 36s (- 14m 41s) (5600 71%) loss : 6.726  accuracy : 21.0 %\n",
      "38m 19s (- 14m 2s) (5700 73%) loss : 6.758  accuracy : 21.2 %\n",
      "38m 58s (- 13m 21s) (5800 74%) loss : 6.811  accuracy : 20.3 %\n",
      "39m 38s (- 12m 41s) (5900 75%) loss : 6.676  accuracy : 21.1 %\n",
      "40m 21s (- 12m 1s) (6000 77%) loss : 6.727  accuracy : 20.8 %\n",
      "41m 0s (- 11m 20s) (6100 78%) loss : 6.654  accuracy : 20.9 %\n",
      "41m 41s (- 10m 40s) (6200 79%) loss : 6.597  accuracy : 21.8 %\n",
      "42m 22s (- 10m 0s) (6300 80%) loss : 6.712  accuracy : 20.7 %\n",
      "43m 1s (- 9m 19s) (6400 82%) loss : 6.596  accuracy : 21.5 %\n",
      "43m 41s (- 8m 39s) (6500 83%) loss : 6.524  accuracy : 21.1 %\n",
      "44m 20s (- 7m 58s) (6600 84%) loss : 6.537  accuracy : 21.2 %\n",
      "45m 1s (- 7m 18s) (6700 86%) loss : 6.523  accuracy : 21.2 %\n",
      "45m 41s (- 6m 38s) (6800 87%) loss : 6.433  accuracy : 22.5 %\n",
      "46m 21s (- 5m 58s) (6900 88%) loss : 6.433  accuracy : 21.4 %\n",
      "47m 1s (- 5m 17s) (7000 89%) loss : 6.420  accuracy : 22.0 %\n",
      "47m 41s (- 4m 37s) (7100 91%) loss : 6.483  accuracy : 21.5 %\n",
      "48m 21s (- 3m 56s) (7200 92%) loss : 6.513  accuracy : 21.1 %\n",
      "49m 1s (- 3m 16s) (7300 93%) loss : 6.386  accuracy : 21.8 %\n",
      "49m 39s (- 2m 36s) (7400 95%) loss : 6.439  accuracy : 21.1 %\n",
      "50m 19s (- 1m 55s) (7500 96%) loss : 6.401  accuracy : 22.4 %\n",
      "50m 56s (- 1m 15s) (7600 97%) loss : 6.409  accuracy : 21.3 %\n",
      "51m 37s (- 0m 35s) (7700 98%) loss : 6.418  accuracy : 21.2 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches, epochs = 1, lr = 0.001, unmasked_ratio = 0.15, compute_accuracy = 'xs', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (- 0m 51s) (100 50%) loss : 1.046  accuracy : 72.5 %\n",
      "1m 44s (- 0m 0s) (200 100%) loss : 1.088  accuracy : 71.4 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches, iters = 200, lr = 0.001, unmasked_ratio = 0.15, compute_accuracy = 'xl', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7788"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches2 = denoiser.generatePackedSentences(sentences_trn, \n",
    "                                            batch_size = 16,\n",
    "                                            mask_ratio = 0.15,\n",
    "                                            max_sentence_length = 50,\n",
    "                                            tol = 10,\n",
    "                                            seed = 4242)\n",
    "len(batches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 39s (- 50m 58s) (100 1%) loss : 6.919  accuracy : 21.5 %\n",
      "1m 19s (- 50m 25s) (200 2%) loss : 6.859  accuracy : 22.3 %\n",
      "1m 58s (- 49m 27s) (300 3%) loss : 6.887  accuracy : 22.8 %\n",
      "2m 39s (- 49m 8s) (400 5%) loss : 6.837  accuracy : 22.8 %\n",
      "3m 20s (- 48m 47s) (500 6%) loss : 6.813  accuracy : 22.9 %\n",
      "4m 0s (- 47m 56s) (600 7%) loss : 6.705  accuracy : 23.5 %\n",
      "4m 39s (- 47m 10s) (700 8%) loss : 6.794  accuracy : 22.4 %\n",
      "5m 17s (- 46m 9s) (800 10%) loss : 6.941  accuracy : 21.9 %\n",
      "5m 56s (- 45m 30s) (900 11%) loss : 6.771  accuracy : 23.1 %\n",
      "6m 34s (- 44m 40s) (1000 12%) loss : 6.764  accuracy : 22.7 %\n",
      "7m 13s (- 43m 56s) (1100 14%) loss : 6.606  accuracy : 23.5 %\n",
      "7m 52s (- 43m 13s) (1200 15%) loss : 6.689  accuracy : 22.7 %\n",
      "8m 31s (- 42m 33s) (1300 16%) loss : 6.756  accuracy : 22.2 %\n",
      "9m 10s (- 41m 52s) (1400 17%) loss : 6.722  accuracy : 22.6 %\n",
      "9m 50s (- 41m 14s) (1500 19%) loss : 6.631  accuracy : 23.2 %\n",
      "10m 30s (- 40m 36s) (1600 20%) loss : 6.659  accuracy : 22.6 %\n",
      "11m 9s (- 39m 59s) (1700 21%) loss : 6.599  accuracy : 23.1 %\n",
      "11m 49s (- 39m 19s) (1800 23%) loss : 6.596  accuracy : 23.6 %\n",
      "12m 29s (- 38m 43s) (1900 24%) loss : 6.659  accuracy : 22.3 %\n",
      "13m 7s (- 37m 58s) (2000 25%) loss : 6.664  accuracy : 22.7 %\n",
      "13m 46s (- 37m 17s) (2100 26%) loss : 6.658  accuracy : 22.8 %\n",
      "14m 24s (- 36m 36s) (2200 28%) loss : 6.578  accuracy : 23.4 %\n",
      "15m 3s (- 35m 56s) (2300 29%) loss : 6.518  accuracy : 23.7 %\n",
      "15m 42s (- 35m 14s) (2400 30%) loss : 6.596  accuracy : 22.6 %\n",
      "16m 19s (- 34m 31s) (2500 32%) loss : 6.597  accuracy : 22.4 %\n",
      "16m 57s (- 33m 50s) (2600 33%) loss : 6.492  accuracy : 22.7 %\n",
      "17m 38s (- 33m 14s) (2700 34%) loss : 6.554  accuracy : 22.2 %\n",
      "18m 18s (- 32m 36s) (2800 35%) loss : 6.465  accuracy : 23.4 %\n",
      "18m 58s (- 31m 58s) (2900 37%) loss : 6.466  accuracy : 23.4 %\n",
      "19m 38s (- 31m 20s) (3000 38%) loss : 6.517  accuracy : 23.2 %\n",
      "20m 17s (- 30m 40s) (3100 39%) loss : 6.422  accuracy : 23.9 %\n",
      "20m 56s (- 30m 0s) (3200 41%) loss : 6.529  accuracy : 22.9 %\n",
      "21m 34s (- 29m 20s) (3300 42%) loss : 6.488  accuracy : 22.9 %\n",
      "22m 13s (- 28m 40s) (3400 43%) loss : 6.467  accuracy : 23.1 %\n",
      "22m 52s (- 28m 1s) (3500 44%) loss : 6.446  accuracy : 23.3 %\n",
      "23m 31s (- 27m 22s) (3600 46%) loss : 6.456  accuracy : 23.0 %\n",
      "24m 10s (- 26m 42s) (3700 47%) loss : 6.532  accuracy : 22.0 %\n",
      "24m 50s (- 26m 4s) (3800 48%) loss : 6.320  accuracy : 23.9 %\n",
      "25m 31s (- 25m 26s) (3900 50%) loss : 6.298  accuracy : 24.3 %\n",
      "26m 10s (- 24m 46s) (4000 51%) loss : 6.419  accuracy : 23.7 %\n",
      "26m 51s (- 24m 9s) (4100 52%) loss : 6.403  accuracy : 23.1 %\n",
      "27m 31s (- 23m 30s) (4200 53%) loss : 6.308  accuracy : 23.6 %\n",
      "28m 10s (- 22m 50s) (4300 55%) loss : 6.315  accuracy : 23.2 %\n",
      "28m 48s (- 22m 11s) (4400 56%) loss : 6.379  accuracy : 22.9 %\n",
      "29m 29s (- 21m 33s) (4500 57%) loss : 6.353  accuracy : 23.4 %\n",
      "30m 9s (- 20m 53s) (4600 59%) loss : 6.343  accuracy : 22.7 %\n",
      "30m 49s (- 20m 15s) (4700 60%) loss : 6.236  accuracy : 24.4 %\n",
      "31m 28s (- 19m 35s) (4800 61%) loss : 6.215  accuracy : 23.9 %\n",
      "32m 8s (- 18m 56s) (4900 62%) loss : 6.245  accuracy : 23.5 %\n",
      "32m 46s (- 18m 16s) (5000 64%) loss : 6.292  accuracy : 23.6 %\n",
      "33m 25s (- 17m 37s) (5100 65%) loss : 6.255  accuracy : 23.5 %\n",
      "34m 5s (- 16m 57s) (5200 66%) loss : 6.248  accuracy : 23.3 %\n",
      "34m 43s (- 16m 18s) (5300 68%) loss : 6.295  accuracy : 23.2 %\n",
      "35m 21s (- 15m 38s) (5400 69%) loss : 6.335  accuracy : 22.8 %\n",
      "36m 0s (- 14m 58s) (5500 70%) loss : 6.204  accuracy : 24.0 %\n",
      "36m 37s (- 14m 18s) (5600 71%) loss : 6.209  accuracy : 24.2 %\n",
      "37m 17s (- 13m 39s) (5700 73%) loss : 6.265  accuracy : 23.8 %\n",
      "37m 56s (- 13m 0s) (5800 74%) loss : 6.327  accuracy : 23.1 %\n",
      "38m 35s (- 12m 20s) (5900 75%) loss : 6.242  accuracy : 23.2 %\n",
      "39m 15s (- 11m 41s) (6000 77%) loss : 6.191  accuracy : 23.8 %\n",
      "39m 54s (- 11m 2s) (6100 78%) loss : 6.234  accuracy : 22.9 %\n",
      "40m 33s (- 10m 23s) (6200 79%) loss : 6.169  accuracy : 23.3 %\n",
      "41m 14s (- 9m 44s) (6300 80%) loss : 6.188  accuracy : 23.6 %\n",
      "41m 57s (- 9m 5s) (6400 82%) loss : 6.140  accuracy : 23.7 %\n",
      "42m 36s (- 8m 26s) (6500 83%) loss : 6.224  accuracy : 23.5 %\n",
      "43m 17s (- 7m 47s) (6600 84%) loss : 6.189  accuracy : 23.6 %\n",
      "43m 58s (- 7m 8s) (6700 86%) loss : 6.173  accuracy : 23.4 %\n",
      "44m 39s (- 6m 29s) (6800 87%) loss : 6.108  accuracy : 23.3 %\n",
      "45m 19s (- 5m 49s) (6900 88%) loss : 6.164  accuracy : 24.3 %\n",
      "46m 0s (- 5m 10s) (7000 89%) loss : 6.202  accuracy : 22.9 %\n",
      "46m 40s (- 4m 31s) (7100 91%) loss : 6.135  accuracy : 24.0 %\n",
      "47m 21s (- 3m 52s) (7200 92%) loss : 6.096  accuracy : 23.5 %\n",
      "48m 0s (- 3m 12s) (7300 93%) loss : 6.171  accuracy : 23.4 %\n",
      "48m 42s (- 2m 33s) (7400 95%) loss : 6.120  accuracy : 23.1 %\n",
      "49m 22s (- 1m 53s) (7500 96%) loss : 6.055  accuracy : 24.2 %\n",
      "50m 3s (- 1m 14s) (7600 97%) loss : 6.113  accuracy : 23.4 %\n",
      "50m 41s (- 0m 34s) (7700 98%) loss : 6.154  accuracy : 23.8 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches2, epochs = 1, lr = 0.00025, unmasked_ratio = 0.15, compute_accuracy = 'xs', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 56s (- 0m 56s) (100 50%) loss : 0.972  accuracy : 76.9 %\n",
      "1m 48s (- 0m 0s) (200 100%) loss : 1.003  accuracy : 76.3 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches2, iters = 200, lr = 0.00025, unmasked_ratio = 0.15, compute_accuracy = 'xl', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "#torch.save(denoiser.state_dict(), path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_sentence_denoiser.pth')\n",
    "\n",
    "# load\n",
    "#denoiser.load_state_dict(torch.load(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_sentence_denoiser.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news sluggish movement on power grid cyber security . industry cyber security standards fail to reach some of the most vulnerable components of the power grid.\\\n",
      "\n",
      "\n",
      "news sluggish movement on power \u001b[93mof\u001b[0m cyber security . industry cyber security standards fail to reach some of the most vulnerable components of the power \u001b[93m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "denoiser.eval()\n",
    "sentence = ' '.join(sentences_tst[25]) #'what are you thinking of this'\n",
    "print(sentence)\n",
    "print('\\n')\n",
    "denoiser(sentence, color = '\\033[93m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctCorpus(word2vec, corpus, threshold = 0.9) :\n",
    "    new_sentences = []\n",
    "    corrections = []\n",
    "    for s in corpus :\n",
    "        new_s = []\n",
    "        for word in s :\n",
    "            try : #fasttext raises an error if no character ngram seen during training appears in the word\n",
    "                if (word not in word2vec.wv.vocab and word2vec.most_similar(word)[0][1] >= threshold) :\n",
    "                    new_word = word2vec.most_similar(word)[0][0]\n",
    "                    new_s.append(new_word)\n",
    "                    corrections.append([word, new_word])\n",
    "                else :\n",
    "                    new_s.append(word)\n",
    "            except : \n",
    "                new_s.append(word)\n",
    "        new_sentences.append(new_s)\n",
    "    return new_sentences, corrections\n",
    "\n",
    "\n",
    "def contextualCorrectCorpus(denoiser, corpus, threshold = 0.9, print_every = 100) :\n",
    "    word2vec = denoiser.word2vec.word2vec\n",
    "    new_sentences = []\n",
    "    corrections = []\n",
    "    corpus = [s for s in corpus if len(s) > 0]\n",
    "    for ws in corpus : \n",
    "        probs = denoiser.predict_proba(ws).squeeze(0) # size = (input_length, lang_size)\n",
    "        new_s = []\n",
    "        for i, word in enumerate(ws) :\n",
    "            try : #fasttext raises an error if no character ngram seen during training appears in the word\n",
    "                candidates = [wp[0] for wp in word2vec.most_similar(word) if wp[1] >= threshold]\n",
    "                if (word not in word2vec.wv.vocab and candidates != []) :\n",
    "                    indices  = [denoiser.word2vec.lang.getIndex(w) for w in candidates]\n",
    "                    probsi   = [probs[i, j].item() for j in indices]\n",
    "                    wps      = [[w, p] for w, p in zip(candidates, probsi)]\n",
    "                    wps.sort(key = lambda wp : wp[1], reverse = True)\n",
    "                    new_word = wps[0][0]\n",
    "                    new_s.append(new_word)\n",
    "                    corrections.append([word, new_word])\n",
    "                else :\n",
    "                    new_s.append(word)\n",
    "            except : \n",
    "                new_s.append(word)\n",
    "        new_sentences.append(new_s)\n",
    "        if len(new_sentences)+1 % print_every == 0 : print(len(new_sentences)+1)\n",
    "    return new_sentences, corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_corpus, corrections = correctCorpus(word2vec, sentences_tst, threshold = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_corrected_corpus, contextual_corrections = contextualCorrectCorpus(denoiser, sentences_tst[:2500], threshold = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500) : \n",
    "    word  = corrections[i][0]\n",
    "    pred1 = corrections[i][1]\n",
    "    pred2 = contextual_corrections[i][1]\n",
    "    if pred2 != pred1 : pred2 = '\\033[93m' + pred2 + '\\033[0m'\n",
    "    print(word, '->', pred1, ' | ', pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
