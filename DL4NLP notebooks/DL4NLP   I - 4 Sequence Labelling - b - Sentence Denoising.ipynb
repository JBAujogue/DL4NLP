{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "\n",
    "\n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "    <font color=orange>I - 4 </font>\n",
    "    Sequence Labelling\n",
    "    \n",
    "  </div> \n",
    "\n",
    "<div style=\"\n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 20px; \n",
    "      margin: 10px;\">\n",
    "  b. Sentence Denoising\n",
    "  </div>\n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. <font color=orange>**Sequence Labelling**</font>\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. Text Classification\n",
    "\n",
    "2. Sequence to sequence\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "1. Abstractive Summarization\n",
    "\n",
    "2. Question Answering\n",
    "\n",
    "3. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "A top-quality Github repository discussing Sequence Labelling is found [here](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Sequence-Labeling)<br>\n",
    "\n",
    "We consider as Sequence labelling task a **Sentence Denoising** problem, which consists in transforming a noisy sequence of words into a correctly formed sentence. Training follows a denoising objective known as _Cloze task_ , which is used :\n",
    "\n",
    "- For the BERT model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.4.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_DL4NLP = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_DL4NLP + '\\\\lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG news\\\\train.csv\", sep = ',', header = None, error_bad_lines = False)\n",
    "df_AGnews_tst = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG news\\\\test.csv\" , sep = ',', header = None, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn.columns = ['index', 'title', 'description']\n",
    "df_AGnews_tst.columns = ['index', 'title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    return s\n",
    "\n",
    "def cleanSentence(s) :\n",
    "    s = s.lower()\n",
    "    s = re.sub('[\\.!?]+ ', ' . ', s)\n",
    "    s = s.replace('%', ' % ')\n",
    "    s = re.sub(' [0-9]*\\.[0-9] ', ' FLOAT ', ' ' + s + ' ').strip()\n",
    "    s = re.sub(' [0-9,]*[0-9] ', ' INT ', ' ' + s + ' ').strip()\n",
    "    \n",
    "    for w in ['\"', \"'\", '”', '“', '/', '(', ')', '[', ']', '<', '>', ':', ','] : s = s.replace(w, '')\n",
    "    return s\n",
    "\n",
    "def trueWord(w) :\n",
    "    return len(w)>0 and re.sub('[^a-zA-Z0-9.,]', '', w) != ''\n",
    "\n",
    "def tokenize(s) :\n",
    "    s = normalizeString(s)\n",
    "    s = cleanSentence(s)\n",
    "    s = nltk.tokenize.word_tokenize(s)\n",
    "    s = [w for w in s if trueWord(w)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce label by 1 to make is starts from 0\n",
    "sentences_trn = [tokenize(s1 + ' . ' + s2) for s1, s2 in zip(df_AGnews_trn[\"title\"].values.tolist(), df_AGnews_trn[\"description\"].values.tolist()) if tokenize(s1) != []]\n",
    "sentences_tst = [tokenize(s1 + ' . ' + s2) for s1, s2 in zip(df_AGnews_tst[\"title\"].values.tolist(), df_AGnews_tst[\"description\"].values.tolist()) if tokenize(s1) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences_trn, \n",
    "                     size = 100, \n",
    "                     window = 5, \n",
    "                     min_count = 5, \n",
    "                     negative = 20, \n",
    "                     iter = 25,\n",
    "                     sg = 1,\n",
    "                     workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#word2vec.save(get_tmpfile(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_skipgram_gensim.model'))\n",
    "\n",
    "# load trained model\n",
    "#word2vec = Word2Vec.load(get_tmpfile(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_skipgram_gensim.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence denoising Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDenoiser(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden_dim = 100, \n",
    "                 n_layers = 1, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(SentenceDenoiser, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(self.word2vec.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.out       = nn.Linear(self.context.output_dim, self.word2vec.lang.n_words)\n",
    "        self.act       = F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index = self.word2vec.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, \n",
    "                                    ignore_index = self.ignore_index, \n",
    "                                    weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def predict_proba(self, words):\n",
    "        embeddings = self.word2vec.twin(words, self.device) # dim = (1, input_length, hidden_dim)\n",
    "        hiddens, _ = self.context(embeddings)               # dim = (1, input_length, hidden_dim)\n",
    "        probs      = self.act(self.out(hiddens), dim = 2)   # dim = (1, input_length, lang_size)\n",
    "        return probs\n",
    "\n",
    "    # main method\n",
    "    def forward(self, sentence = '.', color = '\\033[94m'):\n",
    "        def addColor(w1, w2, color) : return color + w2 + '\\033[0m' if w1 != w2 else w2\n",
    "        words  = self.tokenizer(sentence)\n",
    "        probs  = self.predict_proba(words).squeeze(0) # dim = (input_length, lang_size)\n",
    "        inds   = [probs[i].data.topk(1)[1].item() for i in range(probs.size(0))]\n",
    "        new_ws = [self.word2vec.lang.index2word[ind] for ind in inds]\n",
    "        print(' '.join([addColor(w1, w2, color) for w1, w2 in zip(words, new_ws)]))\n",
    "        return\n",
    "\n",
    "    # load data\n",
    "    def generatePackedSentences(self, \n",
    "                                sentences, \n",
    "                                batch_size = 32, \n",
    "                                mask_ratio = 0.15,\n",
    "                                max_sentence_length = 50,\n",
    "                                tol = 10,\n",
    "                                seed = 42) :\n",
    "        def maskInput(index, b) :\n",
    "            if   b and random.random() > 0.25 : return self.word2vec.lang.getIndex('UNK')\n",
    "            elif b and random.random() > 0.10 : return random.choice(list(self.word2vec.twin.lang.word2index.values()))\n",
    "            else                              : return index\n",
    "            \n",
    "        def maskOutput(index, b) :\n",
    "            return index if b else self.ignore_index\n",
    "        \n",
    "        def splitLongs(words, threshold = 50, tol = 10):\n",
    "            news = []\n",
    "            for i in range(0, len(words), threshold) :\n",
    "                if len(words)-i-threshold > tol : \n",
    "                    news.append(words[i : i + threshold])\n",
    "                else : \n",
    "                    news.append(words[i:])\n",
    "                    break\n",
    "            return news\n",
    "        \n",
    "        packed_data = []\n",
    "        random.seed(seed)\n",
    "        # prepare sentences\n",
    "        #sentences = [self.tokenizer(s) for s in sentences]\n",
    "        sentences = [[self.word2vec.lang.getIndex(w) for w in s] for s in sentences]\n",
    "        sentences = [[w for w in words if w is not None] for words in sentences]\n",
    "        sentences = [s for S in sentences for s in splitLongs(S, max_sentence_length, tol) if len([w for w in s if w != self.word2vec.lang.getIndex('UNK')]) > 1]\n",
    "        sentences.sort(key = lambda s: len(s), reverse = True)\n",
    "        # collect packs\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            # prepare mask\n",
    "            mask_xl = [[i for i, w in enumerate(p) if w != self.word2vec.lang.getIndex('UNK')] for p in pack]\n",
    "            mask_xs = [random.sample(m, k = int(mask_ratio*len(m) +1)) for m in mask_xl]\n",
    "            # prepare input and target packs\n",
    "            pack0    = [[ maskInput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xs)]\n",
    "            pack1_xs = [[maskOutput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xs)]\n",
    "            pack1_xl = [[maskOutput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask_xl)]\n",
    "            lengths  = torch.tensor([len(p) for p in pack0]) # size = (batch_size) \n",
    "            # padd\n",
    "            pack0    = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index)) \n",
    "            pack1_xs = list(itertools.zip_longest(*pack1_xs, fillvalue = self.ignore_index))\n",
    "            pack1_xl = list(itertools.zip_longest(*pack1_xl, fillvalue = self.ignore_index))\n",
    "            # turn into torch variables\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))   # size = (batch_size, max_length)\n",
    "            pack1_xs = Variable(torch.LongTensor(pack1_xs).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            pack1_xl = Variable(torch.LongTensor(pack1_xl).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            # store pack\n",
    "            packed_data.append([[pack0, lengths], [pack1_xs, pack1_xl]])\n",
    "        return packed_data\n",
    "    \n",
    "    # fit model\n",
    "    def fit(self, batches, \n",
    "            iters = None, epochs = None, lr = 0.025, unmasked_ratio = 0,\n",
    "            random_state = 42, print_every = 10, compute_accuracy = 'xs'):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens,_  = self.context(embeddings, lengths = batch[1].to(self.device)) # dim = (batch_size, input_length, hidden_dim)\n",
    "            log_probs  = F.log_softmax(self.out(hiddens), dim = 2)                    # dim = (batch_size, input_length, lang_size)\n",
    "            return log_probs\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            total   = np.sum(targets.data.cpu().numpy() != self.ignore_index)\n",
    "            success = sum([self.ignore_index != targets[i, j].item() == log_probs[i, :, j].data.topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0)) \\\n",
    "                           for j in range(targets.size(1)) ])\n",
    "            return  success * 100 / total\n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, unmasked_ratio, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs  = computeLogProbs(batch[0]).transpose(1, 2) # dim = (batch_size, lang_size, input_length)\n",
    "            targets_xs = batch[1][0].to(self.device)               # dim = (batch_size, input_length)\n",
    "            targets_xl = batch[1][1].to(self.device)               # dim = (batch_size, input_length)\n",
    "            loss       = (1-unmasked_ratio)*self.criterion(log_probs, targets_xs) \\\n",
    "                       + unmasked_ratio    *self.criterion(log_probs, targets_xl)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            if compute_accuracy == 'xs': \n",
    "                accuracy = computeAccuracy(log_probs, targets_xs)\n",
    "                error = float(loss.item() / np.sum(targets_xs.data.cpu().numpy() != self.ignore_index))\n",
    "            elif compute_accuracy == 'xl': \n",
    "                accuracy = computeAccuracy(log_probs, targets_xl)\n",
    "                error = float(loss.item() / np.sum(targets_xl.data.cpu().numpy() != self.ignore_index))\n",
    "            else : \n",
    "                accuracy = 0\n",
    "                error = float(loss.item() / np.sum(targets_xs.data.cpu().numpy() != self.ignore_index))\n",
    "            return error, accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, unmasked_ratio, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer,unmasked_ratio, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566019"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser = SentenceDenoiser(device = device, # torch.device('cpu'),\n",
    "                            tokenizer = lambda s : s.split(' '),\n",
    "                            word2vec = Word2VecConnector(word2vec),\n",
    "                            hidden_dim = 100, \n",
    "                            n_layers = 3, \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.AdamW)\n",
    "\n",
    "denoiser.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7788"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = denoiser.generatePackedSentences(sentences_trn, \n",
    "                                            batch_size = 16,\n",
    "                                            mask_ratio = 0.15,\n",
    "                                            max_sentence_length = 50,\n",
    "                                            tol = 10,\n",
    "                                            seed = 42)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 37s (- 48m 19s) (100 1%) loss : 14.124  accuracy : 6.2 %\n",
      "1m 14s (- 47m 15s) (200 2%) loss : 13.149  accuracy : 7.9 %\n",
      "1m 52s (- 46m 43s) (300 3%) loss : 12.990  accuracy : 8.2 %\n",
      "2m 29s (- 46m 0s) (400 5%) loss : 12.660  accuracy : 8.9 %\n",
      "3m 7s (- 45m 34s) (500 6%) loss : 12.240  accuracy : 9.3 %\n",
      "3m 47s (- 45m 24s) (600 7%) loss : 11.850  accuracy : 10.4 %\n",
      "4m 24s (- 44m 35s) (700 8%) loss : 11.381  accuracy : 12.0 %\n",
      "5m 2s (- 44m 0s) (800 10%) loss : 10.954  accuracy : 12.8 %\n",
      "5m 39s (- 43m 20s) (900 11%) loss : 10.667  accuracy : 13.7 %\n",
      "6m 18s (- 42m 48s) (1000 12%) loss : 10.381  accuracy : 14.2 %\n",
      "6m 57s (- 42m 18s) (1100 14%) loss : 10.125  accuracy : 14.8 %\n",
      "7m 34s (- 41m 36s) (1200 15%) loss : 9.969  accuracy : 15.1 %\n",
      "8m 12s (- 40m 55s) (1300 16%) loss : 9.767  accuracy : 15.1 %\n",
      "8m 49s (- 40m 15s) (1400 17%) loss : 9.500  accuracy : 15.7 %\n",
      "9m 27s (- 39m 39s) (1500 19%) loss : 9.215  accuracy : 16.2 %\n",
      "10m 5s (- 39m 0s) (1600 20%) loss : 9.199  accuracy : 16.2 %\n",
      "10m 43s (- 38m 24s) (1700 21%) loss : 9.033  accuracy : 16.7 %\n",
      "11m 22s (- 37m 49s) (1800 23%) loss : 8.761  accuracy : 17.3 %\n",
      "11m 59s (- 37m 10s) (1900 24%) loss : 8.784  accuracy : 17.2 %\n",
      "12m 38s (- 36m 33s) (2000 25%) loss : 8.596  accuracy : 17.2 %\n",
      "13m 15s (- 35m 55s) (2100 26%) loss : 8.442  accuracy : 17.4 %\n",
      "13m 54s (- 35m 20s) (2200 28%) loss : 8.353  accuracy : 17.7 %\n",
      "14m 34s (- 34m 46s) (2300 29%) loss : 8.262  accuracy : 18.5 %\n",
      "15m 10s (- 34m 4s) (2400 30%) loss : 8.301  accuracy : 18.5 %\n",
      "15m 48s (- 33m 26s) (2500 32%) loss : 8.066  accuracy : 17.9 %\n",
      "16m 26s (- 32m 48s) (2600 33%) loss : 8.087  accuracy : 18.6 %\n",
      "17m 4s (- 32m 10s) (2700 34%) loss : 8.022  accuracy : 18.3 %\n",
      "17m 42s (- 31m 32s) (2800 35%) loss : 7.847  accuracy : 18.6 %\n",
      "18m 17s (- 30m 50s) (2900 37%) loss : 7.961  accuracy : 18.2 %\n",
      "18m 55s (- 30m 12s) (3000 38%) loss : 7.782  accuracy : 18.7 %\n",
      "19m 33s (- 29m 33s) (3100 39%) loss : 7.652  accuracy : 19.4 %\n",
      "20m 11s (- 28m 56s) (3200 41%) loss : 7.750  accuracy : 18.8 %\n",
      "20m 50s (- 28m 20s) (3300 42%) loss : 7.632  accuracy : 18.9 %\n",
      "21m 28s (- 27m 42s) (3400 43%) loss : 7.637  accuracy : 18.9 %\n",
      "22m 6s (- 27m 4s) (3500 44%) loss : 7.501  accuracy : 19.2 %\n",
      "22m 44s (- 26m 27s) (3600 46%) loss : 7.456  accuracy : 19.8 %\n",
      "23m 22s (- 25m 49s) (3700 47%) loss : 7.411  accuracy : 19.9 %\n",
      "23m 59s (- 25m 10s) (3800 48%) loss : 7.334  accuracy : 20.0 %\n",
      "24m 35s (- 24m 31s) (3900 50%) loss : 7.266  accuracy : 19.8 %\n",
      "25m 14s (- 23m 54s) (4000 51%) loss : 7.329  accuracy : 19.7 %\n",
      "25m 52s (- 23m 16s) (4100 52%) loss : 7.149  accuracy : 20.2 %\n",
      "26m 29s (- 22m 38s) (4200 53%) loss : 7.114  accuracy : 20.2 %\n",
      "27m 6s (- 21m 59s) (4300 55%) loss : 7.184  accuracy : 20.0 %\n",
      "27m 43s (- 21m 21s) (4400 56%) loss : 7.091  accuracy : 19.8 %\n",
      "28m 21s (- 20m 43s) (4500 57%) loss : 7.057  accuracy : 20.1 %\n",
      "28m 58s (- 20m 4s) (4600 59%) loss : 7.132  accuracy : 20.3 %\n",
      "29m 35s (- 19m 26s) (4700 60%) loss : 6.947  accuracy : 21.4 %\n",
      "30m 13s (- 18m 48s) (4800 61%) loss : 7.069  accuracy : 20.2 %\n",
      "30m 50s (- 18m 10s) (4900 62%) loss : 6.947  accuracy : 21.4 %\n",
      "31m 27s (- 17m 32s) (5000 64%) loss : 6.973  accuracy : 19.5 %\n",
      "32m 3s (- 16m 53s) (5100 65%) loss : 6.992  accuracy : 20.6 %\n",
      "32m 41s (- 16m 16s) (5200 66%) loss : 6.878  accuracy : 20.4 %\n",
      "33m 17s (- 15m 37s) (5300 68%) loss : 6.800  accuracy : 20.9 %\n",
      "33m 56s (- 15m 0s) (5400 69%) loss : 6.817  accuracy : 21.4 %\n",
      "34m 33s (- 14m 22s) (5500 70%) loss : 6.835  accuracy : 20.4 %\n",
      "35m 11s (- 13m 45s) (5600 71%) loss : 6.712  accuracy : 21.1 %\n",
      "35m 50s (- 13m 7s) (5700 73%) loss : 6.774  accuracy : 20.9 %\n",
      "36m 27s (- 12m 29s) (5800 74%) loss : 6.771  accuracy : 20.8 %\n",
      "37m 5s (- 11m 52s) (5900 75%) loss : 6.653  accuracy : 21.7 %\n",
      "37m 44s (- 11m 14s) (6000 77%) loss : 6.686  accuracy : 20.9 %\n",
      "38m 21s (- 10m 36s) (6100 78%) loss : 6.633  accuracy : 21.3 %\n",
      "38m 59s (- 9m 59s) (6200 79%) loss : 6.555  accuracy : 22.0 %\n",
      "39m 36s (- 9m 21s) (6300 80%) loss : 6.706  accuracy : 20.5 %\n",
      "40m 12s (- 8m 43s) (6400 82%) loss : 6.601  accuracy : 21.5 %\n",
      "40m 50s (- 8m 5s) (6500 83%) loss : 6.514  accuracy : 21.3 %\n",
      "41m 27s (- 7m 27s) (6600 84%) loss : 6.534  accuracy : 21.1 %\n",
      "42m 5s (- 6m 50s) (6700 86%) loss : 6.504  accuracy : 21.5 %\n",
      "42m 43s (- 6m 12s) (6800 87%) loss : 6.428  accuracy : 22.4 %\n",
      "43m 21s (- 5m 34s) (6900 88%) loss : 6.425  accuracy : 21.6 %\n",
      "43m 59s (- 4m 57s) (7000 89%) loss : 6.414  accuracy : 21.9 %\n",
      "44m 37s (- 4m 19s) (7100 91%) loss : 6.493  accuracy : 21.1 %\n",
      "45m 14s (- 3m 41s) (7200 92%) loss : 6.491  accuracy : 21.0 %\n",
      "45m 53s (- 3m 4s) (7300 93%) loss : 6.352  accuracy : 21.7 %\n",
      "46m 30s (- 2m 26s) (7400 95%) loss : 6.421  accuracy : 21.2 %\n",
      "47m 8s (- 1m 48s) (7500 96%) loss : 6.376  accuracy : 22.4 %\n",
      "47m 44s (- 1m 10s) (7600 97%) loss : 6.395  accuracy : 21.5 %\n",
      "48m 21s (- 0m 33s) (7700 98%) loss : 6.411  accuracy : 21.4 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches, epochs = 1, lr = 0.001, unmasked_ratio = 0.15, compute_accuracy = 'xs', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (- 0m 51s) (100 50%) loss : 1.042  accuracy : 72.6 %\n",
      "1m 45s (- 0m 0s) (200 100%) loss : 1.087  accuracy : 71.9 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches, iters = 200, lr = 0.001, unmasked_ratio = 0.15, compute_accuracy = 'xl', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7788"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches2 = denoiser.generatePackedSentences(sentences_trn, \n",
    "                                            batch_size = 16,\n",
    "                                            mask_ratio = 0.15,\n",
    "                                            max_sentence_length = 50,\n",
    "                                            tol = 10,\n",
    "                                            seed = 4242)\n",
    "len(batches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 36s (- 46m 49s) (100 1%) loss : 6.699  accuracy : 22.1 %\n",
      "1m 13s (- 46m 28s) (200 2%) loss : 6.759  accuracy : 22.0 %\n",
      "1m 50s (- 46m 8s) (300 3%) loss : 6.734  accuracy : 22.6 %\n",
      "2m 27s (- 45m 30s) (400 5%) loss : 6.695  accuracy : 22.6 %\n",
      "3m 5s (- 45m 7s) (500 6%) loss : 6.680  accuracy : 21.9 %\n",
      "3m 45s (- 45m 3s) (600 7%) loss : 6.553  accuracy : 23.5 %\n",
      "4m 22s (- 44m 17s) (700 8%) loss : 6.708  accuracy : 22.1 %\n",
      "5m 0s (- 43m 44s) (800 10%) loss : 6.604  accuracy : 22.8 %\n",
      "5m 37s (- 43m 4s) (900 11%) loss : 6.658  accuracy : 22.2 %\n",
      "6m 16s (- 42m 32s) (1000 12%) loss : 6.557  accuracy : 22.7 %\n",
      "6m 54s (- 42m 3s) (1100 14%) loss : 6.614  accuracy : 22.3 %\n",
      "7m 32s (- 41m 21s) (1200 15%) loss : 6.669  accuracy : 22.3 %\n",
      "8m 9s (- 40m 40s) (1300 16%) loss : 6.553  accuracy : 22.5 %\n",
      "8m 46s (- 40m 0s) (1400 17%) loss : 6.582  accuracy : 23.0 %\n",
      "9m 24s (- 39m 25s) (1500 19%) loss : 6.473  accuracy : 22.6 %\n",
      "10m 1s (- 38m 46s) (1600 20%) loss : 6.553  accuracy : 22.2 %\n",
      "10m 39s (- 38m 10s) (1700 21%) loss : 6.581  accuracy : 22.3 %\n",
      "11m 17s (- 37m 35s) (1800 23%) loss : 6.491  accuracy : 22.8 %\n",
      "11m 55s (- 36m 57s) (1900 24%) loss : 6.543  accuracy : 22.6 %\n",
      "12m 33s (- 36m 20s) (2000 25%) loss : 6.438  accuracy : 23.2 %\n",
      "13m 11s (- 35m 43s) (2100 26%) loss : 6.445  accuracy : 22.9 %\n",
      "13m 53s (- 35m 17s) (2200 28%) loss : 6.509  accuracy : 22.6 %\n",
      "14m 41s (- 35m 2s) (2300 29%) loss : 6.467  accuracy : 23.3 %\n",
      "15m 25s (- 34m 38s) (2400 30%) loss : 6.553  accuracy : 22.5 %\n",
      "16m 11s (- 34m 15s) (2500 32%) loss : 6.405  accuracy : 22.8 %\n",
      "16m 53s (- 33m 43s) (2600 33%) loss : 6.496  accuracy : 21.9 %\n",
      "17m 34s (- 33m 7s) (2700 34%) loss : 6.410  accuracy : 22.6 %\n",
      "18m 14s (- 32m 30s) (2800 35%) loss : 6.402  accuracy : 23.0 %\n",
      "18m 52s (- 31m 49s) (2900 37%) loss : 6.492  accuracy : 22.6 %\n",
      "19m 32s (- 31m 11s) (3000 38%) loss : 6.392  accuracy : 23.0 %\n",
      "20m 10s (- 30m 29s) (3100 39%) loss : 6.337  accuracy : 22.9 %\n",
      "20m 51s (- 29m 55s) (3200 41%) loss : 6.383  accuracy : 23.4 %\n",
      "21m 38s (- 29m 26s) (3300 42%) loss : 6.414  accuracy : 22.4 %\n",
      "22m 18s (- 28m 47s) (3400 43%) loss : 6.383  accuracy : 23.3 %\n",
      "22m 56s (- 28m 6s) (3500 44%) loss : 6.302  accuracy : 23.3 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8a99425ee84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdenoiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00025\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munmasked_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'xs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-5368e5c181ce>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, batches, iters, epochs, lr, unmasked_ratio, random_state, print_every, compute_accuracy)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munmasked_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[0mtot_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mtot_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-5368e5c181ce>\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(batch, optimizer, unmasked_ratio, compute_accuracy)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcompute_accuracy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'xs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_xs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_xs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mcompute_accuracy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'xl'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-5368e5c181ce>\u001b[0m in \u001b[0;36mcomputeAccuracy\u001b[1;34m(log_probs, targets)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcomputeAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mtotal\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             success = sum([self.ignore_index != targets[i, j].item() == log_probs[i, :, j].data.topk(1)[1].item() \\\n\u001b[0;32m    130\u001b[0m                            \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches2, epochs = 1, lr = 0.00025, unmasked_ratio = 0.15, compute_accuracy = 'xs', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 53s (- 0m 53s) (100 50%) loss : 1.040  accuracy : 75.0 %\n",
      "1m 47s (- 0m 0s) (200 100%) loss : 1.041  accuracy : 74.6 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches2, iters = 200, lr = 0.00025, unmasked_ratio = 0.15, compute_accuracy = 'xl', print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(denoiser.state_dict(), path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_sentence_denoiser.pth')\n",
    "\n",
    "# load\n",
    "#denoiser.load_state_dict(torch.load(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_I4b_sentence_denoiser.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news sluggish movement on power grid cyber security . industry cyber security standards fail to reach some of the most vulnerable components of the power grid.\\\n",
      "\n",
      "\n",
      "news sluggish \u001b[93mgrowth\u001b[0m on power \u001b[93mcomputing\u001b[0m cyber security . industry cyber security standards fail to reach some of the most vulnerable components of the power \u001b[93m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "denoiser.eval()\n",
    "sentence = ' '.join(sentences_tst[25]) #'what are you thinking of this'\n",
    "print(sentence)\n",
    "print('\\n')\n",
    "denoiser(sentence, color = '\\033[93m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctCorpus(word2vec, corpus, threshold = 0.9) :\n",
    "    new_sentences = []\n",
    "    corrections = []\n",
    "    for s in corpus :\n",
    "        new_s = []\n",
    "        for word in s :\n",
    "            try : #fasttext raises an error if no character ngram seen during training appears in the word\n",
    "                if (word not in word2vec.wv.vocab and word2vec.most_similar(word)[0][1] >= threshold) :\n",
    "                    new_word = word2vec.most_similar(word)[0][0]\n",
    "                    new_s.append(new_word)\n",
    "                    corrections.append([word, new_word])\n",
    "                else :\n",
    "                    new_s.append(word)\n",
    "            except : \n",
    "                new_s.append(word)\n",
    "        new_sentences.append(new_s)\n",
    "    return new_sentences, corrections\n",
    "\n",
    "\n",
    "def contextualCorrectCorpus(denoiser, corpus, threshold = 0.9, print_every = 100) :\n",
    "    word2vec = denoiser.word2vec.word2vec\n",
    "    new_sentences = []\n",
    "    corrections = []\n",
    "    corpus = [s for s in corpus if len(s) > 0]\n",
    "    for ws in corpus : \n",
    "        probs = denoiser.predict_proba(ws).squeeze(0) # size = (input_length, lang_size)\n",
    "        new_s = []\n",
    "        for i, word in enumerate(ws) :\n",
    "            try : #fasttext raises an error if no character ngram seen during training appears in the word\n",
    "                candidates = [wp[0] for wp in word2vec.most_similar(word) if wp[1] >= threshold]\n",
    "                if (word not in word2vec.wv.vocab and candidates != []) :\n",
    "                    indices  = [denoiser.word2vec.lang.getIndex(w) for w in candidates]\n",
    "                    probsi   = [probs[i, j].item() for j in indices]\n",
    "                    wps      = [[w, p] for w, p in zip(candidates, probsi)]\n",
    "                    wps.sort(key = lambda wp : wp[1], reverse = True)\n",
    "                    new_word = wps[0][0]\n",
    "                    new_s.append(new_word)\n",
    "                    corrections.append([word, new_word])\n",
    "                else :\n",
    "                    new_s.append(word)\n",
    "            except : \n",
    "                new_s.append(word)\n",
    "        new_sentences.append(new_s)\n",
    "        if len(new_sentences)+1 % print_every == 0 : print(len(new_sentences)+1)\n",
    "    return new_sentences, corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_corpus, corrections = correctCorpus(word2vec, sentences_tst, threshold = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_corrected_corpus, contextual_corrections = contextualCorrectCorpus(denoiser, sentences_tst[:2500], threshold = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500) : \n",
    "    word  = corrections[i][0]\n",
    "    pred1 = corrections[i][1]\n",
    "    pred2 = contextual_corrections[i][1]\n",
    "    if pred2 != pred1 : pred2 = '\\033[93m' + pred2 + '\\033[0m'\n",
    "    print(word, '->', pred1, ' | ', pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
