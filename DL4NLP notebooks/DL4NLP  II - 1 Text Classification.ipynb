{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "    <font color=orange>II - 1 </font>\n",
    "  Text Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. <font color=orange>**Text Classification**</font>\n",
    "\n",
    "2. Sequence to sequence\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "1. Abstractive Summarization\n",
    "\n",
    "2. Question Answering\n",
    "\n",
    "3. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | | |\n",
    "|------|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | [Open source models](#open_source_models) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "A top-quality Github repository discussing Hierarchical Attention Networks is found [here](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Text-Classification). <br>\n",
    "This repo doesn't feature temporal reccurence in attention provided by the present multi-hoped attention mechanism.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.5.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import gc\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_DL4NLP = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_DL4NLP + '\\\\lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le corpus est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\train.csv\", sep = ',', header = None, error_bad_lines = False)\n",
    "df_AGnews_tst = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\test.csv\" , sep = ',', header = None, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn.columns = ['index', 'title', 'description']\n",
    "df_AGnews_tst.columns = ['index', 'title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AGnews_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    return s\n",
    "\n",
    "def cleanSentence(s) :\n",
    "    s = s.lower()\n",
    "    s = s.replace('\\\\', ' ')\n",
    "    s = re.sub('[\\.!?]+ ', ' . ', s)\n",
    "    s = s.replace('%', ' % ')\n",
    "    s = re.sub(' [0-9]*\\.[0-9] ', ' FLOAT ', ' ' + s + ' ').strip()\n",
    "    s = re.sub(' [0-9,]*[0-9] ', ' INT ', ' ' + s + ' ').strip()\n",
    "    \n",
    "    for w in ['\"', \"'\", '”', '“', '/', '(', ')', '[', ']', '<', '>', ':', ','] : s = s.replace(w, '')\n",
    "    return s\n",
    "\n",
    "def trueWord(w) :\n",
    "    return len(w)>0 and re.sub('[^a-zA-Z0-9.,]', '', w) != ''\n",
    "\n",
    "def tokenize(s) :\n",
    "    s = normalizeString(s)\n",
    "    s = cleanSentence(s)\n",
    "    S = s.split('.')\n",
    "    S = [nltk.tokenize.word_tokenize(s) for s in S]\n",
    "    S = [[w for w in s if trueWord(w)] for s in S]\n",
    "    S = [s for s in S if s != []]\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce label by 1 to make is starts from 0\n",
    "labelled_sentences_trn = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_trn[\"title\"].values.tolist(), df_AGnews_trn[\"description\"].values.tolist(), df_AGnews_trn[\"index\"].values.tolist()) if tokenize(s1) != []]\n",
    "labelled_sentences_tst = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_tst[\"title\"].values.tolist(), df_AGnews_tst[\"description\"].values.tolist(), df_AGnews_tst[\"index\"].values.tolist()) if tokenize(s1) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "_Remark_ : The pre-trained Word2vec models are the same as those used in **Part I - 2 Sentence Classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2VecConnector(Word2Vec.load(get_tmpfile(path_to_DL4NLP + \"\\\\saves\\\\DL4NLP_I2_skipgram_gensim.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Attention Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from libDL4NLP.modules import Attention\n",
    "# from libDL4NLP.misc    import HighwayQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayQ(nn.Module):\n",
    "    def __init__(self, dim, \n",
    "                 query_dim = 0, \n",
    "                 dropout = 0,\n",
    "                 act = F.tanh):\n",
    "        super().__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.dim      = dim + query_dim\n",
    "        self.transf   = nn.Linear(self.dim, dim)\n",
    "        self.gate     = nn.Linear(self.dim, dim)\n",
    "        self.dropout  = nn.Dropout(p = dropout)\n",
    "        self.act      = act\n",
    "\n",
    "    def forward(self, vect, \n",
    "                query = None):\n",
    "        '''vect and (optional) query must be 3D tensors with same size along dim 0 and 1'''\n",
    "        if query is not None : merge = torch.cat((vect, query), dim = 2)\n",
    "        else                 : merge = vect\n",
    "        transf = self.act(self.transf(merge))\n",
    "        gate   = F.sigmoid(self.gate(merge))\n",
    "        vect   = gate * transf + (1 - gate) * vect\n",
    "        vect   = self.dropout(vect)\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim, \n",
    "                 dropout = 0, \n",
    "                 method = 'concat'): \n",
    "        super().__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.method  = method\n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_dim = emb_dim\n",
    "        \n",
    "        # layers\n",
    "        self.dropout    = nn.Dropout(p = dropout)\n",
    "        self.attn_layer = HighwayQ(emb_dim, query_dim, dropout)\n",
    "        self.attn_v     = nn.Linear(emb_dim, 1, bias = False)\n",
    "        self.value      = HighwayQ(emb_dim, query_dim, dropout)\n",
    "        self.act        = F.softmax\n",
    "        \n",
    "    def forward(self, embeddings, query):\n",
    "        '''embeddings       of size (batch_size, input_length, emb_dim)\n",
    "           query (optional) of size (batch_size, 1, emb_dim)\n",
    "        '''\n",
    "        # query is optional for this method\n",
    "        if self.method == 'concat' :\n",
    "            weights = self.attn_layer(embeddings, query)       # size (batch_size, input_length, embedding_dim)\n",
    "            weights = self.act(self.attn_v(weights), dim = 1)  # size (batch_size, input_length, 1)\n",
    "            weights = weights.transpose(1, 2)                  # size (batch_size, 1, input_length)\n",
    "            \n",
    "        # query is necessary for this method\n",
    "        elif self.method == 'dot' :\n",
    "            query   = query.transpose(1, 2)                    # size (batch_size, query_dim, 1)\n",
    "            weights = torch.bmm(embeddings, query)             # size (batch_size, input_length, 1)\n",
    "            weights = self.act(weights, dim = 1)               # size (batch_size, input_length, 1)\n",
    "            weights = torch.transpose(weights, 1, 2)           # size (batch_size, 1, input_length)\n",
    "        applied = self.dropout(torch.bmm(weights, embeddings)) # size (batch_size, 1, embedding_dim)\n",
    "        return applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Multi-hoped Hierarchical Attention Module\n",
    "\n",
    "A combination of ideas originating from :\n",
    "\n",
    "- Hierarchical Attention : [Hierarchical Attention Networks for Document Classification (2016)](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)\n",
    "- Hoping mechanism : [End-To-End Memory Networks (2015)](https://arxiv.org/pdf/1503.08895.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAN(nn.Module):\n",
    "    '''Ce module d'attention est :\n",
    "    \n",
    "    - hiérarchique avec bi-GRU entre les deux niveaux d'attention\n",
    "    - globalement multi-hopé, où il est possible d'effectuer plusieurs passes pour accumuler de l'information\n",
    "    '''\n",
    "    def __init__(self, emb_dim, hidden_dim, query_dim,\n",
    "                 n_layers = 1,\n",
    "                 hops = 1,\n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 dropout = 0):\n",
    "        super(HAN, self).__init__()\n",
    "        \n",
    "        # dimensions\n",
    "        self.emb_dim = emb_dim\n",
    "        self.query_dim = query_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = self.query_dim if (self.query_dim > 0 and \\\n",
    "                                            (transf or (hops > 1 and query_dim != hidden_dim))) \\\n",
    "                                         else hidden_dim\n",
    "        self.hops = hops\n",
    "        self.share = share\n",
    "        \n",
    "        \n",
    "        # modules\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        # first attention module\n",
    "        if share : self.attn1 = nn.ModuleList([Attention(emb_dim, query_dim, dropout)] * hops)\n",
    "        else     : self.attn1 = nn.ModuleList([Attention(emb_dim, query_dim, dropout) for _ in range(hops)])\n",
    "            \n",
    "        # intermediate encoder module\n",
    "        self.bigru = RecurrentEncoder(emb_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        \n",
    "        # second attention module\n",
    "        if share : self.attn2 = nn.ModuleList([Attention(self.bigru.output_dim, query_dim, dropout)] * hops)\n",
    "        else     : self.attn2 = nn.ModuleList([Attention(self.bigru.output_dim, query_dim, dropout) for _ in range(hops)])\n",
    "            \n",
    "        # accumulation step\n",
    "        self.transf = nn.Linear(self.bigru.output_dim, self.output_dim, bias = False) if (transf or (self.hops > 1 and query_dim != self.bigru.output_dim)) else None\n",
    "        \n",
    "        \n",
    "    def singlePass(self, packed_embeddings, query, attn1, attn2): \n",
    "        # first attention\n",
    "        query1 = query.expand(packed_embeddings.size(0), \n",
    "                              packed_embeddings.size(1), \n",
    "                              query.size(2)) if query is not None else None\n",
    "        output, weights1 = attn1(packed_embeddings, query1) # size (dialogue_length, 1, emb_dim)\n",
    "        \n",
    "        # intermediate biGRU\n",
    "        output, _ = self.bigru(output.transpose(0, 1))      # size (1, dialogue_length, hidden_dim)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        # second attention\n",
    "        query2 = query.expand(output.size(0), \n",
    "                              output.size(1), \n",
    "                              query.size(2)) if query is not None else None\n",
    "        output, weights2 = attn2(output, query2)            # size (1, dialogue_length, hid_dim)\n",
    "        \n",
    "        # output decision vector\n",
    "        if self.transf is not None : output = self.transf(output) # size (1, 1, out_dim)\n",
    "        if query is not None       : output = output + query\n",
    "            \n",
    "        # return\n",
    "        return output, weights1, weights2\n",
    "        \n",
    "        \n",
    "    def forward(self, packed_embeddings, query = None):\n",
    "        weights1_list = []\n",
    "        weights2_list = []\n",
    "        \n",
    "        # perform attention loops\n",
    "        if packed_embeddings is not None :\n",
    "            for hop in range(self.hops) :\n",
    "                \n",
    "                # perform attention pass\n",
    "                query, weights1, weights2 = self.singlePass(packed_embeddings, query, self.attn1[hop], self.attn2[hop])\n",
    "                weights1_list.append(weights1)\n",
    "                weights2_list.append(weights2)\n",
    "                \n",
    "        # output decision vector\n",
    "        return query, weights1_list, weights2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.utils import HANViewerOnWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HANViewerOnWords(attn_words, attn_sentences, sentences, \n",
    "                     colors = 'Reds', n = 8) : \n",
    "    '''attn_words = [1D np.array]\n",
    "       attn_sentences = 1D np.array\n",
    "       sentences = [[str]]\n",
    "    '''\n",
    "    def generateColors(colors, n):\n",
    "        colors = plt.get_cmap(colors)\n",
    "        Triplets = []\n",
    "        for i in range(n) :\n",
    "            triplet = [int(j * 256) for j in colors(i/10)[:3]]\n",
    "            Triplets.append(triplet)\n",
    "        return Triplets\n",
    "    \n",
    "    def weight2color(weight, triplets):\n",
    "        n = len(triplets)\n",
    "        for i in range(n):\n",
    "            if weight >= i/n and weight <= (i+1)/n : \n",
    "                return triplets[i]\n",
    "            \n",
    "    def addColor(texte, RGB = (100,100,100)):\n",
    "        new_texte = '\\x1b[48;2;'  + str(RGB[0]) + \";\" + str(RGB[1]) + \";\" + str(RGB[2]) + \"m\"  + texte + \"\\x1b[0m\"\n",
    "        return new_texte\n",
    "    \n",
    "    # -- main --\n",
    "    Triplets = generateColors(colors, n)\n",
    "    Colored_text = ''\n",
    "    for i, s in enumerate(sentences) :\n",
    "        s_color = weight2color(attn_sentences[i], Triplets)\n",
    "        Colored_text += addColor('  ', s_color) + ' '\n",
    "        for j, w in enumerate(s) :\n",
    "            color = weight2color(attn_words[i][j], Triplets)\n",
    "            Colored_text += addColor(w, color) + ' '\n",
    "        Colored_text += '\\n' \n",
    "    print(Colored_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Text Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.models import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden1_dim = 100,\n",
    "                 hidden2_dim = 100,\n",
    "                 n1_layer = 1, \n",
    "                 n2_layer = 1,\n",
    "                 hops = 1, \n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 n_class = 2, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                ):\n",
    "        super(TextClassifier, self).__init__()\n",
    "\n",
    "        # embedding\n",
    "        self.bin_mode  = (n_class == 'binary')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(\n",
    "            emb_dim = self.word2vec.out_dim, \n",
    "            hid_dim = hidden1_dim, \n",
    "            n_layer = n1_layer, \n",
    "            dropout = dropout, \n",
    "            bidirectional = True)\n",
    "        self.query_dim = (self.context.out_dim if hops > 1 else 0)\n",
    "        self.attention = HAN(\n",
    "            emb_dim   = self.context.out_dim,\n",
    "            hid_dim   = hidden2_dim,\n",
    "            query_dim = self.query_dim,\n",
    "            n_layer   = n2_layer,\n",
    "            hops      = hops,\n",
    "            share     = share,\n",
    "            transf    = transf,\n",
    "            dropout   = dropout)\n",
    "        self.out = nn.Linear(self.attention.out_dim, (1 if self.bin_mode else n_class))\n",
    "        self.act = F.sigmoid if self.bin_mode else F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        if self.bin_mode : self.criterion = nn.BCEWithLogitsLoss(size_average = False)\n",
    "        else             : self.criterion = nn.NLLLoss(size_average = False, weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "\n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    # main method\n",
    "    def forward(self, text, \n",
    "                attention_method = None) :\n",
    "        '''classifies a sentence as string'''\n",
    "        # tokenize, embed and contextualize\n",
    "        sentences   = self.tokenizer(text)\n",
    "        embeddings  = [self.word2vec(words, self.device).squeeze(0) for words in sentences] # list of tensors of size (1, n_words, embedding_dim)\n",
    "        embeddings  = nn.utils.rnn.pad_sequence(embeddings, batch_first = True, padding_value = 0)  # size (n_sentences, n_words, embedding_dim)\n",
    "        hiddens, _  = self.context(embeddings, enforce_sorted = False) # size (n_sentences, n_words, embedding_dim)\n",
    "\n",
    "        #init query whether necessary\n",
    "        if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "        else                  : query = None\n",
    "\n",
    "        # compute attention\n",
    "        attended, w1, w2 = self.attention(hiddens, query)\n",
    "        if self.bin_mode : prediction = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        else             : prediction = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "\n",
    "        # display attention weights\n",
    "        if attention_method is not None :\n",
    "            attn_words     = [np.array(s.view(-1).data.cpu().numpy()) for s in w1[0]]\n",
    "            attn_sentences = np.array(w2[0].view(-1).data.cpu().numpy())\n",
    "            attention_method(attn_words, attn_sentences, sentences)\n",
    "        return prediction\n",
    "    \n",
    "    # load data\n",
    "    def generatePaddedTexts(self, texts) :\n",
    "        padded_data = []\n",
    "        for text, label in texts :\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in text]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            lengths = torch.tensor([len(p) for p in pack0])               # size = (text_length) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))     # size = (text_length, max_length)\n",
    "            pack1 = [label]\n",
    "            if self.bin_mode : pack1 = Variable(torch.FloatTensor(pack1)) # size = (1) \n",
    "            else             : pack1 = Variable(torch.LongTensor(pack1))  # size = (1) \n",
    "            padded_data.append([[pack0, lengths], pack1])\n",
    "        return padded_data\n",
    "    \n",
    "    # compute model perf\n",
    "    def compute_accuracy(self, texts) :\n",
    "        def compute_batch_accuracy(batch, target) :\n",
    "            torch.cuda.empty_cache()\n",
    "            # embed and contextualize\n",
    "            embeddings       = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _       = self.context(embeddings, lengths = batch[1].to(self.device), enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query)\n",
    "            # compute score\n",
    "            if self.bin_mode : \n",
    "                pred  = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "                score = (abs(target.item() - pred) < 0.5)\n",
    "            else : \n",
    "                pred  = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "                score = (target.item() == pred)\n",
    "            return score\n",
    "\n",
    "        # --- main ---\n",
    "        batches = self.generatePaddedTexts(texts)\n",
    "        score = 0\n",
    "        for batch, target in batches : score += compute_batch_accuracy(batch, target)\n",
    "        return score * 100 / len(texts)\n",
    "    \n",
    "    # fit model\n",
    "    def fit(self, batches, \n",
    "            iters = None, \n",
    "            epochs = None, \n",
    "            lr = 0.025, \n",
    "            random_state = 42,\n",
    "            print_every = 10, \n",
    "            compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            # embed and contextualize\n",
    "            embeddings       = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _       = self.context(embeddings, lengths = batch[1].to(self.device), enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query)\n",
    "            # compute log prob\n",
    "            if self.bin_mode : return self.out(attended).view(-1)\n",
    "            else             : return F.log_softmax(self.out(attended.squeeze(1)))\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            if self.bin_mode : return sum(torch.abs(targets - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "            else             : return sum([targets[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(targets.size(0))]) * 100 / targets.size(0)\n",
    "            \n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0])\n",
    "            targets = batch[1].to(self.device).view(-1)\n",
    "            loss    = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.item() / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505004"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = TextClassifier(device = torch.device(\"cpu\"),\n",
    "                            tokenizer = tokenize,\n",
    "                            word2vec = gensim_word2vec,\n",
    "                            hidden1_dim = 100,\n",
    "                            hidden2_dim = 100,\n",
    "                            n1_layer = 2,\n",
    "                            n2_layer = 1,\n",
    "                            hops = 1,\n",
    "                            share = True,\n",
    "                            n_class = 4, #'binary', \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.AdamW)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = classifier.generatePaddedTexts(labelled_sentences_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(batches[:30000], epochs = 1, lr = 0.0025, print_every = 1000)\n",
    "classifier.fit(batches[30000:60000], epochs = 1, lr = 0.001, print_every = 1000)\n",
    "classifier.fit(batches[60000:90000], epochs = 1, lr = 0.00025, print_every = 1000)\n",
    "classifier.fit(batches[90000:], epochs = 1, lr = 0.0001, print_every = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(classifier.state_dict(), path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier.pth')\n",
    "\n",
    "# load\n",
    "#classifier.load_state_dict(torch.load(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;252;138;106m  \u001b[0m \u001b[48;2;256;245;240mgreek\u001b[0m \u001b[48;2;256;245;240msprinters\u001b[0m \u001b[48;2;256;245;240mquit\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mend\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \n",
      "\u001b[48;2;252;171;143m  \u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;256;245;240mreuters\u001b[0m \u001b[48;2;256;245;240mgreece\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240ms\u001b[0m \u001b[48;2;256;245;240mtwo\u001b[0m \u001b[48;2;256;245;240mtop\u001b[0m \u001b[48;2;256;245;240mathletes\u001b[0m \u001b[48;2;256;245;240mhave\u001b[0m \u001b[48;2;256;245;240mpulled\u001b[0m \u001b[48;2;256;245;240mout\u001b[0m \u001b[48;2;256;245;240mof\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;256;245;240molympics\u001b[0m \u001b[48;2;256;245;240mand\u001b[0m \u001b[48;2;256;245;240mapologised\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgreek\u001b[0m \u001b[48;2;256;245;240mpeople\u001b[0m \u001b[48;2;256;245;240mfor\u001b[0m \u001b[48;2;256;245;240ma\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \u001b[48;2;256;245;240mover\u001b[0m \u001b[48;2;256;245;240mmissed\u001b[0m \u001b[48;2;256;245;240mdope\u001b[0m \u001b[48;2;256;245;240mtests\u001b[0m \u001b[48;2;256;245;240mthat\u001b[0m \u001b[48;2;256;245;240mhas\u001b[0m \u001b[48;2;256;245;240mtarnished\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240mreturn\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mtheir\u001b[0m \u001b[48;2;256;245;240mbirthplace\u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention heads = 1\n",
    "classifier.eval()\n",
    "text = ' . '.join([' '.join(s) for s in labelled_sentences_tst[157][0]])\n",
    "classifier(text, attention_method = HANViewerOnWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.0657894736842"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier.compute_accuracy(labelled_sentences_tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
