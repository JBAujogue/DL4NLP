{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "    <font color=orange>II - 1 </font>\n",
    "  Text Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. <font color=orange>**Text Classification**</font>\n",
    "\n",
    "2. Sequence to sequence\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "1. Abstractive Summarization\n",
    "\n",
    "2. Question Answering\n",
    "\n",
    "3. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | | |\n",
    "|------|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | [Open source models](#open_source_models) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "A top-quality Github repository discussing Hierarchical Attention Networks is found [here](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Text-Classification). <br>\n",
    "This repo doesn't feature temporal reccurence in attention provided by the present multi-hoped attention mechanism.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.5.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import gc\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_DL4NLP = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_DL4NLP + '\\\\lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le corpus est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\train.csv\", sep = ',', header = None, error_bad_lines = False)\n",
    "df_AGnews_tst = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\test.csv\" , sep = ',', header = None, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn.columns = ['index', 'title', 'description']\n",
    "df_AGnews_tst.columns = ['index', 'title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AGnews_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    return s\n",
    "\n",
    "def cleanSentence(s) :\n",
    "    s = s.lower()\n",
    "    s = s.replace('\\\\', ' ')\n",
    "    s = re.sub('[\\.!?]+ ', ' . ', s)\n",
    "    s = s.replace('%', ' % ')\n",
    "    s = re.sub(' [0-9]*\\.[0-9] ', ' FLOAT ', ' ' + s + ' ').strip()\n",
    "    s = re.sub(' [0-9,]*[0-9] ', ' INT ', ' ' + s + ' ').strip()\n",
    "    \n",
    "    for w in ['\"', \"'\", '”', '“', '/', '(', ')', '[', ']', '<', '>', ':', ','] : s = s.replace(w, '')\n",
    "    return s\n",
    "\n",
    "def trueWord(w) :\n",
    "    return len(w)>0 and re.sub('[^a-zA-Z0-9.,]', '', w) != ''\n",
    "\n",
    "def tokenize(s) :\n",
    "    s = normalizeString(s)\n",
    "    s = cleanSentence(s)\n",
    "    S = s.split('.')\n",
    "    S = [nltk.tokenize.word_tokenize(s) for s in S]\n",
    "    S = [[w for w in s if trueWord(w)] for s in S]\n",
    "    S = [s for s in S if s != []]\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce label by 1 to make is starts from 0\n",
    "labelled_sentences_trn = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_trn[\"title\"].values.tolist(), df_AGnews_trn[\"description\"].values.tolist(), df_AGnews_trn[\"index\"].values.tolist()) if tokenize(s1) != []]\n",
    "labelled_sentences_tst = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_tst[\"title\"].values.tolist(), df_AGnews_tst[\"description\"].values.tolist(), df_AGnews_tst[\"index\"].values.tolist()) if tokenize(s1) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "_Remark_ : The pre-trained Word2vec models are the same as those used in **Part I - 2 Sentence Classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2VecConnector(Word2Vec.load(get_tmpfile(path_to_DL4NLP + \"\\\\saves\\\\DL4NLP_I2_skipgram_gensim.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Attention Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from libDL4NLP.modules import Attention\n",
    "# from libDL4NLP.misc    import HighwayQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayQ(nn.Module):\n",
    "    def __init__(self, dim, \n",
    "                 query_dim = 0, \n",
    "                 dropout = 0,\n",
    "                 act = F.tanh):\n",
    "        super().__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.dim      = dim + query_dim\n",
    "        self.transf   = nn.Linear(self.dim, dim)\n",
    "        self.gate     = nn.Linear(self.dim, dim)\n",
    "        self.dropout  = nn.Dropout(p = dropout)\n",
    "        self.act      = act\n",
    "\n",
    "    def forward(self, vect, \n",
    "                query = None):\n",
    "        '''vect and (optional) query must be 3D tensors with same size along dim 0 and 1'''\n",
    "        if query is not None : merge = torch.cat((vect, query), dim = 2)\n",
    "        else                 : merge = vect\n",
    "        transf = self.act(self.transf(merge))\n",
    "        gate   = F.sigmoid(self.gate(merge))\n",
    "        vect   = gate * transf + (1 - gate) * vect\n",
    "        vect   = self.dropout(vect)\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim, \n",
    "                 dropout = 0, \n",
    "                 method = 'concat'):\n",
    "        '''method must be chosen among [dot, concat, general]'''\n",
    "        super().__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.method  = method\n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_dim = emb_dim\n",
    "        \n",
    "        # layers\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        if method == 'concat' : \n",
    "            self.key1 = HighwayQ(emb_dim, query_dim, dropout)\n",
    "            self.key2 = nn.Linear(emb_dim, 1, bias = False)\n",
    "        elif method == 'general' :\n",
    "            self.key = (HighwayQ(query_dim, 0, dropout) if query_dim == emb_dim else nn.Linear(query_dim, emb_dim, bias = False))\n",
    "        self.value   = HighwayQ(emb_dim, 0, dropout)\n",
    "        self.act     = F.softmax\n",
    "\n",
    "    def computeMask(self, lengths, emb_length) :\n",
    "        # see http://juditacs.github.io/2018/12/27/masked-attention.html\n",
    "        return torch.arange(emb_length).to(lengths.device)[None, :] < lengths[:, None]\n",
    "        \n",
    "    def forward(self, embeddings, query = None, \n",
    "                lengths = None):\n",
    "        '''embeddings       of size (batch_size, emb_length, emb_dim)\n",
    "           query (optional) of size (batch_size, 1, emb_dim)\n",
    "        '''\n",
    "        # compute attention weights\n",
    "        # dot method\n",
    "        if self.method == 'dot' :\n",
    "            query   = query.transpose(1, 2)        # size (batch_size, query_dim, 1)\n",
    "            weights = torch.bmm(embeddings, query) # size (batch_size, emb_length, 1)\n",
    "        # concat method\n",
    "        elif self.method == 'concat' :\n",
    "            query   = query.expand(embeddings.size(0), \n",
    "                                   embeddings.size(1), \n",
    "                                   query.size(2)) if query is not None else None\n",
    "            weights = self.key1(embeddings, query) # size (batch_size, emb_length, 1)\n",
    "            weights = self.key2(weights)           # size (batch_size, emb_length, 1)\n",
    "        # general method\n",
    "        elif self.method == 'general' :\n",
    "            query   = self.key(query)              # size (batch_size, 1, query_dim)\n",
    "            query   = query.transpose(1, 2)        # size (batch_size, query_dim, 1)\n",
    "            weights = torch.bmm(embeddings, query) # size (batch_size, emb_length, 1)\n",
    "        # mask attention over padded tokens\n",
    "        weights = weights.squeeze(2)               # size (batch_size, emb_length)\n",
    "        if lengths is not None :\n",
    "            mask = self.computeMask(lengths, weights.size(1))\n",
    "            weights[~mask] = float('-inf')     # size (batch_size, emb_length)\n",
    "        # compute weighted sum\n",
    "        weights = self.act(weights, dim = 1)       # size (batch_size, emb_length)\n",
    "        weights = weights.unsqueeze(1)             # size (batch_size, 1, emb_length)\n",
    "        values  = self.value(embeddings)           # size (batch_size, emb_length, emb_dim)\n",
    "        applied = torch.bmm(weights, values)       # size (batch_size, 1, emb_dim)\n",
    "        return (applied, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Multi-hoped Hierarchical Attention Module\n",
    "\n",
    "A combination of ideas originating from :\n",
    "\n",
    "- Hierarchical Attention : [Hierarchical Attention Networks for Document Classification (2016)](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)\n",
    "- Hoping mechanism : [End-To-End Memory Networks (2015)](https://arxiv.org/pdf/1503.08895.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAN(nn.Module):\n",
    "    '''Ce module d'attention est :\n",
    "    \n",
    "    - hiérarchique avec bi-GRU entre les deux niveaux d'attention\n",
    "    - globalement multi-hopé, où il est possible d'effectuer plusieurs passes pour accumuler de l'information\n",
    "    '''\n",
    "    def __init__(self, emb_dim, hid_dim, query_dim,\n",
    "                 method = 'concat',\n",
    "                 n_layer = 1,\n",
    "                 hops = 1,\n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 dropout = 0):\n",
    "        super(HAN, self).__init__()\n",
    "        \n",
    "        # dimensions\n",
    "        self.emb_dim = emb_dim\n",
    "        self.query_dim = query_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = self.query_dim if (self.query_dim > 0 and \\\n",
    "                                         (transf or (hops > 1 and query_dim != hid_dim))) \\\n",
    "                                      else hid_dim\n",
    "        self.hops = hops\n",
    "        self.share = share\n",
    "        \n",
    "        # modules\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        # first attention module\n",
    "        if share : self.attn1 = nn.ModuleList([Attention(emb_dim, query_dim, dropout)] * hops)\n",
    "        else     : self.attn1 = nn.ModuleList([Attention(emb_dim, query_dim, dropout) for _ in range(hops)])\n",
    "        # intermediate encoder module\n",
    "        self.bigru = RecurrentEncoder(emb_dim, hid_dim, n_layer, dropout, bidirectional = True)\n",
    "        # second attention module\n",
    "        if share : self.attn2 = nn.ModuleList([Attention(self.bigru.out_dim, query_dim, dropout, method = method)] * hops)\n",
    "        else     : self.attn2 = nn.ModuleList([Attention(self.bigru.out_dim, query_dim, dropout, method = method) for _ in range(hops)])\n",
    "        # accumulation step\n",
    "        self.transf = nn.Linear(self.bigru.out_dim, self.out_dim, bias = False) if (transf or (self.hops > 1 and query_dim != self.bigru.out_dim)) else None\n",
    "        \n",
    "        \n",
    "    def singlePass(self, packed_embeddings, query, attn1, attn2, lengths): \n",
    "        # first attention\n",
    "        output, weights1 = attn1(packed_embeddings, query, lengths) # size (dialogue_length, 1, emb_dim)\n",
    "        # intermediate biGRU\n",
    "        output, _ = self.bigru(output.transpose(0, 1))              # size (1, dialogue_length, hid_dim)\n",
    "        output = self.dropout(output)\n",
    "        # second attention\n",
    "        output, weights2 = attn2(output, query)                     # size (1, dialogue_length, hid_dim)\n",
    "        # output decision vector\n",
    "        if self.transf is not None : output = self.transf(output)   # size (1, 1, out_dim)\n",
    "        if query is not None       : output = output + query\n",
    "        return (output, weights1, weights2)\n",
    "        \n",
    "        \n",
    "    def forward(self, packed_embeddings, query = None, lengths = None):\n",
    "        weights1_list = []\n",
    "        weights2_list = []\n",
    "        # perform attention loops\n",
    "        if packed_embeddings is not None :\n",
    "            for hop in range(self.hops) :\n",
    "                # perform attention pass\n",
    "                query, weights1, weights2 = self.singlePass(\n",
    "                    packed_embeddings, \n",
    "                    query, \n",
    "                    self.attn1[hop], \n",
    "                    self.attn2[hop], \n",
    "                    lengths)\n",
    "                weights1_list.append(weights1)\n",
    "                weights2_list.append(weights2)\n",
    "        # output decision vector\n",
    "        return (query, weights1_list, weights2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.utils import HANViewerOnWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HANViewerOnWords(attn_words, attn_sentences, sentences, \n",
    "                     colors = 'Reds', n = 8) : \n",
    "    '''attn_words = [1D np.array]\n",
    "       attn_sentences = 1D np.array\n",
    "       sentences = [[str]]\n",
    "    '''\n",
    "    def generateColors(colors, n):\n",
    "        colors = plt.get_cmap(colors)\n",
    "        Triplets = []\n",
    "        for i in range(n) :\n",
    "            triplet = [int(j * 256) for j in colors(i/10)[:3]]\n",
    "            Triplets.append(triplet)\n",
    "        return Triplets\n",
    "    \n",
    "    def weight2color(weight, triplets):\n",
    "        n = len(triplets)\n",
    "        for i in range(n):\n",
    "            if weight >= i/n and weight <= (i+1)/n : \n",
    "                return triplets[i]\n",
    "            \n",
    "    def addColor(texte, RGB = (100,100,100)):\n",
    "        new_texte = '\\x1b[48;2;'  + str(RGB[0]) + \";\" + str(RGB[1]) + \";\" + str(RGB[2]) + \"m\"  + texte + \"\\x1b[0m\"\n",
    "        return new_texte\n",
    "    \n",
    "    # -- main --\n",
    "    Triplets = generateColors(colors, n)\n",
    "    Colored_text = ''\n",
    "    for i, s in enumerate(sentences) :\n",
    "        s_color = weight2color(attn_sentences[i], Triplets)\n",
    "        Colored_text += addColor('  ', s_color) + ' '\n",
    "        for j, w in enumerate(s) :\n",
    "            color = weight2color(attn_words[i][j], Triplets)\n",
    "            Colored_text += addColor(w, color) + ' '\n",
    "        Colored_text += '\\n' \n",
    "    print(Colored_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Text Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.models import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden1_dim = 100,\n",
    "                 hidden2_dim = 100,\n",
    "                 n1_layer = 1, \n",
    "                 n2_layer = 1,\n",
    "                 attention_method = 'concat',\n",
    "                 hops = 1, \n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 n_class = 2, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                ):\n",
    "        super(TextClassifier, self).__init__()\n",
    "\n",
    "        # embedding\n",
    "        self.bin_mode  = (n_class == 'binary')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(\n",
    "            emb_dim = self.word2vec.out_dim, \n",
    "            hid_dim = hidden1_dim, \n",
    "            n_layer = n1_layer, \n",
    "            dropout = dropout, \n",
    "            bidirectional = True)\n",
    "        self.query_dim = (self.context.out_dim if hops > 1 else 0)\n",
    "        self.attention = HAN(\n",
    "            emb_dim   = self.context.out_dim,\n",
    "            hid_dim   = hidden2_dim,\n",
    "            query_dim = self.query_dim,\n",
    "            n_layer   = n2_layer,\n",
    "            method    = attention_method,\n",
    "            hops      = hops,\n",
    "            share     = share,\n",
    "            transf    = transf,\n",
    "            dropout   = dropout)\n",
    "        self.out = nn.Linear(self.attention.out_dim, (1 if self.bin_mode else n_class))\n",
    "        self.act = F.sigmoid if self.bin_mode else F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        if self.bin_mode : self.criterion = nn.BCEWithLogitsLoss(size_average = False)\n",
    "        else             : self.criterion = nn.NLLLoss(size_average = False, weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "\n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    # main method\n",
    "    def forward(self, text, \n",
    "                attention_method = None) :\n",
    "        '''classifies a sentence as string'''\n",
    "        # tokenize, embed and contextualize\n",
    "        sentences   = self.tokenizer(text)\n",
    "        lengths     = torch.tensor([len(s) for s in sentences]).to(self.device)\n",
    "        embeddings  = [self.word2vec(words, self.device).squeeze(0) for words in sentences] # list of tensors of size (1, n_words, embedding_dim)\n",
    "        embeddings  = nn.utils.rnn.pad_sequence(embeddings, batch_first = True, padding_value = 0)  # size (n_sentences, n_words, embedding_dim)\n",
    "        hiddens, _  = self.context(embeddings, lengths, enforce_sorted = False) # size (n_sentences, n_words, embedding_dim)\n",
    "\n",
    "        #init query whether necessary\n",
    "        if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "        else                  : query = None\n",
    "\n",
    "        # compute attention\n",
    "        attended, w1, w2 = self.attention(hiddens, query, lengths)\n",
    "        if self.bin_mode : prediction = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        else             : prediction = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "\n",
    "        # display attention weights\n",
    "        if attention_method is not None :\n",
    "            attn_words     = [np.array(s.view(-1).data.cpu().numpy()) for s in w1[0]]\n",
    "            attn_sentences = np.array(w2[0].view(-1).data.cpu().numpy())\n",
    "            attention_method(attn_words, attn_sentences, sentences)\n",
    "        return prediction\n",
    "    \n",
    "    # load data\n",
    "    def generatePaddedTexts(self, texts) :\n",
    "        padded_data = []\n",
    "        for text, label in texts :\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in text]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            lengths = torch.tensor([len(p) for p in pack0])               # size = (text_length) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))     # size = (text_length, max_length)\n",
    "            pack1 = [label]\n",
    "            if self.bin_mode : pack1 = Variable(torch.FloatTensor(pack1)) # size = (1) \n",
    "            else             : pack1 = Variable(torch.LongTensor(pack1))  # size = (1) \n",
    "            padded_data.append([[pack0, lengths], pack1])\n",
    "        return padded_data\n",
    "    \n",
    "    # compute model perf\n",
    "    def compute_accuracy(self, texts) :\n",
    "        def compute_batch_accuracy(batch, target) :\n",
    "            torch.cuda.empty_cache()\n",
    "            # embed and contextualize\n",
    "            lengths    = batch[1].to(self.device)\n",
    "            embeddings = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _ = self.context(embeddings, lengths, enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query, lengths)\n",
    "            # compute score\n",
    "            if self.bin_mode : \n",
    "                pred  = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "                score = (abs(target.item() - pred) < 0.5)\n",
    "            else : \n",
    "                pred  = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "                score = (target.item() == pred)\n",
    "            return score\n",
    "\n",
    "        # --- main ---\n",
    "        batches = self.generatePaddedTexts(texts)\n",
    "        score = 0\n",
    "        for batch, target in batches : score += compute_batch_accuracy(batch, target)\n",
    "        return score * 100 / len(texts)\n",
    "    \n",
    "    # fit model\n",
    "    def fit(self, batches, \n",
    "            iters = None, \n",
    "            epochs = None, \n",
    "            lr = 0.025, \n",
    "            random_state = 42,\n",
    "            print_every = 10, \n",
    "            compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            # embed and contextualize\n",
    "            lengths    = batch[1].to(self.device)\n",
    "            embeddings = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _ = self.context(embeddings, lengths, enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query, lengths)\n",
    "            # compute log prob\n",
    "            if self.bin_mode : return self.out(attended).view(-1)\n",
    "            else             : return F.log_softmax(self.out(attended.squeeze(1)))\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            if self.bin_mode : return sum(torch.abs(targets - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "            else             : return sum([targets[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(targets.size(0))]) * 100 / targets.size(0)\n",
    "            \n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0])\n",
    "            targets = batch[1].to(self.device).view(-1)\n",
    "            loss    = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.item() / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505004"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = TextClassifier(device = device, #torch.device(\"cpu\"),\n",
    "                            tokenizer = tokenize,\n",
    "                            word2vec = gensim_word2vec,\n",
    "                            hidden1_dim = 100,\n",
    "                            hidden2_dim = 100,\n",
    "                            n1_layer = 2,\n",
    "                            n2_layer = 1,\n",
    "                            #attention_method = 'general',\n",
    "                            hops = 1,\n",
    "                            share = True,\n",
    "                            n_class = 4, #'binary', \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.AdamW)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = classifier.generatePaddedTexts(labelled_sentences_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1m 3s (- 30m 37s) (1000 3%) loss : 0.917  accuracy : 59.4 %\n",
      "2m 8s (- 30m 0s) (2000 6%) loss : 0.792  accuracy : 65.1 %\n",
      "3m 9s (- 28m 26s) (3000 10%) loss : 0.716  accuracy : 70.8 %\n",
      "4m 6s (- 26m 42s) (4000 13%) loss : 0.538  accuracy : 82.4 %\n",
      "5m 4s (- 25m 23s) (5000 16%) loss : 0.580  accuracy : 80.9 %\n",
      "6m 2s (- 24m 10s) (6000 20%) loss : 0.479  accuracy : 84.7 %\n",
      "7m 1s (- 23m 5s) (7000 23%) loss : 0.442  accuracy : 85.0 %\n",
      "8m 0s (- 22m 0s) (8000 26%) loss : 0.438  accuracy : 86.2 %\n",
      "8m 58s (- 20m 55s) (9000 30%) loss : 0.466  accuracy : 84.9 %\n",
      "9m 57s (- 19m 55s) (10000 33%) loss : 0.443  accuracy : 86.2 %\n",
      "10m 55s (- 18m 53s) (11000 36%) loss : 0.452  accuracy : 85.5 %\n",
      "11m 54s (- 17m 52s) (12000 40%) loss : 0.436  accuracy : 85.3 %\n",
      "12m 54s (- 16m 53s) (13000 43%) loss : 0.435  accuracy : 85.1 %\n",
      "13m 53s (- 15m 52s) (14000 46%) loss : 0.406  accuracy : 87.3 %\n",
      "14m 51s (- 14m 51s) (15000 50%) loss : 0.415  accuracy : 87.3 %\n",
      "15m 49s (- 13m 50s) (16000 53%) loss : 0.445  accuracy : 86.3 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-a393ccdbafde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0025\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m90000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00025\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m90000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-0cdf038631e6>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, batches, iters, epochs, lr, random_state, print_every, compute_accuracy)\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m                     \u001b[0mtot_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                     \u001b[0mtot_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-0cdf038631e6>\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(batch, optimizer, compute_accuracy)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mloss\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcompute_accuracy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier.fit(batches[:30000], epochs = 1, lr = 0.0025, print_every = 1000)\n",
    "classifier.fit(batches[30000:60000], epochs = 1, lr = 0.001, print_every = 1000)\n",
    "classifier.fit(batches[60000:90000], epochs = 1, lr = 0.00025, print_every = 1000)\n",
    "classifier.fit(batches[90000:], epochs = 1, lr = 0.0001, print_every = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(classifier.state_dict(), path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier.pth')\n",
    "\n",
    "# load\n",
    "#classifier.load_state_dict(torch.load(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;252;138;106m  \u001b[0m \u001b[48;2;242;68;50mgreek\u001b[0m \u001b[48;2;256;245;240msprinters\u001b[0m \u001b[48;2;256;245;240mquit\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mend\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \n",
      "\u001b[48;2;252;171;143m  \u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;255;229;217mreuters\u001b[0m \u001b[48;2;256;245;240mgreece\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240ms\u001b[0m \u001b[48;2;255;229;217mtwo\u001b[0m \u001b[48;2;255;229;217mtop\u001b[0m \u001b[48;2;256;245;240mathletes\u001b[0m \u001b[48;2;256;245;240mhave\u001b[0m \u001b[48;2;256;245;240mpulled\u001b[0m \u001b[48;2;256;245;240mout\u001b[0m \u001b[48;2;256;245;240mof\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;256;245;240molympics\u001b[0m \u001b[48;2;256;245;240mand\u001b[0m \u001b[48;2;256;245;240mapologised\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgreek\u001b[0m \u001b[48;2;256;245;240mpeople\u001b[0m \u001b[48;2;256;245;240mfor\u001b[0m \u001b[48;2;256;245;240ma\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \u001b[48;2;256;245;240mover\u001b[0m \u001b[48;2;256;245;240mmissed\u001b[0m \u001b[48;2;256;245;240mdope\u001b[0m \u001b[48;2;256;245;240mtests\u001b[0m \u001b[48;2;256;245;240mthat\u001b[0m \u001b[48;2;256;245;240mhas\u001b[0m \u001b[48;2;256;245;240mtarnished\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240mreturn\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mtheir\u001b[0m \u001b[48;2;256;245;240mbirthplace\u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention heads = 1\n",
    "classifier.eval()\n",
    "text = ' . '.join([' '.join(s) for s in labelled_sentences_tst[157][0]])\n",
    "classifier(text, attention_method = HANViewerOnWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incomplete training !\n",
    "classifier.eval()\n",
    "classifier.compute_accuracy(labelled_sentences_tst[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
