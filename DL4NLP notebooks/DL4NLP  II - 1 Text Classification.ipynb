{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "    <font color=orange>II - 1 </font>\n",
    "  Text Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. <font color=orange>**Text Classification**</font>\n",
    "\n",
    "2. Sequence to sequence\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "1. Abstractive Summarization\n",
    "\n",
    "2. Question Answering\n",
    "\n",
    "3. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | | |\n",
    "|------|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | [Open source models](#open_source_models) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "A top-quality Github repository discussing Hierarchical Attention Networks is found [here](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Text-Classification). <br>\n",
    "This repo doesn't feature temporal reccurence in attention provided by the present multi-hoped attention mechanism.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.4.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import gc\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_DL4NLP = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_DL4NLP + '\\\\lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le corpus est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\train.csv\", sep = ',', header = None, error_bad_lines = False)\n",
    "df_AGnews_tst = pd.read_csv(path_to_DL4NLP + \"\\\\data\\\\AG News\\\\test.csv\" , sep = ',', header = None, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AGnews_trn.columns = ['index', 'title', 'description']\n",
    "df_AGnews_tst.columns = ['index', 'title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AGnews_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    return s\n",
    "\n",
    "def cleanSentence(s) :\n",
    "    s = s.lower()\n",
    "    s = s.replace('\\\\', ' ')\n",
    "    s = re.sub('[\\.!?]+ ', ' . ', s)\n",
    "    s = s.replace('%', ' % ')\n",
    "    s = re.sub(' [0-9]*\\.[0-9] ', ' FLOAT ', ' ' + s + ' ').strip()\n",
    "    s = re.sub(' [0-9,]*[0-9] ', ' INT ', ' ' + s + ' ').strip()\n",
    "    \n",
    "    for w in ['\"', \"'\", '”', '“', '/', '(', ')', '[', ']', '<', '>', ':', ','] : s = s.replace(w, '')\n",
    "    return s\n",
    "\n",
    "def trueWord(w) :\n",
    "    return len(w)>0 and re.sub('[^a-zA-Z0-9.,]', '', w) != ''\n",
    "\n",
    "def tokenize(s) :\n",
    "    s = normalizeString(s)\n",
    "    s = cleanSentence(s)\n",
    "    S = s.split('.')\n",
    "    S = [nltk.tokenize.word_tokenize(s) for s in S]\n",
    "    S = [[w for w in s if trueWord(w)] for s in S]\n",
    "    S = [s for s in S if s != []]\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce label by 1 to make is starts from 0\n",
    "labelled_sentences_trn = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_trn[\"title\"].values.tolist(), df_AGnews_trn[\"description\"].values.tolist(), df_AGnews_trn[\"index\"].values.tolist()) if tokenize(s1) != []]\n",
    "labelled_sentences_tst = [[tokenize(s1 + ' . ' + s2), l-1] for s1, s2, l in zip(df_AGnews_tst[\"title\"].values.tolist(), df_AGnews_tst[\"description\"].values.tolist(), df_AGnews_tst[\"index\"].values.tolist()) if tokenize(s1) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "_Remark_ : The pre-trained Word2vec models are the same as those used in **Part I - 2 Sentence Classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2VecConnector(Word2Vec.load(get_tmpfile(path_to_DL4NLP + \"\\\\saves\\\\DL4NLP_I2_skipgram_gensim.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Attention Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from libDL4NLP.modules import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dim, query_dim, \n",
    "                 dropout = 0, \n",
    "                 method = 'concat' \n",
    "                ): \n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.method        = method\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim    = embedding_dim\n",
    "        \n",
    "        # parameters\n",
    "        self.dropout    = nn.Dropout(p = dropout)\n",
    "        self.attn_layer = nn.Linear(embedding_dim + query_dim, embedding_dim)\n",
    "        self.attn_v     = nn.Linear(embedding_dim, 1, bias = False)\n",
    "        self.act        = F.softmax\n",
    "        \n",
    "    def forward(self, embeddings, query):\n",
    "        '''embeddings       of size (batch_size, input_length, embedding_dim)\n",
    "           query (optional) of size (batch_size, 1, embedding_dim)\n",
    "        '''\n",
    "        # query is optional for this method\n",
    "        if self.method == 'concat' :\n",
    "            weights = torch.cat((query, embeddings), 2) if query is not None else embeddings\n",
    "            weights = self.attn_layer(weights).tanh()          # size (batch_size, input_length, embedding_dim)\n",
    "            weights = self.act(self.attn_v(weights), dim = 1)  # size (batch_size, input_length, 1)\n",
    "            weights = torch.transpose(weights, 1, 2)           # size (batch_size, 1, input_length)\n",
    "            \n",
    "        # query is necessary for this method\n",
    "        elif self.method == 'dot' :\n",
    "            query   = torch.transpose(query, 1, 2)             # size (batch_size, query_dim, 1)\n",
    "            weights = torch.bmm(embeddings, query)             # size (batch_size, input_length, 1)\n",
    "            weights = self.act(weights, dim = 1)               # size (batch_size, input_length, 1)\n",
    "            weights = torch.transpose(weights, 1, 2)           # size (batch_size, 1, input_length)\n",
    "        applied = self.dropout(torch.bmm(weights, embeddings)) # size (batch_size, 1, embedding_dim)\n",
    "        return applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Multi-hoped Hierarchical Attention Module\n",
    "\n",
    "A combination of ideas originating from :\n",
    "\n",
    "- Hierarchical Attention : [Hierarchical Attention Networks for Document Classification (2016)](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)\n",
    "- Hoping mechanism : [End-To-End Memory Networks (2015)](https://arxiv.org/pdf/1503.08895.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAN(nn.Module):\n",
    "    '''Ce module d'attention est :\n",
    "    \n",
    "    - hiérarchique avec bi-GRU entre les deux niveaux d'attention\n",
    "    - globalement multi-hopé, où il est possible d'effectuer plusieurs passes pour accumuler de l'information\n",
    "    '''\n",
    "    def __init__(self, embedding_dim, hidden_dim, query_dim,\n",
    "                 n_layers = 1,\n",
    "                 hops = 1,\n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 dropout = 0\n",
    "                ):\n",
    "        super(HAN, self).__init__()\n",
    "        \n",
    "        # dimensions\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.query_dim = query_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = self.query_dim if (self.query_dim > 0 and (transf or (hops > 1 and query_dim != hidden_dim))) else hidden_dim\n",
    "        self.hops = hops\n",
    "        self.share = share\n",
    "        \n",
    "        # modules\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        # first attention module\n",
    "        if share : self.attn1 = nn.ModuleList([Attention(embedding_dim, query_dim, dropout)] * hops)\n",
    "        else     : self.attn1 = nn.ModuleList([Attention(embedding_dim, query_dim, dropout) for _ in range(hops)])\n",
    "        # intermediate encoder module\n",
    "        self.bigru = RecurrentEncoder(embedding_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        # second attention module\n",
    "        if share : self.attn2 = nn.ModuleList([Attention(self.bigru.output_dim, query_dim, dropout)] * hops)\n",
    "        else     : self.attn2 = nn.ModuleList([Attention(self.bigru.output_dim, query_dim, dropout) for _ in range(hops)])\n",
    "        # accumulation step\n",
    "        self.transf = nn.Linear(self.bigru.output_dim, self.output_dim, bias = False) \\\n",
    "                      if (transf or (self.hops > 1 and query_dim != self.bigru.output_dim)) else None\n",
    "        \n",
    "    def singlePass(self, packed_embeddings, query, attn1, attn2): \n",
    "        # first attention\n",
    "        query1 = query.expand(packed_embeddings.size(0), \n",
    "                              packed_embeddings.size(1), \n",
    "                              query.size(2)) if query is not None else None\n",
    "        output, weights1 = attn1(packed_embeddings, query1) # size (dialogue_length, 1, embedding_dim)\n",
    "        # intermediate biGRU\n",
    "        output, _ = self.bigru(output.transpose(0, 1))      # size (1, dialogue_length, hidden_dim)\n",
    "        output = self.dropout(output)\n",
    "        # second attention\n",
    "        query2 = query.expand(output.size(0), \n",
    "                              output.size(1), \n",
    "                              query.size(2)) if query is not None else None\n",
    "        output, weights2 = attn2(output, query2)            # size (1, dialogue_length, hidden_dim)\n",
    "        # output decision vector\n",
    "        if self.transf is not None : output = self.transf(output) # size (1, 1, output_dim)\n",
    "        if query is not None       : output = output + query\n",
    "        # return\n",
    "        return output, weights1, weights2\n",
    "        \n",
    "    def forward(self, packed_embeddings, query = None):\n",
    "        weights1_list = []\n",
    "        weights2_list = []\n",
    "        # perform attention loops\n",
    "        if packed_embeddings is not None :\n",
    "            for hop in range(self.hops) :\n",
    "                # perform attention pass\n",
    "                query, weights1, weights2 = self.singlePass(packed_embeddings, query, self.attn1[hop], self.attn2[hop])\n",
    "                weights1_list.append(weights1)\n",
    "                weights2_list.append(weights2)\n",
    "        # output decision vector\n",
    "        return query, weights1_list, weights2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.utils import HANViewerOnWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HANViewerOnWords(attn_words, attn_sentences, sentences, \n",
    "                     colors = 'Reds', n = 8) : \n",
    "    '''attn_words = [1D np.array]\n",
    "       attn_sentences = 1D np.array\n",
    "       sentences = [[str]]\n",
    "    '''\n",
    "    def generateColors(colors, n):\n",
    "        colors = plt.get_cmap(colors)\n",
    "        Triplets = []\n",
    "        for i in range(n) :\n",
    "            triplet = [int(j * 256) for j in colors(i/10)[:3]]\n",
    "            Triplets.append(triplet)\n",
    "        return Triplets\n",
    "    \n",
    "    def weight2color(weight, triplets):\n",
    "        n = len(triplets)\n",
    "        for i in range(n):\n",
    "            if weight >= i/n and weight <= (i+1)/n : \n",
    "                return triplets[i]\n",
    "            \n",
    "    def addColor(texte, RGB = (100,100,100)):\n",
    "        new_texte = '\\x1b[48;2;'  + str(RGB[0]) + \";\" + str(RGB[1]) + \";\" + str(RGB[2]) + \"m\"  + texte + \"\\x1b[0m\"\n",
    "        return new_texte\n",
    "    \n",
    "    # -- main --\n",
    "    Triplets = generateColors(colors, n)\n",
    "    Colored_text = ''\n",
    "    for i, s in enumerate(sentences) :\n",
    "        s_color = weight2color(attn_sentences[i], Triplets)\n",
    "        Colored_text += addColor('  ', s_color) + ' '\n",
    "        for j, w in enumerate(s) :\n",
    "            color = weight2color(attn_words[i][j], Triplets)\n",
    "            Colored_text += addColor(w, color) + ' '\n",
    "        Colored_text += '\\n' \n",
    "    print(Colored_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Text Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.models import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden1_dim = 100,\n",
    "                 hidden2_dim = 100,\n",
    "                 n1_layers = 1, \n",
    "                 n2_layers = 1,\n",
    "                 hops = 1, \n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 n_class = 2, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                ):\n",
    "        super(TextClassifier, self).__init__()\n",
    "\n",
    "        # embedding\n",
    "        self.bin_mode  = (n_class == 'binary')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(self.word2vec.output_dim, \n",
    "                                          hidden1_dim, \n",
    "                                          n1_layers, \n",
    "                                          dropout, \n",
    "                                          bidirectional = True)\n",
    "        self.query_dim = (self.context.output_dim if hops > 1 else 0)\n",
    "        self.attention = HAN(embedding_dim = self.context.output_dim,\n",
    "                             hidden_dim = hidden2_dim,\n",
    "                             query_dim = self.query_dim,\n",
    "                             n_layers = n2_layers,\n",
    "                             hops = hops,\n",
    "                             share = share,\n",
    "                             transf = transf,\n",
    "                             dropout = dropout)\n",
    "        self.out       = nn.Linear(self.attention.output_dim, (1 if self.bin_mode else n_class))\n",
    "        self.act       = F.sigmoid if self.bin_mode else F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        if self.bin_mode : self.criterion = nn.BCEWithLogitsLoss(size_average = False)\n",
    "        else             : self.criterion = nn.NLLLoss(size_average = False, weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "\n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    # main method\n",
    "    def forward(self, text, attention_method = None) :\n",
    "        '''classifies a sentence as string'''\n",
    "        # tokenize, embed and contextualize\n",
    "        sentences        = self.tokenizer(text)\n",
    "        embeddings       = [self.word2vec(words, self.device).squeeze(0) for words in sentences] # list of tensors of size (1, n_words, embedding_dim)\n",
    "        embeddings       = nn.utils.rnn.pad_sequence(embeddings, batch_first = True, padding_value = 0)  # size (n_sentences, n_words, embedding_dim)\n",
    "        hiddens, _       = self.context(embeddings, enforce_sorted = False) # size (n_sentences, n_words, embedding_dim)\n",
    "        #init query whether necessary\n",
    "        if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "        else                  : query = None\n",
    "        # compute attention\n",
    "        attended, w1, w2 = self.attention(hiddens, query)\n",
    "        if self.bin_mode : prediction = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        else             : prediction = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "        # display attention weights\n",
    "        if attention_method is not None :\n",
    "            attn_words     = [np.array(s.view(-1).data.cpu().numpy()) for s in w1[0]]\n",
    "            attn_sentences = np.array(w2[0].view(-1).data.cpu().numpy())\n",
    "            attention_method(attn_words, attn_sentences, sentences)\n",
    "        return prediction\n",
    "    \n",
    "    # load data\n",
    "    def generatePaddedTexts(self, texts) :\n",
    "        padded_data = []\n",
    "        for text, label in texts :\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in text]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            lengths = torch.tensor([len(p) for p in pack0])               # size = (text_length) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))     # size = (text_length, max_length)\n",
    "            pack1 = [label]\n",
    "            if self.bin_mode : pack1 = Variable(torch.FloatTensor(pack1)) # size = (1) \n",
    "            else             : pack1 = Variable(torch.LongTensor(pack1))  # size = (1) \n",
    "            padded_data.append([[pack0, lengths], pack1])\n",
    "        return padded_data\n",
    "    \n",
    "    # compute model perf\n",
    "    def compute_accuracy(self, texts) :\n",
    "        def compute_batch_accuracy(batch, target) :\n",
    "            torch.cuda.empty_cache()\n",
    "            # embed and contextualize\n",
    "            embeddings       = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _       = self.context(embeddings, lengths = batch[1].to(self.device), enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query)\n",
    "            # compute score\n",
    "            if self.bin_mode : \n",
    "                pred  = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "                score = (abs(target.item() - pred) < 0.5)\n",
    "            else : \n",
    "                pred  = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "                score = (target.item() == pred)\n",
    "            return score\n",
    "\n",
    "        # --- main ---\n",
    "        batches = self.generatePaddedTexts(texts)\n",
    "        score = 0\n",
    "        for batch, target in batches : score += compute_batch_accuracy(batch, target)\n",
    "        return score * 100 / len(texts)\n",
    "    \n",
    "    # fit model\n",
    "    def fit(self, batches, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            # embed and contextualize\n",
    "            embeddings       = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _       = self.context(embeddings, lengths = batch[1].to(self.device), enforce_sorted = False)\n",
    "            #init query whether necessary\n",
    "            if self.query_dim > 0 : query = torch.zeros(1, 1, self.query_dim).to(self.device)\n",
    "            else                  : query = None\n",
    "            # compute attention\n",
    "            attended, w1, w2 = self.attention(hiddens, query)\n",
    "            # compute log prob\n",
    "            if self.bin_mode : return self.out(attended).view(-1)\n",
    "            else             : return F.log_softmax(self.out(attended.squeeze(1)))\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            if self.bin_mode : return sum(torch.abs(targets - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "            else             : return sum([targets[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(targets.size(0))]) * 100 / targets.size(0)\n",
    "            \n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0])\n",
    "            targets = batch[1].to(self.device).view(-1)\n",
    "            loss    = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.item() / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464404"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = TextClassifier(device = torch.device(\"cpu\"),\n",
    "                            tokenizer = tokenize,\n",
    "                            word2vec = gensim_word2vec,\n",
    "                            hidden1_dim = 100,\n",
    "                            hidden2_dim = 100,\n",
    "                            n1_layers = 2,\n",
    "                            n2_layers = 1,\n",
    "                            hops = 3,\n",
    "                            share = True,\n",
    "                            n_class = 4, #'binary', \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.AdamW)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = classifier.generatePaddedTexts(labelled_sentences_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 59s (- 48m 14s) (1000 2%) loss : 0.237  accuracy : 92.3 %\n",
      "1m 57s (- 46m 56s) (2000 4%) loss : 0.268  accuracy : 91.1 %\n",
      "2m 56s (- 46m 4s) (3000 6%) loss : 0.295  accuracy : 90.3 %\n",
      "3m 54s (- 45m 1s) (4000 8%) loss : 0.272  accuracy : 91.0 %\n",
      "4m 53s (- 44m 2s) (5000 10%) loss : 0.261  accuracy : 91.7 %\n",
      "5m 52s (- 43m 3s) (6000 12%) loss : 0.313  accuracy : 89.5 %\n",
      "6m 50s (- 42m 3s) (7000 14%) loss : 0.312  accuracy : 90.5 %\n",
      "7m 49s (- 41m 2s) (8000 16%) loss : 0.283  accuracy : 90.1 %\n",
      "8m 47s (- 40m 3s) (9000 18%) loss : 0.257  accuracy : 90.9 %\n",
      "9m 46s (- 39m 4s) (10000 20%) loss : 0.240  accuracy : 92.0 %\n",
      "10m 44s (- 38m 6s) (11000 22%) loss : 0.238  accuracy : 91.4 %\n",
      "11m 43s (- 37m 8s) (12000 24%) loss : 0.225  accuracy : 92.6 %\n",
      "12m 42s (- 36m 10s) (13000 26%) loss : 0.259  accuracy : 91.5 %\n",
      "13m 40s (- 35m 10s) (14000 28%) loss : 0.258  accuracy : 89.9 %\n",
      "14m 39s (- 34m 12s) (15000 30%) loss : 0.253  accuracy : 92.1 %\n",
      "15m 38s (- 33m 14s) (16000 32%) loss : 0.266  accuracy : 91.0 %\n",
      "16m 36s (- 32m 15s) (17000 34%) loss : 0.251  accuracy : 91.1 %\n",
      "17m 35s (- 31m 17s) (18000 36%) loss : 0.252  accuracy : 91.3 %\n",
      "18m 34s (- 30m 18s) (19000 38%) loss : 0.224  accuracy : 92.5 %\n",
      "19m 33s (- 29m 19s) (20000 40%) loss : 0.253  accuracy : 92.2 %\n",
      "20m 32s (- 28m 21s) (21000 42%) loss : 0.245  accuracy : 92.0 %\n",
      "21m 30s (- 27m 22s) (22000 44%) loss : 0.233  accuracy : 93.0 %\n",
      "22m 29s (- 26m 23s) (23000 46%) loss : 0.287  accuracy : 90.2 %\n",
      "23m 27s (- 25m 24s) (24000 48%) loss : 0.261  accuracy : 91.1 %\n",
      "24m 26s (- 24m 26s) (25000 50%) loss : 0.266  accuracy : 90.3 %\n",
      "25m 24s (- 23m 27s) (26000 52%) loss : 0.237  accuracy : 91.0 %\n",
      "26m 23s (- 22m 28s) (27000 54%) loss : 0.239  accuracy : 91.1 %\n",
      "27m 21s (- 21m 30s) (28000 56%) loss : 0.308  accuracy : 89.6 %\n",
      "28m 20s (- 20m 31s) (29000 57%) loss : 0.222  accuracy : 92.5 %\n",
      "29m 18s (- 19m 32s) (30000 60%) loss : 0.287  accuracy : 89.7 %\n",
      "30m 17s (- 18m 33s) (31000 62%) loss : 0.244  accuracy : 90.9 %\n",
      "31m 16s (- 17m 35s) (32000 64%) loss : 0.258  accuracy : 90.9 %\n",
      "32m 14s (- 16m 36s) (33000 66%) loss : 0.232  accuracy : 91.5 %\n",
      "33m 13s (- 15m 38s) (34000 68%) loss : 0.239  accuracy : 92.0 %\n",
      "34m 11s (- 14m 39s) (35000 70%) loss : 0.242  accuracy : 91.4 %\n",
      "35m 10s (- 13m 40s) (36000 72%) loss : 0.328  accuracy : 88.1 %\n",
      "36m 8s (- 12m 41s) (37000 74%) loss : 0.227  accuracy : 91.3 %\n",
      "37m 7s (- 11m 43s) (38000 76%) loss : 0.278  accuracy : 90.8 %\n",
      "38m 5s (- 10m 44s) (39000 78%) loss : 0.272  accuracy : 90.6 %\n",
      "39m 4s (- 9m 46s) (40000 80%) loss : 0.269  accuracy : 91.4 %\n",
      "40m 2s (- 8m 47s) (41000 82%) loss : 0.243  accuracy : 91.4 %\n",
      "41m 1s (- 7m 48s) (42000 84%) loss : 0.221  accuracy : 92.7 %\n",
      "41m 59s (- 6m 50s) (43000 86%) loss : 0.269  accuracy : 91.1 %\n",
      "42m 58s (- 5m 51s) (44000 88%) loss : 0.257  accuracy : 92.6 %\n",
      "43m 56s (- 4m 52s) (45000 90%) loss : 0.250  accuracy : 91.8 %\n",
      "44m 54s (- 3m 54s) (46000 92%) loss : 0.237  accuracy : 92.3 %\n",
      "45m 53s (- 2m 55s) (47000 94%) loss : 0.230  accuracy : 92.1 %\n",
      "46m 51s (- 1m 57s) (48000 96%) loss : 0.211  accuracy : 92.5 %\n",
      "47m 49s (- 0m 58s) (49000 98%) loss : 0.228  accuracy : 93.0 %\n",
      "48m 48s (- 0m 0s) (50000 100%) loss : 0.275  accuracy : 90.2 %\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(batches[:70000], epochs = 1, lr = 0.001, print_every = 1000)\n",
    "classifier.fit(batches[70000:], epochs = 1, lr = 0.00025, print_every = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(classifier.state_dict(), path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier_3hops.pth')\n",
    "\n",
    "# load\n",
    "#classifier.load_state_dict(torch.load(path_to_DL4NLP + '\\\\saves\\\\DL4NLP_II1_text_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;242;68;50m  \u001b[0m \u001b[48;2;256;245;240mgreek\u001b[0m \u001b[48;2;256;245;240msprinters\u001b[0m \u001b[48;2;256;245;240mquit\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mend\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \n",
      "\u001b[48;2;255;229;217m  \u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;256;245;240mreuters\u001b[0m \u001b[48;2;256;245;240mgreece\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240ms\u001b[0m \u001b[48;2;256;245;240mtwo\u001b[0m \u001b[48;2;256;245;240mtop\u001b[0m \u001b[48;2;256;245;240mathletes\u001b[0m \u001b[48;2;256;245;240mhave\u001b[0m \u001b[48;2;256;245;240mpulled\u001b[0m \u001b[48;2;256;245;240mout\u001b[0m \u001b[48;2;256;245;240mof\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mathens\u001b[0m \u001b[48;2;256;245;240molympics\u001b[0m \u001b[48;2;256;245;240mand\u001b[0m \u001b[48;2;256;245;240mapologised\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgreek\u001b[0m \u001b[48;2;256;245;240mpeople\u001b[0m \u001b[48;2;256;245;240mfor\u001b[0m \u001b[48;2;256;245;240ma\u001b[0m \u001b[48;2;256;245;240mscandal\u001b[0m \u001b[48;2;256;245;240mover\u001b[0m \u001b[48;2;256;245;240mmissed\u001b[0m \u001b[48;2;256;245;240mdope\u001b[0m \u001b[48;2;256;245;240mtests\u001b[0m \u001b[48;2;256;245;240mthat\u001b[0m \u001b[48;2;256;245;240mhas\u001b[0m \u001b[48;2;256;245;240mtarnished\u001b[0m \u001b[48;2;256;245;240mthe\u001b[0m \u001b[48;2;256;245;240mgames\u001b[0m \u001b[48;2;256;245;240mINT\u001b[0m \u001b[48;2;256;245;240mreturn\u001b[0m \u001b[48;2;256;245;240mto\u001b[0m \u001b[48;2;256;245;240mtheir\u001b[0m \u001b[48;2;256;245;240mbirthplace\u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention heads = 1\n",
    "classifier.eval()\n",
    "text = ' . '.join([' '.join(s) for s in labelled_sentences_tst[157][0]])\n",
    "classifier(text, attention_method = HANViewerOnWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.36842105263158"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier.compute_accuracy(labelled_sentences_tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
