{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 1 Word Embedding\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  Jean-baptiste Aujogue\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "1. <font color=red>**Word Embedding**</font>\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Extractive Summarization\n",
    "    - Sentiment Analysis\n",
    "    - Text segmentation\n",
    "\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sentence tagging\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Part-of-speech Tagging\n",
    "    - Named Entity Recognition\n",
    "    - Automatic Value Extraction\n",
    "    \n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The global purpose of Word Embedding is to map a word, as raw string, to a dense vector. Three approaches are commonly followed for such task :\n",
    "\n",
    "| Level |  | |\n",
    "|------|------|------|\n",
    "| **Word** | [I.1 Custom model](#word_level_custom) | [I.2 Gensim Model](#gensim) |\n",
    "| **Subword** | [II.1 FastText model](#fastText) |  |\n",
    "| **Character** |  |  |\n",
    "\n",
    "\n",
    "<br>\n",
    "Visualization with TensorBoard : https://www.tensorflow.org/guide/embedding (TODO)\n",
    "\n",
    "# Training objectives\n",
    "\n",
    "#### CBOW training objective\n",
    "\n",
    "Cette méthode de vectorisation est introduite dans \\cite{mikolov2013distributed, mikolov2013efficient}, et consiste à construire pour un vocabulaire de mots une table de vectorisation $T$ contenant un vecteur par mot. La spécificité de cette méthode est que cette vectorisation est faite de façon à pouvoir prédire chaque mot à partir de son contexte. La construction de cette table $T$ passe par la création d'un réseau de neurones, qui sert de modèle pour l'estimation de la probabilité de prédiction d'un mot $w_t$ d'après son contexte $c = w_{t-N}, \\, ... \\, , w_{t-1}$, $w_{t+1}, \\, ... \\, , w_{t+N}$. La table $T$ intégrée au modèle sera optimisée lorsque ce modèle sera entrainé de façon à ce qu'un mot $w_t$ maximise la vraisemblance de la probabilité $P(. \\, | \\, c)$ fournie par le modèle. \n",
    "\n",
    "Le réseau de neurones de décrit de la façon suivante :\n",
    "\n",
    "![cbow](figs/CBOW.png)\n",
    "\n",
    "Un contexte $c = w_{t-N}, \\, ... \\, , w_{t-1}$, $w_{t+1}, \\, ... \\, , w_{t+N}$ est vectorisé via une table $T$ fournissant un ensemble de vecteurs denses (typiquement de dimension comprise entre 50 et 300) $T(w_{t-N}), \\, ... \\, , T(w_{t-1})$, $T(w_{t+1}), \\, ... \\, , T(w_{t+N})$. Chaque vecteur est ensuite transformé via une transformation affine, dont les vecteurs résultants sont superposés en un unique vecteur\n",
    "\n",
    "\\begin{align*}\n",
    "v_c = \\sum _{i = - N}^N M_i T(w_{t+i}) + b_i\n",
    "\\end{align*}\n",
    "\n",
    "Le vecteur $v_c$ est de dimension typiquement égale à la dimension de la vectorisation de mots. Une autre table $T'$ est utilisée pour une nouvelle vectorisation du vocabulaire, de sorte que le mot $w_{t}$ soit transformé en un vecteur $T'(w_{t})$ par cette table, et soit proposé en position $t$ avec probabilité\n",
    "\n",
    "\\begin{align*}\n",
    "P(w_{t} \\, | \\, c\\,) = \\frac{\\exp\\left( T'(w_{t}) \\cdot v_c \\right) }{\\displaystyle \\sum _{w \\in \\mathcal{V}} \\exp\\left(   T'(w) \\cdot v_c \n",
    "\\right) }\n",
    "\\end{align*}\n",
    "\n",
    "Ici $\\cdot$ désigne le produit scalaire entre vecteurs. L'optimisation de ce modèle permet d'ajuster la table $T$ afin que les vecteurs de mots portent suffisamment d'information pour reformer un mot à partir du contexte.\n",
    "\n",
    "\n",
    "#### Skip-Gram training objective\n",
    "\n",
    "\n",
    "Cette méthode de vectorisation est introduite dans \\cite{mikolov2013distributed, mikolov2013efficient} comme version mirroir au Continuous Bag Of Words, et consiste là encore à construire pour un vocabulaire de mots une table de vectorisation $T$ contenant un vecteur par mot. La spécificité de cette méthode est que cette vectorisation est faite non pas de façon prédire un mot central $w$ à partir d'un contexte $c $ comme pour CBOW, mais plutôt de prédire le contexte $c $ à partir du mot central $w$. La construction de cette table $T$ passe par la création d'un réseau de neurones servant de modèle pour l'estimation de la probabilité de prédiction d'un contexte $c = w_{t-N}, \\, ... \\, , w_{t-1}$, $w_{t+1}, \\, ... \\, , w_{t+N}$ à partir d'un mot central $w_t$. La table $T$ intégrée au modèle sera optimisée lorsque ce modèle sera entrainé de façon à ce que le contexte  $ c $ maximise la vraisemblance de la probabilité $P( . \\, | \\, w_t)$ fournie par le modèle.\n",
    "\n",
    "\n",
    "Une implémentation de ce modèle est la suivante : \n",
    "\n",
    "\n",
    "![skipgram](figs/Skipgram.png)\n",
    "\n",
    "\n",
    "Un mot courant $w_t$ est vectorisé par une table $T$ fournissant un vecteur dense (typiquement de dimension comprise entre 50 et 300) $T(w_t)$. Ce vecteur est alors transformé en un ensemble de $2N$ vecteurs\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma (M_{i} T(w_t) + b_{i}) \\qquad \\qquad i =-N,\\, ...\\, , -1, 1, \\, ...\\, , N\n",
    "\\end{align*}\n",
    "\n",
    "où $N$ désigne la taille de la fenêtre retenue, d'une dimension typiquement égale à la dimension de la vectorisation de mots, et $\\sigma$ une fonction non linéaire (typiquement la _Rectified Linear Unit_ $\\sigma (x) = max (0, x)$). Une autre table $T'$ est utilisée pour une nouvelle vectorisation du vocabulaire, de sorte que chaque mot $w_{t+i}$, transformé en un vecteur $T'(w_{t+i})$ par cette table, soit proposé en position $t+i$ avec probabilité\n",
    "\n",
    "\\begin{align*}\n",
    "P( w_{t+i} | \\, w_t) = \\frac{\\exp\\left(  T'(w_{t+i}) ^\\perp \\sigma \\left( M_i T(w_t) + b_{i}\\right) \\right) }{\\displaystyle \\sum _{w \\in \\mathcal{V}} \\exp\\left(   T'(w) ^\\perp \\sigma \\left( M_i T(w_t) + b_i\\right) \\right) }\n",
    "\\end{align*}\n",
    "\n",
    "On modélise alors la probabilité qu'un ensemble de mots $c = w_{t-N}, \\, ... \\, , w_{t-1}$, $w_{t+1}, \\, ... \\, , w_{t+N}$ soit le contexte d'un mot $w_t$ par le produit\n",
    "\n",
    "\\begin{align*}\n",
    " P( c\\, | \\, w_t) = \\prod _{i = -N}^N P( w_{t+i}\\, | \\, w_t)\n",
    "\\end{align*}\n",
    "\n",
    "Ce modèle de probabilité du contexte d'un mot est naif au sens où les mots de contextes sont considérés comme indépendants deux à deux dès lors que le mot central est connu. Cette approximation rend cependant le calcul d'optimisation beaucoup plus court.\n",
    "\n",
    "\n",
    "\n",
    "L'optimisation de ce modèle permet d'ajuster la table $T$ afin que les vecteurs de mots portent suffisamment d'information pour reformer l'intégralité du contexte à partir de ce seul mot. La vectorisation Skip-Gram est typiquement plus performante que CBOW, car la table $T$ subit plus de contrainte dans son optimisation, et puisque le vecteur d'un mot est obtenu de façon à pouvoir prédire l'utilisation réelle du mot, ici donnée par son contexte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "[Back to top](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 0.4.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(path_to_NLP + '\\\\chatNLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus et donc une fois importé sous le forme : [[str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence): # -------------------------  str\n",
    "    sw = ['']\n",
    "    #sw += nltk.corpus.stopwords.words('english')\n",
    "    #sw += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    def normalizeString(s):\n",
    "        '''Remove rare symbols from a string'''\n",
    "        s = unicodeToAscii(s.lower().strip()) # \n",
    "        #s = re.sub(r\"[^a-zA-Z\\.\\(\\)\\[\\]]+\", r\" \", s)  # 'r' before a string is for 'raw' # ?&\\%\\_\\- removed # set('''.,:;()*#&-_%!?/\\'\")''')\n",
    "        return s\n",
    "\n",
    "    def wordTokenizerFunction():\n",
    "        # base version\n",
    "        function = lambda sentence : sentence.strip().split()\n",
    "\n",
    "        # nltk version\n",
    "        #function = word_tokenize    \n",
    "        return function\n",
    "\n",
    "    # 1 - caractères spéciaux\n",
    "    def clean_sentence_punct(text): # --------------  str\n",
    "        text = normalizeString(text)\n",
    "        # suppression de la dernière ponctuation\n",
    "        if (len(text) > 0 and text[-1] in ['.', ',', ';', ':', '!', '?']) : text = text[:-1]\n",
    "\n",
    "        text = text.replace(r'(', r' ( ')\n",
    "        text = text.replace(r')', r' ) ')\n",
    "        text = text.replace(r'[', r' [ ')\n",
    "        text = text.replace(r']', r' ] ')\n",
    "        text = text.replace(r'<', r' < ')\n",
    "        text = text.replace(r'>', r' > ')\n",
    "\n",
    "        text = text.replace(r':', r' : ')\n",
    "        text = text.replace(r';', r' ; ')\n",
    "        for i in range(5) :\n",
    "            text = re.sub('(?P<val1>[0-9])\\.(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "            text = re.sub('(?P<val1>[0-9]),(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "        text = text.replace(r',', ' , ')\n",
    "        text = text.replace(r'.', ' . ')\n",
    "        for i in range(5) : text = re.sub('(?P<val1>[p0-9])__-__(?P<val2>[p0-9])', '\\g<val1>.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. p \\. (?P<val2>[0-9])', '\\g<val1>.p.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. s \\. (?P<val2>[0-9])', '\\g<val1>.s.\\g<val2>', text)\n",
    "\n",
    "        text = text.replace(r'\"', r' \" ')\n",
    "        text = text.replace(r'’', r\" ' \")\n",
    "        text = text.replace(r'”', r' \" ')\n",
    "        text = text.replace(r'“', r' \" ')\n",
    "        text = text.replace(r'/', r' / ')\n",
    "\n",
    "        text = re.sub('(…)+', ' … ', text)\n",
    "        text = text.replace('≤', ' ≤ ')          \n",
    "        text = text.replace('≥', ' ≥ ')\n",
    "        text = text.replace('°c', ' °c ')\n",
    "        text = text.replace('°C', ' °c ')\n",
    "        text = text.replace('ºc', ' °c ')\n",
    "        text = text.replace('n°', 'n° ')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('*', ' * ')\n",
    "        text = text.replace('+', ' + ')\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('_', ' ')\n",
    "        text = text.replace('®', ' ')\n",
    "        text = text.replace('™', ' ')\n",
    "        text = text.replace('±', ' ± ')\n",
    "        text = text.replace('÷', ' ÷ ')\n",
    "        text = text.replace('–', ' - ')\n",
    "        text = text.replace('μg', ' µg')\n",
    "        text = text.replace('µg', ' µg')\n",
    "        text = text.replace('µl', ' µl')\n",
    "        text = text.replace('μl', ' µl')\n",
    "        text = text.replace('µm', ' µm')\n",
    "        text = text.replace('μm', ' µm')\n",
    "        text = text.replace('ppm', ' ppm')\n",
    "        text = re.sub('(?P<val1>[0-9])mm', '\\g<val1> mm', text)\n",
    "        text = re.sub('(?P<val1>[0-9])g', '\\g<val1> g', text)\n",
    "        text = text.replace('nm', ' nm')\n",
    "\n",
    "        text = re.sub('fa(?P<val1>[0-9])', 'fa \\g<val1>', text)\n",
    "        text = re.sub('g(?P<val1>[0-9])', 'g \\g<val1>', text)\n",
    "        text = re.sub('n(?P<val1>[0-9])', 'n \\g<val1>', text)\n",
    "        text = re.sub('p(?P<val1>[0-9])', 'p \\g<val1>', text)\n",
    "        text = re.sub('q_(?P<val1>[0-9])', 'q_ \\g<val1>', text)\n",
    "        text = re.sub('u(?P<val1>[0-9])', 'u \\g<val1>', text)\n",
    "        text = re.sub('ud(?P<val1>[0-9])', 'ud \\g<val1>', text)\n",
    "        text = re.sub('ui(?P<val1>[0-9])', 'ui \\g<val1>', text)\n",
    "\n",
    "        text = text.replace('=', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace(r' , ', ' ')\n",
    "        text = text.replace(r' . ', ' ')\n",
    "\n",
    "        text = re.sub('(?P<val>[0-9])ml', '\\g<val> ml', text)\n",
    "        text = re.sub('(?P<val>[0-9])mg', '\\g<val> mg', text)\n",
    "\n",
    "        for i in range(5) : text = re.sub('( [0-9]+ )', ' ', text)\n",
    "        #text = re.sub('cochran(\\S)*', 'cochran ', text)\n",
    "        return text\n",
    "\n",
    "    # 3 - split des mots\n",
    "    def wordSplit(sentence, tokenizeur): # ------------- [str]\n",
    "        return tokenizeur(sentence)\n",
    "\n",
    "    # 4 - mise en minuscule et enlèvement des stopwords\n",
    "    def stopwordsRemoval(sentence, sw): # ------------- [[str]]\n",
    "        return [word for word in sentence if word not in sw]\n",
    "\n",
    "    # 6 - correction des mots\n",
    "    def correction(text):\n",
    "        def correct(word):\n",
    "            return spelling.suggest(word)[0]\n",
    "        list_of_list_of_words = [[correct(word) for word in sentence] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    # 7 - stemming\n",
    "    def stemming(text): # ------------------------- [[str]]\n",
    "        list_of_list_of_words = [[PorterStemmer().stem(word) for word in sentence if word not in sw] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "\n",
    "    tokenizeur = wordTokenizerFunction()\n",
    "    sentence = clean_sentence_punct(str(sentence))\n",
    "    sentence = wordSplit(sentence, tokenizeur)\n",
    "    sentence = stopwordsRemoval(sentence, sw)\n",
    "    #text = correction(text)\n",
    "    #text = stemming(text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def importSheet(file_name) :\n",
    "    def cleanDatabase(db):\n",
    "        words = []\n",
    "        title = ''\n",
    "        for pair in db :\n",
    "            if pair[0] != title :\n",
    "                words += cleanSentence(pair[0]) #[str]\n",
    "                title  = pair[0]                # str\n",
    "            words += cleanSentence(pair[1])     #[str]\n",
    "        return words\n",
    "\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    db = [el[1: 3] for el in db if el[-1] in [0,1, 10]]\n",
    "    words = cleanDatabase(db)\n",
    "    return words\n",
    "\n",
    "\n",
    "def importCorpus(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus.append(importSheet(file_name))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = importCorpus(path_to_NLP + '\\\\data\\\\AMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'testing',\n",
       " 'performed',\n",
       " 'on',\n",
       " 'the',\n",
       " 'finished',\n",
       " 'product',\n",
       " '(',\n",
       " 'fp',\n",
       " ')',\n",
       " 'is',\n",
       " 'in',\n",
       " 'compliance',\n",
       " 'with',\n",
       " 'both',\n",
       " 'current',\n",
       " 'european',\n",
       " 'pharmacopoeia',\n",
       " '(',\n",
       " 'ph',\n",
       " 'eur',\n",
       " ')',\n",
       " 'and',\n",
       " 'world',\n",
       " 'health',\n",
       " 'organization',\n",
       " '(',\n",
       " 'who',\n",
       " ')',\n",
       " 'requirements',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " '1',\n",
       " 'once',\n",
       " 'the',\n",
       " 'lyophilizate',\n",
       " 'has',\n",
       " 'been',\n",
       " 'reconstituted',\n",
       " 'with',\n",
       " 'the',\n",
       " 'appropriate',\n",
       " 'volume',\n",
       " 'of',\n",
       " 'diluent',\n",
       " '(',\n",
       " '0.4',\n",
       " '%',\n",
       " 'sodium',\n",
       " 'chloride',\n",
       " 'solution',\n",
       " 'for',\n",
       " 'suspension',\n",
       " 'for',\n",
       " 'injection',\n",
       " ')',\n",
       " 'a',\n",
       " 'human',\n",
       " 'dose',\n",
       " 'of',\n",
       " 'fp',\n",
       " 'is',\n",
       " '0.5',\n",
       " 'ml',\n",
       " '0',\n",
       " 'the',\n",
       " 'specifications',\n",
       " 'of',\n",
       " 'the',\n",
       " 'drug',\n",
       " 'product',\n",
       " 'single',\n",
       " 'dose',\n",
       " 'are',\n",
       " 'described',\n",
       " 'in',\n",
       " 'table',\n",
       " '1',\n",
       " '1',\n",
       " 'table',\n",
       " ':',\n",
       " 'specifications',\n",
       " 'for',\n",
       " 'the',\n",
       " 'drug',\n",
       " 'product',\n",
       " '1',\n",
       " 'table',\n",
       " ':',\n",
       " 'specifications',\n",
       " 'for',\n",
       " 'the',\n",
       " 'drug',\n",
       " 'product',\n",
       " '|',\n",
       " '*',\n",
       " 'iu',\n",
       " ':',\n",
       " 'international',\n",
       " 'unit',\n",
       " '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 Word-level Embedding\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Custom Word-level Embedding Model\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "### 1.1.1 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language\n",
    "\n",
    "Classe de langage prennant en paramètre un corpus de la forme [[str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.utils import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, corpus = None, base_tokens = ['SOS', 'EOS', 'UNK'], min_count = None):\n",
    "        self.base_tokens = base_tokens\n",
    "        self.initData(base_tokens)\n",
    "        if    corpus is not None : self.addCorpus(corpus)\n",
    "        if min_count is not None : self.removeRareWords(min_count)\n",
    "\n",
    "        \n",
    "    def initData(self, base_tokens) :\n",
    "        self.word2index = {word : i for i, word in enumerate(base_tokens)}\n",
    "        self.index2word = {i : word for i, word in enumerate(base_tokens)}\n",
    "        self.word2count = {word : 0 for word in base_tokens}\n",
    "        self.n_words = len(base_tokens)\n",
    "        return\n",
    "    \n",
    "    def getIndex(self, word) :\n",
    "        if    word in self.word2index : return self.word2index[word]\n",
    "        elif 'UNK' in self.word2index : return self.word2index['UNK']\n",
    "        return\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        '''Add a word to the language'''\n",
    "        if word not in self.word2index:\n",
    "            if word.strip() != '' :\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        return \n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        '''Add to the language all words of a sentence'''\n",
    "        words = sentence if type(sentence) == list else nltk.word_tokenize(sentence)\n",
    "        for word in words : self.addWord(word)          \n",
    "        return\n",
    "            \n",
    "    def addCorpus(self, corpus):\n",
    "        '''Add to the language all words contained into a corpus'''\n",
    "        for text in corpus : self.addSentence(text)\n",
    "        return \n",
    "                \n",
    "    def removeRareWords(self, min_count):\n",
    "        '''remove words appearing lesser than a min_count threshold'''\n",
    "        kept_word2count = {word: count for word, count in self.word2count.items() if count >= min_count}\n",
    "        self.initData(self.base_tokens)\n",
    "        for word, count in kept_word2count.items(): \n",
    "            self.addWord(word)\n",
    "            self.word2count[word] = kept_word2count[word]\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveLang(name, lang):\n",
    "    with open(path_to_NLP + '\\\\saves\\\\lang\\\\' + name + '.file', 'wb') as fil :\n",
    "        pickle.dump(lang, fil)\n",
    "    return\n",
    "\n",
    "def importLang(name):\n",
    "    with open(path_to_NLP + '\\\\saves\\\\lang\\\\' + name + '.file', 'rb') as fil :\n",
    "        lang = pickle.load(fil)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés avant : 8055\n",
      "Mots comptés après : 4050\n"
     ]
    }
   ],
   "source": [
    "lang = Lang(corpus, base_tokens = ['SOS', 'EOS', 'UNK'])\n",
    "print(\"Mots comptés avant : {}\".format(lang.n_words))\n",
    "lang.removeRareWords(min_count = 4)\n",
    "print(\"Mots comptés après : {}\".format(lang.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveLang(name = 'DL4NLP_I1', lang = lang)\n",
    "#lang = importLang(name = 'DL4NLP_I1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison avec un vocabulaire de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76\n",
    "\n",
    "# --------------------- comparison with Glove vocab ------------------------\n",
    "def vocabGlove(name) :\n",
    "    words = []\n",
    "    path = path_to_NLP + '\\\\vectors\\\\' + name \n",
    "    with open(path + '.txt', 'rb') as f:\n",
    "        for l in f:\n",
    "            line = l.decode().split()\n",
    "            word = line[0]\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "def comparaison(lang) :\n",
    "    vocab_lang = list(lang.word2index.keys())\n",
    "    intersect_glove = intersection(vocab_glove, vocab_lang)\n",
    "    reste_glove = np.setdiff1d(vocab_lang, intersect_glove)\n",
    "    printComparaison('glove', vocab_lang, intersect_glove, reste_glove)\n",
    "    return intersect_glove, reste_glove\n",
    "\n",
    "def printComparaison(nom, vocab_lang, intersect, reste) :\n",
    "    print('proportion de mots du langage appartenants à {}  {:.2f} % \\nproportion de mots du langage ny appartenant pas     {:.2f} %'.format(nom, len(intersect)*100/len(vocab_lang),len(reste)*100/len(vocab_lang) ) )\n",
    "\n",
    "\n",
    "# --------------------- detect missing spaces ------------------------\n",
    "def checkWhetherBroken(vocab, clean_vocab) :\n",
    "    exit = {}\n",
    "    for word in vocab :\n",
    "        exit[word] = True if word in clean_vocab else False\n",
    "    return exit\n",
    "\n",
    "def checkMissingSpaces(word, clean_vocab) :\n",
    "    for word2 in clean_vocab :\n",
    "        if word.startswith(word2) :\n",
    "            rest = word.replace(word2, '')\n",
    "            if rest in clean_vocab :\n",
    "                return word2 + ' ' + rest\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_glove = vocabGlove('glove.6B.200d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion de mots du langage appartenants à glove  85.90 % \n",
      "proportion de mots du langage ny appartenant pas     14.10 %\n"
     ]
    }
   ],
   "source": [
    "words_glove, reste_glove = comparaison(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec model\n",
    "\n",
    "[Back to top](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.models.Word_Embedding import Word2Vec as myWord2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myWord2Vec(nn.Module) :\n",
    "    def __init__(self, lang, T = 100):\n",
    "        super(myWord2Vec, self).__init__()\n",
    "        self.lang = lang\n",
    "        if type(T) == int :\n",
    "            self.embedding = nn.Embedding(lang.n_words, T)  \n",
    "        else :\n",
    "            self.embedding = nn.Embedding(T.shape[0], T.shape[1])\n",
    "            self.embedding.weight = nn.Parameter(torch.FloatTensor(T))\n",
    "            \n",
    "        self.output_dim = self.lookupTable().shape[1]\n",
    "        self.sims = None\n",
    "        \n",
    "    def lookupTable(self) :\n",
    "        return self.embedding.weight.cpu().detach().numpy()\n",
    "        \n",
    "    def computeSimilarities(self) :\n",
    "        T = normalize(self.lookupTable(), norm = 'l2', axis = 1)\n",
    "        self.sims = np.matmul(T, T.transpose())\n",
    "        return\n",
    "\n",
    "    def most_similar(self, word, bound = 10) :\n",
    "        if word not in self.lang.word2index : return\n",
    "        if self.sims is None : self.computeSimilarities()\n",
    "        index = self.lang.word2index[word]\n",
    "        coefs = self.sims[index]\n",
    "        indices = coefs.argsort()[-bound -1 :-1]\n",
    "        output = [(self.lang.index2word[i], coefs[i]) for i in reversed(indices)]\n",
    "        return output\n",
    "    \n",
    "    def wv(self, word) :\n",
    "        return self.lookupTable()[self.lang.getIndex(word)]\n",
    "    \n",
    "    def addWord(self, word, vector = None) :\n",
    "        self.lang.addWord(word)\n",
    "        T = self.lookupTable()\n",
    "        v = np.random.rand(1, T.shape[1]) if vector is None else vector\n",
    "        updated_T = np.concatenate((T, v), axis = 0)\n",
    "        self.embedding = nn.Embedding(updated_T.shape[0], updated_T.shape[1])\n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(updated_T))\n",
    "        return\n",
    "    \n",
    "    def freeze(self) :\n",
    "        for param in self.embedding.parameters() : param.requires_grad = False\n",
    "        return self\n",
    "    \n",
    "    def unfreeze(self) :\n",
    "        for param in self.embedding.parameters() : param.requires_grad = True\n",
    "        return self\n",
    "    \n",
    "    def forward(self, words, device = None) :\n",
    "        '''Transforms a list of n words into a torch.FloatTensor of size (1, n, emb_dim)'''\n",
    "        indices  = [self.lang.getIndex(w) for w in words]\n",
    "        indices  = [[i for i in indices if i is not None]]\n",
    "        variable = Variable(torch.LongTensor(indices)) # size = (1, n)\n",
    "        if device is not None : variable = variable.to(device)\n",
    "        tensor   = self.embedding(variable)            # size = (1, n, emb_dim)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec Shell\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Shell acting as a wrapper around the Word2Vec model, implementing :\n",
    "\n",
    "- The layers suited for the training objective\n",
    "- The methods for all optimization steps\n",
    "- The methods for generating the data suitable for the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.models.Word_Embedding import Word2VecShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecShell(nn.Module):\n",
    "    '''Word2Vec model :\n",
    "        - sg = 0 yields CBOW training procedure\n",
    "        - sg = 1 yields Skip-Gram training procedure\n",
    "    '''\n",
    "    def __init__(self, word2vec, device, sg = 0, context_size = 5, hidden_dim = 150, \n",
    "                 criterion = nn.NLLLoss(size_average = False), optimizer = optim.SGD):\n",
    "        super(Word2VecShell, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # core of Word2Vec\n",
    "        self.word2vec = word2vec\n",
    "        \n",
    "        # training layers\n",
    "        self.input_n_words  = (2 * context_size if sg == 0 else 1)\n",
    "        self.output_n_words = (1 if sg == 0 else 2 * context_size)\n",
    "        self.linear_1  = nn.Linear(self.input_n_words * word2vec.embedding.weight.size(1), self.output_n_words * hidden_dim)\n",
    "        self.linear_2  = nn.Linear(hidden_dim, lang.n_words)\n",
    "        \n",
    "        # training tools\n",
    "        self.sg = sg\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        '''Transforms a batch of Ngrams of size (batch_size, input_n_words)\n",
    "           Into log probabilities of size (batch_size, lang.n_words, output_n_words)\n",
    "           '''\n",
    "        batch = batch.to(self.device)                 # size = (batch_size, self.input_n_words)\n",
    "        embed = self.word2vec.embedding(batch)        # size = (batch_size, self.input_n_words, embedding_dim)\n",
    "        embed = embed.view((batch.size(0), -1))       # size = (batch_size, self.input_n_words * embedding_dim)\n",
    "        out = self.linear_1(embed)                    # size = (batch_size, self.output_n_words * hidden_dim) \n",
    "        out = out.view((batch.size(0),self.output_n_words, -1))\n",
    "        out = F.relu(out)                             # size = (batch_size, self.output_n_words, hidden_dim)                                         \n",
    "        out = self.linear_2(out)                      # size = (batch_size, self.output_n_words, lang.n_words)\n",
    "        out = torch.transpose(out, 1, 2)              # size = (batch_size, lang.n_words, self.output_n_words)\n",
    "        log_probs = F.log_softmax(out, dim = 1)       # size = (batch_size, lang.n_words, self.output_n_words)\n",
    "        return log_probs\n",
    "    \n",
    "    def generatePackedNgrams(self, corpus, context_size = 5, batch_size = 32, seed = 42) :\n",
    "        # generate Ngrams\n",
    "        data = []\n",
    "        for text in corpus :\n",
    "            text = [w for w in text if w in self.word2vec.lang.word2index]\n",
    "            text = ['SOS' for i in range(context_size)] + text + ['EOS' for i in range(context_size)]\n",
    "            for i in range(context_size, len(text) - context_size):\n",
    "                context = text[i-context_size : i] + text[i+1 : i+context_size+1]\n",
    "                word = text[i]\n",
    "                data.append([word, context])\n",
    "        # pack Ngrams into mini_batches\n",
    "        random.seed(seed)\n",
    "        random.shuffle(data)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            pack0 = [el[0] for el in data[i:i + batch_size]]\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w)] for w in pack0]\n",
    "            pack0 = Variable(torch.LongTensor(pack0)) # size = (batch_size, 1)\n",
    "            pack1 = [el[1] for el in data[i:i + batch_size]]\n",
    "            pack1 = [[self.word2vec.lang.getIndex(w) for w in context] for context in pack1]\n",
    "            pack1 = Variable(torch.LongTensor(pack1)) # size = (batch_size, 2*context_size)   \n",
    "            if   self.sg == 1 : packed_data.append([pack0, pack1])\n",
    "            elif self.sg == 0 : packed_data.append([pack1, pack0])\n",
    "            else :\n",
    "                print('A problem occured')\n",
    "                pass\n",
    "        return packed_data\n",
    "    \n",
    "    def train(self, ngrams, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = False):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loop\n",
    "        s\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            accuracy = 0\n",
    "            for i in range(targets.size(0)) :\n",
    "                for j in range(targets.size(1)) :\n",
    "                    topv, topi = log_probs[i, :, j].data.topk(1) \n",
    "                    ni = topi[0][0]\n",
    "                    if ni == targets[i, j].data[0] : accuracy += 1\n",
    "            return (accuracy * 100) / (targets.size(0) * targets.size(1))\n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(couple, optimizer, compute_accuracy = False):\n",
    "            \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = self(couple[0])           # size = (batch_size, agent.output_n_words, agent.lang.n_words)\n",
    "            targets   = couple[1].to(self.device) # size = (batch_size, agent.output_n_words)\n",
    "            loss      = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.data[0] / (targets.size(0) * targets.size(1))), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_loss_words = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                couple = random.choice(ngrams)\n",
    "                loss, loss_words = trainLoop(couple, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_loss_words += loss_words      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_loss_words = printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(ngrams) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(ngrams)\n",
    "                for couple in ngrams :\n",
    "                    loss, loss_words = trainLoop(couple, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_loss_words += loss_words \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_loss_words = printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Training with CBOW objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang(corpus, base_tokens = ['SOS', 'EOS', 'UNK'], min_count = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow.word2vec == word2vec :  True\n"
     ]
    }
   ],
   "source": [
    "word2vec = myWord2Vec(lang, T = 75)\n",
    "cbow = Word2VecShell(word2vec, device, sg = 0, context_size = 5, hidden_dim = 150)\n",
    "print('cbow.word2vec == word2vec : ', cbow.word2vec == word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngrams = cbow.generatePackedNgrams(corpus, context_size = 5, batch_size = 32, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "\n",
    "The training methods allows to display accuracy over predicted target words. However, since the underlying computation is quite time consuming, we display accuracy only at the begining of training, and a few times periodically along the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 0m 0s) (100 100%) loss : 1.568  accuracy : 64.9 %\n",
      "epoch 1\n",
      "0m 0s (- 3m 30s) (100 0%) loss : 1.605                     \n",
      "0m 0s (- 3m 30s) (200 0%) loss : 1.466                     \n",
      "0m 1s (- 3m 29s) (300 0%) loss : 1.534                     \n",
      "0m 1s (- 3m 28s) (400 0%) loss : 1.533                     \n",
      "0m 2s (- 3m 26s) (500 1%) loss : 1.541                     \n",
      "0m 2s (- 3m 25s) (600 1%) loss : 1.496                     \n",
      "0m 3s (- 3m 24s) (700 1%) loss : 1.455                     \n",
      "0m 3s (- 3m 24s) (800 1%) loss : 1.459                     \n",
      "0m 4s (- 3m 24s) (900 2%) loss : 1.488                     \n",
      "0m 4s (- 3m 23s) (1000 2%) loss : 1.460                     \n",
      "0m 5s (- 3m 23s) (1100 2%) loss : 1.432                     \n",
      "0m 5s (- 3m 23s) (1200 2%) loss : 1.487                     \n",
      "0m 6s (- 3m 23s) (1300 2%) loss : 1.457                     \n",
      "0m 6s (- 3m 22s) (1400 3%) loss : 1.470                     \n",
      "0m 7s (- 3m 22s) (1500 3%) loss : 1.444                     \n",
      "0m 7s (- 3m 21s) (1600 3%) loss : 1.434                     \n",
      "0m 7s (- 3m 22s) (1700 3%) loss : 1.370                     \n",
      "0m 8s (- 3m 22s) (1800 4%) loss : 1.531                     \n",
      "0m 8s (- 3m 21s) (1900 4%) loss : 1.454                     \n",
      "0m 9s (- 3m 21s) (2000 4%) loss : 1.462                     \n",
      "0m 9s (- 3m 20s) (2100 4%) loss : 1.504                     \n",
      "0m 10s (- 3m 20s) (2200 4%) loss : 1.483                     \n",
      "0m 10s (- 3m 20s) (2300 5%) loss : 1.436                     \n",
      "0m 11s (- 3m 19s) (2400 5%) loss : 1.428                     \n",
      "0m 11s (- 3m 18s) (2500 5%) loss : 1.430                     \n",
      "0m 12s (- 3m 18s) (2600 5%) loss : 1.502                     \n",
      "0m 12s (- 3m 18s) (2700 6%) loss : 1.401                     \n",
      "0m 13s (- 3m 17s) (2800 6%) loss : 1.423                     \n",
      "0m 13s (- 3m 17s) (2900 6%) loss : 1.446                     \n",
      "0m 14s (- 3m 17s) (3000 6%) loss : 1.524                     \n",
      "0m 14s (- 3m 17s) (3100 6%) loss : 1.388                     \n",
      "0m 15s (- 3m 17s) (3200 7%) loss : 1.434                     \n",
      "0m 15s (- 3m 16s) (3300 7%) loss : 1.459                     \n",
      "0m 16s (- 3m 16s) (3400 7%) loss : 1.416                     \n",
      "0m 16s (- 3m 16s) (3500 7%) loss : 1.426                     \n",
      "0m 17s (- 3m 16s) (3600 8%) loss : 1.424                     \n",
      "0m 17s (- 3m 15s) (3700 8%) loss : 1.388                     \n",
      "0m 18s (- 3m 16s) (3800 8%) loss : 1.444                     \n",
      "0m 18s (- 3m 17s) (3900 8%) loss : 1.445                     \n",
      "0m 19s (- 3m 17s) (4000 8%) loss : 1.419                     \n",
      "0m 19s (- 3m 16s) (4100 9%) loss : 1.473                     \n",
      "0m 20s (- 3m 17s) (4200 9%) loss : 1.389                     \n",
      "0m 20s (- 3m 17s) (4300 9%) loss : 1.462                     \n",
      "0m 21s (- 3m 16s) (4400 9%) loss : 1.442                     \n",
      "0m 21s (- 3m 15s) (4500 10%) loss : 1.445                     \n",
      "0m 22s (- 3m 15s) (4600 10%) loss : 1.418                     \n",
      "0m 22s (- 3m 14s) (4700 10%) loss : 1.500                     \n",
      "0m 23s (- 3m 14s) (4800 10%) loss : 1.447                     \n",
      "0m 23s (- 3m 13s) (4900 10%) loss : 1.468                     \n",
      "0m 24s (- 3m 12s) (5000 11%) loss : 1.397                     \n",
      "0m 24s (- 3m 12s) (5100 11%) loss : 1.492                     \n",
      "0m 25s (- 3m 11s) (5200 11%) loss : 1.490                     \n",
      "0m 25s (- 3m 10s) (5300 11%) loss : 1.393                     \n",
      "0m 26s (- 3m 10s) (5400 12%) loss : 1.501                     \n",
      "0m 26s (- 3m 9s) (5500 12%) loss : 1.500                     \n",
      "0m 27s (- 3m 9s) (5600 12%) loss : 1.515                     \n",
      "0m 27s (- 3m 8s) (5700 12%) loss : 1.455                     \n",
      "0m 28s (- 3m 8s) (5800 12%) loss : 1.377                     \n",
      "0m 28s (- 3m 7s) (5900 13%) loss : 1.500                     \n",
      "0m 28s (- 3m 6s) (6000 13%) loss : 1.409                     \n",
      "0m 29s (- 3m 6s) (6100 13%) loss : 1.409                     \n",
      "0m 29s (- 3m 5s) (6200 13%) loss : 1.474                     \n",
      "0m 30s (- 3m 5s) (6300 14%) loss : 1.488                     \n",
      "0m 30s (- 3m 5s) (6400 14%) loss : 1.464                     \n",
      "0m 31s (- 3m 4s) (6500 14%) loss : 1.469                     \n",
      "0m 31s (- 3m 4s) (6600 14%) loss : 1.431                     \n",
      "0m 32s (- 3m 4s) (6700 14%) loss : 1.428                     \n",
      "0m 32s (- 3m 3s) (6800 15%) loss : 1.419                     \n",
      "0m 33s (- 3m 3s) (6900 15%) loss : 1.469                     \n",
      "0m 33s (- 3m 2s) (7000 15%) loss : 1.481                     \n",
      "0m 34s (- 3m 2s) (7100 15%) loss : 1.507                     \n",
      "0m 34s (- 3m 1s) (7200 16%) loss : 1.446                     \n",
      "0m 35s (- 3m 1s) (7300 16%) loss : 1.451                     \n",
      "0m 35s (- 3m 0s) (7400 16%) loss : 1.428                     \n",
      "0m 36s (- 2m 59s) (7500 16%) loss : 1.403                     \n",
      "0m 36s (- 2m 59s) (7600 16%) loss : 1.383                     \n",
      "0m 37s (- 2m 58s) (7700 17%) loss : 1.412                     \n",
      "0m 37s (- 2m 58s) (7800 17%) loss : 1.428                     \n",
      "0m 38s (- 2m 57s) (7900 17%) loss : 1.483                     \n",
      "0m 38s (- 2m 57s) (8000 17%) loss : 1.419                     \n",
      "0m 39s (- 2m 56s) (8100 18%) loss : 1.398                     \n",
      "0m 39s (- 2m 56s) (8200 18%) loss : 1.507                     \n",
      "0m 39s (- 2m 55s) (8300 18%) loss : 1.390                     \n",
      "0m 40s (- 2m 54s) (8400 18%) loss : 1.415                     \n",
      "0m 40s (- 2m 54s) (8500 19%) loss : 1.472                     \n",
      "0m 41s (- 2m 53s) (8600 19%) loss : 1.498                     \n",
      "0m 41s (- 2m 53s) (8700 19%) loss : 1.465                     \n",
      "0m 42s (- 2m 52s) (8800 19%) loss : 1.443                     \n",
      "0m 42s (- 2m 52s) (8900 19%) loss : 1.453                     \n",
      "0m 43s (- 2m 51s) (9000 20%) loss : 1.459                     \n",
      "0m 43s (- 2m 51s) (9100 20%) loss : 1.476                     \n",
      "0m 44s (- 2m 50s) (9200 20%) loss : 1.449                     \n",
      "0m 44s (- 2m 50s) (9300 20%) loss : 1.441                     \n",
      "0m 45s (- 2m 49s) (9400 21%) loss : 1.381                     \n",
      "0m 45s (- 2m 49s) (9500 21%) loss : 1.449                     \n",
      "0m 46s (- 2m 48s) (9600 21%) loss : 1.543                     \n",
      "0m 46s (- 2m 48s) (9700 21%) loss : 1.437                     \n",
      "0m 47s (- 2m 47s) (9800 21%) loss : 1.481                     \n",
      "0m 47s (- 2m 47s) (9900 22%) loss : 1.493                     \n",
      "0m 47s (- 2m 46s) (10000 22%) loss : 1.417                     \n",
      "0m 48s (- 2m 46s) (10100 22%) loss : 1.501                     \n",
      "0m 48s (- 2m 45s) (10200 22%) loss : 1.452                     \n",
      "0m 49s (- 2m 45s) (10300 23%) loss : 1.461                     \n",
      "0m 49s (- 2m 44s) (10400 23%) loss : 1.495                     \n",
      "0m 50s (- 2m 43s) (10500 23%) loss : 1.430                     \n",
      "0m 50s (- 2m 43s) (10600 23%) loss : 1.380                     \n",
      "0m 51s (- 2m 42s) (10700 23%) loss : 1.402                     \n",
      "0m 51s (- 2m 42s) (10800 24%) loss : 1.458                     \n",
      "0m 52s (- 2m 41s) (10900 24%) loss : 1.514                     \n",
      "0m 52s (- 2m 41s) (11000 24%) loss : 1.472                     \n",
      "0m 53s (- 2m 40s) (11100 24%) loss : 1.442                     \n",
      "0m 53s (- 2m 40s) (11200 25%) loss : 1.427                     \n",
      "0m 54s (- 2m 39s) (11300 25%) loss : 1.530                     \n",
      "0m 54s (- 2m 39s) (11400 25%) loss : 1.437                     \n",
      "0m 54s (- 2m 38s) (11500 25%) loss : 1.425                     \n",
      "0m 55s (- 2m 38s) (11600 25%) loss : 1.466                     \n",
      "0m 55s (- 2m 37s) (11700 26%) loss : 1.446                     \n",
      "0m 56s (- 2m 37s) (11800 26%) loss : 1.508                     \n",
      "0m 56s (- 2m 36s) (11900 26%) loss : 1.481                     \n",
      "0m 57s (- 2m 36s) (12000 26%) loss : 1.411                     \n",
      "0m 57s (- 2m 35s) (12100 27%) loss : 1.518                     \n",
      "0m 58s (- 2m 35s) (12200 27%) loss : 1.502                     \n",
      "0m 58s (- 2m 34s) (12300 27%) loss : 1.426                     \n",
      "0m 59s (- 2m 34s) (12400 27%) loss : 1.410                     \n",
      "0m 59s (- 2m 33s) (12500 27%) loss : 1.460                     \n",
      "1m 0s (- 2m 33s) (12600 28%) loss : 1.451                     \n",
      "1m 0s (- 2m 32s) (12700 28%) loss : 1.488                     \n",
      "1m 1s (- 2m 32s) (12800 28%) loss : 1.490                     \n",
      "1m 1s (- 2m 31s) (12900 28%) loss : 1.438                     \n",
      "1m 1s (- 2m 31s) (13000 29%) loss : 1.444                     \n",
      "1m 2s (- 2m 30s) (13100 29%) loss : 1.515                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 2s (- 2m 30s) (13200 29%) loss : 1.510                     \n",
      "1m 3s (- 2m 29s) (13300 29%) loss : 1.477                     \n",
      "1m 3s (- 2m 29s) (13400 29%) loss : 1.469                     \n",
      "1m 4s (- 2m 28s) (13500 30%) loss : 1.522                     \n",
      "1m 4s (- 2m 28s) (13600 30%) loss : 1.400                     \n",
      "1m 5s (- 2m 27s) (13700 30%) loss : 1.401                     \n",
      "1m 5s (- 2m 27s) (13800 30%) loss : 1.422                     \n",
      "1m 6s (- 2m 26s) (13900 31%) loss : 1.456                     \n",
      "1m 6s (- 2m 26s) (14000 31%) loss : 1.545                     \n",
      "1m 7s (- 2m 25s) (14100 31%) loss : 1.470                     \n",
      "1m 7s (- 2m 25s) (14200 31%) loss : 1.492                     \n",
      "1m 8s (- 2m 24s) (14300 31%) loss : 1.503                     \n",
      "1m 8s (- 2m 24s) (14400 32%) loss : 1.494                     \n",
      "1m 9s (- 2m 23s) (14500 32%) loss : 1.475                     \n",
      "1m 9s (- 2m 23s) (14600 32%) loss : 1.487                     \n",
      "1m 9s (- 2m 22s) (14700 32%) loss : 1.427                     \n",
      "1m 10s (- 2m 22s) (14800 33%) loss : 1.483                     \n",
      "1m 10s (- 2m 21s) (14900 33%) loss : 1.457                     \n",
      "epoch 2\n",
      "1m 11s (- 2m 21s) (15000 33%) loss : 1.367                     \n",
      "1m 11s (- 2m 20s) (15100 33%) loss : 1.375                     \n",
      "1m 12s (- 2m 20s) (15200 33%) loss : 1.341                     \n",
      "1m 12s (- 2m 19s) (15300 34%) loss : 1.369                     \n",
      "1m 13s (- 2m 19s) (15400 34%) loss : 1.391                     \n",
      "1m 13s (- 2m 18s) (15500 34%) loss : 1.297                     \n",
      "1m 14s (- 2m 18s) (15600 34%) loss : 1.310                     \n",
      "1m 14s (- 2m 17s) (15700 35%) loss : 1.368                     \n",
      "1m 15s (- 2m 17s) (15800 35%) loss : 1.368                     \n",
      "1m 15s (- 2m 16s) (15900 35%) loss : 1.371                     \n",
      "1m 16s (- 2m 16s) (16000 35%) loss : 1.392                     \n",
      "1m 16s (- 2m 16s) (16100 35%) loss : 1.326                     \n",
      "1m 16s (- 2m 15s) (16200 36%) loss : 1.374                     \n",
      "1m 17s (- 2m 15s) (16300 36%) loss : 1.396                     \n",
      "1m 17s (- 2m 14s) (16400 36%) loss : 1.405                     \n",
      "1m 18s (- 2m 14s) (16500 36%) loss : 1.442                     \n",
      "1m 18s (- 2m 13s) (16600 37%) loss : 1.431                     \n",
      "1m 19s (- 2m 13s) (16700 37%) loss : 1.409                     \n",
      "1m 19s (- 2m 12s) (16800 37%) loss : 1.410                     \n",
      "1m 20s (- 2m 12s) (16900 37%) loss : 1.413                     \n",
      "1m 20s (- 2m 11s) (17000 38%) loss : 1.370                     \n",
      "1m 21s (- 2m 11s) (17100 38%) loss : 1.444                     \n",
      "1m 21s (- 2m 10s) (17200 38%) loss : 1.347                     \n",
      "1m 22s (- 2m 10s) (17300 38%) loss : 1.410                     \n",
      "1m 22s (- 2m 9s) (17400 38%) loss : 1.403                     \n",
      "1m 23s (- 2m 9s) (17500 39%) loss : 1.446                     \n",
      "1m 23s (- 2m 8s) (17600 39%) loss : 1.415                     \n",
      "1m 24s (- 2m 8s) (17700 39%) loss : 1.392                     \n",
      "1m 24s (- 2m 7s) (17800 39%) loss : 1.408                     \n",
      "1m 24s (- 2m 7s) (17900 40%) loss : 1.373                     \n",
      "1m 25s (- 2m 6s) (18000 40%) loss : 1.396                     \n",
      "1m 25s (- 2m 6s) (18100 40%) loss : 1.357                     \n",
      "1m 26s (- 2m 5s) (18200 40%) loss : 1.450                     \n",
      "1m 26s (- 2m 5s) (18300 40%) loss : 1.370                     \n",
      "1m 27s (- 2m 4s) (18400 41%) loss : 1.355                     \n",
      "1m 27s (- 2m 4s) (18500 41%) loss : 1.404                     \n",
      "1m 28s (- 2m 4s) (18600 41%) loss : 1.331                     \n",
      "1m 28s (- 2m 3s) (18700 41%) loss : 1.417                     \n",
      "1m 29s (- 2m 3s) (18800 42%) loss : 1.379                     \n",
      "1m 29s (- 2m 2s) (18900 42%) loss : 1.334                     \n",
      "1m 30s (- 2m 2s) (19000 42%) loss : 1.392                     \n",
      "1m 31s (- 2m 2s) (19100 42%) loss : 1.429                     \n",
      "1m 31s (- 2m 1s) (19200 42%) loss : 1.452                     \n",
      "1m 32s (- 2m 1s) (19300 43%) loss : 1.416                     \n",
      "1m 32s (- 2m 1s) (19400 43%) loss : 1.396                     \n",
      "1m 33s (- 2m 0s) (19500 43%) loss : 1.376                     \n",
      "1m 33s (- 2m 0s) (19600 43%) loss : 1.434                     \n",
      "1m 34s (- 1m 59s) (19700 44%) loss : 1.448                     \n",
      "1m 34s (- 1m 59s) (19800 44%) loss : 1.329                     \n",
      "1m 35s (- 1m 58s) (19900 44%) loss : 1.440                     \n",
      "1m 35s (- 1m 58s) (20000 44%) loss : 1.377                     \n",
      "1m 36s (- 1m 57s) (20100 44%) loss : 1.394                     \n",
      "1m 36s (- 1m 57s) (20200 45%) loss : 1.413                     \n",
      "1m 37s (- 1m 56s) (20300 45%) loss : 1.354                     \n",
      "1m 37s (- 1m 56s) (20400 45%) loss : 1.357                     \n",
      "1m 38s (- 1m 55s) (20500 45%) loss : 1.365                     \n",
      "1m 38s (- 1m 55s) (20600 46%) loss : 1.418                     \n",
      "1m 39s (- 1m 54s) (20700 46%) loss : 1.402                     \n",
      "1m 39s (- 1m 54s) (20800 46%) loss : 1.431                     \n",
      "1m 40s (- 1m 54s) (20900 46%) loss : 1.483                     \n",
      "1m 40s (- 1m 53s) (21000 46%) loss : 1.366                     \n",
      "1m 41s (- 1m 53s) (21100 47%) loss : 1.417                     \n",
      "1m 41s (- 1m 52s) (21200 47%) loss : 1.460                     \n",
      "1m 41s (- 1m 52s) (21300 47%) loss : 1.410                     \n",
      "1m 42s (- 1m 51s) (21400 47%) loss : 1.435                     \n",
      "1m 42s (- 1m 51s) (21500 48%) loss : 1.433                     \n",
      "1m 43s (- 1m 50s) (21600 48%) loss : 1.376                     \n",
      "1m 43s (- 1m 50s) (21700 48%) loss : 1.413                     \n",
      "1m 44s (- 1m 49s) (21800 48%) loss : 1.452                     \n",
      "1m 44s (- 1m 49s) (21900 48%) loss : 1.419                     \n",
      "1m 45s (- 1m 48s) (22000 49%) loss : 1.458                     \n",
      "1m 45s (- 1m 48s) (22100 49%) loss : 1.468                     \n",
      "1m 46s (- 1m 48s) (22200 49%) loss : 1.412                     \n",
      "1m 47s (- 1m 47s) (22300 49%) loss : 1.460                     \n",
      "1m 47s (- 1m 47s) (22400 50%) loss : 1.359                     \n",
      "1m 48s (- 1m 46s) (22500 50%) loss : 1.427                     \n",
      "1m 48s (- 1m 46s) (22600 50%) loss : 1.413                     \n",
      "1m 49s (- 1m 45s) (22700 50%) loss : 1.357                     \n",
      "1m 49s (- 1m 45s) (22800 50%) loss : 1.455                     \n",
      "1m 50s (- 1m 45s) (22900 51%) loss : 1.438                     \n",
      "1m 50s (- 1m 44s) (23000 51%) loss : 1.388                     \n",
      "1m 51s (- 1m 44s) (23100 51%) loss : 1.452                     \n",
      "1m 51s (- 1m 43s) (23200 51%) loss : 1.450                     \n",
      "1m 52s (- 1m 43s) (23300 52%) loss : 1.393                     \n",
      "1m 52s (- 1m 42s) (23400 52%) loss : 1.474                     \n",
      "1m 53s (- 1m 42s) (23500 52%) loss : 1.408                     \n",
      "1m 53s (- 1m 41s) (23600 52%) loss : 1.345                     \n",
      "1m 54s (- 1m 41s) (23700 52%) loss : 1.406                     \n",
      "1m 54s (- 1m 40s) (23800 53%) loss : 1.434                     \n",
      "1m 55s (- 1m 40s) (23900 53%) loss : 1.428                     \n",
      "1m 55s (- 1m 39s) (24000 53%) loss : 1.408                     \n",
      "1m 56s (- 1m 39s) (24100 53%) loss : 1.411                     \n",
      "1m 56s (- 1m 38s) (24200 54%) loss : 1.455                     \n",
      "1m 56s (- 1m 38s) (24300 54%) loss : 1.506                     \n",
      "1m 57s (- 1m 37s) (24400 54%) loss : 1.430                     \n",
      "1m 57s (- 1m 37s) (24500 54%) loss : 1.449                     \n",
      "1m 58s (- 1m 36s) (24600 55%) loss : 1.384                     \n",
      "1m 58s (- 1m 36s) (24700 55%) loss : 1.438                     \n",
      "1m 59s (- 1m 35s) (24800 55%) loss : 1.479                     \n",
      "1m 59s (- 1m 35s) (24900 55%) loss : 1.466                     \n",
      "2m 0s (- 1m 34s) (25000 55%) loss : 1.439                     \n",
      "2m 0s (- 1m 34s) (25100 56%) loss : 1.445                     \n",
      "2m 1s (- 1m 33s) (25200 56%) loss : 1.472                     \n",
      "2m 1s (- 1m 33s) (25300 56%) loss : 1.474                     \n",
      "2m 2s (- 1m 32s) (25400 56%) loss : 1.479                     \n",
      "2m 2s (- 1m 32s) (25500 57%) loss : 1.511                     \n",
      "2m 3s (- 1m 31s) (25600 57%) loss : 1.441                     \n",
      "2m 3s (- 1m 31s) (25700 57%) loss : 1.439                     \n",
      "2m 4s (- 1m 30s) (25800 57%) loss : 1.410                     \n",
      "2m 4s (- 1m 30s) (25900 57%) loss : 1.436                     \n",
      "2m 4s (- 1m 29s) (26000 58%) loss : 1.451                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 5s (- 1m 29s) (26100 58%) loss : 1.432                     \n",
      "2m 5s (- 1m 29s) (26200 58%) loss : 1.383                     \n",
      "2m 6s (- 1m 28s) (26300 58%) loss : 1.455                     \n",
      "2m 6s (- 1m 28s) (26400 59%) loss : 1.451                     \n",
      "2m 7s (- 1m 27s) (26500 59%) loss : 1.468                     \n",
      "2m 7s (- 1m 27s) (26600 59%) loss : 1.402                     \n",
      "2m 8s (- 1m 26s) (26700 59%) loss : 1.468                     \n",
      "2m 8s (- 1m 26s) (26800 59%) loss : 1.480                     \n",
      "2m 9s (- 1m 25s) (26900 60%) loss : 1.491                     \n",
      "2m 9s (- 1m 25s) (27000 60%) loss : 1.447                     \n",
      "2m 10s (- 1m 24s) (27100 60%) loss : 1.432                     \n",
      "2m 10s (- 1m 24s) (27200 60%) loss : 1.475                     \n",
      "2m 11s (- 1m 23s) (27300 61%) loss : 1.410                     \n",
      "2m 11s (- 1m 23s) (27400 61%) loss : 1.480                     \n",
      "2m 12s (- 1m 22s) (27500 61%) loss : 1.375                     \n",
      "2m 12s (- 1m 22s) (27600 61%) loss : 1.478                     \n",
      "2m 12s (- 1m 21s) (27700 61%) loss : 1.505                     \n",
      "2m 13s (- 1m 21s) (27800 62%) loss : 1.539                     \n",
      "2m 13s (- 1m 20s) (27900 62%) loss : 1.456                     \n",
      "2m 14s (- 1m 20s) (28000 62%) loss : 1.347                     \n",
      "2m 14s (- 1m 19s) (28100 62%) loss : 1.391                     \n",
      "2m 15s (- 1m 19s) (28200 63%) loss : 1.404                     \n",
      "2m 15s (- 1m 18s) (28300 63%) loss : 1.476                     \n",
      "2m 16s (- 1m 18s) (28400 63%) loss : 1.512                     \n",
      "2m 16s (- 1m 17s) (28500 63%) loss : 1.406                     \n",
      "2m 17s (- 1m 17s) (28600 63%) loss : 1.415                     \n",
      "2m 17s (- 1m 16s) (28700 64%) loss : 1.440                     \n",
      "2m 18s (- 1m 16s) (28800 64%) loss : 1.512                     \n",
      "2m 18s (- 1m 15s) (28900 64%) loss : 1.412                     \n",
      "2m 19s (- 1m 15s) (29000 64%) loss : 1.468                     \n",
      "2m 19s (- 1m 14s) (29100 65%) loss : 1.484                     \n",
      "2m 20s (- 1m 14s) (29200 65%) loss : 1.475                     \n",
      "2m 20s (- 1m 14s) (29300 65%) loss : 1.414                     \n",
      "2m 21s (- 1m 13s) (29400 65%) loss : 1.421                     \n",
      "2m 21s (- 1m 13s) (29500 65%) loss : 1.507                     \n",
      "2m 21s (- 1m 12s) (29600 66%) loss : 1.526                     \n",
      "2m 22s (- 1m 12s) (29700 66%) loss : 1.507                     \n",
      "2m 22s (- 1m 11s) (29800 66%) loss : 1.445                     \n",
      "epoch 3\n",
      "2m 23s (- 1m 11s) (29900 66%) loss : 1.355                     \n",
      "2m 23s (- 1m 10s) (30000 67%) loss : 1.336                     \n",
      "2m 24s (- 1m 10s) (30100 67%) loss : 1.353                     \n",
      "2m 24s (- 1m 9s) (30200 67%) loss : 1.399                     \n",
      "2m 25s (- 1m 9s) (30300 67%) loss : 1.322                     \n",
      "2m 25s (- 1m 8s) (30400 67%) loss : 1.370                     \n",
      "2m 26s (- 1m 8s) (30500 68%) loss : 1.300                     \n",
      "2m 26s (- 1m 7s) (30600 68%) loss : 1.389                     \n",
      "2m 27s (- 1m 7s) (30700 68%) loss : 1.427                     \n",
      "2m 27s (- 1m 6s) (30800 68%) loss : 1.363                     \n",
      "2m 28s (- 1m 6s) (30900 69%) loss : 1.426                     \n",
      "2m 28s (- 1m 5s) (31000 69%) loss : 1.337                     \n",
      "2m 29s (- 1m 5s) (31100 69%) loss : 1.381                     \n",
      "2m 29s (- 1m 4s) (31200 69%) loss : 1.316                     \n",
      "2m 29s (- 1m 4s) (31300 69%) loss : 1.408                     \n",
      "2m 30s (- 1m 3s) (31400 70%) loss : 1.425                     \n",
      "2m 30s (- 1m 3s) (31500 70%) loss : 1.374                     \n",
      "2m 31s (- 1m 2s) (31600 70%) loss : 1.306                     \n",
      "2m 31s (- 1m 2s) (31700 70%) loss : 1.337                     \n",
      "2m 32s (- 1m 1s) (31800 71%) loss : 1.341                     \n",
      "2m 32s (- 1m 1s) (31900 71%) loss : 1.349                     \n",
      "2m 33s (- 1m 0s) (32000 71%) loss : 1.393                     \n",
      "2m 33s (- 1m 0s) (32100 71%) loss : 1.384                     \n",
      "2m 34s (- 0m 59s) (32200 71%) loss : 1.349                     \n",
      "2m 34s (- 0m 59s) (32300 72%) loss : 1.415                     \n",
      "2m 35s (- 0m 59s) (32400 72%) loss : 1.342                     \n",
      "2m 35s (- 0m 58s) (32500 72%) loss : 1.384                     \n",
      "2m 36s (- 0m 58s) (32600 72%) loss : 1.375                     \n",
      "2m 36s (- 0m 57s) (32700 73%) loss : 1.388                     \n",
      "2m 36s (- 0m 57s) (32800 73%) loss : 1.369                     \n",
      "2m 37s (- 0m 56s) (32900 73%) loss : 1.361                     \n",
      "2m 37s (- 0m 56s) (33000 73%) loss : 1.445                     \n",
      "2m 38s (- 0m 55s) (33100 74%) loss : 1.396                     \n",
      "2m 38s (- 0m 55s) (33200 74%) loss : 1.383                     \n",
      "2m 39s (- 0m 54s) (33300 74%) loss : 1.394                     \n",
      "2m 39s (- 0m 54s) (33400 74%) loss : 1.440                     \n",
      "2m 40s (- 0m 53s) (33500 74%) loss : 1.411                     \n",
      "2m 40s (- 0m 53s) (33600 75%) loss : 1.419                     \n",
      "2m 41s (- 0m 52s) (33700 75%) loss : 1.386                     \n",
      "2m 41s (- 0m 52s) (33800 75%) loss : 1.338                     \n",
      "2m 42s (- 0m 51s) (33900 75%) loss : 1.411                     \n",
      "2m 42s (- 0m 51s) (34000 76%) loss : 1.417                     \n",
      "2m 43s (- 0m 50s) (34100 76%) loss : 1.401                     \n",
      "2m 43s (- 0m 50s) (34200 76%) loss : 1.394                     \n",
      "2m 44s (- 0m 49s) (34300 76%) loss : 1.366                     \n",
      "2m 44s (- 0m 49s) (34400 76%) loss : 1.329                     \n",
      "2m 44s (- 0m 48s) (34500 77%) loss : 1.374                     \n",
      "2m 45s (- 0m 48s) (34600 77%) loss : 1.316                     \n",
      "2m 45s (- 0m 47s) (34700 77%) loss : 1.390                     \n",
      "2m 46s (- 0m 47s) (34800 77%) loss : 1.354                     \n",
      "2m 46s (- 0m 46s) (34900 78%) loss : 1.369                     \n",
      "2m 47s (- 0m 46s) (35000 78%) loss : 1.385                     \n",
      "2m 47s (- 0m 46s) (35100 78%) loss : 1.426                     \n",
      "2m 48s (- 0m 45s) (35200 78%) loss : 1.370                     \n",
      "2m 48s (- 0m 45s) (35300 78%) loss : 1.385                     \n",
      "2m 49s (- 0m 44s) (35400 79%) loss : 1.448                     \n",
      "2m 49s (- 0m 44s) (35500 79%) loss : 1.361                     \n",
      "2m 50s (- 0m 43s) (35600 79%) loss : 1.474                     \n",
      "2m 50s (- 0m 43s) (35700 79%) loss : 1.426                     \n",
      "2m 51s (- 0m 42s) (35800 80%) loss : 1.373                     \n",
      "2m 51s (- 0m 42s) (35900 80%) loss : 1.392                     \n",
      "2m 52s (- 0m 41s) (36000 80%) loss : 1.441                     \n",
      "2m 52s (- 0m 41s) (36100 80%) loss : 1.448                     \n",
      "2m 52s (- 0m 40s) (36200 80%) loss : 1.399                     \n",
      "2m 53s (- 0m 40s) (36300 81%) loss : 1.399                     \n",
      "2m 53s (- 0m 39s) (36400 81%) loss : 1.429                     \n",
      "2m 54s (- 0m 39s) (36500 81%) loss : 1.404                     \n",
      "2m 54s (- 0m 38s) (36600 81%) loss : 1.514                     \n",
      "2m 55s (- 0m 38s) (36700 82%) loss : 1.437                     \n",
      "2m 55s (- 0m 37s) (36800 82%) loss : 1.413                     \n",
      "2m 56s (- 0m 37s) (36900 82%) loss : 1.347                     \n",
      "2m 56s (- 0m 36s) (37000 82%) loss : 1.434                     \n",
      "2m 57s (- 0m 36s) (37100 82%) loss : 1.397                     \n",
      "2m 57s (- 0m 35s) (37200 83%) loss : 1.399                     \n",
      "2m 58s (- 0m 35s) (37300 83%) loss : 1.424                     \n",
      "2m 58s (- 0m 34s) (37400 83%) loss : 1.420                     \n",
      "2m 59s (- 0m 34s) (37500 83%) loss : 1.396                     \n",
      "2m 59s (- 0m 34s) (37600 84%) loss : 1.451                     \n",
      "2m 59s (- 0m 33s) (37700 84%) loss : 1.378                     \n",
      "3m 0s (- 0m 33s) (37800 84%) loss : 1.412                     \n",
      "3m 1s (- 0m 32s) (37900 84%) loss : 1.342                     \n",
      "3m 1s (- 0m 32s) (38000 84%) loss : 1.411                     \n",
      "3m 1s (- 0m 31s) (38100 85%) loss : 1.359                     \n",
      "3m 2s (- 0m 31s) (38200 85%) loss : 1.386                     \n",
      "3m 2s (- 0m 30s) (38300 85%) loss : 1.341                     \n",
      "3m 3s (- 0m 30s) (38400 85%) loss : 1.401                     \n",
      "3m 3s (- 0m 29s) (38500 86%) loss : 1.373                     \n",
      "3m 4s (- 0m 29s) (38600 86%) loss : 1.397                     \n",
      "3m 4s (- 0m 28s) (38700 86%) loss : 1.467                     \n",
      "3m 5s (- 0m 28s) (38800 86%) loss : 1.400                     \n",
      "3m 5s (- 0m 27s) (38900 86%) loss : 1.415                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 6s (- 0m 27s) (39000 87%) loss : 1.401                     \n",
      "3m 6s (- 0m 26s) (39100 87%) loss : 1.369                     \n",
      "3m 7s (- 0m 26s) (39200 87%) loss : 1.413                     \n",
      "3m 7s (- 0m 25s) (39300 87%) loss : 1.380                     \n",
      "3m 8s (- 0m 25s) (39400 88%) loss : 1.475                     \n",
      "3m 9s (- 0m 25s) (39500 88%) loss : 1.392                     \n",
      "3m 9s (- 0m 24s) (39600 88%) loss : 1.455                     \n",
      "3m 9s (- 0m 24s) (39700 88%) loss : 1.449                     \n",
      "3m 10s (- 0m 23s) (39800 88%) loss : 1.460                     \n",
      "3m 10s (- 0m 23s) (39900 89%) loss : 1.390                     \n",
      "3m 11s (- 0m 22s) (40000 89%) loss : 1.384                     \n",
      "3m 11s (- 0m 22s) (40100 89%) loss : 1.392                     \n",
      "3m 12s (- 0m 21s) (40200 89%) loss : 1.365                     \n",
      "3m 12s (- 0m 21s) (40300 90%) loss : 1.458                     \n",
      "3m 13s (- 0m 20s) (40400 90%) loss : 1.419                     \n",
      "3m 13s (- 0m 20s) (40500 90%) loss : 1.454                     \n",
      "3m 14s (- 0m 19s) (40600 90%) loss : 1.445                     \n",
      "3m 14s (- 0m 19s) (40700 90%) loss : 1.418                     \n",
      "3m 15s (- 0m 18s) (40800 91%) loss : 1.366                     \n",
      "3m 15s (- 0m 18s) (40900 91%) loss : 1.413                     \n",
      "3m 16s (- 0m 17s) (41000 91%) loss : 1.459                     \n",
      "3m 16s (- 0m 17s) (41100 91%) loss : 1.486                     \n",
      "3m 17s (- 0m 16s) (41200 92%) loss : 1.403                     \n",
      "3m 17s (- 0m 16s) (41300 92%) loss : 1.414                     \n",
      "3m 18s (- 0m 15s) (41400 92%) loss : 1.360                     \n",
      "3m 18s (- 0m 15s) (41500 92%) loss : 1.484                     \n",
      "3m 19s (- 0m 14s) (41600 93%) loss : 1.411                     \n",
      "3m 19s (- 0m 14s) (41700 93%) loss : 1.437                     \n",
      "3m 20s (- 0m 14s) (41800 93%) loss : 1.386                     \n",
      "3m 20s (- 0m 13s) (41900 93%) loss : 1.324                     \n",
      "3m 20s (- 0m 13s) (42000 93%) loss : 1.433                     \n",
      "3m 21s (- 0m 12s) (42100 94%) loss : 1.366                     \n",
      "3m 21s (- 0m 12s) (42200 94%) loss : 1.492                     \n",
      "3m 22s (- 0m 11s) (42300 94%) loss : 1.424                     \n",
      "3m 22s (- 0m 11s) (42400 94%) loss : 1.405                     \n",
      "3m 23s (- 0m 10s) (42500 95%) loss : 1.519                     \n",
      "3m 23s (- 0m 10s) (42600 95%) loss : 1.429                     \n",
      "3m 24s (- 0m 9s) (42700 95%) loss : 1.421                     \n",
      "3m 24s (- 0m 9s) (42800 95%) loss : 1.398                     \n",
      "3m 25s (- 0m 8s) (42900 95%) loss : 1.409                     \n",
      "3m 25s (- 0m 8s) (43000 96%) loss : 1.427                     \n",
      "3m 26s (- 0m 7s) (43100 96%) loss : 1.471                     \n",
      "3m 26s (- 0m 7s) (43200 96%) loss : 1.328                     \n",
      "3m 27s (- 0m 6s) (43300 96%) loss : 1.407                     \n",
      "3m 27s (- 0m 6s) (43400 97%) loss : 1.543                     \n",
      "3m 28s (- 0m 5s) (43500 97%) loss : 1.417                     \n",
      "3m 28s (- 0m 5s) (43600 97%) loss : 1.391                     \n",
      "3m 29s (- 0m 4s) (43700 97%) loss : 1.431                     \n",
      "3m 29s (- 0m 4s) (43800 97%) loss : 1.436                     \n",
      "3m 30s (- 0m 3s) (43900 98%) loss : 1.420                     \n",
      "3m 30s (- 0m 3s) (44000 98%) loss : 1.467                     \n",
      "3m 31s (- 0m 3s) (44100 98%) loss : 1.466                     \n",
      "3m 31s (- 0m 2s) (44200 98%) loss : 1.495                     \n",
      "3m 31s (- 0m 2s) (44300 99%) loss : 1.436                     \n",
      "3m 32s (- 0m 1s) (44400 99%) loss : 1.423                     \n",
      "3m 32s (- 0m 1s) (44500 99%) loss : 1.491                     \n",
      "3m 33s (- 0m 0s) (44600 99%) loss : 1.423                     \n",
      "3m 33s (- 0m 0s) (44700 99%) loss : 1.378                     \n",
      "0m 1s (- 0m 0s) (100 100%) loss : 1.374  accuracy : 70.0 %\n",
      "epoch 1\n",
      "0m 0s (- 3m 38s) (100 0%) loss : 1.302                     \n",
      "0m 0s (- 3m 33s) (200 0%) loss : 1.259                     \n",
      "0m 1s (- 3m 32s) (300 0%) loss : 1.297                     \n",
      "0m 1s (- 3m 31s) (400 0%) loss : 1.276                     \n",
      "0m 2s (- 3m 30s) (500 1%) loss : 1.357                     \n",
      "0m 2s (- 3m 29s) (600 1%) loss : 1.343                     \n",
      "0m 3s (- 3m 29s) (700 1%) loss : 1.306                     \n",
      "0m 3s (- 3m 31s) (800 1%) loss : 1.253                     \n",
      "0m 4s (- 3m 30s) (900 2%) loss : 1.340                     \n",
      "0m 4s (- 3m 31s) (1000 2%) loss : 1.340                     \n",
      "0m 5s (- 3m 31s) (1100 2%) loss : 1.385                     \n",
      "0m 5s (- 3m 31s) (1200 2%) loss : 1.346                     \n",
      "0m 6s (- 3m 31s) (1300 2%) loss : 1.340                     \n",
      "0m 6s (- 3m 30s) (1400 3%) loss : 1.363                     \n",
      "0m 7s (- 3m 31s) (1500 3%) loss : 1.322                     \n",
      "0m 7s (- 3m 30s) (1600 3%) loss : 1.365                     \n",
      "0m 8s (- 3m 32s) (1700 3%) loss : 1.306                     \n",
      "0m 8s (- 3m 33s) (1800 4%) loss : 1.353                     \n",
      "0m 9s (- 3m 34s) (1900 4%) loss : 1.352                     \n",
      "0m 10s (- 3m 34s) (2000 4%) loss : 1.322                     \n",
      "0m 10s (- 3m 32s) (2100 4%) loss : 1.317                     \n",
      "0m 10s (- 3m 31s) (2200 4%) loss : 1.295                     \n",
      "0m 11s (- 3m 30s) (2300 5%) loss : 1.390                     \n",
      "0m 11s (- 3m 29s) (2400 5%) loss : 1.312                     \n",
      "0m 12s (- 3m 28s) (2500 5%) loss : 1.365                     \n",
      "0m 12s (- 3m 28s) (2600 5%) loss : 1.312                     \n",
      "0m 13s (- 3m 27s) (2700 6%) loss : 1.370                     \n",
      "0m 13s (- 3m 26s) (2800 6%) loss : 1.297                     \n",
      "0m 14s (- 3m 25s) (2900 6%) loss : 1.281                     \n",
      "0m 14s (- 3m 24s) (3000 6%) loss : 1.393                     \n",
      "0m 15s (- 3m 23s) (3100 6%) loss : 1.383                     \n",
      "0m 15s (- 3m 23s) (3200 7%) loss : 1.388                     \n",
      "0m 16s (- 3m 22s) (3300 7%) loss : 1.307                     \n",
      "0m 16s (- 3m 21s) (3400 7%) loss : 1.339                     \n",
      "0m 17s (- 3m 20s) (3500 7%) loss : 1.370                     \n",
      "0m 17s (- 3m 20s) (3600 8%) loss : 1.432                     \n",
      "0m 17s (- 3m 19s) (3700 8%) loss : 1.343                     \n",
      "0m 18s (- 3m 18s) (3800 8%) loss : 1.282                     \n",
      "0m 18s (- 3m 18s) (3900 8%) loss : 1.305                     \n",
      "0m 19s (- 3m 17s) (4000 8%) loss : 1.353                     \n",
      "0m 19s (- 3m 17s) (4100 9%) loss : 1.341                     \n",
      "0m 20s (- 3m 16s) (4200 9%) loss : 1.250                     \n",
      "0m 20s (- 3m 15s) (4300 9%) loss : 1.381                     \n",
      "0m 21s (- 3m 15s) (4400 9%) loss : 1.315                     \n",
      "0m 21s (- 3m 14s) (4500 10%) loss : 1.353                     \n",
      "0m 22s (- 3m 13s) (4600 10%) loss : 1.384                     \n",
      "0m 22s (- 3m 13s) (4700 10%) loss : 1.313                     \n",
      "0m 23s (- 3m 12s) (4800 10%) loss : 1.378                     \n",
      "0m 23s (- 3m 12s) (4900 10%) loss : 1.371                     \n",
      "0m 24s (- 3m 11s) (5000 11%) loss : 1.369                     \n",
      "0m 24s (- 3m 10s) (5100 11%) loss : 1.328                     \n",
      "0m 25s (- 3m 10s) (5200 11%) loss : 1.364                     \n",
      "0m 25s (- 3m 9s) (5300 11%) loss : 1.339                     \n",
      "0m 25s (- 3m 9s) (5400 12%) loss : 1.325                     \n",
      "0m 26s (- 3m 8s) (5500 12%) loss : 1.388                     \n",
      "0m 26s (- 3m 8s) (5600 12%) loss : 1.392                     \n",
      "0m 27s (- 3m 7s) (5700 12%) loss : 1.338                     \n",
      "0m 27s (- 3m 6s) (5800 12%) loss : 1.363                     \n",
      "0m 28s (- 3m 6s) (5900 13%) loss : 1.337                     \n",
      "0m 28s (- 3m 5s) (6000 13%) loss : 1.350                     \n",
      "0m 29s (- 3m 5s) (6100 13%) loss : 1.350                     \n",
      "0m 29s (- 3m 4s) (6200 13%) loss : 1.339                     \n",
      "0m 30s (- 3m 4s) (6300 14%) loss : 1.385                     \n",
      "0m 30s (- 3m 3s) (6400 14%) loss : 1.335                     \n",
      "0m 31s (- 3m 3s) (6500 14%) loss : 1.451                     \n",
      "0m 31s (- 3m 2s) (6600 14%) loss : 1.333                     \n",
      "0m 32s (- 3m 2s) (6700 14%) loss : 1.325                     \n",
      "0m 32s (- 3m 1s) (6800 15%) loss : 1.329                     \n",
      "0m 33s (- 3m 1s) (6900 15%) loss : 1.337                     \n",
      "0m 33s (- 3m 0s) (7000 15%) loss : 1.369                     \n",
      "0m 34s (- 3m 0s) (7100 15%) loss : 1.326                     \n",
      "0m 34s (- 2m 59s) (7200 16%) loss : 1.340                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 34s (- 2m 59s) (7300 16%) loss : 1.329                     \n",
      "0m 35s (- 2m 58s) (7400 16%) loss : 1.390                     \n",
      "0m 35s (- 2m 58s) (7500 16%) loss : 1.341                     \n",
      "0m 36s (- 2m 57s) (7600 16%) loss : 1.405                     \n",
      "0m 36s (- 2m 57s) (7700 17%) loss : 1.346                     \n",
      "0m 37s (- 2m 56s) (7800 17%) loss : 1.349                     \n",
      "0m 37s (- 2m 56s) (7900 17%) loss : 1.331                     \n",
      "0m 38s (- 2m 55s) (8000 17%) loss : 1.428                     \n",
      "0m 38s (- 2m 55s) (8100 18%) loss : 1.378                     \n",
      "0m 39s (- 2m 54s) (8200 18%) loss : 1.312                     \n",
      "0m 39s (- 2m 53s) (8300 18%) loss : 1.384                     \n",
      "0m 40s (- 2m 53s) (8400 18%) loss : 1.392                     \n",
      "0m 40s (- 2m 52s) (8500 19%) loss : 1.322                     \n",
      "0m 41s (- 2m 52s) (8600 19%) loss : 1.375                     \n",
      "0m 41s (- 2m 51s) (8700 19%) loss : 1.397                     \n",
      "0m 41s (- 2m 51s) (8800 19%) loss : 1.405                     \n",
      "0m 42s (- 2m 50s) (8900 19%) loss : 1.294                     \n",
      "0m 42s (- 2m 50s) (9000 20%) loss : 1.370                     \n",
      "0m 43s (- 2m 49s) (9100 20%) loss : 1.335                     \n",
      "0m 43s (- 2m 49s) (9200 20%) loss : 1.415                     \n",
      "0m 44s (- 2m 48s) (9300 20%) loss : 1.309                     \n",
      "0m 44s (- 2m 48s) (9400 21%) loss : 1.287                     \n",
      "0m 45s (- 2m 47s) (9500 21%) loss : 1.353                     \n",
      "0m 45s (- 2m 47s) (9600 21%) loss : 1.332                     \n",
      "0m 46s (- 2m 47s) (9700 21%) loss : 1.310                     \n",
      "0m 46s (- 2m 47s) (9800 21%) loss : 1.397                     \n",
      "0m 47s (- 2m 46s) (9900 22%) loss : 1.315                     \n",
      "0m 47s (- 2m 46s) (10000 22%) loss : 1.356                     \n",
      "0m 48s (- 2m 45s) (10100 22%) loss : 1.288                     \n",
      "0m 48s (- 2m 45s) (10200 22%) loss : 1.379                     \n",
      "0m 49s (- 2m 44s) (10300 23%) loss : 1.324                     \n",
      "0m 49s (- 2m 44s) (10400 23%) loss : 1.319                     \n",
      "0m 50s (- 2m 43s) (10500 23%) loss : 1.324                     \n",
      "0m 50s (- 2m 43s) (10600 23%) loss : 1.325                     \n",
      "0m 51s (- 2m 42s) (10700 23%) loss : 1.376                     \n",
      "0m 51s (- 2m 42s) (10800 24%) loss : 1.359                     \n",
      "0m 52s (- 2m 41s) (10900 24%) loss : 1.348                     \n",
      "0m 52s (- 2m 41s) (11000 24%) loss : 1.355                     \n",
      "0m 53s (- 2m 40s) (11100 24%) loss : 1.420                     \n",
      "0m 53s (- 2m 40s) (11200 25%) loss : 1.297                     \n",
      "0m 53s (- 2m 39s) (11300 25%) loss : 1.338                     \n",
      "0m 54s (- 2m 39s) (11400 25%) loss : 1.328                     \n",
      "0m 54s (- 2m 38s) (11500 25%) loss : 1.390                     \n",
      "0m 55s (- 2m 38s) (11600 25%) loss : 1.377                     \n",
      "0m 55s (- 2m 37s) (11700 26%) loss : 1.382                     \n",
      "0m 56s (- 2m 37s) (11800 26%) loss : 1.363                     \n",
      "0m 56s (- 2m 36s) (11900 26%) loss : 1.374                     \n",
      "0m 57s (- 2m 36s) (12000 26%) loss : 1.355                     \n",
      "0m 57s (- 2m 35s) (12100 27%) loss : 1.449                     \n",
      "0m 58s (- 2m 35s) (12200 27%) loss : 1.333                     \n",
      "0m 58s (- 2m 34s) (12300 27%) loss : 1.423                     \n",
      "0m 59s (- 2m 34s) (12400 27%) loss : 1.362                     \n",
      "0m 59s (- 2m 33s) (12500 27%) loss : 1.363                     \n",
      "1m 0s (- 2m 33s) (12600 28%) loss : 1.357                     \n",
      "1m 0s (- 2m 32s) (12700 28%) loss : 1.376                     \n",
      "1m 0s (- 2m 32s) (12800 28%) loss : 1.350                     \n",
      "1m 1s (- 2m 31s) (12900 28%) loss : 1.396                     \n",
      "1m 1s (- 2m 31s) (13000 29%) loss : 1.367                     \n",
      "1m 2s (- 2m 30s) (13100 29%) loss : 1.253                     \n",
      "1m 2s (- 2m 30s) (13200 29%) loss : 1.348                     \n",
      "1m 3s (- 2m 29s) (13300 29%) loss : 1.401                     \n",
      "1m 3s (- 2m 29s) (13400 29%) loss : 1.334                     \n",
      "1m 4s (- 2m 28s) (13500 30%) loss : 1.362                     \n",
      "1m 4s (- 2m 28s) (13600 30%) loss : 1.391                     \n",
      "1m 5s (- 2m 28s) (13700 30%) loss : 1.426                     \n",
      "1m 5s (- 2m 27s) (13800 30%) loss : 1.345                     \n",
      "1m 6s (- 2m 27s) (13900 31%) loss : 1.382                     \n",
      "1m 6s (- 2m 26s) (14000 31%) loss : 1.327                     \n",
      "1m 7s (- 2m 26s) (14100 31%) loss : 1.317                     \n",
      "1m 7s (- 2m 25s) (14200 31%) loss : 1.382                     \n",
      "1m 8s (- 2m 25s) (14300 31%) loss : 1.363                     \n",
      "1m 8s (- 2m 24s) (14400 32%) loss : 1.384                     \n",
      "1m 9s (- 2m 24s) (14500 32%) loss : 1.388                     \n",
      "1m 9s (- 2m 23s) (14600 32%) loss : 1.296                     \n",
      "1m 10s (- 2m 23s) (14700 32%) loss : 1.363                     \n",
      "1m 10s (- 2m 22s) (14800 33%) loss : 1.337                     \n",
      "1m 11s (- 2m 22s) (14900 33%) loss : 1.368                     \n",
      "epoch 2\n",
      "1m 11s (- 2m 21s) (15000 33%) loss : 1.311                     \n",
      "1m 11s (- 2m 21s) (15100 33%) loss : 1.282                     \n",
      "1m 12s (- 2m 20s) (15200 33%) loss : 1.327                     \n",
      "1m 12s (- 2m 20s) (15300 34%) loss : 1.318                     \n",
      "1m 13s (- 2m 19s) (15400 34%) loss : 1.298                     \n",
      "1m 13s (- 2m 19s) (15500 34%) loss : 1.294                     \n",
      "1m 14s (- 2m 18s) (15600 34%) loss : 1.392                     \n",
      "1m 14s (- 2m 18s) (15700 35%) loss : 1.319                     \n",
      "1m 15s (- 2m 17s) (15800 35%) loss : 1.299                     \n",
      "1m 15s (- 2m 17s) (15900 35%) loss : 1.300                     \n",
      "1m 16s (- 2m 16s) (16000 35%) loss : 1.316                     \n",
      "1m 16s (- 2m 16s) (16100 35%) loss : 1.340                     \n",
      "1m 17s (- 2m 15s) (16200 36%) loss : 1.294                     \n",
      "1m 17s (- 2m 15s) (16300 36%) loss : 1.258                     \n",
      "1m 18s (- 2m 14s) (16400 36%) loss : 1.308                     \n",
      "1m 18s (- 2m 14s) (16500 36%) loss : 1.317                     \n",
      "1m 18s (- 2m 13s) (16600 37%) loss : 1.391                     \n",
      "1m 19s (- 2m 13s) (16700 37%) loss : 1.343                     \n",
      "1m 19s (- 2m 12s) (16800 37%) loss : 1.306                     \n",
      "1m 20s (- 2m 12s) (16900 37%) loss : 1.284                     \n",
      "1m 20s (- 2m 11s) (17000 38%) loss : 1.367                     \n",
      "1m 21s (- 2m 11s) (17100 38%) loss : 1.291                     \n",
      "1m 21s (- 2m 10s) (17200 38%) loss : 1.266                     \n",
      "1m 22s (- 2m 10s) (17300 38%) loss : 1.314                     \n",
      "1m 22s (- 2m 9s) (17400 38%) loss : 1.337                     \n",
      "1m 23s (- 2m 9s) (17500 39%) loss : 1.316                     \n",
      "1m 23s (- 2m 8s) (17600 39%) loss : 1.320                     \n",
      "1m 24s (- 2m 8s) (17700 39%) loss : 1.350                     \n",
      "1m 24s (- 2m 7s) (17800 39%) loss : 1.332                     \n",
      "1m 24s (- 2m 7s) (17900 40%) loss : 1.273                     \n",
      "1m 25s (- 2m 6s) (18000 40%) loss : 1.359                     \n",
      "1m 25s (- 2m 6s) (18100 40%) loss : 1.293                     \n",
      "1m 26s (- 2m 5s) (18200 40%) loss : 1.452                     \n",
      "1m 26s (- 2m 5s) (18300 40%) loss : 1.353                     \n",
      "1m 27s (- 2m 4s) (18400 41%) loss : 1.299                     \n",
      "1m 27s (- 2m 4s) (18500 41%) loss : 1.319                     \n",
      "1m 28s (- 2m 4s) (18600 41%) loss : 1.336                     \n",
      "1m 28s (- 2m 3s) (18700 41%) loss : 1.363                     \n",
      "1m 29s (- 2m 3s) (18800 42%) loss : 1.338                     \n",
      "1m 29s (- 2m 2s) (18900 42%) loss : 1.319                     \n",
      "1m 30s (- 2m 2s) (19000 42%) loss : 1.321                     \n",
      "1m 30s (- 2m 1s) (19100 42%) loss : 1.277                     \n",
      "1m 31s (- 2m 1s) (19200 42%) loss : 1.322                     \n",
      "1m 31s (- 2m 0s) (19300 43%) loss : 1.336                     \n",
      "1m 32s (- 2m 0s) (19400 43%) loss : 1.348                     \n",
      "1m 32s (- 2m 0s) (19500 43%) loss : 1.423                     \n",
      "1m 33s (- 1m 59s) (19600 43%) loss : 1.383                     \n",
      "1m 33s (- 1m 59s) (19700 44%) loss : 1.435                     \n",
      "1m 34s (- 1m 58s) (19800 44%) loss : 1.296                     \n",
      "1m 34s (- 1m 58s) (19900 44%) loss : 1.342                     \n",
      "1m 35s (- 1m 57s) (20000 44%) loss : 1.319                     \n",
      "1m 35s (- 1m 57s) (20100 44%) loss : 1.352                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 36s (- 1m 56s) (20200 45%) loss : 1.311                     \n",
      "1m 36s (- 1m 56s) (20300 45%) loss : 1.399                     \n",
      "1m 36s (- 1m 55s) (20400 45%) loss : 1.342                     \n",
      "1m 37s (- 1m 55s) (20500 45%) loss : 1.336                     \n",
      "1m 37s (- 1m 54s) (20600 46%) loss : 1.315                     \n",
      "1m 38s (- 1m 54s) (20700 46%) loss : 1.313                     \n",
      "1m 38s (- 1m 53s) (20800 46%) loss : 1.314                     \n",
      "1m 39s (- 1m 53s) (20900 46%) loss : 1.327                     \n",
      "1m 39s (- 1m 52s) (21000 46%) loss : 1.343                     \n",
      "1m 40s (- 1m 52s) (21100 47%) loss : 1.341                     \n",
      "1m 40s (- 1m 51s) (21200 47%) loss : 1.344                     \n",
      "1m 41s (- 1m 51s) (21300 47%) loss : 1.262                     \n",
      "1m 41s (- 1m 50s) (21400 47%) loss : 1.395                     \n",
      "1m 42s (- 1m 50s) (21500 48%) loss : 1.255                     \n",
      "1m 42s (- 1m 49s) (21600 48%) loss : 1.304                     \n",
      "1m 43s (- 1m 49s) (21700 48%) loss : 1.341                     \n",
      "1m 43s (- 1m 48s) (21800 48%) loss : 1.255                     \n",
      "1m 44s (- 1m 48s) (21900 48%) loss : 1.304                     \n",
      "1m 44s (- 1m 47s) (22000 49%) loss : 1.303                     \n",
      "1m 44s (- 1m 47s) (22100 49%) loss : 1.343                     \n",
      "1m 45s (- 1m 46s) (22200 49%) loss : 1.294                     \n",
      "1m 45s (- 1m 46s) (22300 49%) loss : 1.308                     \n",
      "1m 46s (- 1m 46s) (22400 50%) loss : 1.390                     \n",
      "1m 46s (- 1m 45s) (22500 50%) loss : 1.322                     \n",
      "1m 47s (- 1m 45s) (22600 50%) loss : 1.365                     \n",
      "1m 47s (- 1m 44s) (22700 50%) loss : 1.313                     \n",
      "1m 48s (- 1m 44s) (22800 50%) loss : 1.331                     \n",
      "1m 48s (- 1m 43s) (22900 51%) loss : 1.302                     \n",
      "1m 49s (- 1m 43s) (23000 51%) loss : 1.338                     \n",
      "1m 49s (- 1m 42s) (23100 51%) loss : 1.322                     \n",
      "1m 50s (- 1m 42s) (23200 51%) loss : 1.334                     \n",
      "1m 50s (- 1m 41s) (23300 52%) loss : 1.327                     \n",
      "1m 51s (- 1m 41s) (23400 52%) loss : 1.314                     \n",
      "1m 51s (- 1m 40s) (23500 52%) loss : 1.333                     \n",
      "1m 51s (- 1m 40s) (23600 52%) loss : 1.327                     \n",
      "1m 52s (- 1m 39s) (23700 52%) loss : 1.333                     \n",
      "1m 52s (- 1m 39s) (23800 53%) loss : 1.358                     \n",
      "1m 53s (- 1m 38s) (23900 53%) loss : 1.322                     \n",
      "1m 53s (- 1m 38s) (24000 53%) loss : 1.349                     \n",
      "1m 54s (- 1m 37s) (24100 53%) loss : 1.370                     \n",
      "1m 54s (- 1m 37s) (24200 54%) loss : 1.321                     \n",
      "1m 55s (- 1m 36s) (24300 54%) loss : 1.374                     \n",
      "1m 55s (- 1m 36s) (24400 54%) loss : 1.321                     \n",
      "1m 56s (- 1m 35s) (24500 54%) loss : 1.335                     \n",
      "1m 56s (- 1m 35s) (24600 55%) loss : 1.345                     \n",
      "1m 57s (- 1m 35s) (24700 55%) loss : 1.313                     \n",
      "1m 57s (- 1m 34s) (24800 55%) loss : 1.297                     \n",
      "1m 58s (- 1m 34s) (24900 55%) loss : 1.315                     \n",
      "1m 58s (- 1m 33s) (25000 55%) loss : 1.390                     \n",
      "1m 59s (- 1m 33s) (25100 56%) loss : 1.267                     \n",
      "1m 59s (- 1m 32s) (25200 56%) loss : 1.347                     \n",
      "2m 0s (- 1m 32s) (25300 56%) loss : 1.387                     \n",
      "2m 0s (- 1m 31s) (25400 56%) loss : 1.349                     \n",
      "2m 1s (- 1m 31s) (25500 57%) loss : 1.369                     \n",
      "2m 1s (- 1m 31s) (25600 57%) loss : 1.394                     \n",
      "2m 2s (- 1m 30s) (25700 57%) loss : 1.326                     \n",
      "2m 2s (- 1m 30s) (25800 57%) loss : 1.339                     \n",
      "2m 3s (- 1m 29s) (25900 57%) loss : 1.360                     \n",
      "2m 3s (- 1m 29s) (26000 58%) loss : 1.336                     \n",
      "2m 4s (- 1m 28s) (26100 58%) loss : 1.326                     \n",
      "2m 4s (- 1m 28s) (26200 58%) loss : 1.375                     \n",
      "2m 5s (- 1m 27s) (26300 58%) loss : 1.390                     \n",
      "2m 5s (- 1m 27s) (26400 59%) loss : 1.355                     \n",
      "2m 6s (- 1m 26s) (26500 59%) loss : 1.371                     \n",
      "2m 6s (- 1m 26s) (26600 59%) loss : 1.357                     \n",
      "2m 7s (- 1m 25s) (26700 59%) loss : 1.370                     \n",
      "2m 7s (- 1m 25s) (26800 59%) loss : 1.380                     \n",
      "2m 8s (- 1m 24s) (26900 60%) loss : 1.379                     \n",
      "2m 8s (- 1m 24s) (27000 60%) loss : 1.347                     \n",
      "2m 9s (- 1m 23s) (27100 60%) loss : 1.325                     \n",
      "2m 9s (- 1m 23s) (27200 60%) loss : 1.411                     \n",
      "2m 9s (- 1m 22s) (27300 61%) loss : 1.329                     \n",
      "2m 10s (- 1m 22s) (27400 61%) loss : 1.438                     \n",
      "2m 10s (- 1m 21s) (27500 61%) loss : 1.383                     \n",
      "2m 11s (- 1m 21s) (27600 61%) loss : 1.253                     \n",
      "2m 11s (- 1m 21s) (27700 61%) loss : 1.375                     \n",
      "2m 12s (- 1m 20s) (27800 62%) loss : 1.327                     \n",
      "2m 12s (- 1m 20s) (27900 62%) loss : 1.322                     \n",
      "2m 13s (- 1m 19s) (28000 62%) loss : 1.396                     \n",
      "2m 13s (- 1m 19s) (28100 62%) loss : 1.379                     \n",
      "2m 14s (- 1m 18s) (28200 63%) loss : 1.366                     \n",
      "2m 14s (- 1m 18s) (28300 63%) loss : 1.380                     \n",
      "2m 15s (- 1m 17s) (28400 63%) loss : 1.398                     \n",
      "2m 15s (- 1m 17s) (28500 63%) loss : 1.409                     \n",
      "2m 16s (- 1m 16s) (28600 63%) loss : 1.397                     \n",
      "2m 16s (- 1m 16s) (28700 64%) loss : 1.408                     \n",
      "2m 16s (- 1m 15s) (28800 64%) loss : 1.286                     \n",
      "2m 17s (- 1m 15s) (28900 64%) loss : 1.324                     \n",
      "2m 18s (- 1m 14s) (29000 64%) loss : 1.397                     \n",
      "2m 18s (- 1m 14s) (29100 65%) loss : 1.363                     \n",
      "2m 19s (- 1m 13s) (29200 65%) loss : 1.342                     \n",
      "2m 19s (- 1m 13s) (29300 65%) loss : 1.330                     \n",
      "2m 20s (- 1m 13s) (29400 65%) loss : 1.416                     \n",
      "2m 20s (- 1m 12s) (29500 65%) loss : 1.385                     \n",
      "2m 21s (- 1m 12s) (29600 66%) loss : 1.389                     \n",
      "2m 21s (- 1m 11s) (29700 66%) loss : 1.348                     \n",
      "2m 21s (- 1m 11s) (29800 66%) loss : 1.338                     \n",
      "epoch 3\n",
      "2m 22s (- 1m 10s) (29900 66%) loss : 1.307                     \n",
      "2m 22s (- 1m 10s) (30000 67%) loss : 1.351                     \n",
      "2m 23s (- 1m 9s) (30100 67%) loss : 1.311                     \n",
      "2m 23s (- 1m 9s) (30200 67%) loss : 1.286                     \n",
      "2m 24s (- 1m 8s) (30300 67%) loss : 1.340                     \n",
      "2m 24s (- 1m 8s) (30400 67%) loss : 1.264                     \n",
      "2m 25s (- 1m 7s) (30500 68%) loss : 1.318                     \n",
      "2m 25s (- 1m 7s) (30600 68%) loss : 1.332                     \n",
      "2m 26s (- 1m 6s) (30700 68%) loss : 1.290                     \n",
      "2m 26s (- 1m 6s) (30800 68%) loss : 1.329                     \n",
      "2m 27s (- 1m 5s) (30900 69%) loss : 1.286                     \n",
      "2m 27s (- 1m 5s) (31000 69%) loss : 1.254                     \n",
      "2m 28s (- 1m 4s) (31100 69%) loss : 1.323                     \n",
      "2m 28s (- 1m 4s) (31200 69%) loss : 1.365                     \n",
      "2m 28s (- 1m 3s) (31300 69%) loss : 1.305                     \n",
      "2m 29s (- 1m 3s) (31400 70%) loss : 1.297                     \n",
      "2m 30s (- 1m 2s) (31500 70%) loss : 1.341                     \n",
      "2m 30s (- 1m 2s) (31600 70%) loss : 1.321                     \n",
      "2m 31s (- 1m 2s) (31700 70%) loss : 1.312                     \n",
      "2m 31s (- 1m 1s) (31800 71%) loss : 1.309                     \n",
      "2m 32s (- 1m 1s) (31900 71%) loss : 1.331                     \n",
      "2m 32s (- 1m 0s) (32000 71%) loss : 1.319                     \n",
      "2m 33s (- 1m 0s) (32100 71%) loss : 1.271                     \n",
      "2m 33s (- 0m 59s) (32200 71%) loss : 1.341                     \n",
      "2m 33s (- 0m 59s) (32300 72%) loss : 1.228                     \n",
      "2m 34s (- 0m 58s) (32400 72%) loss : 1.334                     \n",
      "2m 34s (- 0m 58s) (32500 72%) loss : 1.302                     \n",
      "2m 35s (- 0m 57s) (32600 72%) loss : 1.323                     \n",
      "2m 35s (- 0m 57s) (32700 73%) loss : 1.314                     \n",
      "2m 36s (- 0m 56s) (32800 73%) loss : 1.264                     \n",
      "2m 36s (- 0m 56s) (32900 73%) loss : 1.317                     \n",
      "2m 37s (- 0m 55s) (33000 73%) loss : 1.260                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 37s (- 0m 55s) (33100 74%) loss : 1.319                     \n",
      "2m 38s (- 0m 54s) (33200 74%) loss : 1.250                     \n",
      "2m 38s (- 0m 54s) (33300 74%) loss : 1.319                     \n",
      "2m 39s (- 0m 53s) (33400 74%) loss : 1.338                     \n",
      "2m 39s (- 0m 53s) (33500 74%) loss : 1.312                     \n",
      "2m 40s (- 0m 52s) (33600 75%) loss : 1.341                     \n",
      "2m 40s (- 0m 52s) (33700 75%) loss : 1.376                     \n",
      "2m 40s (- 0m 52s) (33800 75%) loss : 1.303                     \n",
      "2m 41s (- 0m 51s) (33900 75%) loss : 1.366                     \n",
      "2m 41s (- 0m 51s) (34000 76%) loss : 1.280                     \n",
      "2m 42s (- 0m 50s) (34100 76%) loss : 1.386                     \n",
      "2m 42s (- 0m 50s) (34200 76%) loss : 1.324                     \n",
      "2m 43s (- 0m 49s) (34300 76%) loss : 1.372                     \n",
      "2m 43s (- 0m 49s) (34400 76%) loss : 1.271                     \n",
      "2m 44s (- 0m 48s) (34500 77%) loss : 1.342                     \n",
      "2m 44s (- 0m 48s) (34600 77%) loss : 1.336                     \n",
      "2m 45s (- 0m 47s) (34700 77%) loss : 1.329                     \n",
      "2m 45s (- 0m 47s) (34800 77%) loss : 1.303                     \n",
      "2m 46s (- 0m 46s) (34900 78%) loss : 1.275                     \n",
      "2m 46s (- 0m 46s) (35000 78%) loss : 1.307                     \n",
      "2m 47s (- 0m 45s) (35100 78%) loss : 1.330                     \n",
      "2m 47s (- 0m 45s) (35200 78%) loss : 1.335                     \n",
      "2m 48s (- 0m 44s) (35300 78%) loss : 1.402                     \n",
      "2m 48s (- 0m 44s) (35400 79%) loss : 1.322                     \n",
      "2m 48s (- 0m 43s) (35500 79%) loss : 1.325                     \n",
      "2m 49s (- 0m 43s) (35600 79%) loss : 1.381                     \n",
      "2m 49s (- 0m 42s) (35700 79%) loss : 1.417                     \n",
      "2m 50s (- 0m 42s) (35800 80%) loss : 1.313                     \n",
      "2m 50s (- 0m 41s) (35900 80%) loss : 1.388                     \n",
      "2m 51s (- 0m 41s) (36000 80%) loss : 1.307                     \n",
      "2m 51s (- 0m 41s) (36100 80%) loss : 1.293                     \n",
      "2m 52s (- 0m 40s) (36200 80%) loss : 1.266                     \n",
      "2m 52s (- 0m 40s) (36300 81%) loss : 1.336                     \n",
      "2m 53s (- 0m 39s) (36400 81%) loss : 1.401                     \n",
      "2m 53s (- 0m 39s) (36500 81%) loss : 1.363                     \n",
      "2m 54s (- 0m 38s) (36600 81%) loss : 1.297                     \n",
      "2m 54s (- 0m 38s) (36700 82%) loss : 1.325                     \n",
      "2m 55s (- 0m 37s) (36800 82%) loss : 1.368                     \n",
      "2m 55s (- 0m 37s) (36900 82%) loss : 1.371                     \n",
      "2m 55s (- 0m 36s) (37000 82%) loss : 1.341                     \n",
      "2m 56s (- 0m 36s) (37100 82%) loss : 1.361                     \n",
      "2m 56s (- 0m 35s) (37200 83%) loss : 1.347                     \n",
      "2m 57s (- 0m 35s) (37300 83%) loss : 1.314                     \n",
      "2m 57s (- 0m 34s) (37400 83%) loss : 1.371                     \n",
      "2m 58s (- 0m 34s) (37500 83%) loss : 1.361                     \n",
      "2m 58s (- 0m 33s) (37600 84%) loss : 1.259                     \n",
      "2m 59s (- 0m 33s) (37700 84%) loss : 1.353                     \n",
      "2m 59s (- 0m 32s) (37800 84%) loss : 1.322                     \n",
      "3m 0s (- 0m 32s) (37900 84%) loss : 1.338                     \n",
      "3m 0s (- 0m 31s) (38000 84%) loss : 1.313                     \n",
      "3m 1s (- 0m 31s) (38100 85%) loss : 1.337                     \n",
      "3m 1s (- 0m 31s) (38200 85%) loss : 1.310                     \n",
      "3m 2s (- 0m 30s) (38300 85%) loss : 1.337                     \n",
      "3m 2s (- 0m 30s) (38400 85%) loss : 1.366                     \n",
      "3m 2s (- 0m 29s) (38500 86%) loss : 1.310                     \n",
      "3m 3s (- 0m 29s) (38600 86%) loss : 1.302                     \n",
      "3m 3s (- 0m 28s) (38700 86%) loss : 1.345                     \n",
      "3m 4s (- 0m 28s) (38800 86%) loss : 1.345                     \n",
      "3m 4s (- 0m 27s) (38900 86%) loss : 1.306                     \n",
      "3m 5s (- 0m 27s) (39000 87%) loss : 1.337                     \n",
      "3m 5s (- 0m 26s) (39100 87%) loss : 1.310                     \n",
      "3m 6s (- 0m 26s) (39200 87%) loss : 1.319                     \n",
      "3m 6s (- 0m 25s) (39300 87%) loss : 1.384                     \n",
      "3m 7s (- 0m 25s) (39400 88%) loss : 1.355                     \n",
      "3m 7s (- 0m 24s) (39500 88%) loss : 1.378                     \n",
      "3m 8s (- 0m 24s) (39600 88%) loss : 1.334                     \n",
      "3m 8s (- 0m 23s) (39700 88%) loss : 1.375                     \n",
      "3m 9s (- 0m 23s) (39800 88%) loss : 1.315                     \n",
      "3m 9s (- 0m 22s) (39900 89%) loss : 1.332                     \n",
      "3m 10s (- 0m 22s) (40000 89%) loss : 1.419                     \n",
      "3m 10s (- 0m 21s) (40100 89%) loss : 1.383                     \n",
      "3m 11s (- 0m 21s) (40200 89%) loss : 1.344                     \n",
      "3m 11s (- 0m 21s) (40300 90%) loss : 1.348                     \n",
      "3m 12s (- 0m 20s) (40400 90%) loss : 1.365                     \n",
      "3m 12s (- 0m 20s) (40500 90%) loss : 1.354                     \n",
      "3m 13s (- 0m 19s) (40600 90%) loss : 1.326                     \n",
      "3m 13s (- 0m 19s) (40700 90%) loss : 1.392                     \n",
      "3m 14s (- 0m 18s) (40800 91%) loss : 1.326                     \n",
      "3m 14s (- 0m 18s) (40900 91%) loss : 1.324                     \n",
      "3m 15s (- 0m 17s) (41000 91%) loss : 1.382                     \n",
      "3m 15s (- 0m 17s) (41100 91%) loss : 1.352                     \n",
      "3m 16s (- 0m 16s) (41200 92%) loss : 1.365                     \n",
      "3m 16s (- 0m 16s) (41300 92%) loss : 1.274                     \n",
      "3m 17s (- 0m 15s) (41400 92%) loss : 1.325                     \n",
      "3m 17s (- 0m 15s) (41500 92%) loss : 1.392                     \n",
      "3m 17s (- 0m 14s) (41600 93%) loss : 1.337                     \n",
      "3m 18s (- 0m 14s) (41700 93%) loss : 1.351                     \n",
      "3m 19s (- 0m 13s) (41800 93%) loss : 1.349                     \n",
      "3m 19s (- 0m 13s) (41900 93%) loss : 1.336                     \n",
      "3m 20s (- 0m 12s) (42000 93%) loss : 1.355                     \n",
      "3m 20s (- 0m 12s) (42100 94%) loss : 1.393                     \n",
      "3m 21s (- 0m 12s) (42200 94%) loss : 1.268                     \n",
      "3m 21s (- 0m 11s) (42300 94%) loss : 1.329                     \n",
      "3m 21s (- 0m 11s) (42400 94%) loss : 1.340                     \n",
      "3m 22s (- 0m 10s) (42500 95%) loss : 1.327                     \n",
      "3m 22s (- 0m 10s) (42600 95%) loss : 1.306                     \n",
      "3m 23s (- 0m 9s) (42700 95%) loss : 1.319                     \n",
      "3m 23s (- 0m 9s) (42800 95%) loss : 1.353                     \n",
      "3m 24s (- 0m 8s) (42900 95%) loss : 1.358                     \n",
      "3m 24s (- 0m 8s) (43000 96%) loss : 1.355                     \n",
      "3m 25s (- 0m 7s) (43100 96%) loss : 1.325                     \n",
      "3m 25s (- 0m 7s) (43200 96%) loss : 1.290                     \n",
      "3m 26s (- 0m 6s) (43300 96%) loss : 1.330                     \n",
      "3m 26s (- 0m 6s) (43400 97%) loss : 1.426                     \n",
      "3m 27s (- 0m 5s) (43500 97%) loss : 1.373                     \n",
      "3m 27s (- 0m 5s) (43600 97%) loss : 1.287                     \n",
      "3m 28s (- 0m 4s) (43700 97%) loss : 1.305                     \n",
      "3m 28s (- 0m 4s) (43800 97%) loss : 1.361                     \n",
      "3m 29s (- 0m 3s) (43900 98%) loss : 1.283                     \n",
      "3m 29s (- 0m 3s) (44000 98%) loss : 1.361                     \n",
      "3m 30s (- 0m 2s) (44100 98%) loss : 1.280                     \n",
      "3m 30s (- 0m 2s) (44200 98%) loss : 1.249                     \n",
      "3m 30s (- 0m 2s) (44300 99%) loss : 1.331                     \n",
      "3m 31s (- 0m 1s) (44400 99%) loss : 1.368                     \n",
      "3m 31s (- 0m 1s) (44500 99%) loss : 1.360                     \n",
      "3m 32s (- 0m 0s) (44600 99%) loss : 1.342                     \n",
      "3m 32s (- 0m 0s) (44700 99%) loss : 1.379                     \n",
      "0m 1s (- 0m 0s) (100 100%) loss : 1.243  accuracy : 72.8 %\n",
      "epoch 1\n",
      "0m 0s (- 3m 38s) (100 0%) loss : 1.307                     \n",
      "0m 0s (- 3m 36s) (200 0%) loss : 1.336                     \n",
      "0m 1s (- 3m 32s) (300 0%) loss : 1.320                     \n",
      "0m 1s (- 3m 29s) (400 0%) loss : 1.371                     \n",
      "0m 2s (- 3m 31s) (500 1%) loss : 1.285                     \n",
      "0m 2s (- 3m 32s) (600 1%) loss : 1.371                     \n",
      "0m 3s (- 3m 32s) (700 1%) loss : 1.291                     \n",
      "0m 3s (- 3m 31s) (800 1%) loss : 1.259                     \n",
      "0m 4s (- 3m 31s) (900 2%) loss : 1.288                     \n",
      "0m 4s (- 3m 30s) (1000 2%) loss : 1.329                     \n",
      "0m 5s (- 3m 29s) (1100 2%) loss : 1.249                     \n",
      "0m 5s (- 3m 28s) (1200 2%) loss : 1.274                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 6s (- 3m 28s) (1300 2%) loss : 1.324                     \n",
      "0m 6s (- 3m 27s) (1400 3%) loss : 1.277                     \n",
      "0m 7s (- 3m 28s) (1500 3%) loss : 1.255                     \n",
      "0m 7s (- 3m 27s) (1600 3%) loss : 1.327                     \n",
      "0m 8s (- 3m 27s) (1700 3%) loss : 1.297                     \n",
      "0m 8s (- 3m 26s) (1800 4%) loss : 1.365                     \n",
      "0m 9s (- 3m 25s) (1900 4%) loss : 1.283                     \n",
      "0m 9s (- 3m 24s) (2000 4%) loss : 1.279                     \n",
      "0m 10s (- 3m 24s) (2100 4%) loss : 1.291                     \n",
      "0m 10s (- 3m 23s) (2200 4%) loss : 1.273                     \n",
      "0m 11s (- 3m 23s) (2300 5%) loss : 1.282                     \n",
      "0m 11s (- 3m 22s) (2400 5%) loss : 1.227                     \n",
      "0m 12s (- 3m 22s) (2500 5%) loss : 1.272                     \n",
      "0m 12s (- 3m 22s) (2600 5%) loss : 1.305                     \n",
      "0m 13s (- 3m 22s) (2700 6%) loss : 1.321                     \n",
      "0m 13s (- 3m 22s) (2800 6%) loss : 1.287                     \n",
      "0m 14s (- 3m 22s) (2900 6%) loss : 1.270                     \n",
      "0m 14s (- 3m 24s) (3000 6%) loss : 1.291                     \n",
      "0m 15s (- 3m 24s) (3100 6%) loss : 1.347                     \n",
      "0m 15s (- 3m 23s) (3200 7%) loss : 1.299                     \n",
      "0m 16s (- 3m 22s) (3300 7%) loss : 1.318                     \n",
      "0m 16s (- 3m 22s) (3400 7%) loss : 1.264                     \n",
      "0m 17s (- 3m 22s) (3500 7%) loss : 1.274                     \n",
      "0m 17s (- 3m 22s) (3600 8%) loss : 1.288                     \n",
      "0m 18s (- 3m 22s) (3700 8%) loss : 1.206                     \n",
      "0m 18s (- 3m 21s) (3800 8%) loss : 1.290                     \n",
      "0m 19s (- 3m 20s) (3900 8%) loss : 1.312                     \n",
      "0m 19s (- 3m 20s) (4000 8%) loss : 1.318                     \n",
      "0m 20s (- 3m 20s) (4100 9%) loss : 1.271                     \n",
      "0m 20s (- 3m 19s) (4200 9%) loss : 1.254                     \n",
      "0m 21s (- 3m 18s) (4300 9%) loss : 1.239                     \n",
      "0m 21s (- 3m 17s) (4400 9%) loss : 1.287                     \n",
      "0m 22s (- 3m 17s) (4500 10%) loss : 1.348                     \n",
      "0m 22s (- 3m 17s) (4600 10%) loss : 1.289                     \n",
      "0m 23s (- 3m 16s) (4700 10%) loss : 1.229                     \n",
      "0m 23s (- 3m 15s) (4800 10%) loss : 1.339                     \n",
      "0m 23s (- 3m 15s) (4900 10%) loss : 1.331                     \n",
      "0m 24s (- 3m 14s) (5000 11%) loss : 1.313                     \n",
      "0m 24s (- 3m 13s) (5100 11%) loss : 1.313                     \n",
      "0m 25s (- 3m 12s) (5200 11%) loss : 1.298                     \n",
      "0m 25s (- 3m 12s) (5300 11%) loss : 1.310                     \n",
      "0m 26s (- 3m 11s) (5400 12%) loss : 1.329                     \n",
      "0m 26s (- 3m 11s) (5500 12%) loss : 1.307                     \n",
      "0m 27s (- 3m 10s) (5600 12%) loss : 1.315                     \n",
      "0m 27s (- 3m 9s) (5700 12%) loss : 1.264                     \n",
      "0m 28s (- 3m 9s) (5800 12%) loss : 1.260                     \n",
      "0m 28s (- 3m 9s) (5900 13%) loss : 1.330                     \n",
      "0m 29s (- 3m 8s) (6000 13%) loss : 1.312                     \n",
      "0m 29s (- 3m 7s) (6100 13%) loss : 1.345                     \n",
      "0m 30s (- 3m 7s) (6200 13%) loss : 1.290                     \n",
      "0m 30s (- 3m 6s) (6300 14%) loss : 1.320                     \n",
      "0m 31s (- 3m 6s) (6400 14%) loss : 1.269                     \n",
      "0m 31s (- 3m 5s) (6500 14%) loss : 1.264                     \n",
      "0m 31s (- 3m 4s) (6600 14%) loss : 1.248                     \n",
      "0m 32s (- 3m 4s) (6700 14%) loss : 1.347                     \n",
      "0m 32s (- 3m 3s) (6800 15%) loss : 1.323                     \n",
      "0m 33s (- 3m 3s) (6900 15%) loss : 1.361                     \n",
      "0m 33s (- 3m 2s) (7000 15%) loss : 1.313                     \n",
      "0m 34s (- 3m 1s) (7100 15%) loss : 1.226                     \n",
      "0m 34s (- 3m 1s) (7200 16%) loss : 1.278                     \n",
      "0m 35s (- 3m 0s) (7300 16%) loss : 1.223                     \n",
      "0m 35s (- 3m 0s) (7400 16%) loss : 1.201                     \n",
      "0m 36s (- 2m 59s) (7500 16%) loss : 1.343                     \n",
      "0m 36s (- 2m 59s) (7600 16%) loss : 1.272                     \n",
      "0m 37s (- 2m 58s) (7700 17%) loss : 1.286                     \n",
      "0m 37s (- 2m 58s) (7800 17%) loss : 1.316                     \n",
      "0m 38s (- 2m 57s) (7900 17%) loss : 1.289                     \n",
      "0m 38s (- 2m 57s) (8000 17%) loss : 1.315                     \n",
      "0m 39s (- 2m 56s) (8100 18%) loss : 1.286                     \n",
      "0m 39s (- 2m 55s) (8200 18%) loss : 1.314                     \n",
      "0m 39s (- 2m 55s) (8300 18%) loss : 1.341                     \n",
      "0m 40s (- 2m 54s) (8400 18%) loss : 1.340                     \n",
      "0m 40s (- 2m 54s) (8500 19%) loss : 1.339                     \n",
      "0m 41s (- 2m 53s) (8600 19%) loss : 1.318                     \n",
      "0m 41s (- 2m 53s) (8700 19%) loss : 1.261                     \n",
      "0m 42s (- 2m 52s) (8800 19%) loss : 1.321                     \n",
      "0m 42s (- 2m 52s) (8900 19%) loss : 1.371                     \n",
      "0m 43s (- 2m 51s) (9000 20%) loss : 1.366                     \n",
      "0m 43s (- 2m 51s) (9100 20%) loss : 1.359                     \n",
      "0m 44s (- 2m 50s) (9200 20%) loss : 1.277                     \n",
      "0m 44s (- 2m 50s) (9300 20%) loss : 1.286                     \n",
      "0m 45s (- 2m 49s) (9400 21%) loss : 1.336                     \n",
      "0m 45s (- 2m 49s) (9500 21%) loss : 1.378                     \n",
      "0m 46s (- 2m 48s) (9600 21%) loss : 1.318                     \n",
      "0m 46s (- 2m 48s) (9700 21%) loss : 1.292                     \n",
      "0m 46s (- 2m 47s) (9800 21%) loss : 1.279                     \n",
      "0m 47s (- 2m 46s) (9900 22%) loss : 1.282                     \n",
      "0m 47s (- 2m 46s) (10000 22%) loss : 1.258                     \n",
      "0m 48s (- 2m 45s) (10100 22%) loss : 1.274                     \n",
      "0m 48s (- 2m 45s) (10200 22%) loss : 1.268                     \n",
      "0m 49s (- 2m 44s) (10300 23%) loss : 1.303                     \n",
      "0m 49s (- 2m 44s) (10400 23%) loss : 1.242                     \n",
      "0m 50s (- 2m 43s) (10500 23%) loss : 1.350                     \n",
      "0m 50s (- 2m 43s) (10600 23%) loss : 1.268                     \n",
      "0m 51s (- 2m 42s) (10700 23%) loss : 1.333                     \n",
      "0m 51s (- 2m 42s) (10800 24%) loss : 1.333                     \n",
      "0m 52s (- 2m 41s) (10900 24%) loss : 1.336                     \n",
      "0m 52s (- 2m 41s) (11000 24%) loss : 1.289                     \n",
      "0m 53s (- 2m 40s) (11100 24%) loss : 1.368                     \n",
      "0m 53s (- 2m 40s) (11200 25%) loss : 1.357                     \n",
      "0m 53s (- 2m 39s) (11300 25%) loss : 1.277                     \n",
      "0m 54s (- 2m 39s) (11400 25%) loss : 1.306                     \n",
      "0m 54s (- 2m 38s) (11500 25%) loss : 1.292                     \n",
      "0m 55s (- 2m 38s) (11600 25%) loss : 1.251                     \n",
      "0m 55s (- 2m 37s) (11700 26%) loss : 1.279                     \n",
      "0m 56s (- 2m 37s) (11800 26%) loss : 1.299                     \n",
      "0m 56s (- 2m 36s) (11900 26%) loss : 1.221                     \n",
      "0m 57s (- 2m 36s) (12000 26%) loss : 1.250                     \n",
      "0m 57s (- 2m 35s) (12100 27%) loss : 1.308                     \n",
      "0m 58s (- 2m 35s) (12200 27%) loss : 1.318                     \n",
      "0m 58s (- 2m 34s) (12300 27%) loss : 1.244                     \n",
      "0m 59s (- 2m 34s) (12400 27%) loss : 1.283                     \n",
      "0m 59s (- 2m 33s) (12500 27%) loss : 1.288                     \n",
      "1m 0s (- 2m 33s) (12600 28%) loss : 1.315                     \n",
      "1m 0s (- 2m 32s) (12700 28%) loss : 1.332                     \n",
      "1m 0s (- 2m 32s) (12800 28%) loss : 1.290                     \n",
      "1m 1s (- 2m 31s) (12900 28%) loss : 1.276                     \n",
      "1m 1s (- 2m 31s) (13000 29%) loss : 1.263                     \n",
      "1m 2s (- 2m 30s) (13100 29%) loss : 1.283                     \n",
      "1m 2s (- 2m 30s) (13200 29%) loss : 1.306                     \n",
      "1m 3s (- 2m 29s) (13300 29%) loss : 1.357                     \n",
      "1m 3s (- 2m 29s) (13400 29%) loss : 1.239                     \n",
      "1m 4s (- 2m 28s) (13500 30%) loss : 1.317                     \n",
      "1m 4s (- 2m 28s) (13600 30%) loss : 1.278                     \n",
      "1m 5s (- 2m 27s) (13700 30%) loss : 1.334                     \n",
      "1m 5s (- 2m 27s) (13800 30%) loss : 1.223                     \n",
      "1m 6s (- 2m 26s) (13900 31%) loss : 1.316                     \n",
      "1m 6s (- 2m 26s) (14000 31%) loss : 1.386                     \n",
      "1m 7s (- 2m 25s) (14100 31%) loss : 1.317                     \n",
      "1m 7s (- 2m 25s) (14200 31%) loss : 1.332                     \n",
      "1m 7s (- 2m 24s) (14300 31%) loss : 1.340                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 8s (- 2m 24s) (14400 32%) loss : 1.331                     \n",
      "1m 8s (- 2m 23s) (14500 32%) loss : 1.310                     \n",
      "1m 9s (- 2m 23s) (14600 32%) loss : 1.289                     \n",
      "1m 9s (- 2m 22s) (14700 32%) loss : 1.308                     \n",
      "1m 10s (- 2m 22s) (14800 33%) loss : 1.315                     \n",
      "1m 10s (- 2m 21s) (14900 33%) loss : 1.345                     \n",
      "epoch 2\n",
      "1m 11s (- 2m 21s) (15000 33%) loss : 1.233                     \n",
      "1m 11s (- 2m 20s) (15100 33%) loss : 1.283                     \n",
      "1m 12s (- 2m 20s) (15200 33%) loss : 1.257                     \n",
      "1m 12s (- 2m 19s) (15300 34%) loss : 1.274                     \n",
      "1m 13s (- 2m 19s) (15400 34%) loss : 1.241                     \n",
      "1m 13s (- 2m 18s) (15500 34%) loss : 1.320                     \n",
      "1m 14s (- 2m 18s) (15600 34%) loss : 1.154                     \n",
      "1m 14s (- 2m 17s) (15700 35%) loss : 1.317                     \n",
      "1m 15s (- 2m 17s) (15800 35%) loss : 1.244                     \n",
      "1m 15s (- 2m 16s) (15900 35%) loss : 1.287                     \n",
      "1m 15s (- 2m 16s) (16000 35%) loss : 1.233                     \n",
      "1m 16s (- 2m 15s) (16100 35%) loss : 1.273                     \n",
      "1m 16s (- 2m 15s) (16200 36%) loss : 1.303                     \n",
      "1m 17s (- 2m 14s) (16300 36%) loss : 1.321                     \n",
      "1m 17s (- 2m 14s) (16400 36%) loss : 1.256                     \n",
      "1m 18s (- 2m 13s) (16500 36%) loss : 1.251                     \n",
      "1m 18s (- 2m 13s) (16600 37%) loss : 1.371                     \n",
      "1m 19s (- 2m 13s) (16700 37%) loss : 1.279                     \n",
      "1m 19s (- 2m 12s) (16800 37%) loss : 1.281                     \n",
      "1m 20s (- 2m 12s) (16900 37%) loss : 1.265                     \n",
      "1m 20s (- 2m 11s) (17000 38%) loss : 1.300                     \n",
      "1m 21s (- 2m 11s) (17100 38%) loss : 1.316                     \n",
      "1m 21s (- 2m 10s) (17200 38%) loss : 1.338                     \n",
      "1m 22s (- 2m 10s) (17300 38%) loss : 1.279                     \n",
      "1m 22s (- 2m 9s) (17400 38%) loss : 1.279                     \n",
      "1m 23s (- 2m 9s) (17500 39%) loss : 1.337                     \n",
      "1m 23s (- 2m 8s) (17600 39%) loss : 1.339                     \n",
      "1m 23s (- 2m 8s) (17700 39%) loss : 1.305                     \n",
      "1m 24s (- 2m 7s) (17800 39%) loss : 1.304                     \n",
      "1m 24s (- 2m 7s) (17900 40%) loss : 1.311                     \n",
      "1m 25s (- 2m 6s) (18000 40%) loss : 1.292                     \n",
      "1m 25s (- 2m 6s) (18100 40%) loss : 1.270                     \n",
      "1m 26s (- 2m 5s) (18200 40%) loss : 1.363                     \n",
      "1m 26s (- 2m 5s) (18300 40%) loss : 1.287                     \n",
      "1m 27s (- 2m 4s) (18400 41%) loss : 1.270                     \n",
      "1m 27s (- 2m 4s) (18500 41%) loss : 1.235                     \n",
      "1m 28s (- 2m 3s) (18600 41%) loss : 1.302                     \n",
      "1m 28s (- 2m 3s) (18700 41%) loss : 1.259                     \n",
      "1m 29s (- 2m 2s) (18800 42%) loss : 1.291                     \n",
      "1m 29s (- 2m 2s) (18900 42%) loss : 1.296                     \n",
      "1m 30s (- 2m 1s) (19000 42%) loss : 1.299                     \n",
      "1m 30s (- 2m 1s) (19100 42%) loss : 1.274                     \n",
      "1m 30s (- 2m 0s) (19200 42%) loss : 1.358                     \n",
      "1m 31s (- 2m 0s) (19300 43%) loss : 1.260                     \n",
      "1m 31s (- 1m 59s) (19400 43%) loss : 1.307                     \n",
      "1m 32s (- 1m 59s) (19500 43%) loss : 1.312                     \n",
      "1m 32s (- 1m 58s) (19600 43%) loss : 1.299                     \n",
      "1m 33s (- 1m 58s) (19700 44%) loss : 1.304                     \n",
      "1m 33s (- 1m 58s) (19800 44%) loss : 1.316                     \n",
      "1m 34s (- 1m 57s) (19900 44%) loss : 1.323                     \n",
      "1m 34s (- 1m 57s) (20000 44%) loss : 1.285                     \n",
      "1m 35s (- 1m 56s) (20100 44%) loss : 1.238                     \n",
      "1m 35s (- 1m 56s) (20200 45%) loss : 1.258                     \n",
      "1m 36s (- 1m 55s) (20300 45%) loss : 1.199                     \n",
      "1m 36s (- 1m 55s) (20400 45%) loss : 1.332                     \n",
      "1m 37s (- 1m 54s) (20500 45%) loss : 1.318                     \n",
      "1m 37s (- 1m 54s) (20600 46%) loss : 1.271                     \n",
      "1m 37s (- 1m 53s) (20700 46%) loss : 1.320                     \n",
      "1m 38s (- 1m 53s) (20800 46%) loss : 1.307                     \n",
      "1m 38s (- 1m 52s) (20900 46%) loss : 1.277                     \n",
      "1m 39s (- 1m 52s) (21000 46%) loss : 1.294                     \n",
      "1m 39s (- 1m 51s) (21100 47%) loss : 1.305                     \n",
      "1m 40s (- 1m 51s) (21200 47%) loss : 1.295                     \n",
      "1m 40s (- 1m 50s) (21300 47%) loss : 1.266                     \n",
      "1m 41s (- 1m 50s) (21400 47%) loss : 1.312                     \n",
      "1m 41s (- 1m 49s) (21500 48%) loss : 1.310                     \n",
      "1m 42s (- 1m 49s) (21600 48%) loss : 1.315                     \n",
      "1m 42s (- 1m 48s) (21700 48%) loss : 1.283                     \n",
      "1m 43s (- 1m 48s) (21800 48%) loss : 1.250                     \n",
      "1m 43s (- 1m 48s) (21900 48%) loss : 1.340                     \n",
      "1m 44s (- 1m 47s) (22000 49%) loss : 1.284                     \n",
      "1m 44s (- 1m 47s) (22100 49%) loss : 1.380                     \n",
      "1m 45s (- 1m 46s) (22200 49%) loss : 1.291                     \n",
      "1m 45s (- 1m 46s) (22300 49%) loss : 1.229                     \n",
      "1m 45s (- 1m 45s) (22400 50%) loss : 1.269                     \n",
      "1m 46s (- 1m 45s) (22500 50%) loss : 1.272                     \n",
      "1m 46s (- 1m 44s) (22600 50%) loss : 1.304                     \n",
      "1m 47s (- 1m 44s) (22700 50%) loss : 1.272                     \n",
      "1m 47s (- 1m 43s) (22800 50%) loss : 1.267                     \n",
      "1m 48s (- 1m 43s) (22900 51%) loss : 1.312                     \n",
      "1m 48s (- 1m 42s) (23000 51%) loss : 1.257                     \n",
      "1m 49s (- 1m 42s) (23100 51%) loss : 1.340                     \n",
      "1m 49s (- 1m 41s) (23200 51%) loss : 1.288                     \n",
      "1m 50s (- 1m 41s) (23300 52%) loss : 1.271                     \n",
      "1m 50s (- 1m 40s) (23400 52%) loss : 1.270                     \n",
      "1m 51s (- 1m 40s) (23500 52%) loss : 1.318                     \n",
      "1m 51s (- 1m 39s) (23600 52%) loss : 1.238                     \n",
      "1m 52s (- 1m 39s) (23700 52%) loss : 1.308                     \n",
      "1m 52s (- 1m 38s) (23800 53%) loss : 1.237                     \n",
      "1m 53s (- 1m 38s) (23900 53%) loss : 1.387                     \n",
      "1m 53s (- 1m 37s) (24000 53%) loss : 1.293                     \n",
      "1m 53s (- 1m 37s) (24100 53%) loss : 1.322                     \n",
      "1m 54s (- 1m 37s) (24200 54%) loss : 1.301                     \n",
      "1m 54s (- 1m 36s) (24300 54%) loss : 1.277                     \n",
      "1m 55s (- 1m 36s) (24400 54%) loss : 1.282                     \n",
      "1m 55s (- 1m 35s) (24500 54%) loss : 1.335                     \n",
      "1m 56s (- 1m 35s) (24600 55%) loss : 1.230                     \n",
      "1m 56s (- 1m 34s) (24700 55%) loss : 1.280                     \n",
      "1m 57s (- 1m 34s) (24800 55%) loss : 1.359                     \n",
      "1m 57s (- 1m 33s) (24900 55%) loss : 1.269                     \n",
      "1m 58s (- 1m 33s) (25000 55%) loss : 1.300                     \n",
      "1m 58s (- 1m 32s) (25100 56%) loss : 1.211                     \n",
      "1m 59s (- 1m 32s) (25200 56%) loss : 1.340                     \n",
      "1m 59s (- 1m 31s) (25300 56%) loss : 1.297                     \n",
      "2m 0s (- 1m 31s) (25400 56%) loss : 1.285                     \n",
      "2m 0s (- 1m 30s) (25500 57%) loss : 1.342                     \n",
      "2m 1s (- 1m 30s) (25600 57%) loss : 1.335                     \n",
      "2m 1s (- 1m 30s) (25700 57%) loss : 1.349                     \n",
      "2m 2s (- 1m 29s) (25800 57%) loss : 1.296                     \n",
      "2m 2s (- 1m 29s) (25900 57%) loss : 1.338                     \n",
      "2m 3s (- 1m 28s) (26000 58%) loss : 1.281                     \n",
      "2m 3s (- 1m 28s) (26100 58%) loss : 1.277                     \n",
      "2m 3s (- 1m 27s) (26200 58%) loss : 1.249                     \n",
      "2m 4s (- 1m 27s) (26300 58%) loss : 1.251                     \n",
      "2m 4s (- 1m 26s) (26400 59%) loss : 1.342                     \n",
      "2m 5s (- 1m 26s) (26500 59%) loss : 1.338                     \n",
      "2m 5s (- 1m 25s) (26600 59%) loss : 1.331                     \n",
      "2m 6s (- 1m 25s) (26700 59%) loss : 1.277                     \n",
      "2m 6s (- 1m 24s) (26800 59%) loss : 1.316                     \n",
      "2m 7s (- 1m 24s) (26900 60%) loss : 1.297                     \n",
      "2m 7s (- 1m 23s) (27000 60%) loss : 1.321                     \n",
      "2m 8s (- 1m 23s) (27100 60%) loss : 1.305                     \n",
      "2m 8s (- 1m 22s) (27200 60%) loss : 1.304                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 9s (- 1m 22s) (27300 61%) loss : 1.294                     \n",
      "2m 9s (- 1m 22s) (27400 61%) loss : 1.287                     \n",
      "2m 10s (- 1m 21s) (27500 61%) loss : 1.305                     \n",
      "2m 10s (- 1m 21s) (27600 61%) loss : 1.300                     \n",
      "2m 11s (- 1m 20s) (27700 61%) loss : 1.255                     \n",
      "2m 11s (- 1m 20s) (27800 62%) loss : 1.285                     \n",
      "2m 12s (- 1m 19s) (27900 62%) loss : 1.268                     \n",
      "2m 12s (- 1m 19s) (28000 62%) loss : 1.380                     \n",
      "2m 13s (- 1m 18s) (28100 62%) loss : 1.319                     \n",
      "2m 13s (- 1m 18s) (28200 63%) loss : 1.340                     \n",
      "2m 14s (- 1m 17s) (28300 63%) loss : 1.253                     \n",
      "2m 14s (- 1m 17s) (28400 63%) loss : 1.273                     \n",
      "2m 15s (- 1m 17s) (28500 63%) loss : 1.344                     \n",
      "2m 15s (- 1m 16s) (28600 63%) loss : 1.335                     \n",
      "2m 16s (- 1m 16s) (28700 64%) loss : 1.334                     \n",
      "2m 16s (- 1m 15s) (28800 64%) loss : 1.343                     \n",
      "2m 17s (- 1m 15s) (28900 64%) loss : 1.300                     \n",
      "2m 17s (- 1m 14s) (29000 64%) loss : 1.333                     \n",
      "2m 18s (- 1m 14s) (29100 65%) loss : 1.319                     \n",
      "2m 18s (- 1m 13s) (29200 65%) loss : 1.280                     \n",
      "2m 19s (- 1m 13s) (29300 65%) loss : 1.293                     \n",
      "2m 19s (- 1m 12s) (29400 65%) loss : 1.298                     \n",
      "2m 19s (- 1m 12s) (29500 65%) loss : 1.345                     \n",
      "2m 20s (- 1m 11s) (29600 66%) loss : 1.319                     \n",
      "2m 20s (- 1m 11s) (29700 66%) loss : 1.335                     \n",
      "2m 21s (- 1m 10s) (29800 66%) loss : 1.310                     \n",
      "epoch 3\n",
      "2m 21s (- 1m 10s) (29900 66%) loss : 1.260                     \n",
      "2m 22s (- 1m 9s) (30000 67%) loss : 1.311                     \n",
      "2m 22s (- 1m 9s) (30100 67%) loss : 1.287                     \n",
      "2m 23s (- 1m 8s) (30200 67%) loss : 1.210                     \n",
      "2m 23s (- 1m 8s) (30300 67%) loss : 1.295                     \n",
      "2m 24s (- 1m 7s) (30400 67%) loss : 1.263                     \n",
      "2m 24s (- 1m 7s) (30500 68%) loss : 1.273                     \n",
      "2m 25s (- 1m 6s) (30600 68%) loss : 1.275                     \n",
      "2m 25s (- 1m 6s) (30700 68%) loss : 1.253                     \n",
      "2m 25s (- 1m 6s) (30800 68%) loss : 1.283                     \n",
      "2m 26s (- 1m 5s) (30900 69%) loss : 1.315                     \n",
      "2m 26s (- 1m 5s) (31000 69%) loss : 1.273                     \n",
      "2m 27s (- 1m 4s) (31100 69%) loss : 1.279                     \n",
      "2m 27s (- 1m 4s) (31200 69%) loss : 1.340                     \n",
      "2m 28s (- 1m 3s) (31300 69%) loss : 1.211                     \n",
      "2m 28s (- 1m 3s) (31400 70%) loss : 1.256                     \n",
      "2m 29s (- 1m 2s) (31500 70%) loss : 1.293                     \n",
      "2m 29s (- 1m 2s) (31600 70%) loss : 1.207                     \n",
      "2m 30s (- 1m 1s) (31700 70%) loss : 1.275                     \n",
      "2m 30s (- 1m 1s) (31800 71%) loss : 1.236                     \n",
      "2m 31s (- 1m 0s) (31900 71%) loss : 1.271                     \n",
      "2m 31s (- 1m 0s) (32000 71%) loss : 1.317                     \n",
      "2m 32s (- 0m 59s) (32100 71%) loss : 1.337                     \n",
      "2m 32s (- 0m 59s) (32200 71%) loss : 1.240                     \n",
      "2m 33s (- 0m 58s) (32300 72%) loss : 1.337                     \n",
      "2m 33s (- 0m 58s) (32400 72%) loss : 1.293                     \n",
      "2m 34s (- 0m 57s) (32500 72%) loss : 1.273                     \n",
      "2m 34s (- 0m 57s) (32600 72%) loss : 1.332                     \n",
      "2m 34s (- 0m 57s) (32700 73%) loss : 1.291                     \n",
      "2m 35s (- 0m 56s) (32800 73%) loss : 1.281                     \n",
      "2m 35s (- 0m 56s) (32900 73%) loss : 1.299                     \n",
      "2m 36s (- 0m 55s) (33000 73%) loss : 1.379                     \n",
      "2m 36s (- 0m 55s) (33100 74%) loss : 1.290                     \n",
      "2m 37s (- 0m 54s) (33200 74%) loss : 1.285                     \n",
      "2m 37s (- 0m 54s) (33300 74%) loss : 1.265                     \n",
      "2m 38s (- 0m 53s) (33400 74%) loss : 1.302                     \n",
      "2m 38s (- 0m 53s) (33500 74%) loss : 1.286                     \n",
      "2m 39s (- 0m 52s) (33600 75%) loss : 1.239                     \n",
      "2m 39s (- 0m 52s) (33700 75%) loss : 1.324                     \n",
      "2m 40s (- 0m 51s) (33800 75%) loss : 1.222                     \n",
      "2m 40s (- 0m 51s) (33900 75%) loss : 1.213                     \n",
      "2m 41s (- 0m 50s) (34000 76%) loss : 1.279                     \n",
      "2m 41s (- 0m 50s) (34100 76%) loss : 1.237                     \n",
      "2m 41s (- 0m 49s) (34200 76%) loss : 1.332                     \n",
      "2m 42s (- 0m 49s) (34300 76%) loss : 1.366                     \n",
      "2m 42s (- 0m 48s) (34400 76%) loss : 1.352                     \n",
      "2m 43s (- 0m 48s) (34500 77%) loss : 1.241                     \n",
      "2m 43s (- 0m 47s) (34600 77%) loss : 1.235                     \n",
      "2m 44s (- 0m 47s) (34700 77%) loss : 1.298                     \n",
      "2m 44s (- 0m 47s) (34800 77%) loss : 1.250                     \n",
      "2m 45s (- 0m 46s) (34900 78%) loss : 1.327                     \n",
      "2m 45s (- 0m 46s) (35000 78%) loss : 1.317                     \n",
      "2m 46s (- 0m 45s) (35100 78%) loss : 1.277                     \n",
      "2m 46s (- 0m 45s) (35200 78%) loss : 1.257                     \n",
      "2m 47s (- 0m 44s) (35300 78%) loss : 1.296                     \n",
      "2m 47s (- 0m 44s) (35400 79%) loss : 1.291                     \n",
      "2m 48s (- 0m 43s) (35500 79%) loss : 1.327                     \n",
      "2m 48s (- 0m 43s) (35600 79%) loss : 1.232                     \n",
      "2m 49s (- 0m 42s) (35700 79%) loss : 1.272                     \n",
      "2m 49s (- 0m 42s) (35800 80%) loss : 1.252                     \n",
      "2m 50s (- 0m 41s) (35900 80%) loss : 1.286                     \n",
      "2m 50s (- 0m 41s) (36000 80%) loss : 1.246                     \n",
      "2m 51s (- 0m 40s) (36100 80%) loss : 1.277                     \n",
      "2m 51s (- 0m 40s) (36200 80%) loss : 1.326                     \n",
      "2m 52s (- 0m 39s) (36300 81%) loss : 1.266                     \n",
      "2m 52s (- 0m 39s) (36400 81%) loss : 1.288                     \n",
      "2m 53s (- 0m 39s) (36500 81%) loss : 1.320                     \n",
      "2m 53s (- 0m 38s) (36600 81%) loss : 1.281                     \n",
      "2m 54s (- 0m 38s) (36700 82%) loss : 1.277                     \n",
      "2m 54s (- 0m 37s) (36800 82%) loss : 1.246                     \n",
      "2m 55s (- 0m 37s) (36900 82%) loss : 1.379                     \n",
      "2m 55s (- 0m 36s) (37000 82%) loss : 1.332                     \n",
      "2m 55s (- 0m 36s) (37100 82%) loss : 1.234                     \n",
      "2m 56s (- 0m 35s) (37200 83%) loss : 1.239                     \n",
      "2m 56s (- 0m 35s) (37300 83%) loss : 1.309                     \n",
      "2m 57s (- 0m 34s) (37400 83%) loss : 1.295                     \n",
      "2m 57s (- 0m 34s) (37500 83%) loss : 1.303                     \n",
      "2m 58s (- 0m 33s) (37600 84%) loss : 1.305                     \n",
      "2m 59s (- 0m 33s) (37700 84%) loss : 1.258                     \n",
      "2m 59s (- 0m 32s) (37800 84%) loss : 1.240                     \n",
      "3m 0s (- 0m 32s) (37900 84%) loss : 1.363                     \n",
      "3m 0s (- 0m 31s) (38000 84%) loss : 1.326                     \n",
      "3m 0s (- 0m 31s) (38100 85%) loss : 1.329                     \n",
      "3m 1s (- 0m 31s) (38200 85%) loss : 1.302                     \n",
      "3m 1s (- 0m 30s) (38300 85%) loss : 1.234                     \n",
      "3m 2s (- 0m 30s) (38400 85%) loss : 1.302                     \n",
      "3m 2s (- 0m 29s) (38500 86%) loss : 1.252                     \n",
      "3m 3s (- 0m 29s) (38600 86%) loss : 1.334                     \n",
      "3m 3s (- 0m 28s) (38700 86%) loss : 1.272                     \n",
      "3m 4s (- 0m 28s) (38800 86%) loss : 1.274                     \n",
      "3m 4s (- 0m 27s) (38900 86%) loss : 1.252                     \n",
      "3m 5s (- 0m 27s) (39000 87%) loss : 1.276                     \n",
      "3m 6s (- 0m 26s) (39100 87%) loss : 1.297                     \n",
      "3m 6s (- 0m 26s) (39200 87%) loss : 1.296                     \n",
      "3m 7s (- 0m 25s) (39300 87%) loss : 1.288                     \n",
      "3m 7s (- 0m 25s) (39400 88%) loss : 1.313                     \n",
      "3m 7s (- 0m 24s) (39500 88%) loss : 1.261                     \n",
      "3m 8s (- 0m 24s) (39600 88%) loss : 1.311                     \n",
      "3m 8s (- 0m 23s) (39700 88%) loss : 1.315                     \n",
      "3m 9s (- 0m 23s) (39800 88%) loss : 1.221                     \n",
      "3m 9s (- 0m 22s) (39900 89%) loss : 1.354                     \n",
      "3m 10s (- 0m 22s) (40000 89%) loss : 1.323                     \n",
      "3m 10s (- 0m 22s) (40100 89%) loss : 1.287                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 11s (- 0m 21s) (40200 89%) loss : 1.279                     \n",
      "3m 11s (- 0m 21s) (40300 90%) loss : 1.311                     \n",
      "3m 12s (- 0m 20s) (40400 90%) loss : 1.243                     \n",
      "3m 12s (- 0m 20s) (40500 90%) loss : 1.252                     \n",
      "3m 13s (- 0m 19s) (40600 90%) loss : 1.289                     \n",
      "3m 13s (- 0m 19s) (40700 90%) loss : 1.336                     \n",
      "3m 14s (- 0m 18s) (40800 91%) loss : 1.283                     \n",
      "3m 14s (- 0m 18s) (40900 91%) loss : 1.250                     \n",
      "3m 15s (- 0m 17s) (41000 91%) loss : 1.278                     \n",
      "3m 15s (- 0m 17s) (41100 91%) loss : 1.222                     \n",
      "3m 15s (- 0m 16s) (41200 92%) loss : 1.245                     \n",
      "3m 16s (- 0m 16s) (41300 92%) loss : 1.310                     \n",
      "3m 16s (- 0m 15s) (41400 92%) loss : 1.345                     \n",
      "3m 17s (- 0m 15s) (41500 92%) loss : 1.362                     \n",
      "3m 17s (- 0m 14s) (41600 93%) loss : 1.311                     \n",
      "3m 18s (- 0m 14s) (41700 93%) loss : 1.233                     \n",
      "3m 18s (- 0m 13s) (41800 93%) loss : 1.349                     \n",
      "3m 19s (- 0m 13s) (41900 93%) loss : 1.298                     \n",
      "3m 19s (- 0m 12s) (42000 93%) loss : 1.358                     \n",
      "3m 20s (- 0m 12s) (42100 94%) loss : 1.297                     \n",
      "3m 20s (- 0m 12s) (42200 94%) loss : 1.312                     \n",
      "3m 21s (- 0m 11s) (42300 94%) loss : 1.294                     \n",
      "3m 21s (- 0m 11s) (42400 94%) loss : 1.368                     \n",
      "3m 22s (- 0m 10s) (42500 95%) loss : 1.288                     \n",
      "3m 22s (- 0m 10s) (42600 95%) loss : 1.380                     \n",
      "3m 23s (- 0m 9s) (42700 95%) loss : 1.377                     \n",
      "3m 23s (- 0m 9s) (42800 95%) loss : 1.251                     \n",
      "3m 24s (- 0m 8s) (42900 95%) loss : 1.314                     \n",
      "3m 24s (- 0m 8s) (43000 96%) loss : 1.326                     \n",
      "3m 25s (- 0m 7s) (43100 96%) loss : 1.323                     \n",
      "3m 25s (- 0m 7s) (43200 96%) loss : 1.341                     \n",
      "3m 26s (- 0m 6s) (43300 96%) loss : 1.298                     \n",
      "3m 26s (- 0m 6s) (43400 97%) loss : 1.300                     \n",
      "3m 27s (- 0m 5s) (43500 97%) loss : 1.342                     \n",
      "3m 27s (- 0m 5s) (43600 97%) loss : 1.326                     \n",
      "3m 28s (- 0m 4s) (43700 97%) loss : 1.304                     \n",
      "3m 28s (- 0m 4s) (43800 97%) loss : 1.350                     \n",
      "3m 29s (- 0m 3s) (43900 98%) loss : 1.272                     \n",
      "3m 29s (- 0m 3s) (44000 98%) loss : 1.347                     \n",
      "3m 30s (- 0m 2s) (44100 98%) loss : 1.287                     \n",
      "3m 30s (- 0m 2s) (44200 98%) loss : 1.281                     \n",
      "3m 31s (- 0m 2s) (44300 99%) loss : 1.322                     \n",
      "3m 31s (- 0m 1s) (44400 99%) loss : 1.304                     \n",
      "3m 32s (- 0m 1s) (44500 99%) loss : 1.330                     \n",
      "3m 32s (- 0m 0s) (44600 99%) loss : 1.355                     \n",
      "3m 33s (- 0m 0s) (44700 99%) loss : 1.290                     \n",
      "0m 1s (- 0m 0s) (100 100%) loss : 1.234  accuracy : 72.7 %\n"
     ]
    }
   ],
   "source": [
    "cbow.train(Ngrams, iters = 100, lr = 0.005, print_every = 100, compute_accuracy = True)\n",
    "\n",
    "for alpha in [0.005, 0.001, 0.0005, 0.00025, 0.0001] : \n",
    "    cbow.train(Ngrams, epochs = 3,  lr = alpha, print_every = 100)\n",
    "    cbow.train(Ngrams, iters = 100, lr = alpha, print_every = 100, compute_accuracy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disruption', 0.4915212),\n",
       " ('gmu', 0.36797026),\n",
       " ('biostatistical', 0.3601455),\n",
       " ('milliliter', 0.34712657),\n",
       " ('xy', 0.3376171),\n",
       " ('diffuse', 0.3375387),\n",
       " ('sterile', 0.33623347),\n",
       " ('ah', 0.33311707),\n",
       " ('live', 0.33145988),\n",
       " ('analytical', 0.32609305)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(word = 'formaldehyde', bound = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load<br>\n",
    "\n",
    "The lightweight word2vec model can be saved for further use, or alternatively the full shell wrapping the word2vec model can be saved for subsequent training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(word2vec, path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_cbow.pt')\n",
    "\n",
    "# load\n",
    "#word2vec = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_cbow.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Training with SkipGram objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang(corpus, base_tokens = ['SOS', 'EOS', 'UNK'], min_count = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipgram.word2vec == word2vec :  True\n"
     ]
    }
   ],
   "source": [
    "word2vec = myWord2Vec(lang, T = 75)\n",
    "skipgram = Word2VecShell(word2vec, device, sg = 1, context_size = 5, hidden_dim = 150)\n",
    "print('skipgram.word2vec == word2vec : ', skipgram.word2vec == word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngrams = skipgram.generatePackedNgrams(corpus, context_size = 5, batch_size = 32, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 10s (- 0m 0s) (100 100%) loss : 6.551  accuracy : 7.6 %\n",
      "epoch 1\n",
      "0m 1s (- 11m 44s) (100 0%) loss : 6.082                     \n",
      "0m 3s (- 11m 41s) (200 0%) loss : 6.001                     \n",
      "0m 4s (- 11m 41s) (300 0%) loss : 5.951                     \n",
      "0m 6s (- 11m 39s) (400 0%) loss : 5.921                     \n",
      "0m 7s (- 11m 37s) (500 1%) loss : 5.912                     \n",
      "0m 9s (- 11m 35s) (600 1%) loss : 5.881                     \n",
      "0m 11s (- 11m 33s) (700 1%) loss : 5.837                     \n",
      "0m 12s (- 11m 31s) (800 1%) loss : 5.824                     \n",
      "0m 14s (- 11m 29s) (900 2%) loss : 5.828                     \n",
      "0m 15s (- 11m 28s) (1000 2%) loss : 5.815                     \n",
      "0m 17s (- 11m 26s) (1100 2%) loss : 5.782                     \n",
      "0m 18s (- 11m 25s) (1200 2%) loss : 5.799                     \n",
      "0m 20s (- 11m 23s) (1300 2%) loss : 5.775                     \n",
      "0m 22s (- 11m 22s) (1400 3%) loss : 5.785                     \n",
      "0m 23s (- 11m 20s) (1500 3%) loss : 5.766                     \n",
      "0m 25s (- 11m 18s) (1600 3%) loss : 5.731                     \n",
      "0m 26s (- 11m 17s) (1700 3%) loss : 5.736                     \n",
      "0m 28s (- 11m 15s) (1800 4%) loss : 5.699                     \n",
      "0m 29s (- 11m 13s) (1900 4%) loss : 5.698                     \n",
      "0m 31s (- 11m 11s) (2000 4%) loss : 5.684                     \n",
      "0m 33s (- 11m 9s) (2100 4%) loss : 5.701                     \n",
      "0m 34s (- 11m 8s) (2200 4%) loss : 5.700                     \n",
      "0m 36s (- 11m 6s) (2300 5%) loss : 5.684                     \n",
      "0m 37s (- 11m 5s) (2400 5%) loss : 5.667                     \n",
      "0m 39s (- 11m 3s) (2500 5%) loss : 5.674                     \n",
      "0m 40s (- 11m 1s) (2600 5%) loss : 5.676                     \n",
      "0m 42s (- 10m 59s) (2700 6%) loss : 5.645                     \n",
      "0m 43s (- 10m 57s) (2800 6%) loss : 5.646                     \n",
      "0m 45s (- 10m 56s) (2900 6%) loss : 5.612                     \n",
      "0m 47s (- 10m 54s) (3000 6%) loss : 5.612                     \n",
      "0m 48s (- 10m 52s) (3100 6%) loss : 5.639                     \n",
      "0m 50s (- 10m 51s) (3200 7%) loss : 5.630                     \n",
      "0m 51s (- 10m 49s) (3300 7%) loss : 5.595                     \n",
      "0m 53s (- 10m 47s) (3400 7%) loss : 5.630                     \n",
      "0m 54s (- 10m 46s) (3500 7%) loss : 5.591                     \n",
      "0m 56s (- 10m 44s) (3600 8%) loss : 5.618                     \n",
      "0m 57s (- 10m 42s) (3700 8%) loss : 5.594                     \n",
      "0m 59s (- 10m 41s) (3800 8%) loss : 5.596                     \n",
      "1m 1s (- 10m 40s) (3900 8%) loss : 5.581                     \n",
      "1m 2s (- 10m 38s) (4000 8%) loss : 5.574                     \n",
      "1m 4s (- 10m 37s) (4100 9%) loss : 5.540                     \n",
      "1m 5s (- 10m 36s) (4200 9%) loss : 5.552                     \n",
      "1m 7s (- 10m 34s) (4300 9%) loss : 5.611                     \n",
      "1m 9s (- 10m 33s) (4400 9%) loss : 5.575                     \n",
      "1m 10s (- 10m 31s) (4500 10%) loss : 5.533                     \n",
      "1m 12s (- 10m 30s) (4600 10%) loss : 5.579                     \n",
      "1m 13s (- 10m 28s) (4700 10%) loss : 5.570                     \n",
      "1m 15s (- 10m 27s) (4800 10%) loss : 5.554                     \n",
      "1m 16s (- 10m 25s) (4900 10%) loss : 5.551                     \n",
      "1m 18s (- 10m 23s) (5000 11%) loss : 5.565                     \n",
      "1m 20s (- 10m 21s) (5100 11%) loss : 5.549                     \n",
      "1m 21s (- 10m 20s) (5200 11%) loss : 5.537                     \n",
      "1m 23s (- 10m 18s) (5300 11%) loss : 5.517                     \n",
      "1m 24s (- 10m 17s) (5400 12%) loss : 5.554                     \n",
      "1m 26s (- 10m 15s) (5500 12%) loss : 5.542                     \n",
      "1m 27s (- 10m 13s) (5600 12%) loss : 5.539                     \n",
      "1m 29s (- 10m 12s) (5700 12%) loss : 5.534                     \n",
      "1m 30s (- 10m 10s) (5800 12%) loss : 5.528                     \n",
      "1m 32s (- 10m 8s) (5900 13%) loss : 5.521                     \n",
      "1m 34s (- 10m 7s) (6000 13%) loss : 5.555                     \n",
      "1m 35s (- 10m 5s) (6100 13%) loss : 5.547                     \n",
      "1m 37s (- 10m 3s) (6200 13%) loss : 5.499                     \n",
      "1m 38s (- 10m 2s) (6300 14%) loss : 5.565                     \n",
      "1m 40s (- 10m 0s) (6400 14%) loss : 5.472                     \n",
      "1m 41s (- 9m 59s) (6500 14%) loss : 5.522                     \n",
      "1m 43s (- 9m 57s) (6600 14%) loss : 5.514                     \n",
      "1m 44s (- 9m 55s) (6700 14%) loss : 5.507                     \n",
      "1m 46s (- 9m 54s) (6800 15%) loss : 5.478                     \n",
      "1m 48s (- 9m 52s) (6900 15%) loss : 5.512                     \n",
      "1m 49s (- 9m 51s) (7000 15%) loss : 5.482                     \n",
      "1m 51s (- 9m 49s) (7100 15%) loss : 5.477                     \n",
      "1m 52s (- 9m 48s) (7200 16%) loss : 5.499                     \n",
      "1m 54s (- 9m 46s) (7300 16%) loss : 5.496                     \n",
      "1m 55s (- 9m 44s) (7400 16%) loss : 5.483                     \n",
      "1m 57s (- 9m 43s) (7500 16%) loss : 5.490                     \n",
      "1m 59s (- 9m 41s) (7600 16%) loss : 5.481                     \n",
      "2m 0s (- 9m 39s) (7700 17%) loss : 5.484                     \n",
      "2m 2s (- 9m 38s) (7800 17%) loss : 5.476                     \n",
      "2m 3s (- 9m 36s) (7900 17%) loss : 5.475                     \n",
      "2m 5s (- 9m 35s) (8000 17%) loss : 5.467                     \n",
      "2m 6s (- 9m 33s) (8100 18%) loss : 5.441                     \n",
      "2m 8s (- 9m 31s) (8200 18%) loss : 5.495                     \n",
      "2m 9s (- 9m 30s) (8300 18%) loss : 5.472                     \n",
      "2m 11s (- 9m 28s) (8400 18%) loss : 5.484                     \n",
      "2m 13s (- 9m 27s) (8500 19%) loss : 5.446                     \n",
      "2m 14s (- 9m 25s) (8600 19%) loss : 5.483                     \n",
      "2m 16s (- 9m 23s) (8700 19%) loss : 5.457                     \n",
      "2m 17s (- 9m 22s) (8800 19%) loss : 5.465                     \n",
      "2m 19s (- 9m 20s) (8900 19%) loss : 5.481                     \n",
      "2m 20s (- 9m 19s) (9000 20%) loss : 5.452                     \n",
      "2m 22s (- 9m 17s) (9100 20%) loss : 5.465                     \n",
      "2m 23s (- 9m 15s) (9200 20%) loss : 5.465                     \n",
      "2m 25s (- 9m 14s) (9300 20%) loss : 5.457                     \n",
      "2m 27s (- 9m 12s) (9400 21%) loss : 5.443                     \n",
      "2m 28s (- 9m 11s) (9500 21%) loss : 5.477                     \n",
      "2m 30s (- 9m 9s) (9600 21%) loss : 5.441                     \n",
      "2m 31s (- 9m 7s) (9700 21%) loss : 5.468                     \n",
      "2m 33s (- 9m 6s) (9800 21%) loss : 5.422                     \n",
      "2m 34s (- 9m 4s) (9900 22%) loss : 5.399                     \n",
      "2m 36s (- 9m 3s) (10000 22%) loss : 5.432                     \n",
      "2m 37s (- 9m 1s) (10100 22%) loss : 5.434                     \n",
      "2m 39s (- 8m 59s) (10200 22%) loss : 5.438                     \n",
      "2m 41s (- 8m 58s) (10300 23%) loss : 5.437                     \n",
      "2m 42s (- 8m 56s) (10400 23%) loss : 5.457                     \n",
      "2m 44s (- 8m 55s) (10500 23%) loss : 5.447                     \n",
      "2m 45s (- 8m 53s) (10600 23%) loss : 5.450                     \n",
      "2m 47s (- 8m 51s) (10700 23%) loss : 5.464                     \n",
      "2m 48s (- 8m 50s) (10800 24%) loss : 5.443                     \n",
      "2m 50s (- 8m 48s) (10900 24%) loss : 5.437                     \n",
      "2m 51s (- 8m 47s) (11000 24%) loss : 5.444                     \n",
      "2m 53s (- 8m 45s) (11100 24%) loss : 5.444                     \n",
      "2m 55s (- 8m 44s) (11200 25%) loss : 5.436                     \n",
      "2m 56s (- 8m 42s) (11300 25%) loss : 5.411                     \n",
      "2m 58s (- 8m 40s) (11400 25%) loss : 5.425                     \n",
      "2m 59s (- 8m 39s) (11500 25%) loss : 5.412                     \n",
      "3m 1s (- 8m 37s) (11600 25%) loss : 5.378                     \n",
      "3m 2s (- 8m 36s) (11700 26%) loss : 5.409                     \n",
      "3m 4s (- 8m 34s) (11800 26%) loss : 5.406                     \n",
      "3m 5s (- 8m 33s) (11900 26%) loss : 5.433                     \n",
      "3m 7s (- 8m 31s) (12000 26%) loss : 5.452                     \n",
      "3m 9s (- 8m 29s) (12100 27%) loss : 5.437                     \n",
      "3m 10s (- 8m 28s) (12200 27%) loss : 5.389                     \n",
      "3m 12s (- 8m 26s) (12300 27%) loss : 5.419                     \n",
      "3m 13s (- 8m 25s) (12400 27%) loss : 5.420                     \n",
      "3m 15s (- 8m 23s) (12500 27%) loss : 5.404                     \n",
      "3m 16s (- 8m 22s) (12600 28%) loss : 5.384                     \n",
      "3m 18s (- 8m 20s) (12700 28%) loss : 5.407                     \n",
      "3m 20s (- 8m 18s) (12800 28%) loss : 5.427                     \n",
      "3m 21s (- 8m 17s) (12900 28%) loss : 5.397                     \n",
      "3m 23s (- 8m 15s) (13000 29%) loss : 5.423                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 24s (- 8m 14s) (13100 29%) loss : 5.437                     \n",
      "3m 26s (- 8m 12s) (13200 29%) loss : 5.397                     \n",
      "3m 27s (- 8m 11s) (13300 29%) loss : 5.410                     \n",
      "3m 29s (- 8m 9s) (13400 29%) loss : 5.365                     \n",
      "3m 30s (- 8m 7s) (13500 30%) loss : 5.440                     \n",
      "3m 32s (- 8m 6s) (13600 30%) loss : 5.431                     \n",
      "3m 34s (- 8m 5s) (13700 30%) loss : 5.390                     \n",
      "3m 35s (- 8m 3s) (13800 30%) loss : 5.406                     \n",
      "3m 37s (- 8m 2s) (13900 31%) loss : 5.401                     \n",
      "3m 38s (- 8m 0s) (14000 31%) loss : 5.376                     \n",
      "3m 40s (- 7m 59s) (14100 31%) loss : 5.391                     \n",
      "3m 42s (- 7m 57s) (14200 31%) loss : 5.411                     \n",
      "3m 43s (- 7m 55s) (14300 31%) loss : 5.375                     \n",
      "3m 45s (- 7m 54s) (14400 32%) loss : 5.392                     \n",
      "3m 46s (- 7m 52s) (14500 32%) loss : 5.379                     \n",
      "3m 48s (- 7m 51s) (14600 32%) loss : 5.395                     \n",
      "3m 49s (- 7m 49s) (14700 32%) loss : 5.401                     \n",
      "3m 51s (- 7m 48s) (14800 33%) loss : 5.393                     \n",
      "3m 53s (- 7m 46s) (14900 33%) loss : 5.414                     \n",
      "epoch 2\n",
      "3m 54s (- 7m 44s) (15000 33%) loss : 5.317                     \n",
      "3m 56s (- 7m 43s) (15100 33%) loss : 5.358                     \n",
      "3m 57s (- 7m 41s) (15200 33%) loss : 5.363                     \n",
      "3m 59s (- 7m 40s) (15300 34%) loss : 5.330                     \n",
      "4m 0s (- 7m 38s) (15400 34%) loss : 5.338                     \n",
      "4m 2s (- 7m 36s) (15500 34%) loss : 5.335                     \n",
      "4m 3s (- 7m 35s) (15600 34%) loss : 5.335                     \n",
      "4m 5s (- 7m 33s) (15700 35%) loss : 5.348                     \n",
      "4m 6s (- 7m 32s) (15800 35%) loss : 5.333                     \n",
      "4m 8s (- 7m 30s) (15900 35%) loss : 5.310                     \n",
      "4m 10s (- 7m 29s) (16000 35%) loss : 5.336                     \n",
      "4m 11s (- 7m 27s) (16100 35%) loss : 5.324                     \n",
      "4m 13s (- 7m 25s) (16200 36%) loss : 5.347                     \n",
      "4m 14s (- 7m 24s) (16300 36%) loss : 5.322                     \n",
      "4m 16s (- 7m 22s) (16400 36%) loss : 5.324                     \n",
      "4m 17s (- 7m 21s) (16500 36%) loss : 5.316                     \n",
      "4m 19s (- 7m 19s) (16600 37%) loss : 5.343                     \n",
      "4m 21s (- 7m 18s) (16700 37%) loss : 5.361                     \n",
      "4m 22s (- 7m 16s) (16800 37%) loss : 5.367                     \n",
      "4m 24s (- 7m 14s) (16900 37%) loss : 5.348                     \n",
      "4m 25s (- 7m 13s) (17000 38%) loss : 5.361                     \n",
      "4m 27s (- 7m 11s) (17100 38%) loss : 5.336                     \n",
      "4m 28s (- 7m 10s) (17200 38%) loss : 5.330                     \n",
      "4m 30s (- 7m 8s) (17300 38%) loss : 5.346                     \n",
      "4m 31s (- 7m 7s) (17400 38%) loss : 5.333                     \n",
      "4m 33s (- 7m 5s) (17500 39%) loss : 5.306                     \n",
      "4m 34s (- 7m 3s) (17600 39%) loss : 5.353                     \n",
      "4m 36s (- 7m 2s) (17700 39%) loss : 5.355                     \n",
      "4m 38s (- 7m 0s) (17800 39%) loss : 5.328                     \n",
      "4m 39s (- 6m 59s) (17900 40%) loss : 5.313                     \n",
      "4m 41s (- 6m 57s) (18000 40%) loss : 5.334                     \n",
      "4m 42s (- 6m 55s) (18100 40%) loss : 5.326                     \n",
      "4m 44s (- 6m 54s) (18200 40%) loss : 5.369                     \n",
      "4m 45s (- 6m 52s) (18300 40%) loss : 5.359                     \n",
      "4m 47s (- 6m 51s) (18400 41%) loss : 5.335                     \n",
      "4m 48s (- 6m 49s) (18500 41%) loss : 5.306                     \n",
      "4m 50s (- 6m 48s) (18600 41%) loss : 5.307                     \n",
      "4m 52s (- 6m 46s) (18700 41%) loss : 5.322                     \n",
      "4m 53s (- 6m 44s) (18800 42%) loss : 5.321                     \n",
      "4m 55s (- 6m 43s) (18900 42%) loss : 5.303                     \n",
      "4m 56s (- 6m 41s) (19000 42%) loss : 5.283                     \n",
      "4m 58s (- 6m 40s) (19100 42%) loss : 5.369                     \n",
      "4m 59s (- 6m 38s) (19200 42%) loss : 5.328                     \n",
      "5m 1s (- 6m 37s) (19300 43%) loss : 5.335                     \n",
      "5m 2s (- 6m 35s) (19400 43%) loss : 5.306                     \n",
      "5m 4s (- 6m 33s) (19500 43%) loss : 5.299                     \n",
      "5m 6s (- 6m 32s) (19600 43%) loss : 5.312                     \n",
      "5m 7s (- 6m 30s) (19700 44%) loss : 5.335                     \n",
      "5m 9s (- 6m 29s) (19800 44%) loss : 5.302                     \n",
      "5m 10s (- 6m 27s) (19900 44%) loss : 5.292                     \n",
      "5m 12s (- 6m 26s) (20000 44%) loss : 5.354                     \n",
      "5m 13s (- 6m 24s) (20100 44%) loss : 5.288                     \n",
      "5m 15s (- 6m 22s) (20200 45%) loss : 5.282                     \n",
      "5m 16s (- 6m 21s) (20300 45%) loss : 5.327                     \n",
      "5m 18s (- 6m 19s) (20400 45%) loss : 5.306                     \n",
      "5m 20s (- 6m 18s) (20500 45%) loss : 5.336                     \n",
      "5m 21s (- 6m 16s) (20600 46%) loss : 5.314                     \n",
      "5m 23s (- 6m 15s) (20700 46%) loss : 5.296                     \n",
      "5m 24s (- 6m 13s) (20800 46%) loss : 5.319                     \n",
      "5m 26s (- 6m 11s) (20900 46%) loss : 5.308                     \n",
      "5m 27s (- 6m 10s) (21000 46%) loss : 5.280                     \n",
      "5m 29s (- 6m 8s) (21100 47%) loss : 5.376                     \n",
      "5m 30s (- 6m 7s) (21200 47%) loss : 5.347                     \n",
      "5m 32s (- 6m 5s) (21300 47%) loss : 5.287                     \n",
      "5m 34s (- 6m 4s) (21400 47%) loss : 5.284                     \n",
      "5m 35s (- 6m 2s) (21500 48%) loss : 5.307                     \n",
      "5m 37s (- 6m 1s) (21600 48%) loss : 5.308                     \n",
      "5m 38s (- 5m 59s) (21700 48%) loss : 5.355                     \n",
      "5m 40s (- 5m 58s) (21800 48%) loss : 5.321                     \n",
      "5m 42s (- 5m 56s) (21900 48%) loss : 5.324                     \n",
      "5m 43s (- 5m 55s) (22000 49%) loss : 5.303                     \n",
      "5m 45s (- 5m 53s) (22100 49%) loss : 5.297                     \n",
      "5m 47s (- 5m 52s) (22200 49%) loss : 5.291                     \n",
      "5m 48s (- 5m 50s) (22300 49%) loss : 5.321                     \n",
      "5m 50s (- 5m 49s) (22400 50%) loss : 5.324                     \n",
      "5m 51s (- 5m 47s) (22500 50%) loss : 5.262                     \n",
      "5m 53s (- 5m 45s) (22600 50%) loss : 5.284                     \n",
      "5m 54s (- 5m 44s) (22700 50%) loss : 5.292                     \n",
      "5m 56s (- 5m 42s) (22800 50%) loss : 5.336                     \n",
      "5m 57s (- 5m 41s) (22900 51%) loss : 5.326                     \n",
      "5m 59s (- 5m 39s) (23000 51%) loss : 5.302                     \n",
      "6m 1s (- 5m 38s) (23100 51%) loss : 5.284                     \n",
      "6m 2s (- 5m 36s) (23200 51%) loss : 5.309                     \n",
      "6m 4s (- 5m 35s) (23300 52%) loss : 5.322                     \n",
      "6m 5s (- 5m 33s) (23400 52%) loss : 5.316                     \n",
      "6m 7s (- 5m 32s) (23500 52%) loss : 5.309                     \n",
      "6m 9s (- 5m 30s) (23600 52%) loss : 5.308                     \n",
      "6m 10s (- 5m 28s) (23700 52%) loss : 5.324                     \n",
      "6m 12s (- 5m 27s) (23800 53%) loss : 5.311                     \n",
      "6m 13s (- 5m 25s) (23900 53%) loss : 5.240                     \n",
      "6m 15s (- 5m 24s) (24000 53%) loss : 5.322                     \n",
      "6m 16s (- 5m 22s) (24100 53%) loss : 5.273                     \n",
      "6m 18s (- 5m 21s) (24200 54%) loss : 5.297                     \n",
      "6m 20s (- 5m 19s) (24300 54%) loss : 5.286                     \n",
      "6m 21s (- 5m 17s) (24400 54%) loss : 5.296                     \n",
      "6m 23s (- 5m 16s) (24500 54%) loss : 5.292                     \n",
      "6m 24s (- 5m 14s) (24600 55%) loss : 5.290                     \n",
      "6m 26s (- 5m 13s) (24700 55%) loss : 5.295                     \n",
      "6m 27s (- 5m 11s) (24800 55%) loss : 5.303                     \n",
      "6m 29s (- 5m 10s) (24900 55%) loss : 5.256                     \n",
      "6m 31s (- 5m 8s) (25000 55%) loss : 5.314                     \n",
      "6m 32s (- 5m 7s) (25100 56%) loss : 5.294                     \n",
      "6m 34s (- 5m 5s) (25200 56%) loss : 5.287                     \n",
      "6m 35s (- 5m 4s) (25300 56%) loss : 5.294                     \n",
      "6m 37s (- 5m 2s) (25400 56%) loss : 5.295                     \n",
      "6m 39s (- 5m 0s) (25500 57%) loss : 5.312                     \n",
      "6m 40s (- 4m 59s) (25600 57%) loss : 5.270                     \n",
      "6m 42s (- 4m 57s) (25700 57%) loss : 5.299                     \n",
      "6m 43s (- 4m 56s) (25800 57%) loss : 5.289                     \n",
      "6m 45s (- 4m 54s) (25900 57%) loss : 5.290                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 47s (- 4m 53s) (26000 58%) loss : 5.331                     \n",
      "6m 48s (- 4m 51s) (26100 58%) loss : 5.296                     \n",
      "6m 50s (- 4m 50s) (26200 58%) loss : 5.334                     \n",
      "6m 51s (- 4m 48s) (26300 58%) loss : 5.322                     \n",
      "6m 53s (- 4m 46s) (26400 59%) loss : 5.247                     \n",
      "6m 54s (- 4m 45s) (26500 59%) loss : 5.307                     \n",
      "6m 56s (- 4m 43s) (26600 59%) loss : 5.269                     \n",
      "6m 57s (- 4m 42s) (26700 59%) loss : 5.257                     \n",
      "6m 59s (- 4m 40s) (26800 59%) loss : 5.308                     \n",
      "7m 1s (- 4m 39s) (26900 60%) loss : 5.316                     \n",
      "7m 2s (- 4m 37s) (27000 60%) loss : 5.310                     \n",
      "7m 4s (- 4m 35s) (27100 60%) loss : 5.263                     \n",
      "7m 5s (- 4m 34s) (27200 60%) loss : 5.310                     \n",
      "7m 7s (- 4m 32s) (27300 61%) loss : 5.287                     \n",
      "7m 8s (- 4m 31s) (27400 61%) loss : 5.300                     \n",
      "7m 10s (- 4m 29s) (27500 61%) loss : 5.300                     \n",
      "7m 11s (- 4m 28s) (27600 61%) loss : 5.285                     \n",
      "7m 13s (- 4m 26s) (27700 61%) loss : 5.279                     \n",
      "7m 15s (- 4m 24s) (27800 62%) loss : 5.280                     \n",
      "7m 16s (- 4m 23s) (27900 62%) loss : 5.269                     \n",
      "7m 18s (- 4m 21s) (28000 62%) loss : 5.285                     \n",
      "7m 19s (- 4m 20s) (28100 62%) loss : 5.341                     \n",
      "7m 21s (- 4m 18s) (28200 63%) loss : 5.260                     \n",
      "7m 22s (- 4m 17s) (28300 63%) loss : 5.290                     \n",
      "7m 24s (- 4m 15s) (28400 63%) loss : 5.244                     \n",
      "7m 25s (- 4m 13s) (28500 63%) loss : 5.289                     \n",
      "7m 27s (- 4m 12s) (28600 63%) loss : 5.338                     \n",
      "7m 28s (- 4m 10s) (28700 64%) loss : 5.294                     \n",
      "7m 30s (- 4m 9s) (28800 64%) loss : 5.288                     \n",
      "7m 32s (- 4m 7s) (28900 64%) loss : 5.328                     \n",
      "7m 33s (- 4m 6s) (29000 64%) loss : 5.299                     \n",
      "7m 35s (- 4m 4s) (29100 65%) loss : 5.269                     \n",
      "7m 36s (- 4m 2s) (29200 65%) loss : 5.314                     \n",
      "7m 38s (- 4m 1s) (29300 65%) loss : 5.294                     \n",
      "7m 39s (- 3m 59s) (29400 65%) loss : 5.314                     \n",
      "7m 41s (- 3m 58s) (29500 65%) loss : 5.256                     \n",
      "7m 42s (- 3m 56s) (29600 66%) loss : 5.224                     \n",
      "7m 44s (- 3m 55s) (29700 66%) loss : 5.288                     \n",
      "7m 46s (- 3m 53s) (29800 66%) loss : 5.255                     \n",
      "epoch 3\n",
      "7m 47s (- 3m 51s) (29900 66%) loss : 5.235                     \n",
      "7m 49s (- 3m 50s) (30000 67%) loss : 5.207                     \n",
      "7m 50s (- 3m 48s) (30100 67%) loss : 5.242                     \n",
      "7m 52s (- 3m 47s) (30200 67%) loss : 5.258                     \n",
      "7m 53s (- 3m 45s) (30300 67%) loss : 5.230                     \n",
      "7m 55s (- 3m 44s) (30400 67%) loss : 5.188                     \n",
      "7m 56s (- 3m 42s) (30500 68%) loss : 5.242                     \n",
      "7m 58s (- 3m 40s) (30600 68%) loss : 5.269                     \n",
      "8m 0s (- 3m 39s) (30700 68%) loss : 5.226                     \n",
      "8m 1s (- 3m 37s) (30800 68%) loss : 5.210                     \n",
      "8m 3s (- 3m 36s) (30900 69%) loss : 5.240                     \n",
      "8m 4s (- 3m 34s) (31000 69%) loss : 5.226                     \n",
      "8m 6s (- 3m 33s) (31100 69%) loss : 5.260                     \n",
      "8m 7s (- 3m 31s) (31200 69%) loss : 5.226                     \n",
      "8m 9s (- 3m 29s) (31300 69%) loss : 5.233                     \n",
      "8m 11s (- 3m 28s) (31400 70%) loss : 5.269                     \n",
      "8m 12s (- 3m 26s) (31500 70%) loss : 5.243                     \n",
      "8m 14s (- 3m 25s) (31600 70%) loss : 5.262                     \n",
      "8m 15s (- 3m 23s) (31700 70%) loss : 5.218                     \n",
      "8m 17s (- 3m 22s) (31800 71%) loss : 5.246                     \n",
      "8m 18s (- 3m 20s) (31900 71%) loss : 5.237                     \n",
      "8m 20s (- 3m 18s) (32000 71%) loss : 5.242                     \n",
      "8m 21s (- 3m 17s) (32100 71%) loss : 5.273                     \n",
      "8m 23s (- 3m 15s) (32200 71%) loss : 5.254                     \n",
      "8m 25s (- 3m 14s) (32300 72%) loss : 5.238                     \n",
      "8m 26s (- 3m 12s) (32400 72%) loss : 5.217                     \n",
      "8m 28s (- 3m 11s) (32500 72%) loss : 5.246                     \n",
      "8m 29s (- 3m 9s) (32600 72%) loss : 5.260                     \n",
      "8m 31s (- 3m 8s) (32700 73%) loss : 5.241                     \n",
      "8m 32s (- 3m 6s) (32800 73%) loss : 5.185                     \n",
      "8m 34s (- 3m 4s) (32900 73%) loss : 5.249                     \n",
      "8m 35s (- 3m 3s) (33000 73%) loss : 5.216                     \n",
      "8m 37s (- 3m 1s) (33100 74%) loss : 5.192                     \n",
      "8m 38s (- 3m 0s) (33200 74%) loss : 5.270                     \n",
      "8m 40s (- 2m 58s) (33300 74%) loss : 5.270                     \n",
      "8m 42s (- 2m 57s) (33400 74%) loss : 5.257                     \n",
      "8m 43s (- 2m 55s) (33500 74%) loss : 5.252                     \n",
      "8m 45s (- 2m 54s) (33600 75%) loss : 5.243                     \n",
      "8m 47s (- 2m 52s) (33700 75%) loss : 5.264                     \n",
      "8m 48s (- 2m 50s) (33800 75%) loss : 5.242                     \n",
      "8m 50s (- 2m 49s) (33900 75%) loss : 5.232                     \n",
      "8m 52s (- 2m 47s) (34000 76%) loss : 5.214                     \n",
      "8m 53s (- 2m 46s) (34100 76%) loss : 5.217                     \n",
      "8m 55s (- 2m 44s) (34200 76%) loss : 5.231                     \n",
      "8m 57s (- 2m 43s) (34300 76%) loss : 5.243                     \n",
      "8m 58s (- 2m 41s) (34400 76%) loss : 5.243                     \n",
      "9m 0s (- 2m 40s) (34500 77%) loss : 5.212                     \n",
      "9m 1s (- 2m 38s) (34600 77%) loss : 5.238                     \n",
      "9m 3s (- 2m 37s) (34700 77%) loss : 5.264                     \n",
      "9m 5s (- 2m 35s) (34800 77%) loss : 5.239                     \n",
      "9m 6s (- 2m 33s) (34900 78%) loss : 5.219                     \n",
      "9m 8s (- 2m 32s) (35000 78%) loss : 5.250                     \n",
      "9m 9s (- 2m 30s) (35100 78%) loss : 5.214                     \n",
      "9m 11s (- 2m 29s) (35200 78%) loss : 5.210                     \n",
      "9m 12s (- 2m 27s) (35300 78%) loss : 5.204                     \n",
      "9m 14s (- 2m 26s) (35400 79%) loss : 5.245                     \n",
      "9m 16s (- 2m 24s) (35500 79%) loss : 5.219                     \n",
      "9m 17s (- 2m 22s) (35600 79%) loss : 5.248                     \n",
      "9m 19s (- 2m 21s) (35700 79%) loss : 5.235                     \n",
      "9m 20s (- 2m 19s) (35800 80%) loss : 5.244                     \n",
      "9m 22s (- 2m 18s) (35900 80%) loss : 5.259                     \n",
      "9m 23s (- 2m 16s) (36000 80%) loss : 5.215                     \n",
      "9m 25s (- 2m 15s) (36100 80%) loss : 5.223                     \n",
      "9m 26s (- 2m 13s) (36200 80%) loss : 5.201                     \n",
      "9m 28s (- 2m 11s) (36300 81%) loss : 5.216                     \n",
      "9m 30s (- 2m 10s) (36400 81%) loss : 5.236                     \n",
      "9m 31s (- 2m 8s) (36500 81%) loss : 5.239                     \n",
      "9m 33s (- 2m 7s) (36600 81%) loss : 5.234                     \n",
      "9m 34s (- 2m 5s) (36700 82%) loss : 5.213                     \n",
      "9m 36s (- 2m 4s) (36800 82%) loss : 5.239                     \n",
      "9m 37s (- 2m 2s) (36900 82%) loss : 5.231                     \n",
      "9m 39s (- 2m 1s) (37000 82%) loss : 5.240                     \n",
      "9m 40s (- 1m 59s) (37100 82%) loss : 5.236                     \n",
      "9m 42s (- 1m 57s) (37200 83%) loss : 5.259                     \n",
      "9m 44s (- 1m 56s) (37300 83%) loss : 5.240                     \n",
      "9m 45s (- 1m 54s) (37400 83%) loss : 5.193                     \n",
      "9m 47s (- 1m 53s) (37500 83%) loss : 5.214                     \n",
      "9m 48s (- 1m 51s) (37600 84%) loss : 5.219                     \n",
      "9m 50s (- 1m 50s) (37700 84%) loss : 5.261                     \n",
      "9m 51s (- 1m 48s) (37800 84%) loss : 5.212                     \n",
      "9m 53s (- 1m 46s) (37900 84%) loss : 5.252                     \n",
      "9m 54s (- 1m 45s) (38000 84%) loss : 5.269                     \n",
      "9m 56s (- 1m 43s) (38100 85%) loss : 5.254                     \n",
      "9m 58s (- 1m 42s) (38200 85%) loss : 5.227                     \n",
      "9m 59s (- 1m 40s) (38300 85%) loss : 5.217                     \n",
      "10m 1s (- 1m 39s) (38400 85%) loss : 5.238                     \n",
      "10m 2s (- 1m 37s) (38500 86%) loss : 5.224                     \n",
      "10m 4s (- 1m 35s) (38600 86%) loss : 5.262                     \n",
      "10m 5s (- 1m 34s) (38700 86%) loss : 5.211                     \n",
      "10m 7s (- 1m 32s) (38800 86%) loss : 5.234                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 8s (- 1m 31s) (38900 86%) loss : 5.257                     \n",
      "10m 10s (- 1m 29s) (39000 87%) loss : 5.217                     \n",
      "10m 12s (- 1m 28s) (39100 87%) loss : 5.267                     \n",
      "10m 13s (- 1m 26s) (39200 87%) loss : 5.200                     \n",
      "10m 15s (- 1m 24s) (39300 87%) loss : 5.243                     \n",
      "10m 16s (- 1m 23s) (39400 88%) loss : 5.251                     \n",
      "10m 18s (- 1m 21s) (39500 88%) loss : 5.255                     \n",
      "10m 19s (- 1m 20s) (39600 88%) loss : 5.207                     \n",
      "10m 21s (- 1m 18s) (39700 88%) loss : 5.275                     \n",
      "10m 22s (- 1m 17s) (39800 88%) loss : 5.215                     \n",
      "10m 24s (- 1m 15s) (39900 89%) loss : 5.250                     \n",
      "10m 26s (- 1m 13s) (40000 89%) loss : 5.230                     \n",
      "10m 27s (- 1m 12s) (40100 89%) loss : 5.248                     \n",
      "10m 29s (- 1m 10s) (40200 89%) loss : 5.210                     \n",
      "10m 30s (- 1m 9s) (40300 90%) loss : 5.261                     \n",
      "10m 32s (- 1m 7s) (40400 90%) loss : 5.222                     \n",
      "10m 33s (- 1m 6s) (40500 90%) loss : 5.228                     \n",
      "10m 35s (- 1m 4s) (40600 90%) loss : 5.226                     \n",
      "10m 36s (- 1m 3s) (40700 90%) loss : 5.210                     \n",
      "10m 38s (- 1m 1s) (40800 91%) loss : 5.235                     \n",
      "10m 40s (- 0m 59s) (40900 91%) loss : 5.214                     \n",
      "10m 41s (- 0m 58s) (41000 91%) loss : 5.221                     \n",
      "10m 43s (- 0m 56s) (41100 91%) loss : 5.211                     \n",
      "10m 44s (- 0m 55s) (41200 92%) loss : 5.244                     \n",
      "10m 46s (- 0m 53s) (41300 92%) loss : 5.176                     \n",
      "10m 48s (- 0m 52s) (41400 92%) loss : 5.213                     \n",
      "10m 49s (- 0m 50s) (41500 92%) loss : 5.231                     \n",
      "10m 51s (- 0m 48s) (41600 93%) loss : 5.223                     \n",
      "10m 52s (- 0m 47s) (41700 93%) loss : 5.226                     \n",
      "10m 54s (- 0m 45s) (41800 93%) loss : 5.208                     \n",
      "10m 56s (- 0m 44s) (41900 93%) loss : 5.182                     \n",
      "10m 57s (- 0m 42s) (42000 93%) loss : 5.220                     \n",
      "10m 59s (- 0m 41s) (42100 94%) loss : 5.232                     \n",
      "11m 0s (- 0m 39s) (42200 94%) loss : 5.210                     \n",
      "11m 2s (- 0m 38s) (42300 94%) loss : 5.230                     \n",
      "11m 3s (- 0m 36s) (42400 94%) loss : 5.180                     \n",
      "11m 5s (- 0m 34s) (42500 95%) loss : 5.228                     \n",
      "11m 7s (- 0m 33s) (42600 95%) loss : 5.221                     \n",
      "11m 8s (- 0m 31s) (42700 95%) loss : 5.199                     \n",
      "11m 10s (- 0m 30s) (42800 95%) loss : 5.223                     \n",
      "11m 11s (- 0m 28s) (42900 95%) loss : 5.192                     \n",
      "11m 13s (- 0m 27s) (43000 96%) loss : 5.211                     \n",
      "11m 14s (- 0m 25s) (43100 96%) loss : 5.256                     \n",
      "11m 16s (- 0m 23s) (43200 96%) loss : 5.196                     \n",
      "11m 17s (- 0m 22s) (43300 96%) loss : 5.217                     \n",
      "11m 19s (- 0m 20s) (43400 97%) loss : 5.205                     \n",
      "11m 21s (- 0m 19s) (43500 97%) loss : 5.246                     \n",
      "11m 22s (- 0m 17s) (43600 97%) loss : 5.208                     \n",
      "11m 24s (- 0m 16s) (43700 97%) loss : 5.223                     \n",
      "11m 25s (- 0m 14s) (43800 97%) loss : 5.217                     \n",
      "11m 27s (- 0m 12s) (43900 98%) loss : 5.207                     \n",
      "11m 28s (- 0m 11s) (44000 98%) loss : 5.186                     \n",
      "11m 30s (- 0m 9s) (44100 98%) loss : 5.194                     \n",
      "11m 31s (- 0m 8s) (44200 98%) loss : 5.212                     \n",
      "11m 33s (- 0m 6s) (44300 99%) loss : 5.240                     \n",
      "11m 35s (- 0m 5s) (44400 99%) loss : 5.197                     \n",
      "11m 36s (- 0m 3s) (44500 99%) loss : 5.263                     \n",
      "11m 38s (- 0m 1s) (44600 99%) loss : 5.138                     \n",
      "11m 39s (- 0m 0s) (44700 99%) loss : 5.155                     \n",
      "0m 9s (- 0m 0s) (100 100%) loss : 5.182  accuracy : 13.1 %\n",
      "epoch 1\n",
      "0m 1s (- 11m 39s) (100 0%) loss : 5.121                     \n",
      "0m 3s (- 11m 52s) (200 0%) loss : 5.111                     \n",
      "0m 4s (- 11m 44s) (300 0%) loss : 5.153                     \n",
      "0m 6s (- 11m 39s) (400 0%) loss : 5.144                     \n",
      "0m 7s (- 11m 35s) (500 1%) loss : 5.107                     \n",
      "0m 9s (- 11m 32s) (600 1%) loss : 5.152                     \n",
      "0m 10s (- 11m 30s) (700 1%) loss : 5.165                     \n",
      "0m 12s (- 11m 28s) (800 1%) loss : 5.104                     \n",
      "0m 14s (- 11m 26s) (900 2%) loss : 5.108                     \n",
      "0m 15s (- 11m 24s) (1000 2%) loss : 5.097                     \n",
      "0m 17s (- 11m 22s) (1100 2%) loss : 5.080                     \n",
      "0m 18s (- 11m 20s) (1200 2%) loss : 5.085                     \n",
      "0m 20s (- 11m 18s) (1300 2%) loss : 5.117                     \n",
      "0m 21s (- 11m 16s) (1400 3%) loss : 5.091                     \n",
      "0m 23s (- 11m 14s) (1500 3%) loss : 5.094                     \n",
      "0m 24s (- 11m 13s) (1600 3%) loss : 5.074                     \n",
      "0m 26s (- 11m 12s) (1700 3%) loss : 5.115                     \n",
      "0m 28s (- 11m 10s) (1800 4%) loss : 5.158                     \n",
      "0m 29s (- 11m 9s) (1900 4%) loss : 5.130                     \n",
      "0m 31s (- 11m 7s) (2000 4%) loss : 5.090                     \n",
      "0m 32s (- 11m 5s) (2100 4%) loss : 5.095                     \n",
      "0m 34s (- 11m 4s) (2200 4%) loss : 5.098                     \n",
      "0m 35s (- 11m 2s) (2300 5%) loss : 5.102                     \n",
      "0m 37s (- 11m 0s) (2400 5%) loss : 5.128                     \n",
      "0m 39s (- 11m 1s) (2500 5%) loss : 5.139                     \n",
      "0m 40s (- 10m 59s) (2600 5%) loss : 5.124                     \n",
      "0m 42s (- 10m 58s) (2700 6%) loss : 5.140                     \n",
      "0m 43s (- 10m 56s) (2800 6%) loss : 5.118                     \n",
      "0m 45s (- 10m 54s) (2900 6%) loss : 5.118                     \n",
      "0m 46s (- 10m 52s) (3000 6%) loss : 5.116                     \n",
      "0m 48s (- 10m 51s) (3100 6%) loss : 5.157                     \n",
      "0m 50s (- 10m 49s) (3200 7%) loss : 5.080                     \n",
      "0m 51s (- 10m 48s) (3300 7%) loss : 5.108                     \n",
      "0m 53s (- 10m 46s) (3400 7%) loss : 5.133                     \n",
      "0m 54s (- 10m 45s) (3500 7%) loss : 5.082                     \n",
      "0m 56s (- 10m 43s) (3600 8%) loss : 5.150                     \n",
      "0m 57s (- 10m 41s) (3700 8%) loss : 5.109                     \n",
      "0m 59s (- 10m 39s) (3800 8%) loss : 5.109                     \n",
      "1m 0s (- 10m 38s) (3900 8%) loss : 5.096                     \n",
      "1m 2s (- 10m 36s) (4000 8%) loss : 5.104                     \n",
      "1m 4s (- 10m 35s) (4100 9%) loss : 5.083                     \n",
      "1m 5s (- 10m 33s) (4200 9%) loss : 5.103                     \n",
      "1m 7s (- 10m 31s) (4300 9%) loss : 5.090                     \n",
      "1m 8s (- 10m 30s) (4400 9%) loss : 5.100                     \n",
      "1m 10s (- 10m 28s) (4500 10%) loss : 5.113                     \n",
      "1m 11s (- 10m 26s) (4600 10%) loss : 5.081                     \n",
      "1m 13s (- 10m 25s) (4700 10%) loss : 5.143                     \n",
      "1m 14s (- 10m 23s) (4800 10%) loss : 5.100                     \n",
      "1m 16s (- 10m 21s) (4900 10%) loss : 5.133                     \n",
      "1m 18s (- 10m 20s) (5000 11%) loss : 5.134                     \n",
      "1m 19s (- 10m 18s) (5100 11%) loss : 5.093                     \n",
      "1m 21s (- 10m 17s) (5200 11%) loss : 5.119                     \n",
      "1m 22s (- 10m 15s) (5300 11%) loss : 5.089                     \n",
      "1m 24s (- 10m 13s) (5400 12%) loss : 5.102                     \n",
      "1m 25s (- 10m 12s) (5500 12%) loss : 5.118                     \n",
      "1m 27s (- 10m 10s) (5600 12%) loss : 5.076                     \n",
      "1m 29s (- 10m 9s) (5700 12%) loss : 5.080                     \n",
      "1m 30s (- 10m 7s) (5800 12%) loss : 5.089                     \n",
      "1m 32s (- 10m 6s) (5900 13%) loss : 5.093                     \n",
      "1m 33s (- 10m 4s) (6000 13%) loss : 5.081                     \n",
      "1m 35s (- 10m 3s) (6100 13%) loss : 5.119                     \n",
      "1m 36s (- 10m 1s) (6200 13%) loss : 5.152                     \n",
      "1m 38s (- 9m 59s) (6300 14%) loss : 5.140                     \n",
      "1m 39s (- 9m 58s) (6400 14%) loss : 5.083                     \n",
      "1m 41s (- 9m 56s) (6500 14%) loss : 5.111                     \n",
      "1m 42s (- 9m 54s) (6600 14%) loss : 5.093                     \n",
      "1m 44s (- 9m 53s) (6700 14%) loss : 5.080                     \n",
      "1m 46s (- 9m 51s) (6800 15%) loss : 5.099                     \n",
      "1m 47s (- 9m 50s) (6900 15%) loss : 5.109                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 49s (- 9m 48s) (7000 15%) loss : 5.074                     \n",
      "1m 50s (- 9m 47s) (7100 15%) loss : 5.077                     \n",
      "1m 52s (- 9m 46s) (7200 16%) loss : 5.112                     \n",
      "1m 54s (- 9m 44s) (7300 16%) loss : 5.073                     \n",
      "1m 55s (- 9m 43s) (7400 16%) loss : 5.084                     \n",
      "1m 57s (- 9m 42s) (7500 16%) loss : 5.112                     \n",
      "1m 58s (- 9m 40s) (7600 16%) loss : 5.113                     \n",
      "2m 0s (- 9m 39s) (7700 17%) loss : 5.095                     \n",
      "2m 1s (- 9m 37s) (7800 17%) loss : 5.096                     \n",
      "2m 3s (- 9m 35s) (7900 17%) loss : 5.071                     \n",
      "2m 5s (- 9m 34s) (8000 17%) loss : 5.119                     \n",
      "2m 6s (- 9m 32s) (8100 18%) loss : 5.114                     \n",
      "2m 8s (- 9m 31s) (8200 18%) loss : 5.080                     \n",
      "2m 9s (- 9m 29s) (8300 18%) loss : 5.066                     \n",
      "2m 11s (- 9m 28s) (8400 18%) loss : 5.052                     \n",
      "2m 12s (- 9m 26s) (8500 19%) loss : 5.102                     \n",
      "2m 14s (- 9m 25s) (8600 19%) loss : 5.070                     \n",
      "2m 16s (- 9m 23s) (8700 19%) loss : 5.088                     \n",
      "2m 17s (- 9m 22s) (8800 19%) loss : 5.121                     \n",
      "2m 19s (- 9m 20s) (8900 19%) loss : 5.091                     \n",
      "2m 20s (- 9m 19s) (9000 20%) loss : 5.089                     \n",
      "2m 22s (- 9m 17s) (9100 20%) loss : 5.127                     \n",
      "2m 24s (- 9m 16s) (9200 20%) loss : 5.099                     \n",
      "2m 25s (- 9m 14s) (9300 20%) loss : 5.082                     \n",
      "2m 27s (- 9m 13s) (9400 21%) loss : 5.076                     \n",
      "2m 28s (- 9m 11s) (9500 21%) loss : 5.074                     \n",
      "2m 30s (- 9m 9s) (9600 21%) loss : 5.109                     \n",
      "2m 31s (- 9m 8s) (9700 21%) loss : 5.087                     \n",
      "2m 33s (- 9m 6s) (9800 21%) loss : 5.090                     \n",
      "2m 34s (- 9m 5s) (9900 22%) loss : 5.086                     \n",
      "2m 36s (- 9m 3s) (10000 22%) loss : 5.125                     \n",
      "2m 38s (- 9m 1s) (10100 22%) loss : 5.059                     \n",
      "2m 39s (- 9m 0s) (10200 22%) loss : 5.111                     \n",
      "2m 41s (- 8m 58s) (10300 23%) loss : 5.063                     \n",
      "2m 42s (- 8m 57s) (10400 23%) loss : 5.096                     \n",
      "2m 44s (- 8m 55s) (10500 23%) loss : 5.053                     \n",
      "2m 45s (- 8m 53s) (10600 23%) loss : 5.099                     \n",
      "2m 47s (- 8m 52s) (10700 23%) loss : 5.097                     \n",
      "2m 48s (- 8m 50s) (10800 24%) loss : 5.070                     \n",
      "2m 50s (- 8m 49s) (10900 24%) loss : 5.089                     \n",
      "2m 52s (- 8m 47s) (11000 24%) loss : 5.075                     \n",
      "2m 53s (- 8m 46s) (11100 24%) loss : 5.103                     \n",
      "2m 55s (- 8m 44s) (11200 25%) loss : 5.081                     \n",
      "2m 56s (- 8m 42s) (11300 25%) loss : 5.074                     \n",
      "2m 58s (- 8m 41s) (11400 25%) loss : 5.120                     \n",
      "2m 59s (- 8m 39s) (11500 25%) loss : 5.107                     \n",
      "3m 1s (- 8m 38s) (11600 25%) loss : 5.068                     \n",
      "3m 2s (- 8m 36s) (11700 26%) loss : 5.051                     \n",
      "3m 4s (- 8m 34s) (11800 26%) loss : 5.087                     \n",
      "3m 6s (- 8m 33s) (11900 26%) loss : 5.090                     \n",
      "3m 7s (- 8m 31s) (12000 26%) loss : 5.065                     \n",
      "3m 9s (- 8m 30s) (12100 27%) loss : 5.101                     \n",
      "3m 10s (- 8m 28s) (12200 27%) loss : 5.086                     \n",
      "3m 12s (- 8m 27s) (12300 27%) loss : 5.119                     \n",
      "3m 13s (- 8m 25s) (12400 27%) loss : 5.087                     \n",
      "3m 15s (- 8m 24s) (12500 27%) loss : 5.077                     \n",
      "3m 17s (- 8m 22s) (12600 28%) loss : 5.096                     \n",
      "3m 18s (- 8m 21s) (12700 28%) loss : 5.115                     \n",
      "3m 20s (- 8m 20s) (12800 28%) loss : 5.087                     \n",
      "3m 22s (- 8m 18s) (12900 28%) loss : 5.090                     \n",
      "3m 23s (- 8m 17s) (13000 29%) loss : 5.118                     \n",
      "3m 25s (- 8m 15s) (13100 29%) loss : 5.103                     \n",
      "3m 26s (- 8m 13s) (13200 29%) loss : 5.148                     \n",
      "3m 28s (- 8m 12s) (13300 29%) loss : 5.071                     \n",
      "3m 29s (- 8m 10s) (13400 29%) loss : 5.093                     \n",
      "3m 31s (- 8m 9s) (13500 30%) loss : 5.065                     \n",
      "3m 33s (- 8m 7s) (13600 30%) loss : 5.101                     \n",
      "3m 34s (- 8m 6s) (13700 30%) loss : 5.092                     \n",
      "3m 36s (- 8m 4s) (13800 30%) loss : 5.104                     \n",
      "3m 37s (- 8m 2s) (13900 31%) loss : 5.087                     \n",
      "3m 39s (- 8m 1s) (14000 31%) loss : 5.099                     \n",
      "3m 40s (- 7m 59s) (14100 31%) loss : 5.081                     \n",
      "3m 42s (- 7m 58s) (14200 31%) loss : 5.073                     \n",
      "3m 43s (- 7m 56s) (14300 31%) loss : 5.086                     \n",
      "3m 45s (- 7m 54s) (14400 32%) loss : 5.081                     \n",
      "3m 47s (- 7m 53s) (14500 32%) loss : 5.109                     \n",
      "3m 48s (- 7m 51s) (14600 32%) loss : 5.104                     \n",
      "3m 50s (- 7m 50s) (14700 32%) loss : 5.074                     \n",
      "3m 51s (- 7m 48s) (14800 33%) loss : 5.070                     \n",
      "3m 53s (- 7m 47s) (14900 33%) loss : 5.056                     \n",
      "epoch 2\n",
      "3m 54s (- 7m 45s) (15000 33%) loss : 5.055                     \n",
      "3m 56s (- 7m 44s) (15100 33%) loss : 5.080                     \n",
      "3m 58s (- 7m 42s) (15200 33%) loss : 5.064                     \n",
      "3m 59s (- 7m 40s) (15300 34%) loss : 5.099                     \n",
      "4m 1s (- 7m 39s) (15400 34%) loss : 5.059                     \n",
      "4m 2s (- 7m 37s) (15500 34%) loss : 5.064                     \n",
      "4m 4s (- 7m 36s) (15600 34%) loss : 5.070                     \n",
      "4m 5s (- 7m 34s) (15700 35%) loss : 5.086                     \n",
      "4m 7s (- 7m 33s) (15800 35%) loss : 5.054                     \n",
      "4m 9s (- 7m 31s) (15900 35%) loss : 5.101                     \n",
      "4m 10s (- 7m 30s) (16000 35%) loss : 5.052                     \n",
      "4m 12s (- 7m 28s) (16100 35%) loss : 5.126                     \n",
      "4m 13s (- 7m 26s) (16200 36%) loss : 5.056                     \n",
      "4m 15s (- 7m 25s) (16300 36%) loss : 5.147                     \n",
      "4m 16s (- 7m 23s) (16400 36%) loss : 5.075                     \n",
      "4m 18s (- 7m 22s) (16500 36%) loss : 5.065                     \n",
      "4m 19s (- 7m 20s) (16600 37%) loss : 5.062                     \n",
      "4m 21s (- 7m 18s) (16700 37%) loss : 5.073                     \n",
      "4m 23s (- 7m 17s) (16800 37%) loss : 5.057                     \n",
      "4m 24s (- 7m 15s) (16900 37%) loss : 5.060                     \n",
      "4m 26s (- 7m 14s) (17000 38%) loss : 5.075                     \n",
      "4m 27s (- 7m 12s) (17100 38%) loss : 5.057                     \n",
      "4m 29s (- 7m 11s) (17200 38%) loss : 5.081                     \n",
      "4m 30s (- 7m 9s) (17300 38%) loss : 5.095                     \n",
      "4m 32s (- 7m 7s) (17400 38%) loss : 5.046                     \n",
      "4m 33s (- 7m 6s) (17500 39%) loss : 5.065                     \n",
      "4m 35s (- 7m 4s) (17600 39%) loss : 5.056                     \n",
      "4m 37s (- 7m 3s) (17700 39%) loss : 5.047                     \n",
      "4m 38s (- 7m 1s) (17800 39%) loss : 5.093                     \n",
      "4m 40s (- 6m 59s) (17900 40%) loss : 5.040                     \n",
      "4m 41s (- 6m 58s) (18000 40%) loss : 5.102                     \n",
      "4m 43s (- 6m 56s) (18100 40%) loss : 5.112                     \n",
      "4m 44s (- 6m 55s) (18200 40%) loss : 5.072                     \n",
      "4m 46s (- 6m 53s) (18300 40%) loss : 5.069                     \n",
      "4m 48s (- 6m 52s) (18400 41%) loss : 5.051                     \n",
      "4m 49s (- 6m 50s) (18500 41%) loss : 5.042                     \n",
      "4m 51s (- 6m 48s) (18600 41%) loss : 5.073                     \n",
      "4m 52s (- 6m 47s) (18700 41%) loss : 5.048                     \n",
      "4m 54s (- 6m 45s) (18800 42%) loss : 5.060                     \n",
      "4m 55s (- 6m 44s) (18900 42%) loss : 5.111                     \n",
      "4m 57s (- 6m 42s) (19000 42%) loss : 5.057                     \n",
      "4m 58s (- 6m 41s) (19100 42%) loss : 5.069                     \n",
      "5m 0s (- 6m 39s) (19200 42%) loss : 5.076                     \n",
      "5m 2s (- 6m 37s) (19300 43%) loss : 5.065                     \n",
      "5m 3s (- 6m 36s) (19400 43%) loss : 5.069                     \n",
      "5m 5s (- 6m 34s) (19500 43%) loss : 5.093                     \n",
      "5m 6s (- 6m 33s) (19600 43%) loss : 5.069                     \n",
      "5m 8s (- 6m 31s) (19700 44%) loss : 5.073                     \n",
      "5m 10s (- 6m 30s) (19800 44%) loss : 5.112                     \n",
      "5m 11s (- 6m 28s) (19900 44%) loss : 5.077                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 13s (- 6m 27s) (20000 44%) loss : 5.069                     \n",
      "5m 14s (- 6m 25s) (20100 44%) loss : 5.071                     \n",
      "5m 16s (- 6m 24s) (20200 45%) loss : 5.083                     \n",
      "5m 17s (- 6m 22s) (20300 45%) loss : 5.105                     \n",
      "5m 19s (- 6m 21s) (20400 45%) loss : 5.053                     \n",
      "5m 21s (- 6m 19s) (20500 45%) loss : 5.066                     \n",
      "5m 22s (- 6m 18s) (20600 46%) loss : 5.096                     \n",
      "5m 24s (- 6m 16s) (20700 46%) loss : 5.084                     \n",
      "5m 25s (- 6m 14s) (20800 46%) loss : 5.076                     \n",
      "5m 27s (- 6m 13s) (20900 46%) loss : 5.079                     \n",
      "5m 29s (- 6m 11s) (21000 46%) loss : 5.056                     \n",
      "5m 30s (- 6m 10s) (21100 47%) loss : 5.059                     \n",
      "5m 32s (- 6m 8s) (21200 47%) loss : 5.059                     \n",
      "5m 33s (- 6m 7s) (21300 47%) loss : 5.043                     \n",
      "5m 35s (- 6m 5s) (21400 47%) loss : 5.054                     \n",
      "5m 37s (- 6m 4s) (21500 48%) loss : 5.071                     \n",
      "5m 38s (- 6m 2s) (21600 48%) loss : 5.073                     \n",
      "5m 40s (- 6m 1s) (21700 48%) loss : 5.100                     \n",
      "5m 41s (- 5m 59s) (21800 48%) loss : 5.032                     \n",
      "5m 43s (- 5m 57s) (21900 48%) loss : 5.085                     \n",
      "5m 44s (- 5m 56s) (22000 49%) loss : 5.081                     \n",
      "5m 46s (- 5m 54s) (22100 49%) loss : 5.077                     \n",
      "5m 48s (- 5m 53s) (22200 49%) loss : 5.091                     \n",
      "5m 49s (- 5m 51s) (22300 49%) loss : 5.026                     \n",
      "5m 51s (- 5m 50s) (22400 50%) loss : 5.080                     \n",
      "5m 52s (- 5m 48s) (22500 50%) loss : 5.043                     \n",
      "5m 54s (- 5m 46s) (22600 50%) loss : 5.055                     \n",
      "5m 55s (- 5m 45s) (22700 50%) loss : 5.081                     \n",
      "5m 57s (- 5m 43s) (22800 50%) loss : 5.051                     \n",
      "5m 59s (- 5m 42s) (22900 51%) loss : 5.052                     \n",
      "6m 0s (- 5m 40s) (23000 51%) loss : 5.069                     \n",
      "6m 2s (- 5m 39s) (23100 51%) loss : 5.118                     \n",
      "6m 3s (- 5m 37s) (23200 51%) loss : 5.079                     \n",
      "6m 5s (- 5m 35s) (23300 52%) loss : 5.066                     \n",
      "6m 6s (- 5m 34s) (23400 52%) loss : 5.089                     \n",
      "6m 8s (- 5m 32s) (23500 52%) loss : 5.084                     \n",
      "6m 9s (- 5m 31s) (23600 52%) loss : 5.040                     \n",
      "6m 11s (- 5m 29s) (23700 52%) loss : 5.092                     \n",
      "6m 13s (- 5m 27s) (23800 53%) loss : 5.043                     \n",
      "6m 14s (- 5m 26s) (23900 53%) loss : 5.059                     \n",
      "6m 16s (- 5m 24s) (24000 53%) loss : 5.065                     \n",
      "6m 17s (- 5m 23s) (24100 53%) loss : 5.069                     \n",
      "6m 19s (- 5m 21s) (24200 54%) loss : 5.042                     \n",
      "6m 20s (- 5m 20s) (24300 54%) loss : 5.083                     \n",
      "6m 22s (- 5m 18s) (24400 54%) loss : 5.085                     \n",
      "6m 23s (- 5m 16s) (24500 54%) loss : 5.084                     \n",
      "6m 25s (- 5m 15s) (24600 55%) loss : 5.096                     \n",
      "6m 27s (- 5m 13s) (24700 55%) loss : 5.064                     \n",
      "6m 28s (- 5m 12s) (24800 55%) loss : 5.087                     \n",
      "6m 30s (- 5m 10s) (24900 55%) loss : 5.134                     \n",
      "6m 31s (- 5m 9s) (25000 55%) loss : 5.117                     \n",
      "6m 33s (- 5m 7s) (25100 56%) loss : 5.083                     \n",
      "6m 34s (- 5m 5s) (25200 56%) loss : 5.066                     \n",
      "6m 36s (- 5m 4s) (25300 56%) loss : 5.041                     \n",
      "6m 38s (- 5m 2s) (25400 56%) loss : 5.058                     \n",
      "6m 39s (- 5m 1s) (25500 57%) loss : 5.062                     \n",
      "6m 41s (- 4m 59s) (25600 57%) loss : 5.084                     \n",
      "6m 42s (- 4m 58s) (25700 57%) loss : 5.112                     \n",
      "6m 44s (- 4m 56s) (25800 57%) loss : 5.095                     \n",
      "6m 45s (- 4m 55s) (25900 57%) loss : 5.078                     \n",
      "6m 47s (- 4m 53s) (26000 58%) loss : 5.072                     \n",
      "6m 49s (- 4m 51s) (26100 58%) loss : 5.102                     \n",
      "6m 50s (- 4m 50s) (26200 58%) loss : 5.106                     \n",
      "6m 52s (- 4m 48s) (26300 58%) loss : 5.079                     \n",
      "6m 53s (- 4m 47s) (26400 59%) loss : 5.096                     \n",
      "6m 55s (- 4m 45s) (26500 59%) loss : 5.073                     \n",
      "6m 56s (- 4m 44s) (26600 59%) loss : 5.067                     \n",
      "6m 58s (- 4m 42s) (26700 59%) loss : 5.085                     \n",
      "6m 59s (- 4m 40s) (26800 59%) loss : 5.077                     \n",
      "7m 1s (- 4m 39s) (26900 60%) loss : 5.067                     \n",
      "7m 3s (- 4m 37s) (27000 60%) loss : 5.082                     \n",
      "7m 4s (- 4m 36s) (27100 60%) loss : 5.074                     \n",
      "7m 6s (- 4m 34s) (27200 60%) loss : 5.067                     \n",
      "7m 7s (- 4m 33s) (27300 61%) loss : 5.039                     \n",
      "7m 9s (- 4m 31s) (27400 61%) loss : 5.082                     \n",
      "7m 10s (- 4m 29s) (27500 61%) loss : 5.046                     \n",
      "7m 12s (- 4m 28s) (27600 61%) loss : 5.110                     \n",
      "7m 13s (- 4m 26s) (27700 61%) loss : 5.083                     \n",
      "7m 15s (- 4m 25s) (27800 62%) loss : 5.101                     \n",
      "7m 17s (- 4m 23s) (27900 62%) loss : 5.052                     \n",
      "7m 18s (- 4m 22s) (28000 62%) loss : 5.058                     \n",
      "7m 20s (- 4m 20s) (28100 62%) loss : 5.078                     \n",
      "7m 21s (- 4m 18s) (28200 63%) loss : 5.080                     \n",
      "7m 23s (- 4m 17s) (28300 63%) loss : 5.098                     \n",
      "7m 24s (- 4m 15s) (28400 63%) loss : 5.112                     \n",
      "7m 26s (- 4m 14s) (28500 63%) loss : 5.067                     \n",
      "7m 27s (- 4m 12s) (28600 63%) loss : 5.058                     \n",
      "7m 29s (- 4m 11s) (28700 64%) loss : 5.076                     \n",
      "7m 31s (- 4m 9s) (28800 64%) loss : 5.070                     \n",
      "7m 32s (- 4m 7s) (28900 64%) loss : 5.101                     \n",
      "7m 34s (- 4m 6s) (29000 64%) loss : 5.084                     \n",
      "7m 35s (- 4m 4s) (29100 65%) loss : 5.074                     \n",
      "7m 37s (- 4m 3s) (29200 65%) loss : 5.074                     \n",
      "7m 39s (- 4m 1s) (29300 65%) loss : 5.076                     \n",
      "7m 40s (- 4m 0s) (29400 65%) loss : 5.115                     \n",
      "7m 42s (- 3m 58s) (29500 65%) loss : 5.081                     \n",
      "7m 43s (- 3m 57s) (29600 66%) loss : 5.066                     \n",
      "7m 45s (- 3m 55s) (29700 66%) loss : 5.073                     \n",
      "7m 46s (- 3m 53s) (29800 66%) loss : 5.070                     \n",
      "epoch 3\n",
      "7m 48s (- 3m 52s) (29900 66%) loss : 5.047                     \n",
      "7m 50s (- 3m 50s) (30000 67%) loss : 5.019                     \n",
      "7m 51s (- 3m 49s) (30100 67%) loss : 5.048                     \n",
      "7m 53s (- 3m 47s) (30200 67%) loss : 5.045                     \n",
      "7m 54s (- 3m 46s) (30300 67%) loss : 5.035                     \n",
      "7m 56s (- 3m 44s) (30400 67%) loss : 5.082                     \n",
      "7m 57s (- 3m 42s) (30500 68%) loss : 5.035                     \n",
      "7m 59s (- 3m 41s) (30600 68%) loss : 5.071                     \n",
      "8m 0s (- 3m 39s) (30700 68%) loss : 5.055                     \n",
      "8m 2s (- 3m 38s) (30800 68%) loss : 5.044                     \n",
      "8m 4s (- 3m 36s) (30900 69%) loss : 5.082                     \n",
      "8m 5s (- 3m 35s) (31000 69%) loss : 5.047                     \n",
      "8m 7s (- 3m 33s) (31100 69%) loss : 5.075                     \n",
      "8m 8s (- 3m 31s) (31200 69%) loss : 5.054                     \n",
      "8m 10s (- 3m 30s) (31300 69%) loss : 5.046                     \n",
      "8m 11s (- 3m 28s) (31400 70%) loss : 5.040                     \n",
      "8m 13s (- 3m 27s) (31500 70%) loss : 5.022                     \n",
      "8m 14s (- 3m 25s) (31600 70%) loss : 5.084                     \n",
      "8m 16s (- 3m 24s) (31700 70%) loss : 5.078                     \n",
      "8m 17s (- 3m 22s) (31800 71%) loss : 5.029                     \n",
      "8m 19s (- 3m 20s) (31900 71%) loss : 5.062                     \n",
      "8m 21s (- 3m 19s) (32000 71%) loss : 5.063                     \n",
      "8m 22s (- 3m 17s) (32100 71%) loss : 5.031                     \n",
      "8m 24s (- 3m 16s) (32200 71%) loss : 5.081                     \n",
      "8m 25s (- 3m 14s) (32300 72%) loss : 5.062                     \n",
      "8m 27s (- 3m 13s) (32400 72%) loss : 5.089                     \n",
      "8m 28s (- 3m 11s) (32500 72%) loss : 5.074                     \n",
      "8m 30s (- 3m 9s) (32600 72%) loss : 5.046                     \n",
      "8m 31s (- 3m 8s) (32700 73%) loss : 5.082                     \n",
      "8m 33s (- 3m 6s) (32800 73%) loss : 5.044                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 35s (- 3m 5s) (32900 73%) loss : 5.069                     \n",
      "8m 36s (- 3m 3s) (33000 73%) loss : 5.033                     \n",
      "8m 38s (- 3m 2s) (33100 74%) loss : 5.093                     \n",
      "8m 39s (- 3m 0s) (33200 74%) loss : 5.033                     \n",
      "8m 41s (- 2m 58s) (33300 74%) loss : 5.073                     \n",
      "8m 42s (- 2m 57s) (33400 74%) loss : 5.032                     \n",
      "8m 44s (- 2m 55s) (33500 74%) loss : 5.071                     \n",
      "8m 45s (- 2m 54s) (33600 75%) loss : 5.062                     \n",
      "8m 47s (- 2m 52s) (33700 75%) loss : 5.036                     \n",
      "8m 49s (- 2m 51s) (33800 75%) loss : 5.052                     \n",
      "8m 50s (- 2m 49s) (33900 75%) loss : 5.049                     \n",
      "8m 52s (- 2m 47s) (34000 76%) loss : 5.046                     \n",
      "8m 53s (- 2m 46s) (34100 76%) loss : 5.081                     \n",
      "8m 55s (- 2m 44s) (34200 76%) loss : 5.063                     \n",
      "8m 56s (- 2m 43s) (34300 76%) loss : 5.077                     \n",
      "8m 58s (- 2m 41s) (34400 76%) loss : 5.079                     \n",
      "8m 59s (- 2m 40s) (34500 77%) loss : 5.043                     \n",
      "9m 1s (- 2m 38s) (34600 77%) loss : 5.080                     \n",
      "9m 3s (- 2m 36s) (34700 77%) loss : 5.094                     \n",
      "9m 4s (- 2m 35s) (34800 77%) loss : 5.056                     \n",
      "9m 6s (- 2m 33s) (34900 78%) loss : 5.072                     \n",
      "9m 7s (- 2m 32s) (35000 78%) loss : 5.065                     \n",
      "9m 9s (- 2m 30s) (35100 78%) loss : 5.059                     \n",
      "9m 10s (- 2m 29s) (35200 78%) loss : 5.024                     \n",
      "9m 12s (- 2m 27s) (35300 78%) loss : 5.061                     \n",
      "9m 13s (- 2m 25s) (35400 79%) loss : 5.047                     \n",
      "9m 15s (- 2m 24s) (35500 79%) loss : 5.064                     \n",
      "9m 17s (- 2m 22s) (35600 79%) loss : 5.028                     \n",
      "9m 18s (- 2m 21s) (35700 79%) loss : 5.067                     \n",
      "9m 20s (- 2m 19s) (35800 80%) loss : 5.076                     \n",
      "9m 21s (- 2m 18s) (35900 80%) loss : 5.053                     \n",
      "9m 23s (- 2m 16s) (36000 80%) loss : 5.072                     \n",
      "9m 24s (- 2m 14s) (36100 80%) loss : 5.069                     \n",
      "9m 26s (- 2m 13s) (36200 80%) loss : 5.038                     \n",
      "9m 27s (- 2m 11s) (36300 81%) loss : 5.065                     \n",
      "9m 29s (- 2m 10s) (36400 81%) loss : 5.084                     \n",
      "9m 31s (- 2m 8s) (36500 81%) loss : 5.053                     \n",
      "9m 32s (- 2m 7s) (36600 81%) loss : 5.052                     \n",
      "9m 34s (- 2m 5s) (36700 82%) loss : 5.047                     \n",
      "9m 35s (- 2m 4s) (36800 82%) loss : 5.098                     \n",
      "9m 37s (- 2m 2s) (36900 82%) loss : 5.076                     \n",
      "9m 38s (- 2m 0s) (37000 82%) loss : 5.052                     \n",
      "9m 40s (- 1m 59s) (37100 82%) loss : 5.053                     \n",
      "9m 42s (- 1m 57s) (37200 83%) loss : 5.062                     \n",
      "9m 43s (- 1m 56s) (37300 83%) loss : 5.128                     \n",
      "9m 45s (- 1m 54s) (37400 83%) loss : 5.097                     \n",
      "9m 46s (- 1m 53s) (37500 83%) loss : 5.085                     \n",
      "9m 48s (- 1m 51s) (37600 84%) loss : 5.073                     \n",
      "9m 49s (- 1m 49s) (37700 84%) loss : 5.052                     \n",
      "9m 51s (- 1m 48s) (37800 84%) loss : 5.079                     \n",
      "9m 52s (- 1m 46s) (37900 84%) loss : 5.066                     \n",
      "9m 54s (- 1m 45s) (38000 84%) loss : 5.066                     \n",
      "9m 55s (- 1m 43s) (38100 85%) loss : 5.018                     \n",
      "9m 57s (- 1m 42s) (38200 85%) loss : 5.060                     \n",
      "9m 59s (- 1m 40s) (38300 85%) loss : 5.020                     \n",
      "10m 0s (- 1m 38s) (38400 85%) loss : 5.096                     \n",
      "10m 2s (- 1m 37s) (38500 86%) loss : 5.061                     \n",
      "10m 3s (- 1m 35s) (38600 86%) loss : 5.058                     \n",
      "10m 5s (- 1m 34s) (38700 86%) loss : 5.049                     \n",
      "10m 6s (- 1m 32s) (38800 86%) loss : 5.065                     \n",
      "10m 8s (- 1m 31s) (38900 86%) loss : 5.049                     \n",
      "10m 9s (- 1m 29s) (39000 87%) loss : 5.076                     \n",
      "10m 11s (- 1m 28s) (39100 87%) loss : 5.076                     \n",
      "10m 13s (- 1m 26s) (39200 87%) loss : 5.063                     \n",
      "10m 14s (- 1m 24s) (39300 87%) loss : 5.094                     \n",
      "10m 16s (- 1m 23s) (39400 88%) loss : 5.059                     \n",
      "10m 17s (- 1m 21s) (39500 88%) loss : 5.043                     \n",
      "10m 19s (- 1m 20s) (39600 88%) loss : 5.041                     \n",
      "10m 20s (- 1m 18s) (39700 88%) loss : 5.102                     \n",
      "10m 22s (- 1m 17s) (39800 88%) loss : 5.091                     \n",
      "10m 24s (- 1m 15s) (39900 89%) loss : 5.098                     \n",
      "10m 25s (- 1m 13s) (40000 89%) loss : 5.083                     \n",
      "10m 27s (- 1m 12s) (40100 89%) loss : 5.032                     \n",
      "10m 28s (- 1m 10s) (40200 89%) loss : 5.078                     \n",
      "10m 30s (- 1m 9s) (40300 90%) loss : 5.069                     \n",
      "10m 31s (- 1m 7s) (40400 90%) loss : 5.053                     \n",
      "10m 33s (- 1m 6s) (40500 90%) loss : 5.099                     \n",
      "10m 34s (- 1m 4s) (40600 90%) loss : 5.053                     \n",
      "10m 36s (- 1m 2s) (40700 90%) loss : 5.098                     \n",
      "10m 38s (- 1m 1s) (40800 91%) loss : 5.069                     \n",
      "10m 39s (- 0m 59s) (40900 91%) loss : 5.064                     \n",
      "10m 41s (- 0m 58s) (41000 91%) loss : 5.037                     \n",
      "10m 42s (- 0m 56s) (41100 91%) loss : 5.077                     \n",
      "10m 44s (- 0m 55s) (41200 92%) loss : 5.023                     \n",
      "10m 45s (- 0m 53s) (41300 92%) loss : 5.103                     \n",
      "10m 47s (- 0m 52s) (41400 92%) loss : 5.060                     \n",
      "10m 48s (- 0m 50s) (41500 92%) loss : 5.042                     \n",
      "10m 50s (- 0m 48s) (41600 93%) loss : 5.076                     \n",
      "10m 52s (- 0m 47s) (41700 93%) loss : 5.023                     \n",
      "10m 53s (- 0m 45s) (41800 93%) loss : 5.051                     \n",
      "10m 55s (- 0m 44s) (41900 93%) loss : 5.066                     \n",
      "10m 56s (- 0m 42s) (42000 93%) loss : 5.059                     \n",
      "10m 58s (- 0m 41s) (42100 94%) loss : 5.068                     \n",
      "10m 59s (- 0m 39s) (42200 94%) loss : 5.079                     \n",
      "11m 1s (- 0m 37s) (42300 94%) loss : 5.089                     \n",
      "11m 2s (- 0m 36s) (42400 94%) loss : 5.066                     \n",
      "11m 4s (- 0m 34s) (42500 95%) loss : 5.049                     \n",
      "11m 6s (- 0m 33s) (42600 95%) loss : 5.069                     \n",
      "11m 7s (- 0m 31s) (42700 95%) loss : 5.059                     \n",
      "11m 9s (- 0m 30s) (42800 95%) loss : 5.063                     \n",
      "11m 10s (- 0m 28s) (42900 95%) loss : 5.064                     \n",
      "11m 12s (- 0m 26s) (43000 96%) loss : 5.055                     \n",
      "11m 13s (- 0m 25s) (43100 96%) loss : 5.078                     \n",
      "11m 15s (- 0m 23s) (43200 96%) loss : 5.071                     \n",
      "11m 16s (- 0m 22s) (43300 96%) loss : 5.071                     \n",
      "11m 18s (- 0m 20s) (43400 97%) loss : 5.074                     \n",
      "11m 20s (- 0m 19s) (43500 97%) loss : 5.081                     \n",
      "11m 21s (- 0m 17s) (43600 97%) loss : 5.053                     \n",
      "11m 23s (- 0m 16s) (43700 97%) loss : 5.080                     \n",
      "11m 24s (- 0m 14s) (43800 97%) loss : 5.109                     \n",
      "11m 26s (- 0m 12s) (43900 98%) loss : 5.054                     \n",
      "11m 27s (- 0m 11s) (44000 98%) loss : 5.036                     \n",
      "11m 29s (- 0m 9s) (44100 98%) loss : 5.044                     \n",
      "11m 30s (- 0m 8s) (44200 98%) loss : 5.041                     \n",
      "11m 32s (- 0m 6s) (44300 99%) loss : 5.052                     \n",
      "11m 34s (- 0m 5s) (44400 99%) loss : 5.073                     \n",
      "11m 35s (- 0m 3s) (44500 99%) loss : 5.113                     \n",
      "11m 37s (- 0m 1s) (44600 99%) loss : 5.067                     \n",
      "11m 38s (- 0m 0s) (44700 99%) loss : 5.078                     \n",
      "0m 9s (- 0m 0s) (100 100%) loss : 5.047  accuracy : 14.1 %\n",
      "epoch 1\n",
      "0m 1s (- 11m 41s) (100 0%) loss : 5.026                     \n",
      "0m 3s (- 11m 34s) (200 0%) loss : 5.030                     \n",
      "0m 4s (- 11m 33s) (300 0%) loss : 5.027                     \n",
      "0m 6s (- 11m 30s) (400 0%) loss : 5.024                     \n",
      "0m 7s (- 11m 28s) (500 1%) loss : 5.043                     \n",
      "0m 9s (- 11m 27s) (600 1%) loss : 5.060                     \n",
      "0m 10s (- 11m 25s) (700 1%) loss : 5.034                     \n",
      "0m 12s (- 11m 24s) (800 1%) loss : 5.043                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 14s (- 11m 23s) (900 2%) loss : 5.022                     \n",
      "0m 15s (- 11m 21s) (1000 2%) loss : 5.023                     \n",
      "0m 17s (- 11m 19s) (1100 2%) loss : 5.024                     \n",
      "0m 18s (- 11m 18s) (1200 2%) loss : 5.023                     \n",
      "0m 20s (- 11m 16s) (1300 2%) loss : 5.022                     \n",
      "0m 21s (- 11m 15s) (1400 3%) loss : 5.003                     \n",
      "0m 23s (- 11m 14s) (1500 3%) loss : 5.015                     \n",
      "0m 24s (- 11m 12s) (1600 3%) loss : 5.031                     \n",
      "0m 26s (- 11m 11s) (1700 3%) loss : 5.049                     \n",
      "0m 28s (- 11m 9s) (1800 4%) loss : 5.000                     \n",
      "0m 29s (- 11m 7s) (1900 4%) loss : 5.019                     \n",
      "0m 31s (- 11m 5s) (2000 4%) loss : 5.045                     \n",
      "0m 32s (- 11m 4s) (2100 4%) loss : 5.035                     \n",
      "0m 34s (- 11m 2s) (2200 4%) loss : 5.021                     \n",
      "0m 35s (- 11m 0s) (2300 5%) loss : 5.045                     \n",
      "0m 37s (- 10m 59s) (2400 5%) loss : 5.047                     \n",
      "0m 38s (- 10m 57s) (2500 5%) loss : 4.997                     \n",
      "0m 40s (- 10m 55s) (2600 5%) loss : 5.049                     \n",
      "0m 42s (- 10m 54s) (2700 6%) loss : 5.062                     \n",
      "0m 43s (- 10m 52s) (2800 6%) loss : 5.048                     \n",
      "0m 45s (- 10m 51s) (2900 6%) loss : 5.037                     \n",
      "0m 46s (- 10m 49s) (3000 6%) loss : 5.037                     \n",
      "0m 48s (- 10m 47s) (3100 6%) loss : 5.087                     \n",
      "0m 49s (- 10m 46s) (3200 7%) loss : 5.072                     \n",
      "0m 51s (- 10m 45s) (3300 7%) loss : 5.005                     \n",
      "0m 52s (- 10m 43s) (3400 7%) loss : 5.042                     \n",
      "0m 54s (- 10m 41s) (3500 7%) loss : 5.046                     \n",
      "0m 56s (- 10m 40s) (3600 8%) loss : 5.009                     \n",
      "0m 57s (- 10m 38s) (3700 8%) loss : 5.065                     \n",
      "0m 59s (- 10m 37s) (3800 8%) loss : 5.044                     \n",
      "1m 0s (- 10m 35s) (3900 8%) loss : 5.040                     \n",
      "1m 2s (- 10m 33s) (4000 8%) loss : 5.075                     \n",
      "1m 3s (- 10m 32s) (4100 9%) loss : 5.045                     \n",
      "1m 5s (- 10m 30s) (4200 9%) loss : 5.038                     \n",
      "1m 6s (- 10m 29s) (4300 9%) loss : 5.037                     \n",
      "1m 8s (- 10m 27s) (4400 9%) loss : 5.019                     \n",
      "1m 10s (- 10m 26s) (4500 10%) loss : 5.005                     \n",
      "1m 11s (- 10m 24s) (4600 10%) loss : 5.036                     \n",
      "1m 13s (- 10m 23s) (4700 10%) loss : 5.034                     \n",
      "1m 14s (- 10m 21s) (4800 10%) loss : 5.012                     \n",
      "1m 16s (- 10m 19s) (4900 10%) loss : 5.032                     \n",
      "1m 17s (- 10m 18s) (5000 11%) loss : 5.042                     \n",
      "1m 19s (- 10m 16s) (5100 11%) loss : 5.037                     \n",
      "1m 20s (- 10m 15s) (5200 11%) loss : 5.063                     \n",
      "1m 22s (- 10m 13s) (5300 11%) loss : 5.039                     \n",
      "1m 24s (- 10m 12s) (5400 12%) loss : 5.025                     \n",
      "1m 25s (- 10m 10s) (5500 12%) loss : 5.054                     \n",
      "1m 27s (- 10m 8s) (5600 12%) loss : 5.046                     \n",
      "1m 28s (- 10m 7s) (5700 12%) loss : 5.002                     \n",
      "1m 30s (- 10m 5s) (5800 12%) loss : 5.050                     \n",
      "1m 31s (- 10m 4s) (5900 13%) loss : 5.070                     \n",
      "1m 33s (- 10m 2s) (6000 13%) loss : 5.032                     \n",
      "1m 34s (- 10m 1s) (6100 13%) loss : 5.073                     \n",
      "1m 36s (- 9m 59s) (6200 13%) loss : 5.022                     \n",
      "1m 38s (- 9m 57s) (6300 14%) loss : 5.016                     \n",
      "1m 39s (- 9m 56s) (6400 14%) loss : 5.005                     \n",
      "1m 41s (- 9m 54s) (6500 14%) loss : 5.054                     \n",
      "1m 42s (- 9m 53s) (6600 14%) loss : 5.001                     \n",
      "1m 44s (- 9m 51s) (6700 14%) loss : 4.980                     \n",
      "1m 45s (- 9m 50s) (6800 15%) loss : 5.050                     \n",
      "1m 47s (- 9m 48s) (6900 15%) loss : 5.069                     \n",
      "1m 48s (- 9m 46s) (7000 15%) loss : 5.066                     \n",
      "1m 50s (- 9m 45s) (7100 15%) loss : 5.065                     \n",
      "1m 52s (- 9m 43s) (7200 16%) loss : 5.026                     \n",
      "1m 53s (- 9m 42s) (7300 16%) loss : 5.007                     \n",
      "1m 55s (- 9m 40s) (7400 16%) loss : 4.993                     \n",
      "1m 56s (- 9m 39s) (7500 16%) loss : 5.050                     \n",
      "1m 58s (- 9m 37s) (7600 16%) loss : 5.055                     \n",
      "1m 59s (- 9m 36s) (7700 17%) loss : 5.013                     \n",
      "2m 1s (- 9m 34s) (7800 17%) loss : 5.080                     \n",
      "2m 2s (- 9m 32s) (7900 17%) loss : 5.020                     \n",
      "2m 4s (- 9m 31s) (8000 17%) loss : 5.004                     \n",
      "2m 6s (- 9m 29s) (8100 18%) loss : 5.022                     \n",
      "2m 7s (- 9m 28s) (8200 18%) loss : 5.045                     \n",
      "2m 9s (- 9m 26s) (8300 18%) loss : 5.026                     \n",
      "2m 10s (- 9m 25s) (8400 18%) loss : 5.050                     \n",
      "2m 12s (- 9m 23s) (8500 19%) loss : 5.024                     \n",
      "2m 13s (- 9m 22s) (8600 19%) loss : 5.033                     \n",
      "2m 15s (- 9m 20s) (8700 19%) loss : 4.999                     \n",
      "2m 16s (- 9m 19s) (8800 19%) loss : 5.016                     \n",
      "2m 18s (- 9m 17s) (8900 19%) loss : 5.047                     \n",
      "2m 20s (- 9m 15s) (9000 20%) loss : 5.041                     \n",
      "2m 21s (- 9m 14s) (9100 20%) loss : 5.054                     \n",
      "2m 23s (- 9m 12s) (9200 20%) loss : 5.036                     \n",
      "2m 24s (- 9m 11s) (9300 20%) loss : 5.040                     \n",
      "2m 26s (- 9m 9s) (9400 21%) loss : 5.047                     \n",
      "2m 27s (- 9m 8s) (9500 21%) loss : 4.990                     \n",
      "2m 29s (- 9m 6s) (9600 21%) loss : 5.020                     \n",
      "2m 30s (- 9m 5s) (9700 21%) loss : 5.074                     \n",
      "2m 32s (- 9m 3s) (9800 21%) loss : 5.058                     \n",
      "2m 34s (- 9m 1s) (9900 22%) loss : 5.047                     \n",
      "2m 35s (- 9m 0s) (10000 22%) loss : 5.047                     \n",
      "2m 37s (- 8m 58s) (10100 22%) loss : 5.028                     \n",
      "2m 38s (- 8m 57s) (10200 22%) loss : 5.052                     \n",
      "2m 40s (- 8m 55s) (10300 23%) loss : 5.017                     \n",
      "2m 41s (- 8m 54s) (10400 23%) loss : 5.054                     \n",
      "2m 43s (- 8m 52s) (10500 23%) loss : 5.043                     \n",
      "2m 44s (- 8m 51s) (10600 23%) loss : 5.026                     \n",
      "2m 46s (- 8m 49s) (10700 23%) loss : 5.015                     \n",
      "2m 48s (- 8m 47s) (10800 24%) loss : 5.041                     \n",
      "2m 49s (- 8m 46s) (10900 24%) loss : 5.068                     \n",
      "2m 51s (- 8m 44s) (11000 24%) loss : 5.022                     \n",
      "2m 52s (- 8m 43s) (11100 24%) loss : 5.074                     \n",
      "2m 54s (- 8m 41s) (11200 25%) loss : 5.076                     \n",
      "2m 55s (- 8m 40s) (11300 25%) loss : 5.044                     \n",
      "2m 57s (- 8m 38s) (11400 25%) loss : 5.033                     \n",
      "2m 58s (- 8m 37s) (11500 25%) loss : 5.036                     \n",
      "3m 0s (- 8m 35s) (11600 25%) loss : 5.025                     \n",
      "3m 2s (- 8m 33s) (11700 26%) loss : 5.060                     \n",
      "3m 3s (- 8m 32s) (11800 26%) loss : 5.050                     \n",
      "3m 5s (- 8m 31s) (11900 26%) loss : 5.046                     \n",
      "3m 6s (- 8m 29s) (12000 26%) loss : 5.011                     \n",
      "3m 8s (- 8m 28s) (12100 27%) loss : 5.028                     \n",
      "3m 10s (- 8m 27s) (12200 27%) loss : 5.026                     \n",
      "3m 11s (- 8m 25s) (12300 27%) loss : 5.029                     \n",
      "3m 13s (- 8m 24s) (12400 27%) loss : 5.037                     \n",
      "3m 14s (- 8m 22s) (12500 27%) loss : 5.074                     \n",
      "3m 16s (- 8m 20s) (12600 28%) loss : 5.046                     \n",
      "3m 18s (- 8m 19s) (12700 28%) loss : 5.065                     \n",
      "3m 19s (- 8m 17s) (12800 28%) loss : 5.069                     \n",
      "3m 21s (- 8m 16s) (12900 28%) loss : 5.063                     \n",
      "3m 22s (- 8m 14s) (13000 29%) loss : 5.063                     \n",
      "3m 24s (- 8m 13s) (13100 29%) loss : 5.050                     \n",
      "3m 25s (- 8m 11s) (13200 29%) loss : 5.058                     \n",
      "3m 27s (- 8m 9s) (13300 29%) loss : 5.047                     \n",
      "3m 28s (- 8m 8s) (13400 29%) loss : 5.033                     \n",
      "3m 30s (- 8m 6s) (13500 30%) loss : 5.089                     \n",
      "3m 32s (- 8m 5s) (13600 30%) loss : 5.079                     \n",
      "3m 33s (- 8m 3s) (13700 30%) loss : 5.033                     \n",
      "3m 35s (- 8m 2s) (13800 30%) loss : 5.034                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 36s (- 8m 0s) (13900 31%) loss : 5.020                     \n",
      "3m 38s (- 7m 59s) (14000 31%) loss : 5.085                     \n",
      "3m 39s (- 7m 57s) (14100 31%) loss : 5.037                     \n",
      "3m 41s (- 7m 55s) (14200 31%) loss : 5.032                     \n",
      "3m 42s (- 7m 54s) (14300 31%) loss : 5.060                     \n",
      "3m 44s (- 7m 52s) (14400 32%) loss : 5.041                     \n",
      "3m 46s (- 7m 51s) (14500 32%) loss : 5.074                     \n",
      "3m 47s (- 7m 49s) (14600 32%) loss : 5.075                     \n",
      "3m 49s (- 7m 48s) (14700 32%) loss : 5.060                     \n",
      "3m 50s (- 7m 46s) (14800 33%) loss : 5.032                     \n",
      "3m 52s (- 7m 45s) (14900 33%) loss : 5.030                     \n",
      "epoch 2\n",
      "3m 53s (- 7m 43s) (15000 33%) loss : 5.005                     \n",
      "3m 55s (- 7m 42s) (15100 33%) loss : 5.042                     \n",
      "3m 57s (- 7m 40s) (15200 33%) loss : 5.031                     \n",
      "3m 58s (- 7m 38s) (15300 34%) loss : 4.987                     \n",
      "4m 0s (- 7m 37s) (15400 34%) loss : 5.048                     \n",
      "4m 1s (- 7m 35s) (15500 34%) loss : 5.010                     \n",
      "4m 3s (- 7m 34s) (15600 34%) loss : 4.999                     \n",
      "4m 4s (- 7m 32s) (15700 35%) loss : 5.026                     \n",
      "4m 6s (- 7m 31s) (15800 35%) loss : 4.999                     \n",
      "4m 7s (- 7m 29s) (15900 35%) loss : 5.041                     \n",
      "4m 9s (- 7m 27s) (16000 35%) loss : 5.001                     \n",
      "4m 11s (- 7m 26s) (16100 35%) loss : 5.048                     \n",
      "4m 12s (- 7m 24s) (16200 36%) loss : 5.033                     \n",
      "4m 14s (- 7m 23s) (16300 36%) loss : 5.035                     \n",
      "4m 15s (- 7m 21s) (16400 36%) loss : 5.033                     \n",
      "4m 17s (- 7m 20s) (16500 36%) loss : 5.004                     \n",
      "4m 18s (- 7m 18s) (16600 37%) loss : 5.046                     \n",
      "4m 20s (- 7m 17s) (16700 37%) loss : 5.025                     \n",
      "4m 21s (- 7m 15s) (16800 37%) loss : 5.034                     \n",
      "4m 23s (- 7m 13s) (16900 37%) loss : 5.026                     \n",
      "4m 25s (- 7m 12s) (17000 38%) loss : 5.058                     \n",
      "4m 26s (- 7m 10s) (17100 38%) loss : 5.015                     \n",
      "4m 28s (- 7m 9s) (17200 38%) loss : 5.018                     \n",
      "4m 29s (- 7m 7s) (17300 38%) loss : 5.007                     \n",
      "4m 31s (- 7m 6s) (17400 38%) loss : 5.032                     \n",
      "4m 32s (- 7m 4s) (17500 39%) loss : 5.024                     \n",
      "4m 34s (- 7m 3s) (17600 39%) loss : 5.066                     \n",
      "4m 36s (- 7m 1s) (17700 39%) loss : 5.032                     \n",
      "4m 37s (- 6m 59s) (17800 39%) loss : 4.994                     \n",
      "4m 39s (- 6m 58s) (17900 40%) loss : 5.032                     \n",
      "4m 40s (- 6m 56s) (18000 40%) loss : 5.025                     \n",
      "4m 42s (- 6m 55s) (18100 40%) loss : 5.057                     \n",
      "4m 43s (- 6m 53s) (18200 40%) loss : 5.020                     \n",
      "4m 45s (- 6m 52s) (18300 40%) loss : 4.997                     \n",
      "4m 46s (- 6m 50s) (18400 41%) loss : 5.023                     \n",
      "4m 48s (- 6m 48s) (18500 41%) loss : 5.034                     \n",
      "4m 50s (- 6m 47s) (18600 41%) loss : 5.029                     \n",
      "4m 51s (- 6m 45s) (18700 41%) loss : 4.992                     \n",
      "4m 53s (- 6m 44s) (18800 42%) loss : 5.027                     \n",
      "4m 54s (- 6m 42s) (18900 42%) loss : 5.042                     \n",
      "4m 56s (- 6m 41s) (19000 42%) loss : 5.054                     \n",
      "4m 57s (- 6m 39s) (19100 42%) loss : 5.003                     \n",
      "4m 59s (- 6m 37s) (19200 42%) loss : 4.998                     \n",
      "5m 0s (- 6m 36s) (19300 43%) loss : 5.045                     \n",
      "5m 2s (- 6m 34s) (19400 43%) loss : 5.040                     \n",
      "5m 4s (- 6m 33s) (19500 43%) loss : 5.060                     \n",
      "5m 5s (- 6m 31s) (19600 43%) loss : 5.005                     \n",
      "5m 7s (- 6m 30s) (19700 44%) loss : 5.010                     \n",
      "5m 8s (- 6m 28s) (19800 44%) loss : 5.068                     \n",
      "5m 10s (- 6m 27s) (19900 44%) loss : 5.049                     \n",
      "5m 11s (- 6m 25s) (20000 44%) loss : 5.024                     \n",
      "5m 13s (- 6m 23s) (20100 44%) loss : 5.058                     \n",
      "5m 14s (- 6m 22s) (20200 45%) loss : 5.023                     \n",
      "5m 16s (- 6m 20s) (20300 45%) loss : 4.991                     \n",
      "5m 18s (- 6m 19s) (20400 45%) loss : 5.032                     \n",
      "5m 19s (- 6m 17s) (20500 45%) loss : 5.056                     \n",
      "5m 21s (- 6m 16s) (20600 46%) loss : 5.043                     \n",
      "5m 22s (- 6m 14s) (20700 46%) loss : 5.017                     \n",
      "5m 24s (- 6m 13s) (20800 46%) loss : 5.002                     \n",
      "5m 25s (- 6m 11s) (20900 46%) loss : 5.030                     \n",
      "5m 27s (- 6m 10s) (21000 46%) loss : 5.050                     \n",
      "5m 29s (- 6m 8s) (21100 47%) loss : 5.025                     \n",
      "5m 30s (- 6m 7s) (21200 47%) loss : 5.023                     \n",
      "5m 32s (- 6m 5s) (21300 47%) loss : 5.036                     \n",
      "5m 33s (- 6m 3s) (21400 47%) loss : 5.066                     \n",
      "5m 35s (- 6m 2s) (21500 48%) loss : 5.083                     \n",
      "5m 37s (- 6m 0s) (21600 48%) loss : 5.041                     \n",
      "5m 38s (- 5m 59s) (21700 48%) loss : 5.048                     \n",
      "5m 40s (- 5m 57s) (21800 48%) loss : 5.043                     \n",
      "5m 41s (- 5m 56s) (21900 48%) loss : 5.007                     \n",
      "5m 43s (- 5m 54s) (22000 49%) loss : 5.012                     \n",
      "5m 44s (- 5m 53s) (22100 49%) loss : 5.067                     \n",
      "5m 46s (- 5m 51s) (22200 49%) loss : 5.051                     \n",
      "5m 48s (- 5m 50s) (22300 49%) loss : 5.039                     \n",
      "5m 49s (- 5m 48s) (22400 50%) loss : 5.039                     \n",
      "5m 51s (- 5m 46s) (22500 50%) loss : 4.996                     \n",
      "5m 52s (- 5m 45s) (22600 50%) loss : 5.033                     \n",
      "5m 54s (- 5m 43s) (22700 50%) loss : 5.064                     \n",
      "5m 55s (- 5m 42s) (22800 50%) loss : 5.024                     \n",
      "5m 57s (- 5m 40s) (22900 51%) loss : 5.014                     \n",
      "5m 58s (- 5m 39s) (23000 51%) loss : 5.028                     \n",
      "6m 0s (- 5m 37s) (23100 51%) loss : 5.009                     \n",
      "6m 2s (- 5m 35s) (23200 51%) loss : 5.022                     \n",
      "6m 3s (- 5m 34s) (23300 52%) loss : 5.026                     \n",
      "6m 5s (- 5m 32s) (23400 52%) loss : 5.018                     \n",
      "6m 6s (- 5m 31s) (23500 52%) loss : 4.999                     \n",
      "6m 8s (- 5m 29s) (23600 52%) loss : 5.031                     \n",
      "6m 9s (- 5m 28s) (23700 52%) loss : 5.026                     \n",
      "6m 11s (- 5m 26s) (23800 53%) loss : 5.049                     \n",
      "6m 13s (- 5m 25s) (23900 53%) loss : 5.022                     \n",
      "6m 14s (- 5m 23s) (24000 53%) loss : 5.037                     \n",
      "6m 16s (- 5m 21s) (24100 53%) loss : 5.018                     \n",
      "6m 17s (- 5m 20s) (24200 54%) loss : 5.009                     \n",
      "6m 19s (- 5m 18s) (24300 54%) loss : 4.990                     \n",
      "6m 20s (- 5m 17s) (24400 54%) loss : 5.032                     \n",
      "6m 22s (- 5m 15s) (24500 54%) loss : 4.990                     \n",
      "6m 24s (- 5m 14s) (24600 55%) loss : 5.045                     \n",
      "6m 25s (- 5m 12s) (24700 55%) loss : 5.004                     \n",
      "6m 27s (- 5m 11s) (24800 55%) loss : 5.079                     \n",
      "6m 28s (- 5m 9s) (24900 55%) loss : 5.036                     \n",
      "6m 30s (- 5m 7s) (25000 55%) loss : 5.041                     \n",
      "6m 31s (- 5m 6s) (25100 56%) loss : 5.016                     \n",
      "6m 33s (- 5m 4s) (25200 56%) loss : 5.027                     \n",
      "6m 35s (- 5m 3s) (25300 56%) loss : 5.029                     \n",
      "6m 36s (- 5m 1s) (25400 56%) loss : 5.073                     \n",
      "6m 38s (- 5m 0s) (25500 57%) loss : 5.035                     \n",
      "6m 39s (- 4m 58s) (25600 57%) loss : 5.058                     \n",
      "6m 41s (- 4m 57s) (25700 57%) loss : 5.017                     \n",
      "6m 42s (- 4m 55s) (25800 57%) loss : 5.071                     \n",
      "6m 44s (- 4m 53s) (25900 57%) loss : 5.049                     \n",
      "6m 45s (- 4m 52s) (26000 58%) loss : 5.039                     \n",
      "6m 47s (- 4m 50s) (26100 58%) loss : 5.039                     \n",
      "6m 49s (- 4m 49s) (26200 58%) loss : 5.060                     \n",
      "6m 50s (- 4m 47s) (26300 58%) loss : 5.053                     \n",
      "6m 52s (- 4m 46s) (26400 59%) loss : 5.023                     \n",
      "6m 53s (- 4m 44s) (26500 59%) loss : 5.035                     \n",
      "6m 55s (- 4m 43s) (26600 59%) loss : 5.018                     \n",
      "6m 56s (- 4m 41s) (26700 59%) loss : 5.064                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 58s (- 4m 39s) (26800 59%) loss : 5.021                     \n",
      "7m 0s (- 4m 38s) (26900 60%) loss : 5.040                     \n",
      "7m 1s (- 4m 36s) (27000 60%) loss : 5.069                     \n",
      "7m 3s (- 4m 35s) (27100 60%) loss : 5.025                     \n",
      "7m 4s (- 4m 33s) (27200 60%) loss : 5.032                     \n",
      "7m 6s (- 4m 32s) (27300 61%) loss : 5.092                     \n",
      "7m 8s (- 4m 30s) (27400 61%) loss : 5.048                     \n",
      "7m 9s (- 4m 29s) (27500 61%) loss : 5.045                     \n",
      "7m 11s (- 4m 27s) (27600 61%) loss : 5.005                     \n",
      "7m 12s (- 4m 26s) (27700 61%) loss : 5.046                     \n",
      "7m 14s (- 4m 24s) (27800 62%) loss : 5.038                     \n",
      "7m 15s (- 4m 22s) (27900 62%) loss : 5.035                     \n",
      "7m 17s (- 4m 21s) (28000 62%) loss : 5.027                     \n",
      "7m 19s (- 4m 19s) (28100 62%) loss : 5.040                     \n",
      "7m 20s (- 4m 18s) (28200 63%) loss : 5.045                     \n",
      "7m 22s (- 4m 16s) (28300 63%) loss : 5.024                     \n",
      "7m 23s (- 4m 15s) (28400 63%) loss : 5.058                     \n",
      "7m 25s (- 4m 13s) (28500 63%) loss : 5.074                     \n",
      "7m 26s (- 4m 11s) (28600 63%) loss : 5.038                     \n",
      "7m 28s (- 4m 10s) (28700 64%) loss : 5.042                     \n",
      "7m 29s (- 4m 8s) (28800 64%) loss : 5.089                     \n",
      "7m 31s (- 4m 7s) (28900 64%) loss : 5.055                     \n",
      "7m 33s (- 4m 5s) (29000 64%) loss : 5.052                     \n",
      "7m 34s (- 4m 4s) (29100 65%) loss : 5.049                     \n",
      "7m 36s (- 4m 2s) (29200 65%) loss : 5.037                     \n",
      "7m 37s (- 4m 0s) (29300 65%) loss : 5.011                     \n",
      "7m 39s (- 3m 59s) (29400 65%) loss : 5.013                     \n",
      "7m 40s (- 3m 57s) (29500 65%) loss : 5.027                     \n",
      "7m 42s (- 3m 56s) (29600 66%) loss : 5.027                     \n",
      "7m 44s (- 3m 54s) (29700 66%) loss : 5.047                     \n",
      "7m 45s (- 3m 53s) (29800 66%) loss : 5.033                     \n",
      "epoch 3\n",
      "7m 47s (- 3m 51s) (29900 66%) loss : 5.002                     \n",
      "7m 48s (- 3m 50s) (30000 67%) loss : 5.050                     \n",
      "7m 50s (- 3m 48s) (30100 67%) loss : 5.026                     \n",
      "7m 51s (- 3m 46s) (30200 67%) loss : 4.983                     \n",
      "7m 53s (- 3m 45s) (30300 67%) loss : 5.053                     \n",
      "7m 54s (- 3m 43s) (30400 67%) loss : 5.029                     \n",
      "7m 56s (- 3m 42s) (30500 68%) loss : 5.010                     \n",
      "7m 58s (- 3m 40s) (30600 68%) loss : 5.014                     \n",
      "7m 59s (- 3m 39s) (30700 68%) loss : 5.020                     \n",
      "8m 1s (- 3m 37s) (30800 68%) loss : 4.998                     \n",
      "8m 2s (- 3m 35s) (30900 69%) loss : 4.987                     \n",
      "8m 4s (- 3m 34s) (31000 69%) loss : 5.025                     \n",
      "8m 5s (- 3m 32s) (31100 69%) loss : 5.063                     \n",
      "8m 7s (- 3m 31s) (31200 69%) loss : 5.037                     \n",
      "8m 8s (- 3m 29s) (31300 69%) loss : 5.011                     \n",
      "8m 10s (- 3m 28s) (31400 70%) loss : 5.020                     \n",
      "8m 12s (- 3m 26s) (31500 70%) loss : 5.020                     \n",
      "8m 13s (- 3m 25s) (31600 70%) loss : 5.004                     \n",
      "8m 15s (- 3m 23s) (31700 70%) loss : 5.000                     \n",
      "8m 16s (- 3m 21s) (31800 71%) loss : 5.040                     \n",
      "8m 18s (- 3m 20s) (31900 71%) loss : 5.059                     \n",
      "8m 19s (- 3m 18s) (32000 71%) loss : 5.034                     \n",
      "8m 21s (- 3m 17s) (32100 71%) loss : 5.029                     \n",
      "8m 22s (- 3m 15s) (32200 71%) loss : 5.042                     \n",
      "8m 24s (- 3m 14s) (32300 72%) loss : 5.026                     \n",
      "8m 26s (- 3m 12s) (32400 72%) loss : 5.032                     \n",
      "8m 27s (- 3m 10s) (32500 72%) loss : 5.044                     \n",
      "8m 29s (- 3m 9s) (32600 72%) loss : 5.044                     \n",
      "8m 30s (- 3m 7s) (32700 73%) loss : 5.000                     \n",
      "8m 32s (- 3m 6s) (32800 73%) loss : 5.001                     \n",
      "8m 33s (- 3m 4s) (32900 73%) loss : 5.066                     \n",
      "8m 35s (- 3m 3s) (33000 73%) loss : 5.034                     \n",
      "8m 36s (- 3m 1s) (33100 74%) loss : 5.018                     \n",
      "8m 38s (- 3m 0s) (33200 74%) loss : 5.021                     \n",
      "8m 39s (- 2m 58s) (33300 74%) loss : 5.048                     \n",
      "8m 41s (- 2m 56s) (33400 74%) loss : 5.043                     \n",
      "8m 43s (- 2m 55s) (33500 74%) loss : 5.013                     \n",
      "8m 44s (- 2m 53s) (33600 75%) loss : 4.995                     \n",
      "8m 46s (- 2m 52s) (33700 75%) loss : 5.025                     \n",
      "8m 47s (- 2m 50s) (33800 75%) loss : 5.048                     \n",
      "8m 49s (- 2m 49s) (33900 75%) loss : 5.031                     \n",
      "8m 51s (- 2m 47s) (34000 76%) loss : 4.969                     \n",
      "8m 52s (- 2m 45s) (34100 76%) loss : 5.005                     \n",
      "8m 54s (- 2m 44s) (34200 76%) loss : 5.007                     \n",
      "8m 55s (- 2m 42s) (34300 76%) loss : 5.056                     \n",
      "8m 57s (- 2m 41s) (34400 76%) loss : 5.022                     \n",
      "8m 58s (- 2m 39s) (34500 77%) loss : 5.032                     \n",
      "9m 0s (- 2m 38s) (34600 77%) loss : 5.019                     \n",
      "9m 1s (- 2m 36s) (34700 77%) loss : 5.039                     \n",
      "9m 3s (- 2m 35s) (34800 77%) loss : 5.009                     \n",
      "9m 5s (- 2m 33s) (34900 78%) loss : 5.038                     \n",
      "9m 6s (- 2m 31s) (35000 78%) loss : 5.024                     \n",
      "9m 8s (- 2m 30s) (35100 78%) loss : 5.032                     \n",
      "9m 9s (- 2m 28s) (35200 78%) loss : 5.033                     \n",
      "9m 11s (- 2m 27s) (35300 78%) loss : 5.038                     \n",
      "9m 12s (- 2m 25s) (35400 79%) loss : 5.004                     \n",
      "9m 14s (- 2m 24s) (35500 79%) loss : 5.022                     \n",
      "9m 15s (- 2m 22s) (35600 79%) loss : 4.991                     \n",
      "9m 17s (- 2m 20s) (35700 79%) loss : 5.021                     \n",
      "9m 19s (- 2m 19s) (35800 80%) loss : 5.034                     \n",
      "9m 20s (- 2m 17s) (35900 80%) loss : 5.041                     \n",
      "9m 22s (- 2m 16s) (36000 80%) loss : 5.033                     \n",
      "9m 23s (- 2m 14s) (36100 80%) loss : 4.984                     \n",
      "9m 25s (- 2m 13s) (36200 80%) loss : 5.032                     \n",
      "9m 26s (- 2m 11s) (36300 81%) loss : 5.098                     \n",
      "9m 28s (- 2m 10s) (36400 81%) loss : 5.030                     \n",
      "9m 29s (- 2m 8s) (36500 81%) loss : 5.019                     \n",
      "9m 31s (- 2m 6s) (36600 81%) loss : 5.042                     \n",
      "9m 33s (- 2m 5s) (36700 82%) loss : 5.001                     \n",
      "9m 34s (- 2m 3s) (36800 82%) loss : 5.046                     \n",
      "9m 36s (- 2m 2s) (36900 82%) loss : 5.012                     \n",
      "9m 37s (- 2m 0s) (37000 82%) loss : 5.037                     \n",
      "9m 39s (- 1m 59s) (37100 82%) loss : 5.045                     \n",
      "9m 40s (- 1m 57s) (37200 83%) loss : 5.006                     \n",
      "9m 42s (- 1m 55s) (37300 83%) loss : 5.015                     \n",
      "9m 43s (- 1m 54s) (37400 83%) loss : 5.028                     \n",
      "9m 45s (- 1m 52s) (37500 83%) loss : 4.968                     \n",
      "9m 47s (- 1m 51s) (37600 84%) loss : 5.041                     \n",
      "9m 48s (- 1m 49s) (37700 84%) loss : 5.023                     \n",
      "9m 50s (- 1m 48s) (37800 84%) loss : 5.011                     \n",
      "9m 51s (- 1m 46s) (37900 84%) loss : 4.995                     \n",
      "9m 53s (- 1m 45s) (38000 84%) loss : 5.042                     \n",
      "9m 54s (- 1m 43s) (38100 85%) loss : 5.039                     \n",
      "9m 56s (- 1m 41s) (38200 85%) loss : 5.041                     \n",
      "9m 57s (- 1m 40s) (38300 85%) loss : 5.016                     \n",
      "9m 59s (- 1m 38s) (38400 85%) loss : 5.043                     \n",
      "10m 1s (- 1m 37s) (38500 86%) loss : 5.049                     \n",
      "10m 2s (- 1m 35s) (38600 86%) loss : 4.984                     \n",
      "10m 4s (- 1m 34s) (38700 86%) loss : 4.998                     \n",
      "10m 5s (- 1m 32s) (38800 86%) loss : 5.064                     \n",
      "10m 7s (- 1m 30s) (38900 86%) loss : 5.055                     \n",
      "10m 8s (- 1m 29s) (39000 87%) loss : 5.022                     \n",
      "10m 10s (- 1m 27s) (39100 87%) loss : 5.031                     \n",
      "10m 11s (- 1m 26s) (39200 87%) loss : 5.073                     \n",
      "10m 13s (- 1m 24s) (39300 87%) loss : 5.064                     \n",
      "10m 15s (- 1m 23s) (39400 88%) loss : 5.045                     \n",
      "10m 16s (- 1m 21s) (39500 88%) loss : 5.044                     \n",
      "10m 18s (- 1m 20s) (39600 88%) loss : 5.009                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 19s (- 1m 18s) (39700 88%) loss : 5.019                     \n",
      "10m 21s (- 1m 16s) (39800 88%) loss : 5.013                     \n",
      "10m 22s (- 1m 15s) (39900 89%) loss : 5.025                     \n",
      "10m 24s (- 1m 13s) (40000 89%) loss : 5.010                     \n",
      "10m 25s (- 1m 12s) (40100 89%) loss : 5.035                     \n",
      "10m 27s (- 1m 10s) (40200 89%) loss : 5.012                     \n",
      "10m 29s (- 1m 9s) (40300 90%) loss : 4.991                     \n",
      "10m 30s (- 1m 7s) (40400 90%) loss : 5.012                     \n",
      "10m 32s (- 1m 5s) (40500 90%) loss : 5.046                     \n",
      "10m 33s (- 1m 4s) (40600 90%) loss : 5.018                     \n",
      "10m 35s (- 1m 2s) (40700 90%) loss : 5.014                     \n",
      "10m 36s (- 1m 1s) (40800 91%) loss : 5.065                     \n",
      "10m 38s (- 0m 59s) (40900 91%) loss : 5.015                     \n",
      "10m 39s (- 0m 58s) (41000 91%) loss : 5.028                     \n",
      "10m 41s (- 0m 56s) (41100 91%) loss : 5.072                     \n",
      "10m 43s (- 0m 55s) (41200 92%) loss : 5.028                     \n",
      "10m 44s (- 0m 53s) (41300 92%) loss : 5.010                     \n",
      "10m 46s (- 0m 51s) (41400 92%) loss : 5.006                     \n",
      "10m 47s (- 0m 50s) (41500 92%) loss : 5.054                     \n",
      "10m 49s (- 0m 48s) (41600 93%) loss : 5.031                     \n",
      "10m 50s (- 0m 47s) (41700 93%) loss : 5.056                     \n",
      "10m 52s (- 0m 45s) (41800 93%) loss : 5.062                     \n",
      "10m 53s (- 0m 44s) (41900 93%) loss : 5.049                     \n",
      "10m 55s (- 0m 42s) (42000 93%) loss : 5.036                     \n",
      "10m 57s (- 0m 40s) (42100 94%) loss : 5.013                     \n",
      "10m 58s (- 0m 39s) (42200 94%) loss : 5.003                     \n",
      "11m 0s (- 0m 37s) (42300 94%) loss : 5.028                     \n",
      "11m 1s (- 0m 36s) (42400 94%) loss : 5.019                     \n",
      "11m 3s (- 0m 34s) (42500 95%) loss : 5.036                     \n",
      "11m 4s (- 0m 33s) (42600 95%) loss : 5.039                     \n",
      "11m 6s (- 0m 31s) (42700 95%) loss : 5.044                     \n",
      "11m 7s (- 0m 30s) (42800 95%) loss : 5.021                     \n",
      "11m 9s (- 0m 28s) (42900 95%) loss : 5.029                     \n",
      "11m 11s (- 0m 26s) (43000 96%) loss : 5.031                     \n",
      "11m 12s (- 0m 25s) (43100 96%) loss : 5.011                     \n",
      "11m 14s (- 0m 23s) (43200 96%) loss : 5.050                     \n",
      "11m 15s (- 0m 22s) (43300 96%) loss : 5.023                     \n",
      "11m 17s (- 0m 20s) (43400 97%) loss : 5.028                     \n",
      "11m 18s (- 0m 19s) (43500 97%) loss : 5.051                     \n",
      "11m 20s (- 0m 17s) (43600 97%) loss : 5.018                     \n",
      "11m 21s (- 0m 16s) (43700 97%) loss : 5.013                     \n",
      "11m 23s (- 0m 14s) (43800 97%) loss : 5.083                     \n",
      "11m 25s (- 0m 12s) (43900 98%) loss : 5.057                     \n",
      "11m 26s (- 0m 11s) (44000 98%) loss : 5.050                     \n",
      "11m 28s (- 0m 9s) (44100 98%) loss : 5.026                     \n",
      "11m 29s (- 0m 8s) (44200 98%) loss : 5.051                     \n",
      "11m 31s (- 0m 6s) (44300 99%) loss : 5.043                     \n",
      "11m 32s (- 0m 5s) (44400 99%) loss : 5.061                     \n",
      "11m 34s (- 0m 3s) (44500 99%) loss : 5.039                     \n",
      "11m 35s (- 0m 1s) (44600 99%) loss : 5.003                     \n",
      "11m 37s (- 0m 0s) (44700 99%) loss : 5.035                     \n",
      "0m 9s (- 0m 0s) (100 100%) loss : 4.972  accuracy : 14.7 %\n"
     ]
    }
   ],
   "source": [
    "skipgram.train(Ngrams, iters = 100, lr = 0.005, print_every = 100, compute_accuracy = True)\n",
    "\n",
    "for alpha in [0.005, 0.001, 0.0005] : \n",
    "    skipgram.train(Ngrams, epochs = 3,  lr = alpha, print_every = 100)\n",
    "    skipgram.train(Ngrams, iters = 100, lr = alpha, print_every = 100, compute_accuracy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weights', 0.3850521),\n",
       " ('2.4', 0.36428553),\n",
       " ('cho', 0.35723716),\n",
       " ('0.20', 0.3491864),\n",
       " ('glucose', 0.3309465),\n",
       " ('double', 0.32847974),\n",
       " ('m5178', 0.3262306),\n",
       " ('northern', 0.32450148),\n",
       " ('normality', 0.32145855),\n",
       " ('9.0', 0.31833637)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(word = 'final', bound = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load<br>\n",
    "\n",
    "The lightweight word2vec model can be saved for further use, or alternatively the full shell wrapping the word2vec model can be saved for subsequent training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(word2vec, path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_skipgram.pt')\n",
    "\n",
    "# load\n",
    "#word2vec = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_skipgram.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Gensim Word2Vec\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Link : https://radimrehurek.com/gensim/models/word2vec.html<br>\n",
    "Tutorials :\n",
    "\n",
    "- https://cambridgespark.com/4046-2/\n",
    "- https://rare-technologies.com/word2vec-tutorial/\n",
    "- http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "\n",
    "### 1.2.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Training with CBOW objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Model & Data & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_gensim = Word2Vec(corpus, \n",
    "                       size = 75, \n",
    "                       window = 5, \n",
    "                       min_count = 4, \n",
    "                       negative = 15, \n",
    "                       iter = 50,\n",
    "                       sg = 0,\n",
    "                       workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polysorbate', 0.6989661455154419),\n",
       " ('ovalbumin', 0.6707851886749268),\n",
       " ('thiomersal', 0.6553795337677002),\n",
       " ('phenol', 0.6534852981567383),\n",
       " ('phosphorus', 0.620326042175293),\n",
       " ('phenoxyethanol', 0.617948055267334),\n",
       " ('moisture', 0.5869265198707581),\n",
       " ('sucrose', 0.5719404220581055),\n",
       " ('2phenoxyethanol', 0.5603488683700562),\n",
       " ('aluminium', 0.5357670783996582)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(cbow_gensim)\n",
    "cbow_gensim.wv.most_similar('formaldehyde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load\n",
    "\n",
    "The Gensim model can easily be saved & loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_cbow_gensim.model\")\n",
    "#cbow_gensim.save(file_name)\n",
    "\n",
    "# load\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_cbow_gensim.model\")\n",
    "#cbow_gensim = Word2Vec.load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively it is direct to build a lightweight word2vec model out of a trained gensim model and then save & load it as done in previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = myWord2Vec(lang = Lang(corpus = [list(cbow_gensim.wv.index2word)], base_tokens = []), T = cbow_gensim.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polysorbate', 0.6989662),\n",
       " ('ovalbumin', 0.67078525),\n",
       " ('thiomersal', 0.6553794),\n",
       " ('phenol', 0.6534851),\n",
       " ('phosphorus', 0.6203261),\n",
       " ('phenoxyethanol', 0.61794806),\n",
       " ('moisture', 0.5869265),\n",
       " ('sucrose', 0.5719405),\n",
       " ('2phenoxyethanol', 0.5603489),\n",
       " ('aluminium', 0.535767)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar('formaldehyde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Training with SkipGram objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Model & Data & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_gensim = Word2Vec(corpus, \n",
    "                           size = 75, \n",
    "                           window = 5, \n",
    "                           min_count = 4, \n",
    "                           negative = 15, \n",
    "                           iter = 50,\n",
    "                           sg = 1,\n",
    "                           workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phenoxyethanol', 0.687885046005249),\n",
       " ('thiomersal', 0.6411113739013672),\n",
       " ('polysorbate', 0.6349731683731079),\n",
       " ('ovalbumin', 0.6308521628379822),\n",
       " ('phenol', 0.5957325100898743),\n",
       " ('free', 0.5818331241607666),\n",
       " ('hcho', 0.580868124961853),\n",
       " ('triton', 0.5749791264533997),\n",
       " ('residual', 0.5559578537940979),\n",
       " ('acetyl', 0.5499086380004883)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(skipgram_gensim)\n",
    "skipgram_gensim.wv.most_similar('formaldehyde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_skipgram_gensim.model\")\n",
    "#skipgram_gensim.save(file_name)\n",
    "\n",
    "# load\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_skipgram_gensim.model\")\n",
    "#skipgram_gensim = Word2Vec.load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sub_word_level\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2 Subword-level Embedding\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 FastText Subword-level Embedding Model\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "\n",
    "We consider the Gensim implementation of FastText, based on the CBOW training objective.<br>\n",
    "Tutorial : [Gensim FastText](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb)<br>\n",
    "Link to the original paper : [Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606.pdf).\n",
    "\n",
    "### 2.1.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Training with CBOW objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_fastText_gensim = FT_gensim(size = 75, \n",
    "                                 window = 5, \n",
    "                                 min_count = 4, \n",
    "                                 negative = 15,\n",
    "                                 sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_fastText_gensim.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_fastText_gensim.train(sentences = corpus, \n",
    "                           epochs = 50,\n",
    "                           total_examples = cbow_fastText_gensim.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glutaraldehyde', 0.7981022596359253),\n",
       " ('thiomersal', 0.6922125816345215),\n",
       " ('phenoxyethanol', 0.6608516573905945),\n",
       " ('formal', 0.6601725816726685),\n",
       " ('2phenoxyethanol', 0.6546887755393982),\n",
       " ('ovalbumin', 0.6526973247528076),\n",
       " ('acetaldehyde', 0.647036612033844),\n",
       " ('phenoxy', 0.6376691460609436),\n",
       " ('polysorbate', 0.6080763339996338),\n",
       " ('phenol', 0.5886105298995972)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fastText_gensim.wv.most_similar('formaldehyde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_cbow_fasttext.model\")\n",
    "#cbow_fastText_gensim.save(file_name)\n",
    "\n",
    "# load\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_cbow_fasttext.model\")\n",
    "#cbow_fastText_gensim = FT_gensim.load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively it is direct to build a lightweight word2vec model out of a trained gensim model and then save & load it as done in previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = myWord2Vec(lang = Lang(corpus = [list(cbow_fastText_gensim.wv.index2word)], base_tokens = []), T = cbow_fastText_gensim.wv.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the main advantage FastText offers is the possibility to get an embedding vector out of **any word**, and in fact any string thanks to the character-ngrams embedding trick :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60040593, -0.61111313, -2.4772959 , -3.5749006 , -0.43338707,\n",
       "       -2.2147598 , -1.1924213 , -1.3568501 ,  1.5161968 ,  1.8103373 ,\n",
       "       -2.0902889 , -2.6638277 , -1.4272233 , -0.10690732, -1.9536633 ,\n",
       "       -0.23879535,  1.602015  ,  0.01936079,  0.04406525, -0.3471393 ,\n",
       "       -3.406037  ,  0.9583735 ,  0.7140704 ,  0.17500015,  0.46005052,\n",
       "        2.257169  , -1.0044819 ,  0.5483043 , -0.9547367 , -0.49952805,\n",
       "       -0.24594651, -0.21130262, -1.2208652 , -0.6694741 ,  0.87412256,\n",
       "        1.7601272 ,  0.73085773,  0.10473473,  1.5312183 , -1.3219206 ,\n",
       "       -1.3290527 ,  0.9072932 ,  1.3730991 , -0.90493995,  0.28533888,\n",
       "        0.38472265, -1.5437093 ,  0.04730683, -0.2976788 ,  2.7981303 ,\n",
       "       -1.7771748 ,  0.29214206, -0.9805347 , -0.35345754, -1.2273612 ,\n",
       "        0.33308518,  1.4707417 , -1.3735195 , -1.2793874 ,  0.39640912,\n",
       "       -0.04994425,  3.4968672 , -3.8160832 , -0.6460553 ,  1.6184001 ,\n",
       "        1.4465878 , -1.3832889 , -1.1182241 , -1.0623002 ,  0.19845706,\n",
       "       -0.8827951 , -1.7708261 ,  0.41213292,  1.9345915 ,  1.2453561 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_fastText_gensim['HelloWorld']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonetheless, it can be interesting to load the look-up word vectors table into a lightweight word2vec module, as it allows to further optimize this table for any specific downstream task performed by a larger PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Training with SkipGram objective\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim = FT_gensim(size = 75, \n",
    "                           window = 5, \n",
    "                           min_count = 4, \n",
    "                           negative = 15,\n",
    "                           sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.train(sentences = corpus, \n",
    "                      epochs = 500,\n",
    "                      total_examples = fastText_gensim.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phenoxyethanol', 0.7689735889434814),\n",
       " ('thiomersal', 0.6627542972564697),\n",
       " ('polysorbate', 0.6582513451576233),\n",
       " ('residual', 0.6486191749572754),\n",
       " ('acetyl', 0.6439298391342163),\n",
       " ('free', 0.6395246386528015),\n",
       " ('hcho', 0.6370760798454285),\n",
       " ('ovalbumin', 0.6338086724281311),\n",
       " ('phosphorus', 0.6294593811035156),\n",
       " ('acetaldehyde', 0.618198037147522)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastText_gensim.wv.most_similar('formaldehyde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_fasttext.model\")\n",
    "#fastText_gensim.save(file_name)\n",
    "\n",
    "# load\n",
    "file_name = get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_fasttext.model\")\n",
    "fastText_gensim = FT_gensim.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.1185090e-01, -1.8866447e-01,  4.5702112e-01,  9.5058337e-02,\n",
       "        -4.9046433e-01, -1.7982282e-01, -8.3711225e-01, -2.1798968e-01,\n",
       "         1.3073857e+00,  5.6606084e-03,  2.3142101e-01,  6.9535589e-01,\n",
       "         5.9402555e-02,  4.7985664e-01,  5.4549623e-01, -4.1711867e-01,\n",
       "        -3.2760030e-01,  6.0999656e-01, -8.2229602e-01, -5.0304300e-01,\n",
       "        -1.2463865e+00, -6.4032364e-01, -3.3593947e-01,  2.3377445e-01,\n",
       "         8.3939898e-01, -5.6188452e-01,  7.1624267e-01,  3.1629649e-01,\n",
       "        -6.5501964e-01, -1.3965420e-02, -2.3780808e-01,  3.3856243e-01,\n",
       "         9.1053849e-01,  8.3878809e-01, -6.5342933e-01,  3.2637709e-01,\n",
       "        -5.9420161e-02,  4.7055259e-04,  1.5663326e-02, -1.3566703e+00,\n",
       "         3.0353647e-01,  4.4896945e-02, -3.3726567e-01, -3.1158471e-01,\n",
       "         5.7190084e-01, -2.0193291e-01, -1.8398750e-01,  1.4189348e-01,\n",
       "         3.6389869e-01,  8.2089943e-01, -2.3509660e-01, -2.9905848e-02,\n",
       "        -4.0085071e-01, -9.8194093e-01,  8.6322200e-01,  2.0440830e-01,\n",
       "         4.4818613e-01,  3.6934751e-01, -9.3635969e-02,  5.5121288e-02,\n",
       "        -3.2470068e-01,  4.6824709e-01, -2.3280752e-01,  9.8648477e-01,\n",
       "         1.9610731e-01,  5.0058949e-01, -4.4794276e-01, -5.0624740e-01,\n",
       "         2.7403872e-02, -6.8143439e-01,  8.9184123e-01, -3.8065004e-01,\n",
       "         1.6974752e-01,  2.1044408e-01,  1.1723402e+00],\n",
       "       [ 1.7961624e-01, -8.5740365e-02,  4.0865207e-01,  3.5131705e-01,\n",
       "        -6.0503030e-01,  7.9881445e-02,  2.2734746e-02,  2.7436674e-02,\n",
       "        -7.4848935e-02, -8.1804857e-02, -2.1891460e-02,  5.3876722e-01,\n",
       "        -1.3575308e-01,  7.9054296e-02, -3.0502194e-01, -2.2587907e-01,\n",
       "         8.4736049e-02, -8.5181147e-03, -3.6626723e-01,  3.1475636e-01,\n",
       "        -2.3750851e-01,  1.2736151e-01, -7.1801946e-02,  2.9204944e-01,\n",
       "        -4.2787904e-01,  2.5110000e-01,  1.9278140e-01, -3.9647959e-02,\n",
       "         1.0584996e-01, -1.0819733e-03,  9.3760513e-02,  1.4922020e-01,\n",
       "        -1.7209664e-01,  4.2567545e-01, -3.4912366e-01, -1.9005427e-01,\n",
       "        -1.2627620e-01,  6.4015716e-02, -1.5219563e-01, -4.2456308e-01,\n",
       "         1.0939985e-02, -2.0537834e-01,  3.2594362e-01, -3.3642143e-02,\n",
       "        -2.6956102e-01, -6.1849006e-02, -3.0066711e-01,  1.7535323e-01,\n",
       "         1.2674099e-01, -8.2003087e-02, -1.0984391e-01,  1.3929486e-02,\n",
       "         1.0804382e-01, -3.0968213e-01,  4.1171509e-01,  4.0899143e-02,\n",
       "        -2.1608469e-01, -3.4861386e-02,  5.6581050e-03,  6.0320646e-02,\n",
       "        -1.5280612e-02,  6.8269871e-02,  2.4935603e-04,  6.1947703e-03,\n",
       "        -3.7482340e-02, -3.8812870e-01, -1.3512118e-01, -8.2392529e-02,\n",
       "         1.2022180e-02, -1.4945740e-01, -1.3399085e-01,  1.1433151e-01,\n",
       "         1.5207852e-01, -1.8367937e-01,  3.3320752e-01]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastText_gensim[['13', 'to']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
