{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 2 <br><br><br>\n",
    "  Sentence Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. <font color=red>**Sentence Classification**</font>\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Extractive Summarization\n",
    "    - Sentiment Analysis\n",
    "    - Text segmentation\n",
    "\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sentence tagging\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Part-of-speech Tagging\n",
    "    - Named Entity Recognition\n",
    "    - Automatic Value Extraction\n",
    "    \n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The global structure of the [sentence classifier](#classifier) is the pipeline of three modules, followed by a final classification layer :\n",
    "\n",
    "\n",
    "\n",
    "| | Module |  | |\n",
    "|------|------|------|------|\n",
    "| 1 | **Word Embedding** | [I.1 Custom model](#word_level_custom) | [I.2 Gensim Model](#gensim) | [I.3 FastText model](#fastText) |\n",
    "| 2 | **Contextualization** | [II.1 bidirectionnal GRU](#bi_gru) | [II.2 Transformer](#transformer) |\n",
    "| 3 | **Attention** | [III.1 Attention](#attention) | [III.2 Multi-head Attention](#attention) |\n",
    "\n",
    "\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 0.4.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\chatNLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus et donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text, label]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence): # -------------------------  str\n",
    "    sw = ['']\n",
    "    #sw += nltk.corpus.stopwords.words('english')\n",
    "    #sw += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    def normalizeString(s):\n",
    "        '''Remove rare symbols from a string'''\n",
    "        s = unicodeToAscii(s.lower().strip()) # \n",
    "        #s = re.sub(r\"[^a-zA-Z\\.\\(\\)\\[\\]]+\", r\" \", s)  # 'r' before a string is for 'raw' # ?&\\%\\_\\- removed # set('''.,:;()*#&-_%!?/\\'\")''')\n",
    "        return s\n",
    "\n",
    "    def wordTokenizerFunction():\n",
    "        # base version\n",
    "        function = lambda sentence : sentence.strip().split()\n",
    "\n",
    "        # nltk version\n",
    "        #function = word_tokenize    \n",
    "        return function\n",
    "\n",
    "    # 1 - caractères spéciaux\n",
    "    def clean_sentence_punct(text): # --------------  str\n",
    "        text = normalizeString(text)\n",
    "        # suppression de la dernière ponctuation\n",
    "        if (len(text) > 0 and text[-1] in ['.', ',', ';', ':', '!', '?']) : text = text[:-1]\n",
    "\n",
    "        text = text.replace(r'(', r' ( ')\n",
    "        text = text.replace(r')', r' ) ')\n",
    "        text = text.replace(r'[', r' [ ')\n",
    "        text = text.replace(r']', r' ] ')\n",
    "        text = text.replace(r'<', r' < ')\n",
    "        text = text.replace(r'>', r' > ')\n",
    "\n",
    "        text = text.replace(r':', r' : ')\n",
    "        text = text.replace(r';', r' ; ')\n",
    "        for i in range(5) :\n",
    "            text = re.sub('(?P<val1>[0-9])\\.(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "            text = re.sub('(?P<val1>[0-9]),(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "        text = text.replace(r',', ' , ')\n",
    "        text = text.replace(r'.', ' . ')\n",
    "        for i in range(5) : text = re.sub('(?P<val1>[p0-9])__-__(?P<val2>[p0-9])', '\\g<val1>.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. p \\. (?P<val2>[0-9])', '\\g<val1>.p.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. s \\. (?P<val2>[0-9])', '\\g<val1>.s.\\g<val2>', text)\n",
    "\n",
    "        text = text.replace(r'\"', r' \" ')\n",
    "        text = text.replace(r'’', r\" ' \")\n",
    "        text = text.replace(r'”', r' \" ')\n",
    "        text = text.replace(r'“', r' \" ')\n",
    "        text = text.replace(r'/', r' / ')\n",
    "\n",
    "        text = re.sub('(…)+', ' … ', text)\n",
    "        text = text.replace('≤', ' ≤ ')          \n",
    "        text = text.replace('≥', ' ≥ ')\n",
    "        text = text.replace('°c', ' °c ')\n",
    "        text = text.replace('°C', ' °c ')\n",
    "        text = text.replace('ºc', ' °c ')\n",
    "        text = text.replace('n°', 'n° ')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('*', ' * ')\n",
    "        text = text.replace('+', ' + ')\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('_', ' ')\n",
    "        text = text.replace('®', ' ')\n",
    "        text = text.replace('™', ' ')\n",
    "        text = text.replace('±', ' ± ')\n",
    "        text = text.replace('÷', ' ÷ ')\n",
    "        text = text.replace('–', ' - ')\n",
    "        text = text.replace('μg', ' µg')\n",
    "        text = text.replace('µg', ' µg')\n",
    "        text = text.replace('µl', ' µl')\n",
    "        text = text.replace('μl', ' µl')\n",
    "        text = text.replace('µm', ' µm')\n",
    "        text = text.replace('μm', ' µm')\n",
    "        text = text.replace('ppm', ' ppm')\n",
    "        text = re.sub('(?P<val1>[0-9])mm', '\\g<val1> mm', text)\n",
    "        text = re.sub('(?P<val1>[0-9])g', '\\g<val1> g', text)\n",
    "        text = text.replace('nm', ' nm')\n",
    "\n",
    "        text = re.sub('fa(?P<val1>[0-9])', 'fa \\g<val1>', text)\n",
    "        text = re.sub('g(?P<val1>[0-9])', 'g \\g<val1>', text)\n",
    "        text = re.sub('n(?P<val1>[0-9])', 'n \\g<val1>', text)\n",
    "        text = re.sub('p(?P<val1>[0-9])', 'p \\g<val1>', text)\n",
    "        text = re.sub('q_(?P<val1>[0-9])', 'q_ \\g<val1>', text)\n",
    "        text = re.sub('u(?P<val1>[0-9])', 'u \\g<val1>', text)\n",
    "        text = re.sub('ud(?P<val1>[0-9])', 'ud \\g<val1>', text)\n",
    "        text = re.sub('ui(?P<val1>[0-9])', 'ui \\g<val1>', text)\n",
    "\n",
    "        text = text.replace('=', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace(r' , ', ' ')\n",
    "        text = text.replace(r' . ', ' ')\n",
    "\n",
    "        text = re.sub('(?P<val>[0-9])ml', '\\g<val> ml', text)\n",
    "        text = re.sub('(?P<val>[0-9])mg', '\\g<val> mg', text)\n",
    "\n",
    "        for i in range(5) : text = re.sub('( [0-9]+ )', ' ', text)\n",
    "        #text = re.sub('cochran(\\S)*', 'cochran ', text)\n",
    "        return text\n",
    "\n",
    "    # 3 - split des mots\n",
    "    def wordSplit(sentence, tokenizeur): # ------------- [str]\n",
    "        return tokenizeur(sentence)\n",
    "\n",
    "    # 4 - mise en minuscule et enlèvement des stopwords\n",
    "    def stopwordsRemoval(sentence, sw): # ------------- [[str]]\n",
    "        return [word for word in sentence if word not in sw]\n",
    "\n",
    "    # 6 - correction des mots\n",
    "    def correction(text):\n",
    "        def correct(word):\n",
    "            return spelling.suggest(word)[0]\n",
    "        list_of_list_of_words = [[correct(word) for word in sentence] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    # 7 - stemming\n",
    "    def stemming(text): # ------------------------- [[str]]\n",
    "        list_of_list_of_words = [[PorterStemmer().stem(word) for word in sentence if word not in sw] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    tokenizeur = wordTokenizerFunction()\n",
    "    sentence = clean_sentence_punct(str(sentence))\n",
    "    sentence = wordSplit(sentence, tokenizeur)\n",
    "    sentence = stopwordsRemoval(sentence, sw)\n",
    "    #text = correction(text)\n",
    "    #text = stemming(text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def importSheet(file_name) :\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    labelled_sentences = [[' '.join(cleanSentence(str(el[0]) + ' | ' + str(el[1]))), el[-1]] for el in db if el[-1] in [0, 1]]\n",
    "    return labelled_sentences\n",
    "\n",
    "\n",
    "def importCorpus(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus += importSheet(file_name)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_sentences = importCorpus(path_to_NLP + '\\\\data\\\\AMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section 3.2.p.5.1 specification ( s ) | the testing performed on the finished product ( fp ) is in compliance with both current european pharmacopoeia ( ph eur ) and world health organization ( who ) requirements of the vaccine',\n",
       " 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "## 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "We assume that embedding model were pretrained following the steps detailed in **Part I - 1**.<br>\n",
    "We consider here Word2Vec models pre-trained following the Skip-Gram training objective.\n",
    "\n",
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model as native Pytorch module\n",
    "\n",
    "The model is frozen after being loaded, so that none of its parameters is targeted by the sentence classifier optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatNLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from chatNLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_word2vec = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_skipgram.pt').freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model through Pytorch twin\n",
    "\n",
    "Since the chosen word embedding model must interact with subsequent modules int the sentence classification model, we wrap each model into a common small module that uniformize communication between any of these modules with subsequent ones.\n",
    "\n",
    "To speed up training we want to pre-pack sentences into mini-batches, each mini-batch forming a single Torch Variable. There are two issues for this :<br> First, packing sentences into mini-batches needs to introduce a additionnal _padding_ word in the Word2Vc model, in order to put sentences of a single mini-batch at equal length. Second, the Word2Vc model must be able to handle Torch Variables, which is not the case for Gensim and FastText models.\n",
    "\n",
    "A solution to these issues is to associate to the Word2Vec model a _twin_, which will be a Pytorch module containing and additionnal padding word/vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2Vec.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_skipgram_gensim.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_gensim_word2vec = myWord2Vec(lang = Lang([list(gensim_word2vec.wv.index2word)], base_tokens = []), T = gensim_word2vec.wv.vectors)\n",
    "twin_gensim_word2vec.addWord('PADDING_WORD')\n",
    "twin_gensim_word2vec.addWord('UNK')\n",
    "twin_gensim_word2vec = twin_gensim_word2vec.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model through Pytorch wrapper\n",
    "\n",
    "The strength of FastText is the possiblity to advocate a word vctor to most unseen word by taking embedding of subword units.<br> However this advantage no longer exists for the Pytorch twin, since in such model only the lookup table remains.<br> Therefore it is necessary to wrap the fastText model into another Pytorch model, which will use a twin of the model for fast training and then use the original Word2Vec model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec = FT_gensim.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_fasttext.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecConnector(nn.Module) :\n",
    "    def __init__(self, word2vec) :\n",
    "        super(Word2VecConnector, self).__init__()\n",
    "        self.word2vec = word2vec\n",
    "        self.twin = myWord2Vec(lang = Lang([list(word2vec.wv.index2word)], base_tokens = []), T = word2vec.wv.vectors)\n",
    "        self.twin.addWord('PADDING_WORD')\n",
    "        self.twin.addWord('UNK')\n",
    "        self.twin = self.twin.freeze()\n",
    "        \n",
    "        self.lang       = self.twin.lang\n",
    "        self.embedding  = self.twin.embedding\n",
    "        self.output_dim = self.twin.output_dim\n",
    "        \n",
    "    def forward(self, words, device = None) :\n",
    "        '''Transforms a sequence of n words into a Torch FloatTensor of size (1, n, emb_dim)'''\n",
    "        embeddings = Variable(torch.Tensor(self.word2vec[words])).unsqueeze(0)\n",
    "        if device is not None : embeddings = embeddings.to(device)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_fastText_word2vec = Word2VecConnector(fastText_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentWordsEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_layers = 1, dropout = 0): \n",
    "        super(RecurrentWordsEncoder, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim           # dimension of hidden state of GRUs \n",
    "        self.output_dim = hidden_dim * 2       # dimension of outputed rep. of words and utterance\n",
    "        \n",
    "        # layers\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.bigru = nn.GRU(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            n_layers,\n",
    "                            dropout = (0 if n_layers == 1 else dropout), \n",
    "                            bidirectional = True,\n",
    "                            batch_first = True)\n",
    "\n",
    "    def forward(self, embeddings, lengths = None, hidden = None) :\n",
    "        '''Transforms a batch of size (batch_size, input_length, embedding_dim) into \n",
    "        \n",
    "              - outputs of size (batch_size, input_length, 2 * embedding_dim)\n",
    "              - hidden  of size (batch_size, 2 * n_layers, embedding_dim)\n",
    "        '''\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        if lengths is not None : embeddings = torch.nn.utils.rnn.pack_padded_sequence(embeddings, lengths, batch_first = True)\n",
    "        outputs, hidden = self.bigru(embeddings, hidden) # dim = (batch_size, input_length, output_dim)\n",
    "        if lengths is not None : outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True)\n",
    "        outputs = self.dropout(outputs)                  # dim = (batch_size, input_length, output_dim)\n",
    "        hidden  = self.dropout(hidden)                   # dim = (batch_size, 2, hidden_dim)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Attention module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout = 0): \n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = embedding_dim\n",
    "\n",
    "        # parameters\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.attn_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.attn_v = nn.Linear(embedding_dim, 1, bias = False)\n",
    "        self.act = F.softmax\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        weights = self.attn_layer(embeddings).tanh()       # size (minibatch_size, input_length, embedding_dim)\n",
    "        weights = self.act(self.attn_v(weights), dim = 1)  # size (minibatch_size, input_length, 1)\n",
    "        weights = torch.transpose(weights, 1, 2)           # size (minibatch_size, 1, input_length)\n",
    "        attn_applied = torch.bmm(weights, embeddings)      # size (minibatch_size, 1, embedding_dim)\n",
    "        attn_applied = self.dropout(attn_applied)\n",
    "        return attn_applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n",
    "\n",
    "Taken from [this page](https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax = None, cbar_kw = {}, cbarlabel = \"\", **kwargs):\n",
    "    if not ax: ax = plt.gca()\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data = None, valfmt = \"{x:.2f}\", textcolors = [\"black\", \"white\"], threshold = None, **textkw):\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module) :\n",
    "    def __init__(self, word2vec, hidden_dim, n_layers, n_class = 2, dropout = 0,\n",
    "                 criterion = nn.NLLLoss(size_average = False), optimizer = optim.SGD, device = device) :\n",
    "        super(SentenceClassifier, self).__init__()\n",
    "        # embedding\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentWordsEncoder(self.word2vec.output_dim, hidden_dim, n_layers, dropout)\n",
    "        self.attention = SelfAttention(self.context.output_dim, dropout)\n",
    "        self.out       = nn.Linear(self.attention.output_dim, (1 if n_class == 2 else n_class))\n",
    "        self.act       = F.sigmoid if n_class == 2 else F.softmax\n",
    "        # optimizer\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def showAttention(self, words, attn) :\n",
    "        fig, ax = plt.subplots()\n",
    "        im, cbar = heatmap(np.array(attn.view(1, -1).data.cpu().numpy()),  [' '], words, ax=ax, cmap=\"YlGn\", cbarlabel=\"harvest [t/year]\")\n",
    "        texts = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "        \n",
    "    def forward(self, sentence, show_attention = False) :\n",
    "        words         = sentence.split(' ')\n",
    "        embeddings    = self.word2vec(words, self.device)\n",
    "        embeddings, _ = self.context(embeddings) \n",
    "        attended, atn = self.attention(embeddings)\n",
    "        prediction    = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        if show_attention : self.showAttention(words, atn)\n",
    "        return prediction\n",
    "    \n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) :\n",
    "        sentences.sort(key = lambda s: len(s[0].split(' ')), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            pack0 = [s[0].split(' ') for s in sentences[i:i + batch_size]]\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in pack0]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack0.sort(key = len, reverse = True)\n",
    "            lengths = torch.tensor([len(p) for p in pack0])           # size = (batch_size) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1)) # size = (batch_size, max_length)\n",
    "            pack1 = [[el[1]] for el in sentences[i:i + batch_size]]\n",
    "            pack1 = Variable(torch.FloatTensor(pack1))                # size = (batch_size)       \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings    = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            embeddings, _ = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended,   _ = self.attention(embeddings)\n",
    "            vects         = self.out(attended).view(-1)\n",
    "            return vects\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            return sum(torch.abs(targets.view(-1) - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0])\n",
    "            targets   = batch[1].to(self.device).view(-1)\n",
    "            loss      = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.data[0] / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91351"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SentenceClassifier(twin_fastText_word2vec,\n",
    "                                hidden_dim = 75, \n",
    "                                n_layers = 1, \n",
    "                                n_class = 2, \n",
    "                                dropout = 0.25,\n",
    "                                criterion = nn.BCEWithLogitsLoss(size_average = False),\n",
    "                                optimizer = optim.SGD,\n",
    "                                device = device)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = classifier.generatePackedSentences(labelled_sentences, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 2s (- 1m 16s) (100 3%) loss : 0.429  accuracy : 82.4 %\n",
      "0m 4s (- 1m 13s) (200 6%) loss : 0.325  accuracy : 86.2 %\n",
      "0m 7s (- 1m 11s) (300 9%) loss : 0.257  accuracy : 89.4 %\n",
      "epoch 2\n",
      "0m 9s (- 1m 9s) (400 12%) loss : 0.243  accuracy : 89.7 %\n",
      "0m 12s (- 1m 6s) (500 15%) loss : 0.208  accuracy : 91.5 %\n",
      "0m 14s (- 1m 3s) (600 18%) loss : 0.205  accuracy : 91.3 %\n",
      "epoch 3\n",
      "0m 16s (- 1m 1s) (700 21%) loss : 0.215  accuracy : 91.0 %\n",
      "0m 19s (- 0m 58s) (800 24%) loss : 0.193  accuracy : 92.0 %\n",
      "0m 21s (- 0m 56s) (900 27%) loss : 0.194  accuracy : 91.9 %\n",
      "epoch 4\n",
      "0m 24s (- 0m 54s) (1000 30%) loss : 0.188  accuracy : 92.2 %\n",
      "0m 26s (- 0m 51s) (1100 33%) loss : 0.183  accuracy : 92.4 %\n",
      "0m 28s (- 0m 49s) (1200 36%) loss : 0.187  accuracy : 92.4 %\n",
      "0m 31s (- 0m 46s) (1300 40%) loss : 0.175  accuracy : 93.3 %\n",
      "epoch 5\n",
      "0m 33s (- 0m 44s) (1400 43%) loss : 0.177  accuracy : 92.9 %\n",
      "0m 36s (- 0m 42s) (1500 46%) loss : 0.171  accuracy : 92.9 %\n",
      "0m 38s (- 0m 39s) (1600 49%) loss : 0.180  accuracy : 92.2 %\n",
      "epoch 6\n",
      "0m 40s (- 0m 37s) (1700 52%) loss : 0.168  accuracy : 93.0 %\n",
      "0m 43s (- 0m 34s) (1800 55%) loss : 0.167  accuracy : 93.1 %\n",
      "0m 45s (- 0m 32s) (1900 58%) loss : 0.167  accuracy : 92.8 %\n",
      "epoch 7\n",
      "0m 48s (- 0m 30s) (2000 61%) loss : 0.156  accuracy : 93.9 %\n",
      "0m 50s (- 0m 27s) (2100 64%) loss : 0.165  accuracy : 93.4 %\n",
      "0m 52s (- 0m 25s) (2200 67%) loss : 0.171  accuracy : 92.9 %\n",
      "epoch 8\n",
      "0m 55s (- 0m 22s) (2300 70%) loss : 0.161  accuracy : 93.3 %\n",
      "0m 57s (- 0m 20s) (2400 73%) loss : 0.151  accuracy : 94.3 %\n",
      "0m 59s (- 0m 17s) (2500 76%) loss : 0.151  accuracy : 93.7 %\n",
      "1m 2s (- 0m 15s) (2600 80%) loss : 0.164  accuracy : 93.2 %\n",
      "epoch 9\n",
      "1m 4s (- 0m 13s) (2700 83%) loss : 0.140  accuracy : 94.3 %\n",
      "1m 7s (- 0m 10s) (2800 86%) loss : 0.152  accuracy : 93.9 %\n",
      "1m 9s (- 0m 8s) (2900 89%) loss : 0.161  accuracy : 93.5 %\n",
      "epoch 10\n",
      "1m 12s (- 0m 6s) (3000 92%) loss : 0.139  accuracy : 94.1 %\n",
      "1m 14s (- 0m 3s) (3100 95%) loss : 0.143  accuracy : 94.3 %\n",
      "1m 16s (- 0m 1s) (3200 98%) loss : 0.144  accuracy : 94.2 %\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(batches, epochs = 10, lr = 0.01, print_every = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8189277648925781"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier(labelled_sentences[-20][0],  show_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6504966020584106"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('final bulk product i high prubofjsb jobbing sign',  show_attention = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(skipgram.state_dict(), path_to_NLP + '\\\\saves\\\\DDL_I1_skipgram.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
