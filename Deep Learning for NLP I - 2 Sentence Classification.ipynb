{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 2 <br><br><br>\n",
    "  Sentence Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. <font color=red>**Sentence Classification**</font>\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | | |\n",
    "|------|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | [Open source models](#open_source_models) | \n",
    "\n",
    "# Overview\n",
    "\n",
    "\n",
    "The global structure of the [sentence classifier](#classifier) is the pipeline of three modules, followed by a final classification layer :\n",
    "\n",
    "\n",
    "\n",
    "| | Module |  | |\n",
    "|------|------|------|------|\n",
    "| 1 | **Word Embedding** | [I.1 Custom model](#word_level_custom) | [I.2 Gensim Model](#gensim) | [I.3 FastText model](#fastText) |\n",
    "| 2 | **Contextualization** | [II.1 bidirectionnal GRU](#bi_gru) | [II.2 Transformer](#transformer) |\n",
    "| 3 | **Self-Attention** | [III.1 Self-Attention](#attention) | [III.2 Multi-head Self-Attention](#multihead_attention) |\n",
    "\n",
    "\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.3.1\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\libDL4NLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus est donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [[text, label]]<br>\n",
    "- text   = str<br>\n",
    "- label = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence): # -------------------------  str\n",
    "    sw = ['']\n",
    "    #sw += nltk.corpus.stopwords.words('english')\n",
    "    #sw += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    def normalizeString(s):\n",
    "        '''Remove rare symbols from a string'''\n",
    "        s = unicodeToAscii(s.lower().strip()) # \n",
    "        #s = re.sub(r\"[^a-zA-Z\\.\\(\\)\\[\\]]+\", r\" \", s)  # 'r' before a string is for 'raw' # ?&\\%\\_\\- removed # set('''.,:;()*#&-_%!?/\\'\")''')\n",
    "        return s\n",
    "\n",
    "    def wordTokenizerFunction():\n",
    "        # base version\n",
    "        function = lambda sentence : sentence.strip().split()\n",
    "\n",
    "        # nltk version\n",
    "        #function = word_tokenize    \n",
    "        return function\n",
    "\n",
    "    # 1 - caractères spéciaux\n",
    "    def clean_sentence_punct(text): # --------------  str\n",
    "        text = normalizeString(text)\n",
    "        # suppression de la dernière ponctuation\n",
    "        if (len(text) > 0 and text[-1] in ['.', ',', ';', ':', '!', '?']) : text = text[:-1]\n",
    "\n",
    "        text = text.replace(r'(', r' ( ')\n",
    "        text = text.replace(r')', r' ) ')\n",
    "        text = text.replace(r'[', r' [ ')\n",
    "        text = text.replace(r']', r' ] ')\n",
    "        text = text.replace(r'<', r' < ')\n",
    "        text = text.replace(r'>', r' > ')\n",
    "\n",
    "        text = text.replace(r':', r' : ')\n",
    "        text = text.replace(r';', r' ; ')\n",
    "        for i in range(5) :\n",
    "            text = re.sub('(?P<val1>[0-9])\\.(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "            text = re.sub('(?P<val1>[0-9]),(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "        text = text.replace(r',', ' , ')\n",
    "        text = text.replace(r'.', ' . ')\n",
    "        for i in range(5) : text = re.sub('(?P<val1>[p0-9])__-__(?P<val2>[p0-9])', '\\g<val1>.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. p \\. (?P<val2>[0-9])', '\\g<val1>.p.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. s \\. (?P<val2>[0-9])', '\\g<val1>.s.\\g<val2>', text)\n",
    "\n",
    "        text = text.replace(r'\"', r' \" ')\n",
    "        text = text.replace(r'’', r\" ' \")\n",
    "        text = text.replace(r'”', r' \" ')\n",
    "        text = text.replace(r'“', r' \" ')\n",
    "        text = text.replace(r'/', r' / ')\n",
    "\n",
    "        text = re.sub('(…)+', ' … ', text)\n",
    "        text = text.replace('≤', ' ≤ ')          \n",
    "        text = text.replace('≥', ' ≥ ')\n",
    "        text = text.replace('°c', ' °c ')\n",
    "        text = text.replace('°C', ' °c ')\n",
    "        text = text.replace('ºc', ' °c ')\n",
    "        text = text.replace('n°', 'n° ')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('*', ' * ')\n",
    "        text = text.replace('+', ' + ')\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('_', ' ')\n",
    "        text = text.replace('®', ' ')\n",
    "        text = text.replace('™', ' ')\n",
    "        text = text.replace('±', ' ± ')\n",
    "        text = text.replace('÷', ' ÷ ')\n",
    "        text = text.replace('–', ' - ')\n",
    "        text = text.replace('μg', ' µg')\n",
    "        text = text.replace('µg', ' µg')\n",
    "        text = text.replace('µl', ' µl')\n",
    "        text = text.replace('μl', ' µl')\n",
    "        text = text.replace('µm', ' µm')\n",
    "        text = text.replace('μm', ' µm')\n",
    "        text = text.replace('ppm', ' ppm')\n",
    "        text = re.sub('(?P<val1>[0-9])mm', '\\g<val1> mm', text)\n",
    "        text = re.sub('(?P<val1>[0-9])g', '\\g<val1> g', text)\n",
    "        text = text.replace('nm', ' nm')\n",
    "\n",
    "        text = re.sub('fa(?P<val1>[0-9])', 'fa \\g<val1>', text)\n",
    "        text = re.sub('g(?P<val1>[0-9])', 'g \\g<val1>', text)\n",
    "        text = re.sub('n(?P<val1>[0-9])', 'n \\g<val1>', text)\n",
    "        text = re.sub('p(?P<val1>[0-9])', 'p \\g<val1>', text)\n",
    "        text = re.sub('q_(?P<val1>[0-9])', 'q_ \\g<val1>', text)\n",
    "        text = re.sub('u(?P<val1>[0-9])', 'u \\g<val1>', text)\n",
    "        text = re.sub('ud(?P<val1>[0-9])', 'ud \\g<val1>', text)\n",
    "        text = re.sub('ui(?P<val1>[0-9])', 'ui \\g<val1>', text)\n",
    "\n",
    "        text = text.replace('=', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace(r' , ', ' ')\n",
    "        text = text.replace(r' . ', ' ')\n",
    "\n",
    "        text = re.sub('(?P<val>[0-9])ml', '\\g<val> ml', text)\n",
    "        text = re.sub('(?P<val>[0-9])mg', '\\g<val> mg', text)\n",
    "\n",
    "        for i in range(5) : text = re.sub('( [0-9]+ )', ' ', text)\n",
    "        #text = re.sub('cochran(\\S)*', 'cochran ', text)\n",
    "        return text\n",
    "\n",
    "    # 3 - split des mots\n",
    "    def wordSplit(sentence, tokenizeur): # ------------- [str]\n",
    "        return tokenizeur(sentence)\n",
    "\n",
    "    # 4 - mise en minuscule et enlèvement des stopwords\n",
    "    def stopwordsRemoval(sentence, sw): # ------------- [[str]]\n",
    "        return [word for word in sentence if word not in sw]\n",
    "\n",
    "    # 6 - correction des mots\n",
    "    def correction(text):\n",
    "        def correct(word):\n",
    "            return spelling.suggest(word)[0]\n",
    "        list_of_list_of_words = [[correct(word) for word in sentence] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    # 7 - stemming\n",
    "    def stemming(text): # ------------------------- [[str]]\n",
    "        list_of_list_of_words = [[PorterStemmer().stem(word) for word in sentence if word not in sw] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    tokenizeur = wordTokenizerFunction()\n",
    "    sentence = clean_sentence_punct(str(sentence))\n",
    "    sentence = wordSplit(sentence, tokenizeur)\n",
    "    sentence = stopwordsRemoval(sentence, sw)\n",
    "    #text = correction(text)\n",
    "    #text = stemming(text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def importSheet(file_name) :\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    labelled_sentences = [[' '.join(cleanSentence(str(el[0]) + ' | ' + str(el[1]))), el[-1]] for el in db if el[-1] in [0, 1]]\n",
    "    return labelled_sentences\n",
    "\n",
    "\n",
    "def importCorpus(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus += importSheet(file_name)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_sentences = importCorpus(path_to_NLP + '\\\\data\\\\AMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section 3.2.p.5.1 specification ( s ) | the testing performed on the finished product ( fp ) is in compliance with both current european pharmacopoeia ( ph eur ) and world health organization ( who ) requirements of the vaccine',\n",
       " 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "We assume that embedding model were pretrained following the steps detailed in **Part I - 1**.<br>\n",
    "We consider here Word2Vec models pre-trained following the Skip-Gram training objective.\n",
    "\n",
    "Since the chosen word embedding model must interact with subsequent modules int the sentence classification model, we wrap each model into a common small module that uniformize communication between any of these modules with subsequent ones.\n",
    "\n",
    "To speed up training we want to pre-pack sentences into mini-batches, each mini-batch forming a single Torch Variable. There are two issues for this :<br> First, packing sentences into mini-batches needs to introduce a additionnal _padding_ word in the Word2Vc model, in order to put sentences of a single mini-batch at equal length. Second, the Word2Vc model must be able to handle Torch Variables, which is not the case for Gensim and FastText models.\n",
    "\n",
    "A solution to these issues is to associate to the Word2Vec model a _twin_, which will be a Pytorch module containing and additionnal padding word/vector.\n",
    "\n",
    "\n",
    "The strength of FastText is the possiblity to advocate a word vctor to most unseen word by taking embedding of subword units.<br> However this advantage no longer exists for the Pytorch twin, since in such model only the lookup table remains.<br> Therefore it is necessary to wrap the fastText model into another Pytorch model, which will use a twin of the model for fast training and then use the original Word2Vec model for inference.\n",
    "\n",
    "All models are frozen after being loaded, so that none of their parameters is targeted by the sentence classifier optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecConnector(nn.Module) :\n",
    "    '''A Pytorch module wrapping a FastText word2vec model'''\n",
    "    def __init__(self, word2vec) :\n",
    "        super(Word2VecConnector, self).__init__()\n",
    "        self.word2vec = word2vec\n",
    "        self.twin = myWord2Vec(lang = Lang([list(word2vec.wv.index2word)], base_tokens = []), T = word2vec.wv.vectors)\n",
    "        self.twin.addWord('PADDING_WORD')\n",
    "        self.twin.addWord('UNK')\n",
    "        self.twin = self.twin.freeze()\n",
    "        \n",
    "        self.lang       = self.twin.lang\n",
    "        self.embedding  = self.twin.embedding\n",
    "        self.output_dim = self.twin.output_dim\n",
    "        \n",
    "    def lookupTable(self) :\n",
    "        return self.word2vec.wv.vectors\n",
    "        \n",
    "    def forward(self, words, device = None) :\n",
    "        '''Transforms a sequence of n words into a Torch FloatTensor of size (1, n, emb_dim)'''\n",
    "        try :\n",
    "            embeddings = Variable(torch.Tensor(self.word2vec[words])).unsqueeze(0)\n",
    "            if device is not None : embeddings = embeddings.to(device)\n",
    "        except :\n",
    "            embeddings = self.twin(words, device)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.utils import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_word2vec = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_skipgram.pt').freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2VecConnector(Word2Vec.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_skipgram_gensim.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec = Word2VecConnector(FastText.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_fasttext.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_layers = 1, dropout = 0, bidirectional = False): \n",
    "        super(RecurrentEncoder, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = hidden_dim # * (2 if bidirectional else 1)\n",
    "        self.n_layers   = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # layers\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.bigru = nn.GRU(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            n_layers,\n",
    "                            dropout = (0 if n_layers == 1 else dropout), \n",
    "                            bidirectional = bidirectional,\n",
    "                            batch_first = True)\n",
    "\n",
    "    def forward(self, embeddings, lengths = None, hidden = None, enforce_sorted = True) :\n",
    "        embeddings = self.dropout(embeddings) # size (batch_size, input_length, embedding_dim)\n",
    "        # GRU pass\n",
    "        if lengths is not None : embeddings = torch.nn.utils.rnn.pack_padded_sequence(embeddings, lengths, batch_first = True, enforce_sorted = enforce_sorted)\n",
    "        outputs, hidden = self.bigru(embeddings, hidden)\n",
    "        if lengths is not None : outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        if self.bidirectional : outputs = outputs[:, :, :self.hidden_dim] + outputs[:, : ,self.hidden_dim:]\n",
    "        # dropout\n",
    "        outputs = self.dropout(outputs)       # size (batch_size, input_length, output_dim)\n",
    "        hidden  = self.dropout(hidden)        # size (n_layers * num_directions, batch_size, hidden_dim)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Self-Attention Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout = 0): \n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = embedding_dim\n",
    "\n",
    "        # parameters\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.attn_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.attn_v = nn.Linear(embedding_dim, 1, bias = False)\n",
    "        self.act = F.softmax\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        weights = self.attn_layer(embeddings).tanh()       # size (batch_size, input_length, embedding_dim)\n",
    "        weights = self.act(self.attn_v(weights), dim = 1)  # size (batch_size, input_length, 1)\n",
    "        weights = torch.transpose(weights, 1, 2)           # size (batch_size, 1, input_length)\n",
    "        applied = torch.bmm(weights, embeddings)           # size (batch_size, 1, embedding_dim)\n",
    "        applied = self.dropout(applied)\n",
    "        return applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multihead_attention\"></a>\n",
    "\n",
    "#### 1.3.2 Multi-head Self-Attention Module\n",
    "\n",
    "- Idea presented at ICLR 2017 : [A structured self-attentive sentence embedding (2017)](https://arxiv.org/pdf/1703.03130.pdf)\n",
    "- Latest development : [Orthogonality Constrained Multi-Head Attention For Keyword Spotting (2019)](https://arxiv.org/pdf/1910.04500.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import MultiHeadSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_head = 1, dropout = 0): \n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = n_head * embedding_dim\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        # parameters\n",
    "        self.attn_list = nn.ModuleList([SelfAttention(embedding_dim, dropout) for i in range(n_head)])\n",
    "        \n",
    "    def compute_penalty(self, weights, device = None) :\n",
    "        weights_t = torch.transpose(weights, 1, 2)\n",
    "        def_pos = [torch.mm(weights[i], weights_t[i]) for i in range(weights.size(0))] # size (minibatch_size, n_heads, n_heads)\n",
    "        ide = Variable(torch.eye(self.n_head))\n",
    "        if device is not None : ide = ide.to(device)\n",
    "        penal = torch.sum(torch.cat([torch.norm(mmt - ide).view(1) for mmt in def_pos]))\n",
    "        return penal\n",
    "    \n",
    "    def forward(self, embeddings, penal = False, device = None):\n",
    "        outputs = [attn(embeddings) for attn in self.attn_list]\n",
    "        applied = torch.cat([out[0] for out in outputs], dim = 2) # size (batch_size, 1, n_heads * embedding_dim)\n",
    "        weights = torch.cat([out[1] for out in outputs], dim = 1) # size (batch_size, n_heads, input_length)\n",
    "        if penal and self.n_head > 1 :\n",
    "            penal = self.compute_penalty(weights, device)\n",
    "            return applied, weights, penal\n",
    "        elif penal : \n",
    "            return applied, weights, None\n",
    "        else :\n",
    "            return applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n",
    "\n",
    "Taken from [this page](https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.utils import heatmap, annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax = None, cbar_kw = {}, cbarlabel = \"\", **kwargs):\n",
    "    if not ax: ax = plt.gca()\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    return im\n",
    "\n",
    "def annotate_heatmap(im, data = None, valfmt = \"{x:.2f}\", textcolors = [\"black\", \"white\"], threshold = None, **textkw):\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.models import SentenceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden_dim = 100, \n",
    "                 n_layers = 1, \n",
    "                 n_attn_heads = 1, \n",
    "                 n_class = 2, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(SentenceClassifier, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.bin_mode  = (n_class == 'binary')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(self.word2vec.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.attention = MultiHeadSelfAttention(self.context.output_dim, n_head = n_attn_heads, dropout = dropout)\n",
    "        self.out       = nn.Linear(self.attention.output_dim, (1 if self.bin_mode else n_class))\n",
    "        self.act       = F.sigmoid if self.bin_mode else F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        if self.bin_mode : self.criterion = nn.BCEWithLogitsLoss(size_average = False)\n",
    "        else             : self.criterion = nn.NLLLoss(size_average = False, weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def showAttention(self, words, attn) : \n",
    "        attn = np.array(attn[0].data.cpu().numpy()) # size (n_heads, input_length)\n",
    "        labels = ['head '+str(i+1) for i in range(attn.shape[0])]\n",
    "        fig, ax  = plt.subplots()\n",
    "        im       = heatmap(attn, labels, words, ax=ax, cmap=\"YlGn\", cbarlabel=\"harvest [t/year]\")\n",
    "        texts    = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "        \n",
    "    def forward(self, sentence, show_attention = False) :\n",
    "        '''classifies a sentence as string'''\n",
    "        words         = self.tokenizer(sentence)\n",
    "        embeddings    = self.word2vec(words, self.device)\n",
    "        hiddens, _    = self.context(embeddings) \n",
    "        attended, atn = self.attention(hiddens)\n",
    "        if self.bin_mode : prediction = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        else             : prediction = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "        if show_attention : self.showAttention(words, atn)\n",
    "        return prediction\n",
    "    \n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) :\n",
    "        sentences.sort(key = lambda s: len(self.tokenizer(s[0])), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            pack0 = [self.tokenizer(s[0]) for s in sentences[i:i + batch_size]]\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in pack0]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack0.sort(key = len, reverse = True)\n",
    "            lengths = torch.tensor([len(p) for p in pack0])               # size (batch_size) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))     # size (batch_size, max_length)\n",
    "            pack1 = [[el[1]] for el in sentences[i:i + batch_size]]\n",
    "            if self.bin_mode : pack1 = Variable(torch.FloatTensor(pack1)) # size (batch_size) \n",
    "            else             : pack1 = Variable(torch.LongTensor(pack1))  # size (batch_size) \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def compute_accuracy(self, sentences) :\n",
    "        batches = self.generatePackedSentences(sentences, batch_size = 32)\n",
    "        score = 0\n",
    "        for batch, target in batches :\n",
    "            embeddings  = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _  = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended, _ = self.attention(hiddens)\n",
    "            if self.bin_mode : \n",
    "                vects  = self.out(attended).view(-1)\n",
    "                target = target.to(self.device).view(-1)\n",
    "                score += sum(torch.abs(target - self.act(vects)) < 0.5).item()\n",
    "            else : \n",
    "                log_probs = F.log_softmax(self.out(attended.squeeze(1)))\n",
    "                target    = target.to(self.device).view(-1)\n",
    "                score    += sum([target[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(target.size(0))])\n",
    "        return score * 100 / len(sentences)\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings  = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens, _  = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended, atn, penal = self.attention(hiddens, penal = True, device = self.device)\n",
    "            if self.bin_mode : return self.out(attended).view(-1), penal\n",
    "            else             : return F.log_softmax(self.out(attended.squeeze(1))), penal\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            if self.bin_mode : return sum(torch.abs(targets - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "            else             : return sum([targets[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(targets.size(0))]) * 100 / targets.size(0)\n",
    "            \n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs, penal = computeLogProbs(batch[0])\n",
    "            targets = batch[1].to(self.device).view(-1)\n",
    "            loss    = self.criterion(log_probs, targets)\n",
    "            if penal is not None and penal.item() > 10 : loss = loss + penal\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.item() / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86351"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SentenceClassifier(device,\n",
    "                                tokenizer = lambda s : s.split(' '),\n",
    "                                word2vec = fastText_word2vec,\n",
    "                                hidden_dim = 50, \n",
    "                                n_layers = 2,\n",
    "                                n_attn_heads = 1,\n",
    "                                n_class = 'binary', \n",
    "                                dropout = 0.2,\n",
    "                                optimizer = optim.AdamW)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceClassifier(\n",
       "  (word2vec): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(4065, 75)\n",
       "    )\n",
       "    (embedding): Embedding(4065, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (bigru): GRU(75, 50, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (attention): MultiHeadSelfAttention(\n",
       "    (attn_list): ModuleList(\n",
       "      (0): SelfAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (attn_layer): Linear(in_features=50, out_features=50, bias=True)\n",
       "        (attn_v): Linear(in_features=50, out_features=1, bias=False)\n",
       "      )\n",
       "      (1): SelfAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (attn_layer): Linear(in_features=50, out_features=50, bias=True)\n",
       "        (attn_v): Linear(in_features=50, out_features=1, bias=False)\n",
       "      )\n",
       "      (2): SelfAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (attn_layer): Linear(in_features=50, out_features=50, bias=True)\n",
       "        (attn_v): Linear(in_features=50, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=150, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = classifier.generatePackedSentences(labelled_sentences, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 4s (- 0m 39s) (100 10%) loss : 0.318  accuracy : 86.6 %\n",
      "0m 8s (- 0m 34s) (200 20%) loss : 0.205  accuracy : 91.2 %\n",
      "0m 13s (- 0m 29s) (300 30%) loss : 0.181  accuracy : 92.5 %\n",
      "epoch 2\n",
      "0m 17s (- 0m 25s) (400 41%) loss : 0.146  accuracy : 93.6 %\n",
      "0m 22s (- 0m 21s) (500 51%) loss : 0.164  accuracy : 92.7 %\n",
      "0m 26s (- 0m 16s) (600 61%) loss : 0.149  accuracy : 93.4 %\n",
      "epoch 3\n",
      "0m 31s (- 0m 12s) (700 71%) loss : 0.136  accuracy : 94.3 %\n",
      "0m 35s (- 0m 7s) (800 82%) loss : 0.131  accuracy : 94.6 %\n",
      "0m 40s (- 0m 3s) (900 92%) loss : 0.127  accuracy : 94.8 %\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(batches, epochs = 3, lr = 0.01, print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(classifier.state_dict(), path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I2_sentence_classifier.pth')\n",
    "\n",
    "# load\n",
    "#classifier.load_state_dict(torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I2_sentence_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8775690793991089"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention heads = 1\n",
    "classifier.eval()\n",
    "classifier('section 3.2.p.5.2 analytical procedures overview | tetanus identification', show_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.17013086989992"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier.compute_accuracy(labelled_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation multi-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8062561750411987"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention heads = 3\n",
    "classifier.eval()\n",
    "classifier('section 3.2.p.5.2 analytical procedures overview | tetanus identification', show_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.67378752886836"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier.compute_accuracy(labelled_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open_source_models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Open source models\n",
    "\n",
    "[Back to top](#plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 HuggingFace Transformers\n",
    "\n",
    "The repo is located at [this address](https://github.com/huggingface/transformers).\n",
    "\n",
    "A simple tutorial for binary sentence classification is given [here](https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SimpleTransformers (build on top of HuggingFace)\n",
    "\n",
    "Explanations are found [here](https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3) and [here](https://medium.com/swlh/simple-transformers-multi-class-text-classification-with-bert-roberta-xlnet-xlm-and-8b585000ce3a).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL apex\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labelled_sentences, columns = ['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20784, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>section 3.2.p.5.6 justification of specificati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>section 3.2.p.5.3 validation of analytical pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>section 3.2.p.5.3 validation of analytical pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>section 3.2.p.5.6 justification of specificati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>section 3.2.p.5.6 justification of specificati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  section 3.2.p.5.6 justification of specificati...      1\n",
       "1  section 3.2.p.5.3 validation of analytical pro...      0\n",
       "2  section 3.2.p.5.3 validation of analytical pro...      0\n",
       "3  section 3.2.p.5.6 justification of specificati...      0\n",
       "4  section 3.2.p.5.6 justification of specificati...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_tst = df.iloc[:15000, :], df.iloc[15000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpletransformers_model = ClassificationModel('bert', 'bert-base-cased', num_labels = 2, \n",
    "                                               args = {'num_train_epochs': 1, 'learning_rate': 3e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from cache at cache_dir/cached_train_bert_128_2_15000\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Please install apex from https://www.github.com/nvidia/apex to use fp16 training.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, output_dir, show_running_loss, eval_df)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'apex'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-05bf6dbfc650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimpletransformers_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_and_cache_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_running_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_running_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, output_dir, show_running_loss, eval_df)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 raise ImportError(\n\u001b[1;32m--> 240\u001b[1;33m                     \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fp16_opt_level\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Please install apex from https://www.github.com/nvidia/apex to use fp16 training."
     ]
    }
   ],
   "source": [
    "simpletransformers_model.train_model(df_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = simpletransformers_model.eval_model(eval_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
