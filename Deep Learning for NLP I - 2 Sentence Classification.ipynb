{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 2 <br><br><br>\n",
    "  Sentence Classification\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. <font color=red>**Sentence Classification**</font>\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Extractive Summarization\n",
    "    - Sentiment Analysis\n",
    "    - Text segmentation\n",
    "\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sentence tagging\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Part-of-speech Tagging\n",
    "    - Named Entity Recognition\n",
    "    - Automatic Value Extraction\n",
    "    \n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The global structure of the [sentence classifier](#classifier) is the pipeline of three modules, followed by a final classification layer :\n",
    "\n",
    "\n",
    "\n",
    "| | Module |  | |\n",
    "|------|------|------|------|\n",
    "| 1 | **Word Embedding** | [I.1 Custom model](#word_level_custom) | [I.2 Gensim Model](#gensim) | [I.3 FastText model](#fastText) |\n",
    "| 2 | **Contextualization** | [II.1 bidirectionnal GRU](#bi_gru) | [II.2 Transformer](#transformer) |\n",
    "| 3 | **Attention** | [III.1 Attention](#attention) | [III.2 Multi-head Attention](#attention) |\n",
    "\n",
    "\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 0.4.0\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\chatNLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus et donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text, label]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence): # -------------------------  str\n",
    "    sw = ['']\n",
    "    #sw += nltk.corpus.stopwords.words('english')\n",
    "    #sw += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    def normalizeString(s):\n",
    "        '''Remove rare symbols from a string'''\n",
    "        s = unicodeToAscii(s.lower().strip()) # \n",
    "        #s = re.sub(r\"[^a-zA-Z\\.\\(\\)\\[\\]]+\", r\" \", s)  # 'r' before a string is for 'raw' # ?&\\%\\_\\- removed # set('''.,:;()*#&-_%!?/\\'\")''')\n",
    "        return s\n",
    "\n",
    "    def wordTokenizerFunction():\n",
    "        # base version\n",
    "        function = lambda sentence : sentence.strip().split()\n",
    "\n",
    "        # nltk version\n",
    "        #function = word_tokenize    \n",
    "        return function\n",
    "\n",
    "    # 1 - caractères spéciaux\n",
    "    def clean_sentence_punct(text): # --------------  str\n",
    "        text = normalizeString(text)\n",
    "        # suppression de la dernière ponctuation\n",
    "        if (len(text) > 0 and text[-1] in ['.', ',', ';', ':', '!', '?']) : text = text[:-1]\n",
    "\n",
    "        text = text.replace(r'(', r' ( ')\n",
    "        text = text.replace(r')', r' ) ')\n",
    "        text = text.replace(r'[', r' [ ')\n",
    "        text = text.replace(r']', r' ] ')\n",
    "        text = text.replace(r'<', r' < ')\n",
    "        text = text.replace(r'>', r' > ')\n",
    "\n",
    "        text = text.replace(r':', r' : ')\n",
    "        text = text.replace(r';', r' ; ')\n",
    "        for i in range(5) :\n",
    "            text = re.sub('(?P<val1>[0-9])\\.(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "            text = re.sub('(?P<val1>[0-9]),(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "        text = text.replace(r',', ' , ')\n",
    "        text = text.replace(r'.', ' . ')\n",
    "        for i in range(5) : text = re.sub('(?P<val1>[p0-9])__-__(?P<val2>[p0-9])', '\\g<val1>.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. p \\. (?P<val2>[0-9])', '\\g<val1>.p.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. s \\. (?P<val2>[0-9])', '\\g<val1>.s.\\g<val2>', text)\n",
    "\n",
    "        text = text.replace(r'\"', r' \" ')\n",
    "        text = text.replace(r'’', r\" ' \")\n",
    "        text = text.replace(r'”', r' \" ')\n",
    "        text = text.replace(r'“', r' \" ')\n",
    "        text = text.replace(r'/', r' / ')\n",
    "\n",
    "        text = re.sub('(…)+', ' … ', text)\n",
    "        text = text.replace('≤', ' ≤ ')          \n",
    "        text = text.replace('≥', ' ≥ ')\n",
    "        text = text.replace('°c', ' °c ')\n",
    "        text = text.replace('°C', ' °c ')\n",
    "        text = text.replace('ºc', ' °c ')\n",
    "        text = text.replace('n°', 'n° ')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('*', ' * ')\n",
    "        text = text.replace('+', ' + ')\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('_', ' ')\n",
    "        text = text.replace('®', ' ')\n",
    "        text = text.replace('™', ' ')\n",
    "        text = text.replace('±', ' ± ')\n",
    "        text = text.replace('÷', ' ÷ ')\n",
    "        text = text.replace('–', ' - ')\n",
    "        text = text.replace('μg', ' µg')\n",
    "        text = text.replace('µg', ' µg')\n",
    "        text = text.replace('µl', ' µl')\n",
    "        text = text.replace('μl', ' µl')\n",
    "        text = text.replace('µm', ' µm')\n",
    "        text = text.replace('μm', ' µm')\n",
    "        text = text.replace('ppm', ' ppm')\n",
    "        text = re.sub('(?P<val1>[0-9])mm', '\\g<val1> mm', text)\n",
    "        text = re.sub('(?P<val1>[0-9])g', '\\g<val1> g', text)\n",
    "        text = text.replace('nm', ' nm')\n",
    "\n",
    "        text = re.sub('fa(?P<val1>[0-9])', 'fa \\g<val1>', text)\n",
    "        text = re.sub('g(?P<val1>[0-9])', 'g \\g<val1>', text)\n",
    "        text = re.sub('n(?P<val1>[0-9])', 'n \\g<val1>', text)\n",
    "        text = re.sub('p(?P<val1>[0-9])', 'p \\g<val1>', text)\n",
    "        text = re.sub('q_(?P<val1>[0-9])', 'q_ \\g<val1>', text)\n",
    "        text = re.sub('u(?P<val1>[0-9])', 'u \\g<val1>', text)\n",
    "        text = re.sub('ud(?P<val1>[0-9])', 'ud \\g<val1>', text)\n",
    "        text = re.sub('ui(?P<val1>[0-9])', 'ui \\g<val1>', text)\n",
    "\n",
    "        text = text.replace('=', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace(r' , ', ' ')\n",
    "        text = text.replace(r' . ', ' ')\n",
    "\n",
    "        text = re.sub('(?P<val>[0-9])ml', '\\g<val> ml', text)\n",
    "        text = re.sub('(?P<val>[0-9])mg', '\\g<val> mg', text)\n",
    "\n",
    "        for i in range(5) : text = re.sub('( [0-9]+ )', ' ', text)\n",
    "        #text = re.sub('cochran(\\S)*', 'cochran ', text)\n",
    "        return text\n",
    "\n",
    "    # 3 - split des mots\n",
    "    def wordSplit(sentence, tokenizeur): # ------------- [str]\n",
    "        return tokenizeur(sentence)\n",
    "\n",
    "    # 4 - mise en minuscule et enlèvement des stopwords\n",
    "    def stopwordsRemoval(sentence, sw): # ------------- [[str]]\n",
    "        return [word for word in sentence if word not in sw]\n",
    "\n",
    "    # 6 - correction des mots\n",
    "    def correction(text):\n",
    "        def correct(word):\n",
    "            return spelling.suggest(word)[0]\n",
    "        list_of_list_of_words = [[correct(word) for word in sentence] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    # 7 - stemming\n",
    "    def stemming(text): # ------------------------- [[str]]\n",
    "        list_of_list_of_words = [[PorterStemmer().stem(word) for word in sentence if word not in sw] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    tokenizeur = wordTokenizerFunction()\n",
    "    sentence = clean_sentence_punct(str(sentence))\n",
    "    sentence = wordSplit(sentence, tokenizeur)\n",
    "    sentence = stopwordsRemoval(sentence, sw)\n",
    "    #text = correction(text)\n",
    "    #text = stemming(text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def importSheet(file_name) :\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    labelled_sentences = [[' '.join(cleanSentence(str(el[0]) + ' | ' + str(el[1]))), el[-1]] for el in db if el[-1] in [0, 1]]\n",
    "    return labelled_sentences\n",
    "\n",
    "\n",
    "def importCorpus(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus += importSheet(file_name)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_sentences = importCorpus(path_to_NLP + '\\\\data\\\\AMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section 3.2.p.5.1 specification ( s ) | the testing performed on the finished product ( fp ) is in compliance with both current european pharmacopoeia ( ph eur ) and world health organization ( who ) requirements of the vaccine',\n",
       " 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "## 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "We assume that embedding model were pretrained following the steps detailed in **Part I - 1**.<br>\n",
    "We consider here Word2Vec models pre-trained following the Skip-Gram training objective.\n",
    "\n",
    "Since the chosen word embedding model must interact with subsequent modules int the sentence classification model, we wrap each model into a common small module that uniformize communication between any of these modules with subsequent ones.\n",
    "\n",
    "To speed up training we want to pre-pack sentences into mini-batches, each mini-batch forming a single Torch Variable. There are two issues for this :<br> First, packing sentences into mini-batches needs to introduce a additionnal _padding_ word in the Word2Vc model, in order to put sentences of a single mini-batch at equal length. Second, the Word2Vc model must be able to handle Torch Variables, which is not the case for Gensim and FastText models.\n",
    "\n",
    "A solution to these issues is to associate to the Word2Vec model a _twin_, which will be a Pytorch module containing and additionnal padding word/vector.\n",
    "\n",
    "\n",
    "The strength of FastText is the possiblity to advocate a word vctor to most unseen word by taking embedding of subword units.<br> However this advantage no longer exists for the Pytorch twin, since in such model only the lookup table remains.<br> Therefore it is necessary to wrap the fastText model into another Pytorch model, which will use a twin of the model for fast training and then use the original Word2Vec model for inference.\n",
    "\n",
    "All models are frozen after being loaded, so that none of their parameters is targeted by the sentence classifier optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecConnector(nn.Module) :\n",
    "    '''A Pytorch module wrapping a FastText word2vec model'''\n",
    "    def __init__(self, word2vec) :\n",
    "        super(Word2VecConnector, self).__init__()\n",
    "        self.word2vec = word2vec\n",
    "        self.twin = myWord2Vec(lang = Lang([list(word2vec.wv.index2word)], base_tokens = []), T = word2vec.wv.vectors)\n",
    "        self.twin.addWord('PADDING_WORD')\n",
    "        self.twin.addWord('UNK')\n",
    "        self.twin = self.twin.freeze()\n",
    "        \n",
    "        self.lang       = self.twin.lang\n",
    "        self.embedding  = self.twin.embedding\n",
    "        self.output_dim = self.twin.output_dim\n",
    "        \n",
    "    def forward(self, words, device = None) :\n",
    "        '''Transforms a sequence of n words into a Torch FloatTensor of size (1, n, emb_dim)'''\n",
    "        try :\n",
    "            embeddings = Variable(torch.Tensor(self.word2vec[words])).unsqueeze(0)\n",
    "            if device is not None : embeddings = embeddings.to(device)\n",
    "        except :\n",
    "            embeddings = self.twin(words, device)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_level_custom\"></a>\n",
    "\n",
    "\n",
    "#### 1.1.1 Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatNLP.models import Word2Vec as myWord2Vec\n",
    "from chatNLP.utils import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_word2vec = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I1_skipgram.pt').freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim\"></a>\n",
    "\n",
    "#### 1.1.2 Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word2vec = Word2VecConnector(Word2Vec.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_skipgram_gensim.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fastText\"></a>\n",
    "\n",
    "#### 1.1.3 FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec = Word2VecConnector(FastText.load(get_tmpfile(path_to_NLP + \"\\\\saves\\\\models\\\\DL4NLP_I1_fasttext.model\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "The contextualization layer transforms a sequences of word vectors into another one, of same length, where each output vector corresponds to a new version of each input vector that is contextualized with respect to neighboring vectors.\n",
    "\n",
    "<a id=\"bi_gru\"></a>\n",
    "\n",
    "#### 1.2.1 Bi-directionnal GRU contextualization\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_layers = 1, dropout = 0, bidirectional = False): \n",
    "        super(RecurrentEncoder, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "\n",
    "        # layers\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.bigru = nn.GRU(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            n_layers,\n",
    "                            dropout = (0 if n_layers == 1 else dropout), \n",
    "                            bidirectional = bidirectional,\n",
    "                            batch_first = True)\n",
    "\n",
    "    def forward(self, embeddings, lengths = None, hidden = None) :\n",
    "        '''Transforms a batch of size (batch_size, input_length, embedding_dim) into \n",
    "        \n",
    "              - outputs of size (batch_size, input_length, 2 * embedding_dim)\n",
    "              - hidden  of size (batch_size, 2 * n_layers, embedding_dim)\n",
    "        '''\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        if lengths is not None : embeddings = torch.nn.utils.rnn.pack_padded_sequence(embeddings, lengths, batch_first = True)\n",
    "        outputs, hidden = self.bigru(embeddings, hidden) # dim = (batch_size, input_length, output_dim)\n",
    "        if lengths is not None : outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True)\n",
    "        outputs = self.dropout(outputs)                  # dim = (batch_size, input_length, output_dim)\n",
    "        hidden  = self.dropout(hidden)                   # dim = (batch_size, 2, hidden_dim)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "#### 1.3.1 Classical Attention module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.modules import SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout = 0): \n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        # relevant quantities\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = embedding_dim\n",
    "\n",
    "        # parameters\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.attn_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.attn_v = nn.Linear(embedding_dim, 1, bias = False)\n",
    "        self.act = F.softmax\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        weights = self.attn_layer(embeddings).tanh()       # size (minibatch_size, input_length, embedding_dim)\n",
    "        weights = self.act(self.attn_v(weights), dim = 1)  # size (minibatch_size, input_length, 1)\n",
    "        weights = torch.transpose(weights, 1, 2)           # size (minibatch_size, 1, input_length)\n",
    "        attn_applied = torch.bmm(weights, embeddings)      # size (minibatch_size, 1, embedding_dim)\n",
    "        attn_applied = self.dropout(attn_applied)\n",
    "        return attn_applied, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n",
    "\n",
    "Taken from [this page](https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.utils import heatmap, annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax = None, cbar_kw = {}, cbarlabel = \"\", **kwargs):\n",
    "    if not ax: ax = plt.gca()\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    return im\n",
    "\n",
    "def annotate_heatmap(im, data = None, valfmt = \"{x:.2f}\", textcolors = [\"black\", \"white\"], threshold = None, **textkw):\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence Classifier\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chatNLP.models import SentenceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module) :\n",
    "    def __init__(self, device, word2vec, hidden_dim, n_layers, n_class = 2, dropout = 0, optimizer = optim.SGD) :\n",
    "        super(SentenceClassifier, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.bin_mode  = (n_class == 'binary')\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(self.word2vec.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.attention = SelfAttention(self.context.output_dim, dropout)\n",
    "        self.out       = nn.Linear(self.attention.output_dim, (1 if self.bin_mode else n_class))\n",
    "        self.act       = F.sigmoid if self.bin_mode else F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss(size_average = False) if self.bin_mode else nn.NLLLoss(size_average = False)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def showAttention(self, words, attn) :\n",
    "        fig, ax  = plt.subplots()\n",
    "        im       = heatmap(np.array(attn.view(1, -1).data.cpu().numpy()),  [' '], words, ax=ax, cmap=\"YlGn\", cbarlabel=\"harvest [t/year]\")\n",
    "        texts    = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "        \n",
    "    def forward(self, sentence, show_attention = False) :\n",
    "        words         = sentence.split(' ')\n",
    "        embeddings    = self.word2vec(words, self.device)\n",
    "        embeddings, _ = self.context(embeddings) \n",
    "        attended, atn = self.attention(embeddings)\n",
    "        if self.bin_mode : prediction = self.act(self.out(attended).view(-1)).data.topk(1)[0].item()\n",
    "        else             : prediction = self.act(self.out(attended.squeeze(1)), dim = 1).data.topk(1)[1].item()\n",
    "        if show_attention : self.showAttention(words, atn)\n",
    "        return prediction\n",
    "    \n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) :\n",
    "        sentences.sort(key = lambda s: len(s[0].split(' ')), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            pack0 = [s[0].split(' ') for s in sentences[i:i + batch_size]]\n",
    "            pack0 = [[self.word2vec.lang.getIndex(w) for w in words] for words in pack0]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack0.sort(key = len, reverse = True)\n",
    "            lengths = torch.tensor([len(p) for p in pack0])               # size = (batch_size) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.word2vec.lang.getIndex('PADDING_WORD')))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))     # size = (batch_size, max_length)\n",
    "            pack1 = [[el[1]] for el in sentences[i:i + batch_size]]\n",
    "            if self.bin_mode : pack1 = Variable(torch.FloatTensor(pack1)) # size = (batch_size) \n",
    "            else             : pack1 = Variable(torch.LongTensor(pack1))  # size = (batch_size) \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def compute_accuracy(self, sentences) :\n",
    "        batches = self.generatePackedSentences(sentences, batch_size = 32)\n",
    "        score = 0\n",
    "        for batch, target in batches :\n",
    "            embeddings    = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            embeddings, _ = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended,   _ = self.attention(embeddings)\n",
    "            if self.bin_mode : \n",
    "                vects  = self.out(attended).view(-1)\n",
    "                target = target.to(self.device).view(-1)\n",
    "                score += sum(torch.abs(target - self.act(vects)) < 0.5).item()\n",
    "            else : \n",
    "                log_probs = F.log_softmax(self.out(attended.squeeze(1)))\n",
    "                target    = target.to(self.device).view(-1)\n",
    "                score    += sum([target[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(target.size(0))])\n",
    "        return score * 100 / len(sentences)\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings    = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            embeddings, _ = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended,   _ = self.attention(embeddings)\n",
    "            if self.bin_mode : return self.out(attended).view(-1)\n",
    "            else             : return F.log_softmax(self.out(attended.squeeze(1)))\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            if self.bin_mode : return sum(torch.abs(targets - self.act(log_probs)) < 0.5).item() * 100 / targets.size(0)\n",
    "            else             : return sum([targets[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(targets.size(0))]) * 100 / targets.size(0)\n",
    "            \n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0])\n",
    "            targets   = batch[1].to(self.device).view(-1)\n",
    "            loss      = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.data[0] / targets.size(0)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91351"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SentenceClassifier(device,\n",
    "                                custom_word2vec,\n",
    "                                hidden_dim = 75, \n",
    "                                n_layers = 1, \n",
    "                                n_class = 'binary', \n",
    "                                dropout = 0.25)\n",
    "\n",
    "classifier.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceClassifier(\n",
       "  (word2vec): Word2Vec(\n",
       "    (embedding): Embedding(4066, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.25)\n",
       "    (bigru): GRU(75, 75, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (attention): SelfAttention(\n",
       "    (dropout): Dropout(p=0.25)\n",
       "    (attn_layer): Linear(in_features=150, out_features=150, bias=True)\n",
       "    (attn_v): Linear(in_features=150, out_features=1, bias=False)\n",
       "  )\n",
       "  (out): Linear(in_features=150, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = classifier.generatePackedSentences(labelled_sentences, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 2s (- 1m 17s) (100 3%) loss : 0.388  accuracy : 83.9 %\n",
      "0m 4s (- 1m 14s) (200 6%) loss : 0.268  accuracy : 88.2 %\n",
      "0m 7s (- 1m 12s) (300 9%) loss : 0.218  accuracy : 90.5 %\n",
      "epoch 2\n",
      "0m 9s (- 1m 10s) (400 12%) loss : 0.211  accuracy : 91.2 %\n",
      "0m 12s (- 1m 7s) (500 15%) loss : 0.184  accuracy : 92.2 %\n",
      "0m 14s (- 1m 4s) (600 18%) loss : 0.189  accuracy : 92.0 %\n",
      "epoch 3\n",
      "0m 16s (- 1m 1s) (700 21%) loss : 0.189  accuracy : 91.8 %\n",
      "0m 19s (- 0m 59s) (800 24%) loss : 0.174  accuracy : 92.4 %\n",
      "0m 21s (- 0m 56s) (900 27%) loss : 0.173  accuracy : 92.7 %\n",
      "epoch 4\n",
      "0m 24s (- 0m 54s) (1000 30%) loss : 0.165  accuracy : 92.7 %\n",
      "0m 26s (- 0m 51s) (1100 33%) loss : 0.161  accuracy : 93.4 %\n",
      "0m 28s (- 0m 49s) (1200 36%) loss : 0.153  accuracy : 93.5 %\n",
      "0m 31s (- 0m 46s) (1300 40%) loss : 0.156  accuracy : 93.5 %\n",
      "epoch 5\n",
      "0m 33s (- 0m 44s) (1400 43%) loss : 0.145  accuracy : 94.0 %\n",
      "0m 36s (- 0m 42s) (1500 46%) loss : 0.147  accuracy : 94.1 %\n",
      "0m 38s (- 0m 39s) (1600 49%) loss : 0.145  accuracy : 94.1 %\n",
      "epoch 6\n",
      "0m 41s (- 0m 37s) (1700 52%) loss : 0.139  accuracy : 94.1 %\n",
      "0m 43s (- 0m 35s) (1800 55%) loss : 0.142  accuracy : 93.8 %\n",
      "0m 45s (- 0m 32s) (1900 58%) loss : 0.133  accuracy : 94.5 %\n",
      "epoch 7\n",
      "0m 48s (- 0m 30s) (2000 61%) loss : 0.128  accuracy : 94.8 %\n",
      "0m 50s (- 0m 27s) (2100 64%) loss : 0.132  accuracy : 94.4 %\n",
      "0m 53s (- 0m 25s) (2200 67%) loss : 0.134  accuracy : 94.2 %\n",
      "epoch 8\n",
      "0m 55s (- 0m 22s) (2300 70%) loss : 0.126  accuracy : 94.8 %\n",
      "0m 57s (- 0m 20s) (2400 73%) loss : 0.118  accuracy : 95.0 %\n",
      "1m 0s (- 0m 18s) (2500 76%) loss : 0.115  accuracy : 95.3 %\n",
      "1m 2s (- 0m 15s) (2600 80%) loss : 0.127  accuracy : 94.8 %\n",
      "epoch 9\n",
      "1m 5s (- 0m 13s) (2700 83%) loss : 0.106  accuracy : 95.7 %\n",
      "1m 7s (- 0m 10s) (2800 86%) loss : 0.115  accuracy : 95.5 %\n",
      "1m 9s (- 0m 8s) (2900 89%) loss : 0.131  accuracy : 94.5 %\n",
      "epoch 10\n",
      "1m 12s (- 0m 6s) (3000 92%) loss : 0.103  accuracy : 95.9 %\n",
      "1m 14s (- 0m 3s) (3100 95%) loss : 0.110  accuracy : 95.6 %\n",
      "1m 17s (- 0m 1s) (3200 98%) loss : 0.114  accuracy : 95.4 %\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(batches, epochs = 10, lr = 0.01, print_every = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.963522732257843"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.eval()\n",
    "classifier('section 3.2.p.5.2 analytical procedures overview | tetanus identification', show_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.00731331793688"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compute_accuracy(labelled_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(skipgram.state_dict(), path_to_NLP + '\\\\saves\\\\DDL_I1_skipgram.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
