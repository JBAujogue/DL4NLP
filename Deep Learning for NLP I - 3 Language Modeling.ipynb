{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 3 <br><br><br>\n",
    "  Language Modeling\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Extractive Summarization\n",
    "    - Sentiment Analysis\n",
    "    - Text segmentation\n",
    "\n",
    "\n",
    "3. <font color=red>**Language Modeling**</font>\n",
    "\n",
    "4. Sentence tagging\n",
    "\n",
    "    _Applications :_\n",
    "    \n",
    "    - Part-of-speech Tagging\n",
    "    - Named Entity Recognition\n",
    "    - Automatic Value Extraction\n",
    "    \n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to anaconda : C:\\ProgramData\\Anaconda3\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manipulating dataframes, arrays, containers...\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "from unidecode import unidecode\n",
    "\n",
    "# equivalent of numpy for very large arrays (such as a database of pretrained word vectors)\n",
    "# optimized for SQL-like operations, not for math computations\n",
    "# see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "\n",
    "# installer avec la commande : conda install bcolz\n",
    "import bcolz\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "use_cuda = False\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NLP\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_rep = 'C:\\\\Users\\\\jbaujogue\\\\Desktop\\\\NLP\\\\démonstrateurs NLP'\n",
    "path_to_NLP = 'C:\\\\Users\\\\jbaujogue\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Préparation\n",
    "\n",
    "<a id=\"import\"></a>\n",
    "\n",
    "### 0.1 Import du corpus\n",
    "\n",
    "[Retour à la table des matières](#plan)\n",
    "\n",
    "Import du corpus de tickets Lilly, avec chaque ticket sous la forme d'une liste nettoyée de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3394, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Created</th>\n",
       "      <th>Problem</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Description</th>\n",
       "      <th>Resolution Code</th>\n",
       "      <th>Resolve Notes</th>\n",
       "      <th>Résumé</th>\n",
       "      <th>Résolution</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>QAimpact</th>\n",
       "      <th>Analyse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC2976351</td>\n",
       "      <td>2016-06-01 06:54:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AST : PMX-PKG : Démarrage étape de production ...</td>\n",
       "      <td>Impossible de démarrer l'étape de production s...</td>\n",
       "      <td>People/System use</td>\n",
       "      <td>• [Résumé] Impossible de démarrer l'étape de p...</td>\n",
       "      <td>Impossible de démarrer l'étape de production s...</td>\n",
       "      <td>Fermeture de la session concernée via la Conso...</td>\n",
       "      <td>HE/PKG/Limos</td>\n",
       "      <td>Sans impact</td>\n",
       "      <td>Hscope/Duplicate/Cslt/Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC2976936</td>\n",
       "      <td>2016-06-01 09:56:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : Alarme type 2 non vue par l'équipement</td>\n",
       "      <td>Une alarme s'est déclenchée sur le limos LPF-E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>• [Résumé]\\n\\n• [Catégorie] \\n\\n• [Résolution]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sans impact</td>\n",
       "      <td>Matrikon/Alarme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC2977191</td>\n",
       "      <td>2016-06-01 10:51:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : ticket journalier MO3524 du 01/06/2016</td>\n",
       "      <td>01/06/2016 00:00:00 =&gt;  01/06/2016 10:47:14\\n-...</td>\n",
       "      <td>Monitoring</td>\n",
       "      <td>• [Catégorie] Monitoring des erreurs d'interfa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interface</td>\n",
       "      <td>Sans impact</td>\n",
       "      <td>Dailyinterfacemonitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC2981590</td>\n",
       "      <td>2016-06-02 09:55:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : ref_relation = WESSTOCKREMOVAL  (LC ...</td>\n",
       "      <td>Message envoyé le 01/06/2016 12:57:07\\n\\nid = ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>• [Résumé] Message d'erreur reçu sur l'interfa...</td>\n",
       "      <td>Message d'erreur reçu sur l'interface WES</td>\n",
       "      <td>Régulation effectuée par Stephane Seyller du b...</td>\n",
       "      <td>HE/WES</td>\n",
       "      <td>Sans impact</td>\n",
       "      <td>Lcmovementerror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC2981597</td>\n",
       "      <td>2016-06-02 09:56:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : ref_relation = WESSTOCKREMOVAL (LC =...</td>\n",
       "      <td>Message envoyé le 01/06/2016 12:59:07\\n\\nid = ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>• [Résumé] Message d'erreur reçu sur l'interfa...</td>\n",
       "      <td>Message d'erreur reçu sur l'interface WES</td>\n",
       "      <td>Régulation effectuée par Stephane Seyller du b...</td>\n",
       "      <td>HE/WES</td>\n",
       "      <td>Sans impact</td>\n",
       "      <td>Lcmovementerror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number             Created Problem  \\\n",
       "0  INC2976351 2016-06-01 06:54:32     NaN   \n",
       "1  INC2976936 2016-06-01 09:56:53     NaN   \n",
       "2  INC2977191 2016-06-01 10:51:31     NaN   \n",
       "3  INC2981590 2016-06-02 09:55:10     NaN   \n",
       "4  INC2981597 2016-06-02 09:56:36     NaN   \n",
       "\n",
       "                                   Short Description  \\\n",
       "0  AST : PMX-PKG : Démarrage étape de production ...   \n",
       "1   PMX-PKG : Alarme type 2 non vue par l'équipement   \n",
       "2   PMX-PKG : ticket journalier MO3524 du 01/06/2016   \n",
       "3  PMX-PKG : ref_relation = WESSTOCKREMOVAL  (LC ...   \n",
       "4  PMX-PKG : ref_relation = WESSTOCKREMOVAL (LC =...   \n",
       "\n",
       "                                         Description    Resolution Code  \\\n",
       "0  Impossible de démarrer l'étape de production s...  People/System use   \n",
       "1  Une alarme s'est déclenchée sur le limos LPF-E...                NaN   \n",
       "2  01/06/2016 00:00:00 =>  01/06/2016 10:47:14\\n-...         Monitoring   \n",
       "3  Message envoyé le 01/06/2016 12:57:07\\n\\nid = ...                NaN   \n",
       "4  Message envoyé le 01/06/2016 12:59:07\\n\\nid = ...                NaN   \n",
       "\n",
       "                                       Resolve Notes  \\\n",
       "0  • [Résumé] Impossible de démarrer l'étape de p...   \n",
       "1  • [Résumé]\\n\\n• [Catégorie] \\n\\n• [Résolution]...   \n",
       "2  • [Catégorie] Monitoring des erreurs d'interfa...   \n",
       "3  • [Résumé] Message d'erreur reçu sur l'interfa...   \n",
       "4  • [Résumé] Message d'erreur reçu sur l'interfa...   \n",
       "\n",
       "                                              Résumé  \\\n",
       "0  Impossible de démarrer l'étape de production s...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3          Message d'erreur reçu sur l'interface WES   \n",
       "4          Message d'erreur reçu sur l'interface WES   \n",
       "\n",
       "                                          Résolution     Catégorie  \\\n",
       "0  Fermeture de la session concernée via la Conso...  HE/PKG/Limos   \n",
       "1                                                  0           NaN   \n",
       "2                                                NaN     Interface   \n",
       "3  Régulation effectuée par Stephane Seyller du b...        HE/WES   \n",
       "4  Régulation effectuée par Stephane Seyller du b...        HE/WES   \n",
       "\n",
       "      QAimpact                       Analyse  \n",
       "0  Sans impact  Hscope/Duplicate/Cslt/Action  \n",
       "1  Sans impact               Matrikon/Alarme  \n",
       "2  Sans impact      Dailyinterfacemonitoring  \n",
       "3  Sans impact               Lcmovementerror  \n",
       "4  Sans impact               Lcmovementerror  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl = pd.ExcelFile(path_to_rep + '\\data\\\\tickets_Lilly_05_03_2019_attributs_additionnels.xlsx' )\n",
    "df_total = xl.parse('Sheet1')\n",
    "\n",
    "df_Lilly = df_total.dropna(subset = ['Short Description', \n",
    "                                     'Description', \n",
    "                                     'Analyse'])\n",
    "\n",
    "print(df_Lilly.shape)\n",
    "df_Lilly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(liste1, liste2):\n",
    "    return [a.lower() + ' ' + b.lower() for a,b in zip(liste2, liste1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "titres = ['Short Description : ', 'Description : ', 'Resolve Notes : ']\n",
    "X = [' . '.join(fusion([str(el) for el in els], titres )) \\\n",
    "            for els in zip(df_Lilly['Short Description'].values.tolist(),\n",
    "                           df_Lilly['Description'].values.tolist(),\n",
    "                           df_Lilly['Resolve Notes'].values.tolist()\n",
    "                          )]\n",
    "X = [[[word.strip() for word in sentence.split()] + ['.'] for sentence in text.split('.')] for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formation du language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, init = 3):\n",
    "        self.name = name\n",
    "        if init == 0 :\n",
    "            self.word2index = {}\n",
    "            self.word2count = {}\n",
    "            self.index2word = {}\n",
    "            self.n_words = 0\n",
    "        elif init == 3 :\n",
    "            self.word2index = {\"SOS\": 0, \"EOS\": 1, \"UNK\": 2}\n",
    "            self.word2count = {\"SOS\": 0, \"EOS\": 0, \"UNK\": 0}\n",
    "            self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\"}\n",
    "            self.n_words = 3\n",
    "\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        '''Add a word to the language'''\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        '''Add to the language all words of a sentence'''\n",
    "        if type(sentence) == str :\n",
    "            for word in nltk.word_tokenize(sentence): # sentence.split()\n",
    "                self.addWord(word)\n",
    "        elif type(sentence) == list :\n",
    "            for word in sentence:\n",
    "                self.addWord(word)            \n",
    "            \n",
    "            \n",
    "    def addDescriptions(self, descriptions, lvl = 1):\n",
    "        '''Add to the language all words contained into : either all user utterances \n",
    "          (if i = 0) or all bot utterances (if i = 1), of a list of dialogues'''\n",
    "        for description in descriptions :\n",
    "            \n",
    "            # si la description est une seule ligne\n",
    "            if type(description) == str :\n",
    "                    try :\n",
    "                        if lvl == 2 :\n",
    "                            for sentence in nltk.sent_tokenize(description) :\n",
    "                                self.addSentence(sentence)\n",
    "                        else :\n",
    "                            self.addSentence(description)\n",
    "                    except IndexError:\n",
    "                        print(\"Problem with {}\".format(description))\n",
    "                        \n",
    "            # si la description est une liste de lignes\n",
    "            elif type(description) == list :\n",
    "                for line in description:\n",
    "                    try :\n",
    "                        self.addSentence(line)\n",
    "                    except IndexError:\n",
    "                        print(\"Problem with {}\".format(line))\n",
    "                              \n",
    "            # sinon\n",
    "            else :\n",
    "                print(\"Problem with {}\".format(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLanguageFromWordList(liste, init = 0):\n",
    "    lang = Lang('descriptions', init)\n",
    "    lang.addSentence(liste)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang\n",
    "\n",
    "\n",
    "def generateLanguageFromNumpy(descriptions, init = 0, lvl = 1):\n",
    "    lang = Lang('descriptions', init)\n",
    "    lang.addDescriptions(descriptions)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang\n",
    "\n",
    "\n",
    "def generateLanguageFromPanda(df, i):\n",
    "    descriptions = df.ix[:, i].values\n",
    "    lang = Lang('descriptions')\n",
    "    lang.addDescriptions(descriptions)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés :  6474\n"
     ]
    }
   ],
   "source": [
    "lang = generateLanguageFromNumpy(X, init = 3, lvl = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"embedding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Word Embedding\n",
    "\n",
    "[Retour à la table des matières](#plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.1 Modèle Skip-gram de Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gensim_skipgram = flatten(X) # ------ [[str]] : al list of list of tockens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_gensim = Word2Vec(data_gensim_skipgram, \n",
    "                           size = 100, \n",
    "                           window = 5, \n",
    "                           min_count = 1, \n",
    "                           negative = 20, \n",
    "                           iter = 500,\n",
    "                           sg = 1,\n",
    "                           workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir la table des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T est de type <class 'numpy.ndarray'> et de taille (6488, 100)\n"
     ]
    }
   ],
   "source": [
    "T = skipgram_gensim.wv.vectors\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.2 Modèle Skip-gram sur mesure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(description) :\n",
    "    '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "    flatten = []\n",
    "    for line in description :\n",
    "        flatten += line + ['.']\n",
    "    return flatten\n",
    "\n",
    "\n",
    "def generateNgrams(descriptions, context_size = 5) :\n",
    "    '''descriptions = [[str]]'''\n",
    "    data = []\n",
    "    for description in descriptions :\n",
    "        line = flatten(description)\n",
    "        line = ['SOS' for i in range(context_size)] + line + ['EOS' for i in range(context_size)] \n",
    "        for i in range(context_size, len(line) - context_size):\n",
    "            context = line[i-context_size : i] + line[i+1 : i+context_size+1]\n",
    "            target = [line[i]]\n",
    "            data.append((context, target))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, device, \n",
    "                 lang, \n",
    "                 context_size, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim):\n",
    "        \n",
    "        super(SkipGram, self).__init__()\n",
    "        self.device = device\n",
    "        self.lang = lang\n",
    "        self.output_lang = copy.copy(lang)\n",
    "        self.output_lang.addDescriptions(['SOS', 'UNK', 'EOS'])\n",
    "        self.context_size = 2 * context_size\n",
    "        self.embedding = nn.Embedding(lang.n_words, embedding_dim)\n",
    "        self.linear_1 = nn.Linear(embedding_dim, 2*context_size * hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, self.output_lang.n_words)\n",
    "        \n",
    "        \n",
    "    def variableFromSentence(self, sentence):\n",
    "        '''Turn a sentence into a torch variable, containing a list of indices according\n",
    "           to a given language.'''\n",
    "        indexes = [self.lang.word2index[word] for word in sentence if word in self.lang.word2index]          \n",
    "        result = Variable(torch.LongTensor(indexes).view(1, -1)).to(self.device)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def forward(self, word):\n",
    "        input = self.variableFromSentence(word)                   # size = (1, 1)\n",
    "        embed = self.embedding(input)#.view((1, -1))              # size = (1, embedding_dim)\n",
    "        out = self.linear_1(embed).view((self.context_size, -1))  # size = (2 * context_size , hidden_dim)\n",
    "        out = F.relu(out)                                         # size = (2 * context_size , hidden_dim)\n",
    "        out = self.linear_2(out)                                  # size = (2 * context_size , lang.n_words)\n",
    "        log_probs = F.log_softmax(out)                            # size = (2 * context_size , lang.n_words)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramTrainer(object):\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 criterion = nn.NLLLoss(reduce = False), #nn.BCEWithLogitsLoss(), #nn.BCELoss(), \n",
    "                 optimizer = optim.SGD,\n",
    "                 print_every=100):\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "    \n",
    "    \n",
    "    def timeSince(self, since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "        \n",
    "        \n",
    "    def trainLoop(self, agent, context, word, weights, optimizer, learning_rate):\n",
    "        \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        agent.zero_grad()\n",
    "        \n",
    "        log_probs = agent(word)\n",
    "        context_var = agent.variableFromSentence(context).view(-1)\n",
    "        loss = self.criterion(log_probs, context_var)\n",
    "        loss = torch.sum(weights * loss)\n",
    "        loss_diff = 0\n",
    "        for i in range(agent.context_size) :\n",
    "            topv, topi = log_probs[i].data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            loss_diff = loss_diff + 1 if ni != context_var[i].data[0] else loss_diff\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        return loss.data[0], loss_diff\n",
    "        \n",
    "        \n",
    "    def train(self,\n",
    "              agent, \n",
    "              ngrams, \n",
    "              weights,\n",
    "              n_iters = 100,\n",
    "              n_epochs = None,\n",
    "              learning_rate=0.01,\n",
    "              random_state = 42\n",
    "             ):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops.\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in agent.parameters() if param.requires_grad == True], lr=learning_rate)\n",
    "        weights = Variable(torch.FloatTensor(weights)).to(self.device)\n",
    "        print_loss_total = 0  \n",
    "        print_loss_diff_mots_total = 0\n",
    "        if n_epochs is None :\n",
    "            for iter in range(1, n_iters + 1):\n",
    "                couple = random.choice(ngrams)\n",
    "                context = couple[0] \n",
    "                target = couple[1] \n",
    "                loss, loss_diff_mots = self.trainLoop(agent, context, target, weights, optimizer, learning_rate)\n",
    "                # quantité d'erreurs sur la réponse i\n",
    "                print_loss_total += loss\n",
    "                print_loss_diff_mots_total += loss_diff_mots       \n",
    "                if iter % (self.print_every) == 0:\n",
    "                    print_loss_avg = print_loss_total / self.print_every\n",
    "                    print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                    print_loss_total = 0\n",
    "                    print_loss_diff_mots_total = 0\n",
    "                    print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                                 iter, iter / n_iters * 100, \n",
    "                                                      print_loss_avg, print_loss_diff_mots_avg))\n",
    "        else :\n",
    "            for epoch in range(n_epochs):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(ngrams)\n",
    "                for couple in ngrams :\n",
    "                    context = couple[0] \n",
    "                    target = couple[1] \n",
    "                    loss, loss_diff_mots = self.trainLoop(agent, context, target, weights, optimizer, learning_rate)\n",
    "\n",
    "                    # quantité d'erreurs sur la réponse i\n",
    "                    print_loss_total += loss\n",
    "                    print_loss_diff_mots_total += loss_diff_mots       \n",
    "\n",
    "                    if iter % (self.print_every) == 0:\n",
    "                        print_loss_avg = print_loss_total / self.print_every\n",
    "                        print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                        print_loss_total = 0\n",
    "                        print_loss_diff_mots_total = 0\n",
    "                        print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                                     iter, iter / n_iters * 100, \n",
    "                                                          print_loss_avg, print_loss_diff_mots_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightsList(n):\n",
    "    half = (n-1)/2\n",
    "    weights = [n**2 -(half-i)**2 for i in range(n)]\n",
    "    weights = [el/sum(weights) for el in weights]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = SkipGram(device, lang, context_size = 5, embedding_dim = 75, hidden_dim = 75)\n",
    "skipgram = skipgram.to(device)\n",
    "skipgram_trainer = SkipGramTrainer(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngrams = generateNgrams(X, context_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 8m 21s) (100 0%) 8.6615 9.31\n",
      "0m 2s (- 8m 14s) (200 0%) 8.3966 7.81\n",
      "0m 3s (- 8m 14s) (300 0%) 7.9387 7.37\n",
      "0m 4s (- 8m 11s) (400 1%) 7.6289 7.46\n",
      "0m 6s (- 8m 8s) (500 1%) 7.3045 7.53\n",
      "0m 7s (- 8m 5s) (600 1%) 7.2159 7.55\n",
      "0m 8s (- 8m 5s) (700 1%) 6.9773 7.34\n",
      "0m 9s (- 8m 4s) (800 2%) 7.3433 7.89\n",
      "0m 11s (- 8m 3s) (900 2%) 6.9874 7.49\n",
      "0m 12s (- 8m 0s) (1000 2%) 7.0193 7.57\n",
      "0m 13s (- 7m 59s) (1100 2%) 6.9350 7.46\n",
      "0m 14s (- 7m 58s) (1200 3%) 7.2537 7.85\n",
      "0m 16s (- 7m 56s) (1300 3%) 6.8125 7.40\n",
      "0m 17s (- 7m 55s) (1400 3%) 6.9897 7.67\n",
      "0m 18s (- 7m 54s) (1500 3%) 6.8655 7.45\n",
      "0m 19s (- 7m 54s) (1600 4%) 6.7800 7.33\n",
      "0m 21s (- 7m 53s) (1700 4%) 6.8878 7.56\n",
      "0m 22s (- 7m 51s) (1800 4%) 6.7829 7.45\n",
      "0m 23s (- 7m 51s) (1900 4%) 6.7094 7.43\n",
      "0m 24s (- 7m 49s) (2000 5%) 6.9370 7.81\n",
      "0m 25s (- 7m 48s) (2100 5%) 6.8034 7.65\n",
      "0m 27s (- 7m 46s) (2200 5%) 6.8269 7.61\n",
      "0m 28s (- 7m 45s) (2300 5%) 6.7266 7.65\n",
      "0m 29s (- 7m 44s) (2400 6%) 6.6305 7.67\n",
      "0m 30s (- 7m 44s) (2500 6%) 6.6411 7.53\n",
      "0m 32s (- 7m 44s) (2600 6%) 6.7969 7.77\n",
      "0m 33s (- 7m 43s) (2700 6%) 6.4996 7.40\n",
      "0m 34s (- 7m 43s) (2800 7%) 6.6406 7.72\n",
      "0m 36s (- 7m 42s) (2900 7%) 6.4595 7.54\n",
      "0m 37s (- 7m 41s) (3000 7%) 6.7789 8.05\n",
      "0m 38s (- 7m 39s) (3100 7%) 6.4581 7.45\n",
      "0m 39s (- 7m 38s) (3200 8%) 6.4712 7.42\n",
      "0m 41s (- 7m 36s) (3300 8%) 6.2887 7.31\n",
      "0m 42s (- 7m 36s) (3400 8%) 6.4758 7.65\n",
      "0m 43s (- 7m 35s) (3500 8%) 6.4377 7.71\n",
      "0m 44s (- 7m 34s) (3600 9%) 6.7320 7.91\n",
      "0m 46s (- 7m 33s) (3700 9%) 6.2127 7.36\n",
      "0m 47s (- 7m 32s) (3800 9%) 6.3204 7.80\n",
      "0m 48s (- 7m 31s) (3900 9%) 6.3081 7.82\n",
      "0m 49s (- 7m 29s) (4000 10%) 6.2571 7.57\n",
      "0m 51s (- 7m 28s) (4100 10%) 6.1123 7.61\n",
      "0m 52s (- 7m 27s) (4200 10%) 6.1270 7.80\n",
      "0m 53s (- 7m 26s) (4300 10%) 6.1603 7.53\n",
      "0m 55s (- 7m 25s) (4400 11%) 6.2320 7.56\n",
      "0m 56s (- 7m 24s) (4500 11%) 6.0913 7.46\n",
      "0m 57s (- 7m 23s) (4600 11%) 6.1502 7.46\n",
      "0m 58s (- 7m 21s) (4700 11%) 6.0450 7.68\n",
      "1m 0s (- 7m 20s) (4800 12%) 6.0461 7.50\n",
      "1m 1s (- 7m 19s) (4900 12%) 6.0230 7.55\n",
      "1m 2s (- 7m 18s) (5000 12%) 5.8940 7.48\n",
      "1m 3s (- 7m 17s) (5100 12%) 5.9454 7.45\n",
      "1m 5s (- 7m 16s) (5200 13%) 6.0896 7.65\n",
      "1m 6s (- 7m 15s) (5300 13%) 6.0536 8.03\n",
      "1m 7s (- 7m 13s) (5400 13%) 5.9529 7.63\n",
      "1m 8s (- 7m 12s) (5500 13%) 5.9795 7.79\n",
      "1m 10s (- 7m 11s) (5600 14%) 5.8034 7.27\n",
      "1m 11s (- 7m 10s) (5700 14%) 5.6314 7.29\n",
      "1m 12s (- 7m 8s) (5800 14%) 5.9909 7.70\n",
      "1m 14s (- 7m 7s) (5900 14%) 5.6876 7.49\n",
      "1m 15s (- 7m 6s) (6000 15%) 5.9289 7.71\n",
      "1m 16s (- 7m 5s) (6100 15%) 5.9352 7.61\n",
      "1m 17s (- 7m 4s) (6200 15%) 5.7304 7.55\n",
      "1m 19s (- 7m 3s) (6300 15%) 5.8627 7.51\n",
      "1m 20s (- 7m 2s) (6400 16%) 5.6568 7.25\n",
      "1m 21s (- 7m 1s) (6500 16%) 5.5978 7.44\n",
      "1m 22s (- 6m 59s) (6600 16%) 5.7787 7.54\n",
      "1m 24s (- 6m 58s) (6700 16%) 5.6524 7.46\n",
      "1m 25s (- 6m 57s) (6800 17%) 5.8222 7.52\n",
      "1m 26s (- 6m 56s) (6900 17%) 5.3473 7.41\n",
      "1m 28s (- 6m 55s) (7000 17%) 5.7781 7.54\n",
      "1m 29s (- 6m 54s) (7100 17%) 5.4405 7.23\n",
      "1m 30s (- 6m 52s) (7200 18%) 5.4687 7.32\n",
      "1m 31s (- 6m 51s) (7300 18%) 5.6587 7.35\n",
      "1m 33s (- 6m 50s) (7400 18%) 5.5639 7.32\n",
      "1m 34s (- 6m 48s) (7500 18%) 5.4366 7.44\n",
      "1m 35s (- 6m 47s) (7600 19%) 5.3753 7.21\n",
      "1m 37s (- 6m 47s) (7700 19%) 5.3746 7.12\n",
      "1m 38s (- 6m 45s) (7800 19%) 5.5866 7.44\n",
      "1m 39s (- 6m 44s) (7900 19%) 5.4486 7.33\n",
      "1m 40s (- 6m 43s) (8000 20%) 5.4179 7.28\n",
      "1m 42s (- 6m 42s) (8100 20%) 5.3389 7.36\n",
      "1m 43s (- 6m 41s) (8200 20%) 5.4015 7.48\n",
      "1m 44s (- 6m 39s) (8300 20%) 5.4010 7.12\n",
      "1m 45s (- 6m 38s) (8400 21%) 5.4561 7.29\n",
      "1m 47s (- 6m 36s) (8500 21%) 5.4579 7.38\n",
      "1m 48s (- 6m 35s) (8600 21%) 5.3677 7.26\n",
      "1m 49s (- 6m 34s) (8700 21%) 5.1098 6.98\n",
      "1m 50s (- 6m 33s) (8800 22%) 5.4772 7.52\n",
      "1m 52s (- 6m 31s) (8900 22%) 5.3877 7.46\n",
      "1m 53s (- 6m 30s) (9000 22%) 5.4684 7.50\n",
      "1m 54s (- 6m 29s) (9100 22%) 5.4269 7.38\n",
      "1m 55s (- 6m 27s) (9200 23%) 5.2360 7.30\n",
      "1m 57s (- 6m 26s) (9300 23%) 5.2803 7.30\n",
      "1m 58s (- 6m 25s) (9400 23%) 5.3237 7.29\n",
      "1m 59s (- 6m 23s) (9500 23%) 5.2267 7.15\n",
      "2m 0s (- 6m 22s) (9600 24%) 5.4281 7.60\n",
      "2m 2s (- 6m 21s) (9700 24%) 5.1467 7.23\n",
      "2m 3s (- 6m 19s) (9800 24%) 5.2421 7.14\n",
      "2m 4s (- 6m 18s) (9900 24%) 5.3248 7.35\n",
      "2m 5s (- 6m 17s) (10000 25%) 5.2930 7.41\n",
      "2m 6s (- 6m 15s) (10100 25%) 4.9638 6.98\n",
      "2m 8s (- 6m 14s) (10200 25%) 5.3523 7.34\n",
      "2m 9s (- 6m 13s) (10300 25%) 5.2235 7.28\n",
      "2m 10s (- 6m 11s) (10400 26%) 5.0621 7.18\n",
      "2m 12s (- 6m 10s) (10500 26%) 5.1619 7.39\n",
      "2m 13s (- 6m 9s) (10600 26%) 5.4741 7.68\n",
      "2m 14s (- 6m 8s) (10700 26%) 5.2377 7.31\n",
      "2m 15s (- 6m 7s) (10800 27%) 4.9845 7.07\n",
      "2m 17s (- 6m 5s) (10900 27%) 4.9064 7.06\n",
      "2m 18s (- 6m 4s) (11000 27%) 5.1082 7.19\n",
      "2m 19s (- 6m 3s) (11100 27%) 5.1458 7.21\n",
      "2m 20s (- 6m 1s) (11200 28%) 4.9755 6.87\n",
      "2m 21s (- 6m 0s) (11300 28%) 5.0334 6.94\n",
      "2m 23s (- 5m 59s) (11400 28%) 5.1123 7.07\n",
      "2m 24s (- 5m 58s) (11500 28%) 4.7213 6.85\n",
      "2m 25s (- 5m 57s) (11600 28%) 4.7854 6.92\n",
      "2m 27s (- 5m 55s) (11700 29%) 5.1332 7.17\n",
      "2m 28s (- 5m 54s) (11800 29%) 4.8181 6.99\n",
      "2m 29s (- 5m 53s) (11900 29%) 5.3340 7.43\n",
      "2m 30s (- 5m 52s) (12000 30%) 5.1068 6.96\n",
      "2m 32s (- 5m 50s) (12100 30%) 5.2971 7.27\n",
      "2m 33s (- 5m 49s) (12200 30%) 5.2583 7.24\n",
      "2m 34s (- 5m 48s) (12300 30%) 5.3455 7.23\n",
      "2m 35s (- 5m 47s) (12400 31%) 5.0182 7.08\n",
      "2m 37s (- 5m 45s) (12500 31%) 5.0647 7.23\n",
      "2m 38s (- 5m 44s) (12600 31%) 4.8601 6.97\n",
      "2m 39s (- 5m 43s) (12700 31%) 4.9414 7.25\n",
      "2m 40s (- 5m 41s) (12800 32%) 4.7077 6.80\n",
      "2m 42s (- 5m 40s) (12900 32%) 4.6766 6.68\n",
      "2m 43s (- 5m 39s) (13000 32%) 4.8761 6.86\n",
      "2m 44s (- 5m 37s) (13100 32%) 4.9557 6.85\n",
      "2m 45s (- 5m 36s) (13200 33%) 5.1301 7.32\n",
      "2m 46s (- 5m 35s) (13300 33%) 4.8423 6.88\n",
      "2m 48s (- 5m 33s) (13400 33%) 4.6477 6.97\n",
      "2m 49s (- 5m 32s) (13500 33%) 4.6952 6.95\n",
      "2m 50s (- 5m 31s) (13600 34%) 5.1718 7.10\n",
      "2m 51s (- 5m 29s) (13700 34%) 5.3300 7.38\n",
      "2m 53s (- 5m 28s) (13800 34%) 4.9257 7.02\n",
      "2m 54s (- 5m 27s) (13900 34%) 4.9727 7.07\n",
      "2m 55s (- 5m 26s) (14000 35%) 4.7509 6.77\n",
      "2m 56s (- 5m 24s) (14100 35%) 4.8065 6.89\n",
      "2m 57s (- 5m 23s) (14200 35%) 5.0161 7.09\n",
      "2m 59s (- 5m 22s) (14300 35%) 4.9967 7.06\n",
      "3m 0s (- 5m 20s) (14400 36%) 4.9203 7.05\n",
      "3m 1s (- 5m 19s) (14500 36%) 4.8846 6.92\n",
      "3m 2s (- 5m 18s) (14600 36%) 4.7685 6.83\n",
      "3m 4s (- 5m 16s) (14700 36%) 4.7403 6.70\n",
      "3m 5s (- 5m 15s) (14800 37%) 5.0226 7.01\n",
      "3m 6s (- 5m 14s) (14900 37%) 4.5484 6.65\n",
      "3m 7s (- 5m 12s) (15000 37%) 4.6288 6.85\n",
      "3m 8s (- 5m 11s) (15100 37%) 4.7514 6.96\n",
      "3m 10s (- 5m 10s) (15200 38%) 4.6314 6.60\n",
      "3m 11s (- 5m 9s) (15300 38%) 5.1724 7.22\n",
      "3m 12s (- 5m 7s) (15400 38%) 4.8281 6.80\n",
      "3m 13s (- 5m 6s) (15500 38%) 4.6910 6.78\n",
      "3m 15s (- 5m 5s) (15600 39%) 4.5898 6.95\n",
      "3m 16s (- 5m 3s) (15700 39%) 4.7492 6.99\n",
      "3m 17s (- 5m 2s) (15800 39%) 4.5130 6.69\n",
      "3m 18s (- 5m 1s) (15900 39%) 4.7340 6.88\n",
      "3m 20s (- 5m 0s) (16000 40%) 4.6538 6.97\n",
      "3m 21s (- 4m 58s) (16100 40%) 4.5473 6.60\n",
      "3m 22s (- 4m 57s) (16200 40%) 5.1426 7.19\n",
      "3m 23s (- 4m 56s) (16300 40%) 4.6600 6.96\n",
      "3m 25s (- 4m 55s) (16400 41%) 4.8737 6.96\n",
      "3m 26s (- 4m 54s) (16500 41%) 4.8335 7.14\n",
      "3m 27s (- 4m 53s) (16600 41%) 4.7090 6.87\n",
      "3m 29s (- 4m 51s) (16700 41%) 4.8957 6.90\n",
      "3m 30s (- 4m 50s) (16800 42%) 4.4751 6.66\n",
      "3m 31s (- 4m 49s) (16900 42%) 4.6948 7.21\n",
      "3m 32s (- 4m 48s) (17000 42%) 4.6068 6.80\n",
      "3m 34s (- 4m 46s) (17100 42%) 4.5375 6.97\n",
      "3m 35s (- 4m 45s) (17200 43%) 4.6702 6.85\n",
      "3m 36s (- 4m 44s) (17300 43%) 4.5682 6.88\n",
      "3m 37s (- 4m 42s) (17400 43%) 4.5205 6.89\n",
      "3m 39s (- 4m 41s) (17500 43%) 4.7004 6.78\n",
      "3m 40s (- 4m 40s) (17600 44%) 4.6068 6.93\n",
      "3m 41s (- 4m 39s) (17700 44%) 5.0208 7.04\n",
      "3m 42s (- 4m 37s) (17800 44%) 4.7240 7.00\n",
      "3m 44s (- 4m 36s) (17900 44%) 4.7389 6.97\n",
      "3m 45s (- 4m 35s) (18000 45%) 4.5729 6.68\n",
      "3m 46s (- 4m 34s) (18100 45%) 4.8204 6.98\n",
      "3m 47s (- 4m 33s) (18200 45%) 4.5097 6.82\n",
      "3m 49s (- 4m 31s) (18300 45%) 4.3035 6.53\n",
      "3m 50s (- 4m 30s) (18400 46%) 4.7357 6.81\n",
      "3m 51s (- 4m 29s) (18500 46%) 4.4850 6.80\n",
      "3m 53s (- 4m 28s) (18600 46%) 4.5312 6.76\n",
      "3m 54s (- 4m 26s) (18700 46%) 4.6273 6.70\n",
      "3m 55s (- 4m 25s) (18800 47%) 4.7272 6.84\n",
      "3m 56s (- 4m 24s) (18900 47%) 4.7503 7.03\n",
      "3m 58s (- 4m 23s) (19000 47%) 4.2807 6.65\n",
      "3m 59s (- 4m 22s) (19100 47%) 4.5920 6.85\n",
      "4m 0s (- 4m 20s) (19200 48%) 4.7035 6.82\n",
      "4m 2s (- 4m 19s) (19300 48%) 4.6812 6.97\n",
      "4m 3s (- 4m 18s) (19400 48%) 4.6291 6.69\n",
      "4m 4s (- 4m 17s) (19500 48%) 4.8805 6.98\n",
      "4m 6s (- 4m 16s) (19600 49%) 4.2814 6.50\n",
      "4m 7s (- 4m 14s) (19700 49%) 4.6863 6.87\n",
      "4m 8s (- 4m 13s) (19800 49%) 4.6272 7.00\n",
      "4m 9s (- 4m 12s) (19900 49%) 4.4543 6.70\n",
      "4m 10s (- 4m 10s) (20000 50%) 4.8064 7.12\n",
      "4m 12s (- 4m 9s) (20100 50%) 4.6447 6.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 13s (- 4m 8s) (20200 50%) 4.6532 6.74\n",
      "4m 14s (- 4m 7s) (20300 50%) 4.5873 6.68\n",
      "4m 15s (- 4m 5s) (20400 51%) 4.5567 6.74\n",
      "4m 17s (- 4m 4s) (20500 51%) 4.6774 6.89\n",
      "4m 18s (- 4m 3s) (20600 51%) 4.9188 7.06\n",
      "4m 19s (- 4m 2s) (20700 51%) 4.5559 6.77\n",
      "4m 20s (- 4m 0s) (20800 52%) 4.2201 6.46\n",
      "4m 22s (- 3m 59s) (20900 52%) 4.3170 6.56\n",
      "4m 23s (- 3m 58s) (21000 52%) 4.6413 6.99\n",
      "4m 24s (- 3m 56s) (21100 52%) 4.5372 6.83\n",
      "4m 25s (- 3m 55s) (21200 53%) 4.3307 6.49\n",
      "4m 27s (- 3m 54s) (21300 53%) 4.6840 6.79\n",
      "4m 28s (- 3m 53s) (21400 53%) 4.6583 6.91\n",
      "4m 29s (- 3m 51s) (21500 53%) 4.3774 6.50\n",
      "4m 30s (- 3m 50s) (21600 54%) 4.4222 6.63\n",
      "4m 31s (- 3m 49s) (21700 54%) 4.6390 6.85\n",
      "4m 33s (- 3m 48s) (21800 54%) 4.5037 6.67\n",
      "4m 34s (- 3m 46s) (21900 54%) 4.6484 6.85\n",
      "4m 35s (- 3m 45s) (22000 55%) 4.7608 7.11\n",
      "4m 36s (- 3m 44s) (22100 55%) 4.3271 6.68\n",
      "4m 38s (- 3m 43s) (22200 55%) 4.2208 6.14\n",
      "4m 39s (- 3m 41s) (22300 55%) 4.3677 6.53\n",
      "4m 40s (- 3m 40s) (22400 56%) 4.4364 6.70\n",
      "4m 41s (- 3m 39s) (22500 56%) 4.3389 6.66\n",
      "4m 43s (- 3m 38s) (22600 56%) 4.2643 6.40\n",
      "4m 44s (- 3m 36s) (22700 56%) 4.6718 6.77\n",
      "4m 45s (- 3m 35s) (22800 56%) 4.5573 6.95\n",
      "4m 46s (- 3m 34s) (22900 57%) 4.8544 7.03\n",
      "4m 48s (- 3m 33s) (23000 57%) 4.3664 6.62\n",
      "4m 49s (- 3m 31s) (23100 57%) 4.5247 6.87\n",
      "4m 50s (- 3m 30s) (23200 57%) 4.6444 6.76\n",
      "4m 51s (- 3m 29s) (23300 58%) 4.5618 6.94\n",
      "4m 53s (- 3m 28s) (23400 58%) 4.4939 6.75\n",
      "4m 54s (- 3m 26s) (23500 58%) 4.4788 6.67\n",
      "4m 55s (- 3m 25s) (23600 59%) 4.4773 6.74\n",
      "4m 57s (- 3m 24s) (23700 59%) 4.0622 6.33\n",
      "4m 58s (- 3m 23s) (23800 59%) 4.5983 6.98\n",
      "4m 59s (- 3m 21s) (23900 59%) 4.3066 6.49\n",
      "5m 1s (- 3m 20s) (24000 60%) 4.2329 6.50\n",
      "5m 2s (- 3m 19s) (24100 60%) 4.3951 6.62\n",
      "5m 3s (- 3m 18s) (24200 60%) 4.4839 6.56\n",
      "5m 5s (- 3m 17s) (24300 60%) 4.5320 6.90\n",
      "5m 6s (- 3m 15s) (24400 61%) 4.2525 6.51\n",
      "5m 7s (- 3m 14s) (24500 61%) 4.1467 6.29\n",
      "5m 8s (- 3m 13s) (24600 61%) 4.3831 6.55\n",
      "5m 10s (- 3m 12s) (24700 61%) 4.2864 6.37\n",
      "5m 11s (- 3m 10s) (24800 62%) 4.5371 6.74\n",
      "5m 12s (- 3m 9s) (24900 62%) 4.2982 6.49\n",
      "5m 14s (- 3m 8s) (25000 62%) 4.0665 6.38\n",
      "5m 15s (- 3m 7s) (25100 62%) 4.1604 6.27\n",
      "5m 16s (- 3m 5s) (25200 63%) 4.3044 6.73\n",
      "5m 17s (- 3m 4s) (25300 63%) 4.1787 6.36\n",
      "5m 19s (- 3m 3s) (25400 63%) 4.0593 6.43\n",
      "5m 20s (- 3m 2s) (25500 63%) 4.2617 6.56\n",
      "5m 21s (- 3m 0s) (25600 64%) 4.4368 6.72\n",
      "5m 22s (- 2m 59s) (25700 64%) 4.4442 6.65\n",
      "5m 24s (- 2m 58s) (25800 64%) 4.1990 6.34\n",
      "5m 25s (- 2m 57s) (25900 64%) 4.4259 6.61\n",
      "5m 26s (- 2m 55s) (26000 65%) 4.2331 6.52\n",
      "5m 27s (- 2m 54s) (26100 65%) 4.6255 6.98\n",
      "5m 29s (- 2m 53s) (26200 65%) 4.1342 6.42\n",
      "5m 30s (- 2m 52s) (26300 65%) 4.4609 6.67\n",
      "5m 31s (- 2m 50s) (26400 66%) 4.2900 6.58\n",
      "5m 32s (- 2m 49s) (26500 66%) 4.1857 6.52\n",
      "5m 34s (- 2m 48s) (26600 66%) 4.2039 6.43\n",
      "5m 35s (- 2m 47s) (26700 66%) 4.2168 6.51\n",
      "5m 36s (- 2m 45s) (26800 67%) 4.2556 6.24\n",
      "5m 37s (- 2m 44s) (26900 67%) 4.6089 6.88\n",
      "5m 39s (- 2m 43s) (27000 67%) 4.1298 6.15\n",
      "5m 40s (- 2m 41s) (27100 67%) 4.4494 6.55\n",
      "5m 41s (- 2m 40s) (27200 68%) 4.5697 6.58\n",
      "5m 42s (- 2m 39s) (27300 68%) 4.4742 6.51\n",
      "5m 44s (- 2m 38s) (27400 68%) 4.2806 6.45\n",
      "5m 45s (- 2m 36s) (27500 68%) 4.7221 6.85\n",
      "5m 46s (- 2m 35s) (27600 69%) 4.1584 6.58\n",
      "5m 47s (- 2m 34s) (27700 69%) 4.6061 6.93\n",
      "5m 49s (- 2m 33s) (27800 69%) 4.5746 7.03\n",
      "5m 50s (- 2m 31s) (27900 69%) 4.2203 6.25\n",
      "5m 51s (- 2m 30s) (28000 70%) 4.4881 6.66\n",
      "5m 52s (- 2m 29s) (28100 70%) 4.3475 6.80\n",
      "5m 54s (- 2m 28s) (28200 70%) 4.2761 6.52\n",
      "5m 55s (- 2m 26s) (28300 70%) 4.3251 6.62\n",
      "5m 56s (- 2m 25s) (28400 71%) 4.3100 6.56\n",
      "5m 57s (- 2m 24s) (28500 71%) 4.5457 6.80\n",
      "5m 59s (- 2m 23s) (28600 71%) 4.4359 6.51\n",
      "6m 0s (- 2m 21s) (28700 71%) 4.1099 6.45\n",
      "6m 1s (- 2m 20s) (28800 72%) 4.3431 6.72\n",
      "6m 2s (- 2m 19s) (28900 72%) 4.1208 6.38\n",
      "6m 4s (- 2m 18s) (29000 72%) 4.3721 6.55\n",
      "6m 5s (- 2m 16s) (29100 72%) 4.5035 6.81\n",
      "6m 6s (- 2m 15s) (29200 73%) 4.2416 6.52\n",
      "6m 7s (- 2m 14s) (29300 73%) 4.1407 6.20\n",
      "6m 9s (- 2m 13s) (29400 73%) 4.6266 6.88\n",
      "6m 10s (- 2m 11s) (29500 73%) 4.3134 6.46\n",
      "6m 11s (- 2m 10s) (29600 74%) 4.3262 6.37\n",
      "6m 12s (- 2m 9s) (29700 74%) 4.0470 6.14\n",
      "6m 14s (- 2m 8s) (29800 74%) 4.2983 6.25\n",
      "6m 15s (- 2m 6s) (29900 74%) 4.3766 6.88\n",
      "6m 16s (- 2m 5s) (30000 75%) 3.8438 6.14\n",
      "6m 17s (- 2m 4s) (30100 75%) 4.1475 6.45\n",
      "6m 19s (- 2m 2s) (30200 75%) 3.9964 6.38\n",
      "6m 20s (- 2m 1s) (30300 75%) 4.3674 6.52\n",
      "6m 21s (- 2m 0s) (30400 76%) 4.1256 6.27\n",
      "6m 22s (- 1m 59s) (30500 76%) 4.3484 6.60\n",
      "6m 24s (- 1m 57s) (30600 76%) 4.2855 6.46\n",
      "6m 25s (- 1m 56s) (30700 76%) 4.0798 6.28\n",
      "6m 26s (- 1m 55s) (30800 77%) 4.0512 6.19\n",
      "6m 27s (- 1m 54s) (30900 77%) 4.5616 6.93\n",
      "6m 29s (- 1m 52s) (31000 77%) 4.1151 6.21\n",
      "6m 30s (- 1m 51s) (31100 77%) 3.9579 6.42\n",
      "6m 31s (- 1m 50s) (31200 78%) 4.0843 6.38\n",
      "6m 32s (- 1m 49s) (31300 78%) 3.9186 6.25\n",
      "6m 33s (- 1m 47s) (31400 78%) 4.4506 6.51\n",
      "6m 35s (- 1m 46s) (31500 78%) 3.8950 6.30\n",
      "6m 36s (- 1m 45s) (31600 79%) 4.4801 6.57\n",
      "6m 37s (- 1m 44s) (31700 79%) 4.0745 6.29\n",
      "6m 38s (- 1m 42s) (31800 79%) 4.1540 6.34\n",
      "6m 40s (- 1m 41s) (31900 79%) 4.4328 6.54\n",
      "6m 41s (- 1m 40s) (32000 80%) 4.2692 6.62\n",
      "6m 42s (- 1m 39s) (32100 80%) 4.4915 6.59\n",
      "6m 43s (- 1m 37s) (32200 80%) 4.2676 6.88\n",
      "6m 44s (- 1m 36s) (32300 80%) 3.9861 6.25\n",
      "6m 46s (- 1m 35s) (32400 81%) 4.1451 6.24\n",
      "6m 47s (- 1m 34s) (32500 81%) 4.0784 6.20\n",
      "6m 48s (- 1m 32s) (32600 81%) 4.3523 6.64\n",
      "6m 49s (- 1m 31s) (32700 81%) 4.2260 6.51\n",
      "6m 51s (- 1m 30s) (32800 82%) 4.1524 6.49\n",
      "6m 52s (- 1m 28s) (32900 82%) 4.4271 6.60\n",
      "6m 53s (- 1m 27s) (33000 82%) 4.3793 6.29\n",
      "6m 54s (- 1m 26s) (33100 82%) 4.2101 6.48\n",
      "6m 55s (- 1m 25s) (33200 83%) 3.9859 6.28\n",
      "6m 57s (- 1m 23s) (33300 83%) 3.9911 6.27\n",
      "6m 58s (- 1m 22s) (33400 83%) 4.4280 6.50\n",
      "6m 59s (- 1m 21s) (33500 83%) 4.7104 6.86\n",
      "7m 0s (- 1m 20s) (33600 84%) 4.4293 6.34\n",
      "7m 2s (- 1m 18s) (33700 84%) 4.1958 6.32\n",
      "7m 3s (- 1m 17s) (33800 84%) 4.2401 6.61\n",
      "7m 4s (- 1m 16s) (33900 84%) 3.9486 6.15\n",
      "7m 5s (- 1m 15s) (34000 85%) 4.2100 6.23\n",
      "7m 7s (- 1m 13s) (34100 85%) 3.9183 6.21\n",
      "7m 8s (- 1m 12s) (34200 85%) 4.7845 7.00\n",
      "7m 9s (- 1m 11s) (34300 85%) 3.9436 6.15\n",
      "7m 10s (- 1m 10s) (34400 86%) 4.0240 6.17\n",
      "7m 11s (- 1m 8s) (34500 86%) 4.4394 6.69\n",
      "7m 13s (- 1m 7s) (34600 86%) 3.8413 6.36\n",
      "7m 14s (- 1m 6s) (34700 86%) 3.9813 6.37\n",
      "7m 15s (- 1m 5s) (34800 87%) 3.8133 6.17\n",
      "7m 16s (- 1m 3s) (34900 87%) 4.3022 6.65\n",
      "7m 18s (- 1m 2s) (35000 87%) 4.1764 6.45\n",
      "7m 19s (- 1m 1s) (35100 87%) 4.0796 6.38\n",
      "7m 20s (- 1m 0s) (35200 88%) 3.8825 6.12\n",
      "7m 21s (- 0m 58s) (35300 88%) 3.9314 6.34\n",
      "7m 23s (- 0m 57s) (35400 88%) 4.0677 6.28\n",
      "7m 24s (- 0m 56s) (35500 88%) 4.3054 6.42\n",
      "7m 25s (- 0m 55s) (35600 89%) 4.2190 6.66\n",
      "7m 26s (- 0m 53s) (35700 89%) 4.0831 6.61\n",
      "7m 28s (- 0m 52s) (35800 89%) 3.9551 6.17\n",
      "7m 29s (- 0m 51s) (35900 89%) 4.1056 6.59\n",
      "7m 30s (- 0m 50s) (36000 90%) 3.9213 6.25\n",
      "7m 32s (- 0m 48s) (36100 90%) 4.0232 6.17\n",
      "7m 33s (- 0m 47s) (36200 90%) 4.1694 6.40\n",
      "7m 34s (- 0m 46s) (36300 90%) 3.9631 6.32\n",
      "7m 35s (- 0m 45s) (36400 91%) 3.9264 6.32\n",
      "7m 36s (- 0m 43s) (36500 91%) 4.2825 6.56\n",
      "7m 38s (- 0m 42s) (36600 91%) 4.2654 6.56\n",
      "7m 39s (- 0m 41s) (36700 91%) 3.9529 6.44\n",
      "7m 40s (- 0m 40s) (36800 92%) 4.3374 6.74\n",
      "7m 41s (- 0m 38s) (36900 92%) 4.3523 6.61\n",
      "7m 43s (- 0m 37s) (37000 92%) 4.1978 6.53\n",
      "7m 44s (- 0m 36s) (37100 92%) 4.5809 6.74\n",
      "7m 45s (- 0m 35s) (37200 93%) 4.0607 6.57\n",
      "7m 46s (- 0m 33s) (37300 93%) 4.1622 6.42\n",
      "7m 48s (- 0m 32s) (37400 93%) 4.0756 6.38\n",
      "7m 49s (- 0m 31s) (37500 93%) 4.3793 6.75\n",
      "7m 50s (- 0m 30s) (37600 94%) 4.2124 6.25\n",
      "7m 51s (- 0m 28s) (37700 94%) 3.8324 6.13\n",
      "7m 52s (- 0m 27s) (37800 94%) 4.2614 6.41\n",
      "7m 54s (- 0m 26s) (37900 94%) 4.2611 6.73\n",
      "7m 55s (- 0m 25s) (38000 95%) 3.9651 6.21\n",
      "7m 56s (- 0m 23s) (38100 95%) 3.9939 6.45\n",
      "7m 57s (- 0m 22s) (38200 95%) 4.6553 7.05\n",
      "7m 58s (- 0m 21s) (38300 95%) 3.8918 6.10\n",
      "8m 0s (- 0m 20s) (38400 96%) 3.5280 5.94\n",
      "8m 1s (- 0m 18s) (38500 96%) 4.3399 6.45\n",
      "8m 2s (- 0m 17s) (38600 96%) 4.2899 6.50\n",
      "8m 3s (- 0m 16s) (38700 96%) 4.2993 6.48\n",
      "8m 4s (- 0m 14s) (38800 97%) 4.1558 6.46\n",
      "8m 6s (- 0m 13s) (38900 97%) 4.0600 6.32\n",
      "8m 7s (- 0m 12s) (39000 97%) 3.7686 5.96\n",
      "8m 8s (- 0m 11s) (39100 97%) 3.9890 6.20\n",
      "8m 9s (- 0m 9s) (39200 98%) 4.1660 6.30\n",
      "8m 11s (- 0m 8s) (39300 98%) 4.3302 6.47\n",
      "8m 12s (- 0m 7s) (39400 98%) 3.7819 5.88\n",
      "8m 13s (- 0m 6s) (39500 98%) 4.0634 6.48\n",
      "8m 14s (- 0m 4s) (39600 99%) 4.2792 6.23\n",
      "8m 16s (- 0m 3s) (39700 99%) 4.5700 6.67\n",
      "8m 17s (- 0m 2s) (39800 99%) 4.0768 6.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 18s (- 0m 1s) (39900 99%) 3.9669 6.40\n",
      "8m 19s (- 0m 0s) (40000 100%) 4.2651 6.35\n"
     ]
    }
   ],
   "source": [
    "skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 40000, learning_rate=0.01)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.005)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.0025)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauver\n",
    "#torch.save(skipgram.state_dict(), path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_skipgram.pth')\n",
    "\n",
    "# charger\n",
    "#skipgram.load_state_dict(torch.load(path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_skipgram.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir la table des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T est de type <class 'numpy.ndarray'> et de taille (6474, 75)\n"
     ]
    }
   ],
   "source": [
    "T = skipgram.embedding.weight.cpu().detach().numpy()\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'alignement mot-indice est donné par le dictionnaire lang.word2index du language chargé dans le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.3 Modèle Skip-gram de FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim = FT_gensim(size = 100, \n",
    "                           window = 5, \n",
    "                           min_count = 1, \n",
    "                           negative = 20,\n",
    "                           sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(description) :\n",
    "    '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "    flatten = []\n",
    "    for line in description :\n",
    "        flatten += line\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = [['SOS'] + flatten(text) + ['EOS'] for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.build_vocab(sentences = X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.train(sentences = X_flat, \n",
    "                      epochs = 500,\n",
    "                      total_examples=fastText_gensim.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastText_gensim.save('Lilly_pkg_modele_linguistique_fastText')\n",
    "#fastText_gensim = FT_gensim.load('Lilly_pkg_modele_linguistique_fastText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=6473, size=100, alpha=0.025)\n",
      "T est de type <class 'numpy.ndarray'> et de taille (6473, 100)\n"
     ]
    }
   ],
   "source": [
    "print(fastText_gensim)\n",
    "\n",
    "T = fastText_gensim.wv.vectors\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés :  6473\n"
     ]
    }
   ],
   "source": [
    "lang = generateLanguageFromWordList(list(fastText_gensim.wv.vocab.keys()), init = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_linguistique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modèle Linguistique\n",
    "\n",
    "Exemples d'implémentation en PyTorch :\n",
    "\n",
    "- https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n",
    "\n",
    "\n",
    "Différentes architectures sont décrites dans la litérature :\n",
    "\n",
    "- Regularizing and Optimizing LSTM Language Models - https://arxiv.org/pdf/1708.02182.pdf\n",
    "\n",
    "Un modèle linguistique est intérressant en soi, mais peut aussi servir pour le pré-entrainement de couches basses d'un modèle plus complexe :\n",
    "\n",
    "- Deep contextualized word representations - https://arxiv.org/pdf/1802.05365.pdf\n",
    "- Improving Language Understanding by Generative Pre-Training - https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\n",
    "- Language Models are Unsupervised Multitask Learners - https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Le modèle linguistique\n",
    "\n",
    "[Retour à la table des matières](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, device, \n",
    "                 lang,\n",
    "                 embedding_weights, \n",
    "                 hidden_dim,\n",
    "                 n_layers = 1, \n",
    "                 dropout = 0): \n",
    "        \n",
    "        super(LanguageModel, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.lang = lang\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_p = dropout\n",
    "        self.n_layers = n_layers               # number of stacked GRU layers\n",
    "        self.output_dim = hidden_dim           # dimension of outputed rep. of words and utterance\n",
    "        # parameters\n",
    "        self.embedding = nn.Embedding(embedding_weights[0], embedding_weights[1]) if type(embedding_weights) == tuple else \\\n",
    "                         nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights), freeze=True)\n",
    "        for p in self.embedding.parameters() :\n",
    "            embedding_dim = p.data.size(1)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          self.hidden_dim, \n",
    "                          n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), \n",
    "                          bidirectional = False)\n",
    "        self.out = nn.Linear(self.hidden_dim, lang.n_words)\n",
    "        #self.out.weight = self.embedding.weight\n",
    "        \n",
    "        \n",
    "    # ------------- technical methods ------------------    \n",
    "    def nbParametres(self) :\n",
    "        count = 0\n",
    "        for p in self.parameters():\n",
    "            if p.requires_grad == True :\n",
    "                count += p.data.nelement()\n",
    "        return count\n",
    "    \n",
    "\n",
    "    def variableFromSentence(self, sentence):\n",
    "        '''Turn a sentence into a torch variable, containing a list of indices according\n",
    "           to a given language.'''\n",
    "        indexes = [self.lang.word2index[word] for word in sentence if word in self.lang.word2index]          \n",
    "        result = Variable(torch.LongTensor(indexes).view(-1, 1)).to(self.device)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def initHidden(self): \n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_dim)).to(self.device)\n",
    "    \n",
    "    \n",
    "    # ------------- main methods ------------------\n",
    "    def generateWord(self, utterance, hidden = None):\n",
    "        embeddings = self.embedding(utterance)                          # dim = (input_length, 1, embedding_dim)\n",
    "        embeddings = self.dropout(embeddings)                           # dim = (input_length, 1, embedding_dim)\n",
    "        hidden = self.initHidden() if hidden is None else hidden\n",
    "        _, hidden = self.gru(embeddings, hidden)                        # dim = (input_length, 1, hidden_dim)\n",
    "        hidden = self.dropout(hidden)\n",
    "        log_probs = F.log_softmax(self.out(hidden[-1]))         # dim = (1, lang_size)\n",
    "        return log_probs, hidden  \n",
    "\n",
    "    \n",
    "    def forward(self, sentence = ['SOS'], hidden = None, limit = 10, retain = False):\n",
    "        result = sentence + ['\\033[94m']\n",
    "        count = 0\n",
    "        stop = False\n",
    "        utterance = self.variableFromSentence(sentence)\n",
    "        while not stop :\n",
    "            log_probs, hidden = self.generateWord(utterance, hidden)\n",
    "            topv, topi = log_probs[0].data.topk(1)\n",
    "            ni = topi.item()\n",
    "            utterance = Variable(torch.LongTensor([[ni]])).to(self.device)\n",
    "            result.append(self.lang.index2word[ni])\n",
    "            count += 1\n",
    "            if count == limit or (type(limit) == str and ni == self.lang.word2index[limit]) or count == 50 :\n",
    "                stop = True\n",
    "        if not retain :\n",
    "            print(' '.join(result + ['\\033[0m']))\n",
    "            return\n",
    "        else :\n",
    "            return result, hidden   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, device, \n",
    "                 lang,\n",
    "                 embedding_weights, \n",
    "                 hidden_dim,\n",
    "                 n_layers = 1, \n",
    "                 dropout = 0): \n",
    "        \n",
    "        super(LanguageModel, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.lang = lang\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_p = dropout\n",
    "        self.n_layers = n_layers               # number of stacked GRU layers\n",
    "        self.output_dim = hidden_dim           # dimension of outputed rep. of words and utterance\n",
    "        # parameters\n",
    "        self.embedding = nn.Embedding(embedding_weights[0], embedding_weights[1]) if type(embedding_weights) == tuple else \\\n",
    "                         nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights), freeze=True)\n",
    "        for p in self.embedding.parameters() :\n",
    "            embedding_dim = p.data.size(1)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          self.hidden_dim, \n",
    "                          n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), \n",
    "                          bidirectional = False)\n",
    "        self.out = nn.Linear(self.hidden_dim, lang.n_words)\n",
    "        #self.out.weight = self.embedding.weight\n",
    "        \n",
    "        \n",
    "    # ------------- technical methods ------------------    \n",
    "    def nbParametres(self) :\n",
    "        count = 0\n",
    "        for p in self.parameters():\n",
    "            if p.requires_grad == True :\n",
    "                count += p.data.nelement()\n",
    "        return count\n",
    "    \n",
    "\n",
    "    def variableFromSentence(self, sentence):\n",
    "        '''Turn a sentence into a torch variable, containing a list of indices according\n",
    "           to a given language.'''\n",
    "        indexes = [self.lang.word2index[word] for word in sentence if word in self.lang.word2index]          \n",
    "        result = Variable(torch.LongTensor(indexes).view(-1, 1)).to(self.device)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def initHidden(self): \n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_dim)).to(self.device)\n",
    "    \n",
    "    \n",
    "    # ------------- main methods ------------------\n",
    "    def generateWord(self, utterance, hidden = None):\n",
    "        embeddings = self.embedding(utterance)                          # dim = (input_length, 1, embedding_dim)\n",
    "        embeddings = self.dropout(embeddings)                           # dim = (input_length, 1, embedding_dim)\n",
    "        hidden = self.initHidden() if hidden is None else hidden\n",
    "        _, hidden = self.gru(embeddings, hidden)                        # dim = (input_length, 1, hidden_dim)\n",
    "        hidden = self.dropout(hidden)\n",
    "        log_probs = F.log_softmax(self.out(hidden[-1]))         # dim = (1, lang_size)\n",
    "        return log_probs, hidden  \n",
    "\n",
    "    \n",
    "    def forward(self, sentence = ['SOS'], hidden = None, limit = 10, retain = False, color_code = '\\033[40m'):\n",
    "        result = sentence + [color_code]\n",
    "        count = 0\n",
    "        stop = False\n",
    "        utterance = self.variableFromSentence(sentence)\n",
    "        while not stop :\n",
    "            log_probs, hidden = self.generateWord(utterance, hidden)\n",
    "            topv, topi = log_probs[0].data.topk(1)\n",
    "            ni = topi.item()\n",
    "            utterance = Variable(torch.LongTensor([[ni]])).to(self.device)\n",
    "            result.append(self.lang.index2word[ni])\n",
    "            count += 1\n",
    "            if count == limit or (type(limit) == str and ni == self.lang.word2index[limit]) or count == 50 :\n",
    "                stop = True\n",
    "        if not retain :\n",
    "            print(' '.join(result + ['\\033[0m']))\n",
    "            return\n",
    "        else :\n",
    "            return result, hidden   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelTrainer(object):\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 criterion = nn.NLLLoss(reduce = False), #nn.BCEWithLogitsLoss(), #nn.BCELoss(), \n",
    "                 optimizer = optim.SGD,\n",
    "                 print_every=100):\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "    \n",
    "    \n",
    "    def timeSince(self, since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "        \n",
    "        \n",
    "    def trainLoop(self, agent, sentence, word, optimizer, learning_rate):\n",
    "        \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        agent.zero_grad()\n",
    "        word_var     = agent.variableFromSentence([word]).view(-1)\n",
    "        sentence_var = agent.variableFromSentence(sentence)\n",
    "        log_probs, _ = agent.generateWord(sentence_var)\n",
    "        \n",
    "        loss = self.criterion(log_probs, word_var)\n",
    "        topv, topi = log_probs[0].data.topk(1)\n",
    "        loss_diff = 1 if topi.item() != word_var.data.item() else 0\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        return loss.data[0], loss_diff\n",
    "        \n",
    "        \n",
    "    def train(self,\n",
    "              agent, \n",
    "              sentences,\n",
    "              n_iters = 100,\n",
    "              learning_rate=0.01,\n",
    "              random_state = 42\n",
    "             ):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops.\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in agent.parameters() if param.requires_grad == True], lr=learning_rate)\n",
    "        print_loss_total = 0  \n",
    "        print_loss_diff_mots_total = 0\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            sentence = random.choice(sentences) #--- [str]\n",
    "            i = random.choice(range(len(sentence)))\n",
    "            context = ['SOS'] + sentence[:i] \n",
    "            target = sentence[i]\n",
    "\n",
    "            loss, loss_diff_mots = self.trainLoop(agent, context, target, optimizer, learning_rate)\n",
    "            \n",
    "            # affichage\n",
    "            print_loss_total += loss\n",
    "            print_loss_diff_mots_total += loss_diff_mots       \n",
    "            if iter % (self.print_every) == 0:\n",
    "                print_loss_avg = print_loss_total / self.print_every\n",
    "                print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                print_loss_total = 0\n",
    "                print_loss_diff_mots_total = 0\n",
    "                print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, \n",
    "                                                  print_loss_avg, print_loss_diff_mots_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(description) :\n",
    "    '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "    flatten = []\n",
    "    for line in description :\n",
    "        flatten += line\n",
    "    return flatten\n",
    "    \n",
    "\n",
    "language_model_data = [flatten(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés :  6473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1362623"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skipgram custom\n",
    "#T = skipgram.embedding.weight.cpu().detach().numpy()\n",
    "#lang = generateLanguageFromNumpy(X, init = 3, lvl = 2)\n",
    "\n",
    "# fastText gensim\n",
    "T = fastText_gensim.wv.vectors\n",
    "lang = generateLanguageFromWordList(list(fastText_gensim.wv.vocab.keys()), init = 0)\n",
    "\n",
    "\n",
    "language_model = LanguageModel(device = device,\n",
    "                               lang = lang,\n",
    "                               hidden_dim = 150, #100\n",
    "                               embedding_weights = T,\n",
    "                               n_layers = 3, #2\n",
    "                               dropout = 0.15)\n",
    "language_model = language_model.to(device)\n",
    "language_model.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (embedding): Embedding(6473, 100)\n",
       "  (dropout): Dropout(p=0.15)\n",
       "  (gru): GRU(100, 100, num_layers=2, dropout=0.15)\n",
       "  (out): Linear(in_features=100, out_features=6473, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang.addDescriptions(X)\n",
    "\n",
    "freqs = list(lang.word2count.values())\n",
    "freqs = [1/np.log(el+1) for el in freqs]\n",
    "freqs = torch.tensor(freqs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0903, device='cuda:0') tensor(1.4427, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(min(freqs), max(freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model_trainer = LanguageModelTrainer(device = device, \n",
    "                                              criterion = nn.NLLLoss(weight = freqs), \n",
    "                                              print_every = 500\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.load_state_dict(torch.load(path_to_rep + '\\saves\\\\demonstrateur_modele_linguistique.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 12s (- 17m 3s) (500 1%) 2.5293 0.42\n",
      "0m 25s (- 16m 29s) (1000 2%) 2.5450 0.41\n",
      "0m 37s (- 16m 7s) (1500 3%) 2.5891 0.41\n",
      "0m 50s (- 16m 0s) (2000 5%) 2.2461 0.37\n",
      "1m 2s (- 15m 42s) (2500 6%) 2.5721 0.42\n",
      "1m 15s (- 15m 25s) (3000 7%) 2.7686 0.46\n",
      "1m 26s (- 15m 0s) (3500 8%) 2.6629 0.43\n",
      "1m 38s (- 14m 43s) (4000 10%) 2.6649 0.41\n",
      "1m 49s (- 14m 27s) (4500 11%) 2.6879 0.43\n",
      "2m 1s (- 14m 12s) (5000 12%) 2.8130 0.42\n",
      "2m 14s (- 14m 2s) (5500 13%) 2.6266 0.43\n",
      "2m 26s (- 13m 50s) (6000 15%) 2.2948 0.39\n",
      "2m 39s (- 13m 43s) (6500 16%) 2.6697 0.42\n",
      "2m 52s (- 13m 35s) (7000 17%) 2.5634 0.39\n",
      "3m 6s (- 13m 29s) (7500 18%) 2.3739 0.40\n",
      "3m 18s (- 13m 13s) (8000 20%) 2.8764 0.46\n",
      "3m 30s (- 12m 59s) (8500 21%) 2.4915 0.41\n",
      "3m 42s (- 12m 46s) (9000 22%) 2.4700 0.43\n",
      "3m 56s (- 12m 37s) (9500 23%) 2.4957 0.43\n",
      "4m 8s (- 12m 26s) (10000 25%) 2.6503 0.42\n",
      "4m 22s (- 12m 16s) (10500 26%) 2.5782 0.43\n",
      "4m 34s (- 12m 2s) (11000 27%) 2.4855 0.43\n",
      "4m 46s (- 11m 49s) (11500 28%) 2.6465 0.41\n",
      "4m 58s (- 11m 35s) (12000 30%) 2.5825 0.41\n",
      "5m 9s (- 11m 21s) (12500 31%) 2.6206 0.43\n",
      "5m 22s (- 11m 8s) (13000 32%) 2.6764 0.42\n",
      "5m 33s (- 10m 55s) (13500 33%) 2.5765 0.41\n",
      "5m 46s (- 10m 43s) (14000 35%) 2.5258 0.42\n",
      "5m 58s (- 10m 30s) (14500 36%) 2.6304 0.41\n",
      "6m 10s (- 10m 18s) (15000 37%) 2.7029 0.45\n",
      "6m 23s (- 10m 6s) (15500 38%) 2.5571 0.39\n",
      "6m 36s (- 9m 54s) (16000 40%) 2.8143 0.43\n",
      "6m 49s (- 9m 43s) (16500 41%) 2.5347 0.40\n",
      "7m 2s (- 9m 31s) (17000 42%) 2.5648 0.43\n",
      "7m 14s (- 9m 18s) (17500 43%) 2.6611 0.44\n",
      "7m 27s (- 9m 7s) (18000 45%) 2.7706 0.44\n",
      "7m 41s (- 8m 56s) (18500 46%) 2.5651 0.41\n",
      "7m 53s (- 8m 43s) (19000 47%) 2.6502 0.43\n",
      "8m 6s (- 8m 31s) (19500 48%) 2.4278 0.39\n",
      "8m 18s (- 8m 18s) (20000 50%) 2.6693 0.41\n",
      "8m 30s (- 8m 5s) (20500 51%) 2.7813 0.42\n",
      "8m 43s (- 7m 53s) (21000 52%) 2.7048 0.41\n",
      "8m 56s (- 7m 41s) (21500 53%) 2.4039 0.37\n",
      "9m 9s (- 7m 29s) (22000 55%) 2.3118 0.38\n",
      "9m 22s (- 7m 17s) (22500 56%) 2.5578 0.43\n",
      "9m 34s (- 7m 4s) (23000 57%) 2.3876 0.38\n",
      "9m 47s (- 6m 52s) (23500 58%) 2.5758 0.43\n",
      "10m 0s (- 6m 40s) (24000 60%) 2.6016 0.42\n",
      "10m 13s (- 6m 27s) (24500 61%) 2.4907 0.38\n",
      "10m 28s (- 6m 16s) (25000 62%) 2.8761 0.45\n",
      "10m 45s (- 6m 6s) (25500 63%) 2.7047 0.42\n",
      "11m 1s (- 5m 56s) (26000 65%) 2.8536 0.43\n",
      "11m 16s (- 5m 44s) (26500 66%) 2.5154 0.41\n",
      "11m 33s (- 5m 34s) (27000 67%) 2.7512 0.41\n",
      "11m 50s (- 5m 23s) (27500 68%) 2.4986 0.41\n",
      "12m 7s (- 5m 11s) (28000 70%) 2.4518 0.40\n",
      "12m 23s (- 5m 0s) (28500 71%) 2.4116 0.41\n",
      "12m 38s (- 4m 47s) (29000 72%) 2.2426 0.38\n",
      "12m 54s (- 4m 35s) (29500 73%) 2.5148 0.41\n",
      "13m 11s (- 4m 23s) (30000 75%) 2.5879 0.41\n",
      "13m 27s (- 4m 11s) (30500 76%) 2.6018 0.41\n",
      "13m 45s (- 3m 59s) (31000 77%) 2.6989 0.44\n",
      "14m 1s (- 3m 47s) (31500 78%) 2.4921 0.41\n",
      "14m 14s (- 3m 33s) (32000 80%) 2.7091 0.41\n",
      "14m 26s (- 3m 20s) (32500 81%) 2.5361 0.41\n",
      "14m 38s (- 3m 6s) (33000 82%) 2.7139 0.43\n",
      "14m 51s (- 2m 52s) (33500 83%) 2.7610 0.47\n",
      "15m 4s (- 2m 39s) (34000 85%) 2.6309 0.41\n",
      "15m 17s (- 2m 26s) (34500 86%) 2.5546 0.39\n",
      "15m 30s (- 2m 12s) (35000 87%) 2.6296 0.40\n",
      "15m 44s (- 1m 59s) (35500 88%) 2.6605 0.43\n",
      "15m 59s (- 1m 46s) (36000 90%) 2.6289 0.44\n",
      "16m 16s (- 1m 33s) (36500 91%) 2.4844 0.41\n",
      "16m 32s (- 1m 20s) (37000 92%) 2.5833 0.42\n",
      "16m 47s (- 1m 7s) (37500 93%) 2.7756 0.44\n",
      "17m 4s (- 0m 53s) (38000 95%) 2.5801 0.43\n",
      "17m 21s (- 0m 40s) (38500 96%) 2.6305 0.44\n",
      "17m 36s (- 0m 27s) (39000 97%) 2.4420 0.40\n",
      "17m 53s (- 0m 13s) (39500 98%) 2.6276 0.40\n",
      "18m 10s (- 0m 0s) (40000 100%) 2.5956 0.41\n"
     ]
    }
   ],
   "source": [
    "language_model.train()\n",
    "#language_model_trainer.train(language_model, language_model_data, n_iters = 40000, learning_rate=0.01)\n",
    "#language_model_trainer.train(language_model, language_model_data, n_iters = 40000, learning_rate=0.005)\n",
    "#language_model_trainer.train(language_model, language_model_data, n_iters = 40000, learning_rate=0.002)\n",
    "language_model_trainer.train(language_model, language_model_data, n_iters = 40000, learning_rate=0.001)\n",
    "#language_model_trainer.train(language_model, language_model_data, n_iters = 30000, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(language_model.state_dict(), path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short description : ast pmx pkg relance afficheur apollo yfspv ord . description : appel signaler afficheur yfspv ord affiche lot cours . relancer preparer visite zone executif demain matin . resolve notes : resume afficheur yfspv ord affiche lot cours . relancer preparer visite zone executif demain matin . \u001b[48;2;255;229;217m consequence factuelle impossible utiliser production . resolution . verification session limos . cbok . qualityassessment absence impact sispq valider . qaimpact impact qualite selon mail mar . resolution . ticket . qualityassessment absence impact sispq valider . qaimpact impact qualite selon mail mar . resolution . ticket . qualityassessment absence \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# fastText gensim, n_layers = 3, dh = 150\n",
    "language_model.eval()\n",
    "sentence = random.choice(language_model_data)\n",
    "i = random.choice(range(len(sentence)))\n",
    "sentence = sentence[:i] if i > 0 else ['SOS']\n",
    "language_model(sentence, limit = 'EOS', color_code = '\\x1b[48;2;255;229;217m' ) #  '\\x1b[48;2;255;229;217m' '\\x1b[31m'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
