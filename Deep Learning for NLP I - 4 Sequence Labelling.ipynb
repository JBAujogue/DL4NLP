{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part I - 4 <br><br><br>\n",
    "  Sequence Labelling\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. <font color=red>**Sequence Labelling**</font>\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "5. Auto-Encoding\n",
    "\n",
    "6. Machine Translation\n",
    "\n",
    "7. Text Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "We consider as Sequence labelling task a **Sentence Denoising** problem, which consists in transforming a noisy sequence of words into a correctly formed sentence.<br> Training follows a denoising objective known as _Cloze task_, which is used :\n",
    "\n",
    "- For the BERT model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.3.1\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\libDL4NLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus est donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence): # -------------------------  str\n",
    "    sw = ['']\n",
    "    #sw += nltk.corpus.stopwords.words('english')\n",
    "    #sw += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join( c for c in unicodedata.normalize('NFD', s)\n",
    "                        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    def normalizeString(s):\n",
    "        '''Remove rare symbols from a string'''\n",
    "        s = unicodeToAscii(s.lower().strip()) # \n",
    "        #s = re.sub(r\"[^a-zA-Z\\.\\(\\)\\[\\]]+\", r\" \", s)  # 'r' before a string is for 'raw' # ?&\\%\\_\\- removed # set('''.,:;()*#&-_%!?/\\'\")''')\n",
    "        return s\n",
    "\n",
    "    def wordTokenizerFunction():\n",
    "        # base version\n",
    "        function = lambda sentence : sentence.strip().split()\n",
    "\n",
    "        # nltk version\n",
    "        #function = word_tokenize    \n",
    "        return function\n",
    "\n",
    "    # 1 - caractères spéciaux\n",
    "    def clean_sentence_punct(text): # --------------  str\n",
    "        text = normalizeString(text)\n",
    "        # suppression de la dernière ponctuation\n",
    "        if (len(text) > 0 and text[-1] in ['.', ',', ';', ':', '!', '?']) : text = text[:-1]\n",
    "\n",
    "        text = text.replace(r'(', r' ( ')\n",
    "        text = text.replace(r')', r' ) ')\n",
    "        text = text.replace(r'[', r' [ ')\n",
    "        text = text.replace(r']', r' ] ')\n",
    "        text = text.replace(r'<', r' < ')\n",
    "        text = text.replace(r'>', r' > ')\n",
    "\n",
    "        text = text.replace(r':', r' : ')\n",
    "        text = text.replace(r';', r' ; ')\n",
    "        for i in range(5) :\n",
    "            text = re.sub('(?P<val1>[0-9])\\.(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "            text = re.sub('(?P<val1>[0-9]),(?P<val2>[0-9])', '\\g<val1>__-__\\g<val2>', text)\n",
    "        text = text.replace(r',', ' , ')\n",
    "        text = text.replace(r'.', ' . ')\n",
    "        for i in range(5) : text = re.sub('(?P<val1>[p0-9])__-__(?P<val2>[p0-9])', '\\g<val1>.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. p \\. (?P<val2>[0-9])', '\\g<val1>.p.\\g<val2>', text)\n",
    "        text = re.sub('(?P<val1>[0-9]) \\. s \\. (?P<val2>[0-9])', '\\g<val1>.s.\\g<val2>', text)\n",
    "\n",
    "        text = text.replace(r'\"', r' \" ')\n",
    "        text = text.replace(r'’', r\" ' \")\n",
    "        text = text.replace(r'”', r' \" ')\n",
    "        text = text.replace(r'“', r' \" ')\n",
    "        text = text.replace(r'/', r' / ')\n",
    "\n",
    "        text = re.sub('(…)+', ' … ', text)\n",
    "        text = text.replace('≤', ' ≤ ')          \n",
    "        text = text.replace('≥', ' ≥ ')\n",
    "        text = text.replace('°c', ' °c ')\n",
    "        text = text.replace('°C', ' °c ')\n",
    "        text = text.replace('ºc', ' °c ')\n",
    "        text = text.replace('n°', 'n° ')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('*', ' * ')\n",
    "        text = text.replace('+', ' + ')\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('_', ' ')\n",
    "        text = text.replace('®', ' ')\n",
    "        text = text.replace('™', ' ')\n",
    "        text = text.replace('±', ' ± ')\n",
    "        text = text.replace('÷', ' ÷ ')\n",
    "        text = text.replace('–', ' - ')\n",
    "        text = text.replace('μg', ' µg')\n",
    "        text = text.replace('µg', ' µg')\n",
    "        text = text.replace('µl', ' µl')\n",
    "        text = text.replace('μl', ' µl')\n",
    "        text = text.replace('µm', ' µm')\n",
    "        text = text.replace('μm', ' µm')\n",
    "        text = text.replace('ppm', ' ppm')\n",
    "        text = re.sub('(?P<val1>[0-9])mm', '\\g<val1> mm', text)\n",
    "        text = re.sub('(?P<val1>[0-9])g', '\\g<val1> g', text)\n",
    "        text = text.replace('nm', ' nm')\n",
    "\n",
    "        text = re.sub('fa(?P<val1>[0-9])', 'fa \\g<val1>', text)\n",
    "        text = re.sub('g(?P<val1>[0-9])', 'g \\g<val1>', text)\n",
    "        text = re.sub('n(?P<val1>[0-9])', 'n \\g<val1>', text)\n",
    "        text = re.sub('p(?P<val1>[0-9])', 'p \\g<val1>', text)\n",
    "        text = re.sub('q_(?P<val1>[0-9])', 'q_ \\g<val1>', text)\n",
    "        text = re.sub('u(?P<val1>[0-9])', 'u \\g<val1>', text)\n",
    "        text = re.sub('ud(?P<val1>[0-9])', 'ud \\g<val1>', text)\n",
    "        text = re.sub('ui(?P<val1>[0-9])', 'ui \\g<val1>', text)\n",
    "\n",
    "        text = text.replace('=', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace(r' , ', ' ')\n",
    "        text = text.replace(r' . ', ' ')\n",
    "\n",
    "        text = re.sub('(?P<val>[0-9])ml', '\\g<val> ml', text)\n",
    "        text = re.sub('(?P<val>[0-9])mg', '\\g<val> mg', text)\n",
    "\n",
    "        for i in range(5) : text = re.sub('( [0-9]+ )', ' ', text)\n",
    "        #text = re.sub('cochran(\\S)*', 'cochran ', text)\n",
    "        return text\n",
    "\n",
    "    # 3 - split des mots\n",
    "    def wordSplit(sentence, tokenizeur): # ------------- [str]\n",
    "        return tokenizeur(sentence)\n",
    "\n",
    "    # 4 - mise en minuscule et enlèvement des stopwords\n",
    "    def stopwordsRemoval(sentence, sw): # ------------- [[str]]\n",
    "        return [word for word in sentence if word not in sw]\n",
    "\n",
    "    # 6 - correction des mots\n",
    "    def correction(text):\n",
    "        def correct(word):\n",
    "            return spelling.suggest(word)[0]\n",
    "        list_of_list_of_words = [[correct(word) for word in sentence] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "    # 7 - stemming\n",
    "    def stemming(text): # ------------------------- [[str]]\n",
    "        list_of_list_of_words = [[PorterStemmer().stem(word) for word in sentence if word not in sw] for sentence in text]\n",
    "        return list_of_list_of_words\n",
    "\n",
    "\n",
    "    tokenizeur = wordTokenizerFunction()\n",
    "    sentence = clean_sentence_punct(str(sentence))\n",
    "    sentence = wordSplit(sentence, tokenizeur)\n",
    "    sentence = stopwordsRemoval(sentence, sw)\n",
    "    #text = correction(text)\n",
    "    #text = stemming(text)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def importWords(file_name) :\n",
    "    def cleanDatabase(db):\n",
    "        words = ['.']\n",
    "        title = ''\n",
    "        for pair in db :\n",
    "            #print(pair)\n",
    "            current_tile = pair[0].split(' | ')[-1]\n",
    "            if current_tile != title :\n",
    "                words += cleanSentence(current_tile) + ['.']\n",
    "                title  = current_tile\n",
    "            words += cleanSentence(str(pair[1]).split(' | ')[-1]) + ['.']\n",
    "        return words\n",
    "\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    db = [el[:2] for el in db if el[-1] in [0,1, 10]]\n",
    "    words = cleanDatabase(db)\n",
    "    return words\n",
    "\n",
    "\n",
    "def importAllWords(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus.append(importWords(file_name))\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "def importSentences(file_name) :\n",
    "    def cleanDatabase(db):\n",
    "        sentences = []\n",
    "        title = ''\n",
    "        for pair in db :\n",
    "            current_tile = pair[0].split(' | ')[-1]\n",
    "            if current_tile != title :\n",
    "                sentences.append(cleanSentence(current_tile))\n",
    "                title = current_tile\n",
    "            sentences.append(cleanSentence(str(pair[1]).split(' | ')[-1]))\n",
    "        return sentences\n",
    "\n",
    "    df = pd.read_excel(file_name, sep = ',', header = None)\n",
    "    headers = [i for i, titre in enumerate(df.ix[0,:].values) if i in [1, 2] or titre == 'score manuel'] \n",
    "    db = df.ix[1:, headers].values.tolist()\n",
    "    db = [el[:2] for el in db if el[-1] in [0,1, 10]]\n",
    "    sentences = cleanDatabase(db)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def importAllSentences(path_to_data) :\n",
    "    corpus = []\n",
    "    reps = os.listdir(path_to_data)\n",
    "    for rep in reps :\n",
    "        files = os.listdir(path_to_data + '\\\\' + rep)\n",
    "        for file in files :\n",
    "            file_name = path_to_data + '\\\\' + rep + '\\\\' + file\n",
    "            corpus += importSentences(file_name)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = importAllWords(path_to_NLP + '\\\\data\\\\AMM')\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31574"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = importAllSentences(path_to_NLP + '\\\\data\\\\AMM')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec = FastText(size = 75, \n",
    "                             window = 5, \n",
    "                             min_count = 1, \n",
    "                             negative = 20,\n",
    "                             sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8086"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fastText_word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_word2vec.train(sentences = corpus, \n",
    "                        epochs = 50,\n",
    "                        total_examples = fastText_word2vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2VecConnector(fastText_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sentence denoising Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDenoiser(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec, \n",
    "                 hidden_dim = 100, \n",
    "                 n_layers = 1, \n",
    "                 dropout = 0, \n",
    "                 class_weights = None, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(SentenceDenoiser, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2vec  = word2vec\n",
    "        self.context   = RecurrentEncoder(self.word2vec.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.out       = nn.Linear(self.context.output_dim, self.word2vec.lang.n_words)\n",
    "        self.act       = F.softmax\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index = self.word2vec.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, \n",
    "                                    ignore_index = self.ignore_index, \n",
    "                                    weight = class_weights)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def forward(self, sentence = '.', hidden = None, limit = 10, color_code = '\\033[94m'):\n",
    "        words  = self.tokenizer(sentence)\n",
    "        result = words + [color_code]\n",
    "        hidden, count, stop = None, 0, False\n",
    "        while not stop :\n",
    "            # compute probs\n",
    "            embeddings = self.word2vec(words, self.device)\n",
    "            _, hidden  = self.context(embeddings, lengths = None, hidden = hidden)\n",
    "            if self.context.bidirectional :\n",
    "                hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "            probs  = self.act(self.out(hidden[-1]), dim = 1).view(-1)\n",
    "            # get predicted word\n",
    "            topv, topi = probs.data.topk(1)\n",
    "            words = [self.word2vec.lang.index2word[topi.item()]]\n",
    "            result += words\n",
    "            # stopping criterion\n",
    "            count += 1\n",
    "            if count == limit or words == [limit] or count == 50 : stop = True\n",
    "        print(' '.join(result + ['\\033[0m']))\n",
    "        return\n",
    "    \n",
    "    def generatePackedSentences(self, \n",
    "                                sentences, \n",
    "                                batch_size = 32, \n",
    "                                mask_ratio = 0.15,\n",
    "                                predict_masked_only = True,\n",
    "                                seed = 42) :\n",
    "        def maskInput(index, b) :\n",
    "            if   b and random.random() > 0.25 : return self.ignore_index\n",
    "            elif b and random.random() > 0.10 : return random.choice(list(self.word2vec.twin.lang.word2index.values()))\n",
    "            else                              : return index\n",
    "            \n",
    "        def maskOutput(index, b) :\n",
    "            return index if b else self.ignore_index\n",
    "            \n",
    "        random.seed(seed)\n",
    "        sentences.sort(key = lambda s: len(s), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            # prepare pack\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            pack = [[self.word2vec.lang.getIndex(w) for w in s] for s in pack]\n",
    "            pack = [[w for w in words if w is not None] for words in pack]\n",
    "            mask = [random.sample([_ for _ in range(len(p))], k = int(mask_ratio*len(p) +1)) for p in pack]\n",
    "            # split into input and target pack\n",
    "            pack0 = [[ maskInput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask)]\n",
    "            pack1 = [[maskOutput(s[i], i in m) for i in range(len(s))] for s, m in zip(pack, mask)] if predict_masked_only else pack\n",
    "            lengths = torch.tensor([len(p) for p in pack0]) # size = (batch_size) \n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            pack1 = list(itertools.zip_longest(*pack1, fillvalue = self.ignore_index))\n",
    "            pack1 = Variable(torch.LongTensor(pack1).transpose(0, 1))   # size = (batch_size, max_length) \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeLogProbs(batch) :\n",
    "            embeddings = self.word2vec.embedding(batch[0].to(self.device))\n",
    "            hiddens,_  = self.context(embeddings, lengths = batch[1].to(self.device)) # dim = (batch_size, input_length, hidden_dim)\n",
    "            log_probs  = F.log_softmax(self.out(hiddens), dim = 2)                    # dim = (batch_size, input_length, lang_size)\n",
    "            return log_probs\n",
    "\n",
    "        def computeAccuracy(log_probs, targets) :\n",
    "            total   = np.sum(targets.data.cpu().numpy() != self.ignore_index)\n",
    "            success = sum([self.ignore_index != targets[i, j].item() == log_probs[i, :, j].data.topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0)) \\\n",
    "                           for j in range(targets.size(1)) ])\n",
    "            return  success * 100 / total\n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            log_probs = computeLogProbs(batch[0]).transpose(1, 2) # dim = (batch_size, lang_size, input_length)\n",
    "            targets   = batch[1].to(self.device)                  # dim = (batch_size, input_length)\n",
    "            loss      = self.criterion(log_probs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            accuracy = computeAccuracy(log_probs, targets) if compute_accuracy else 0\n",
    "            return float(loss.item() / np.sum(targets.data.cpu().numpy() != self.ignore_index)), accuracy\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887388"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser = SentenceDenoiser(device,\n",
    "                            tokenizer = lambda s : s.split(' '),\n",
    "                            word2vec = word2vec,\n",
    "                            hidden_dim = 75, \n",
    "                            n_layers = 3, \n",
    "                            dropout = 0.1,\n",
    "                            optimizer = optim.SGD)\n",
    "\n",
    "denoiser.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceDenoiser(\n",
       "  (word2vec): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(8088, 75)\n",
       "    )\n",
       "    (embedding): Embedding(8088, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (bigru): GRU(75, 75, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (out): Linear(in_features=75, out_features=8088, bias=True)\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29610"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = []\n",
    "for seed in [42, 854, 3, 7956, 881125, 76, 5721, 1499, 8752, 374, 14758, 23, 9543, 856, 75] :\n",
    "    batches += denoiser.generatePackedSentences(sentences, \n",
    "                                                batch_size = 16,\n",
    "                                                mask_ratio = 0.15,\n",
    "                                                predict_masked_only = True,\n",
    "                                                seed = seed)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 8s (- 43m 8s) (100 0%) loss : 9.148  accuracy : 3.6 %\n",
      "0m 15s (- 38m 51s) (200 0%) loss : 7.102  accuracy : 3.5 %\n",
      "0m 23s (- 38m 37s) (300 1%) loss : 6.739  accuracy : 4.6 %\n",
      "0m 31s (- 37m 55s) (400 1%) loss : 6.767  accuracy : 4.9 %\n",
      "0m 38s (- 37m 39s) (500 1%) loss : 6.602  accuracy : 5.4 %\n",
      "0m 45s (- 36m 50s) (600 2%) loss : 6.389  accuracy : 5.6 %\n",
      "0m 52s (- 36m 22s) (700 2%) loss : 6.484  accuracy : 6.2 %\n",
      "0m 59s (- 35m 51s) (800 2%) loss : 6.311  accuracy : 6.5 %\n",
      "1m 7s (- 35m 48s) (900 3%) loss : 6.386  accuracy : 5.8 %\n",
      "1m 15s (- 36m 7s) (1000 3%) loss : 6.458  accuracy : 6.1 %\n",
      "1m 23s (- 36m 12s) (1100 3%) loss : 6.316  accuracy : 6.8 %\n",
      "1m 31s (- 36m 1s) (1200 4%) loss : 6.255  accuracy : 5.9 %\n",
      "1m 38s (- 35m 47s) (1300 4%) loss : 6.289  accuracy : 6.9 %\n",
      "1m 46s (- 35m 42s) (1400 4%) loss : 6.296  accuracy : 6.2 %\n",
      "1m 54s (- 35m 49s) (1500 5%) loss : 6.238  accuracy : 6.0 %\n",
      "2m 3s (- 35m 54s) (1600 5%) loss : 6.192  accuracy : 6.8 %\n",
      "2m 11s (- 35m 52s) (1700 5%) loss : 6.174  accuracy : 7.1 %\n",
      "2m 18s (- 35m 32s) (1800 6%) loss : 6.133  accuracy : 8.7 %\n",
      "2m 25s (- 35m 19s) (1900 6%) loss : 6.107  accuracy : 7.1 %\n",
      "2m 33s (- 35m 22s) (2000 6%) loss : 6.195  accuracy : 6.1 %\n",
      "2m 41s (- 35m 13s) (2100 7%) loss : 6.222  accuracy : 6.4 %\n",
      "2m 48s (- 34m 57s) (2200 7%) loss : 6.075  accuracy : 7.4 %\n",
      "2m 56s (- 34m 50s) (2300 7%) loss : 6.083  accuracy : 6.4 %\n",
      "3m 2s (- 34m 34s) (2400 8%) loss : 5.970  accuracy : 8.2 %\n",
      "3m 10s (- 34m 20s) (2500 8%) loss : 6.157  accuracy : 6.9 %\n",
      "3m 17s (- 34m 9s) (2600 8%) loss : 6.237  accuracy : 7.3 %\n",
      "3m 25s (- 34m 5s) (2700 9%) loss : 6.065  accuracy : 7.9 %\n",
      "3m 32s (- 33m 55s) (2800 9%) loss : 6.099  accuracy : 8.3 %\n",
      "3m 39s (- 33m 42s) (2900 9%) loss : 6.099  accuracy : 7.7 %\n",
      "3m 47s (- 33m 34s) (3000 10%) loss : 6.018  accuracy : 7.5 %\n",
      "3m 54s (- 33m 27s) (3100 10%) loss : 6.150  accuracy : 7.4 %\n",
      "4m 1s (- 33m 16s) (3200 10%) loss : 6.027  accuracy : 7.5 %\n",
      "4m 8s (- 32m 59s) (3300 11%) loss : 5.975  accuracy : 7.5 %\n",
      "4m 16s (- 32m 54s) (3400 11%) loss : 6.113  accuracy : 7.8 %\n",
      "4m 23s (- 32m 44s) (3500 11%) loss : 6.084  accuracy : 7.2 %\n",
      "4m 31s (- 32m 42s) (3600 12%) loss : 6.041  accuracy : 7.7 %\n",
      "4m 38s (- 32m 32s) (3700 12%) loss : 6.037  accuracy : 6.4 %\n",
      "4m 46s (- 32m 24s) (3800 12%) loss : 5.945  accuracy : 8.2 %\n",
      "4m 54s (- 32m 18s) (3900 13%) loss : 5.899  accuracy : 9.0 %\n",
      "5m 1s (- 32m 9s) (4000 13%) loss : 6.037  accuracy : 8.5 %\n",
      "5m 8s (- 31m 59s) (4100 13%) loss : 6.029  accuracy : 7.3 %\n",
      "5m 15s (- 31m 51s) (4200 14%) loss : 5.810  accuracy : 8.8 %\n",
      "5m 22s (- 31m 40s) (4300 14%) loss : 5.830  accuracy : 9.2 %\n",
      "5m 29s (- 31m 30s) (4400 14%) loss : 5.939  accuracy : 7.8 %\n",
      "5m 36s (- 31m 19s) (4500 15%) loss : 5.854  accuracy : 8.3 %\n",
      "5m 44s (- 31m 11s) (4600 15%) loss : 5.805  accuracy : 7.7 %\n",
      "5m 52s (- 31m 7s) (4700 15%) loss : 5.877  accuracy : 8.8 %\n",
      "5m 59s (- 30m 57s) (4800 16%) loss : 5.821  accuracy : 8.8 %\n",
      "6m 7s (- 30m 53s) (4900 16%) loss : 5.883  accuracy : 8.9 %\n",
      "6m 15s (- 30m 48s) (5000 16%) loss : 5.831  accuracy : 9.4 %\n",
      "6m 23s (- 30m 44s) (5100 17%) loss : 5.791  accuracy : 8.7 %\n",
      "6m 31s (- 30m 36s) (5200 17%) loss : 5.810  accuracy : 10.1 %\n",
      "6m 39s (- 30m 32s) (5300 17%) loss : 5.839  accuracy : 9.2 %\n",
      "6m 46s (- 30m 24s) (5400 18%) loss : 5.719  accuracy : 9.0 %\n",
      "6m 53s (- 30m 14s) (5500 18%) loss : 5.793  accuracy : 9.9 %\n",
      "7m 1s (- 30m 5s) (5600 18%) loss : 5.758  accuracy : 9.7 %\n",
      "7m 8s (- 29m 57s) (5700 19%) loss : 5.770  accuracy : 9.8 %\n",
      "7m 16s (- 29m 50s) (5800 19%) loss : 5.874  accuracy : 8.7 %\n",
      "7m 22s (- 29m 39s) (5900 19%) loss : 5.686  accuracy : 9.7 %\n",
      "7m 30s (- 29m 33s) (6000 20%) loss : 5.683  accuracy : 9.6 %\n",
      "7m 38s (- 29m 25s) (6100 20%) loss : 5.725  accuracy : 10.7 %\n",
      "7m 44s (- 29m 15s) (6200 20%) loss : 5.660  accuracy : 9.3 %\n",
      "7m 52s (- 29m 8s) (6300 21%) loss : 5.691  accuracy : 9.0 %\n",
      "7m 59s (- 29m 0s) (6400 21%) loss : 5.710  accuracy : 10.4 %\n",
      "8m 7s (- 28m 51s) (6500 21%) loss : 5.751  accuracy : 8.9 %\n",
      "8m 15s (- 28m 46s) (6600 22%) loss : 5.605  accuracy : 10.3 %\n",
      "8m 21s (- 28m 35s) (6700 22%) loss : 5.698  accuracy : 10.6 %\n",
      "8m 29s (- 28m 28s) (6800 22%) loss : 5.670  accuracy : 10.9 %\n",
      "8m 37s (- 28m 22s) (6900 23%) loss : 5.606  accuracy : 11.2 %\n",
      "8m 44s (- 28m 14s) (7000 23%) loss : 5.629  accuracy : 10.4 %\n",
      "8m 50s (- 28m 2s) (7100 23%) loss : 5.481  accuracy : 11.0 %\n",
      "8m 57s (- 27m 51s) (7200 24%) loss : 5.721  accuracy : 10.0 %\n",
      "9m 4s (- 27m 43s) (7300 24%) loss : 5.655  accuracy : 9.6 %\n",
      "9m 11s (- 27m 33s) (7400 24%) loss : 5.596  accuracy : 10.4 %\n",
      "9m 19s (- 27m 29s) (7500 25%) loss : 5.696  accuracy : 11.0 %\n",
      "9m 27s (- 27m 23s) (7600 25%) loss : 5.591  accuracy : 10.9 %\n",
      "9m 34s (- 27m 14s) (7700 26%) loss : 5.589  accuracy : 10.9 %\n",
      "9m 42s (- 27m 7s) (7800 26%) loss : 5.662  accuracy : 10.2 %\n",
      "9m 49s (- 26m 58s) (7900 26%) loss : 5.445  accuracy : 12.2 %\n",
      "9m 55s (- 26m 48s) (8000 27%) loss : 5.423  accuracy : 12.2 %\n",
      "10m 2s (- 26m 38s) (8100 27%) loss : 5.400  accuracy : 11.2 %\n",
      "10m 10s (- 26m 33s) (8200 27%) loss : 5.504  accuracy : 11.9 %\n",
      "10m 17s (- 26m 25s) (8300 28%) loss : 5.469  accuracy : 13.8 %\n",
      "10m 25s (- 26m 18s) (8400 28%) loss : 5.421  accuracy : 13.4 %\n",
      "10m 32s (- 26m 11s) (8500 28%) loss : 5.357  accuracy : 12.7 %\n",
      "10m 39s (- 26m 1s) (8600 29%) loss : 5.390  accuracy : 13.6 %\n",
      "10m 46s (- 25m 54s) (8700 29%) loss : 5.464  accuracy : 12.2 %\n",
      "10m 53s (- 25m 45s) (8800 29%) loss : 5.278  accuracy : 12.9 %\n",
      "11m 0s (- 25m 36s) (8900 30%) loss : 5.339  accuracy : 14.3 %\n",
      "11m 7s (- 25m 29s) (9000 30%) loss : 5.387  accuracy : 12.9 %\n",
      "11m 15s (- 25m 23s) (9100 30%) loss : 5.431  accuracy : 12.3 %\n",
      "11m 23s (- 25m 16s) (9200 31%) loss : 5.360  accuracy : 13.4 %\n",
      "11m 30s (- 25m 7s) (9300 31%) loss : 5.410  accuracy : 14.2 %\n",
      "11m 37s (- 24m 59s) (9400 31%) loss : 5.256  accuracy : 15.9 %\n",
      "11m 45s (- 24m 52s) (9500 32%) loss : 5.357  accuracy : 15.5 %\n",
      "11m 52s (- 24m 44s) (9600 32%) loss : 5.197  accuracy : 16.3 %\n",
      "11m 59s (- 24m 36s) (9700 32%) loss : 5.320  accuracy : 14.3 %\n",
      "12m 6s (- 24m 27s) (9800 33%) loss : 5.226  accuracy : 14.4 %\n",
      "12m 13s (- 24m 19s) (9900 33%) loss : 5.143  accuracy : 15.6 %\n",
      "12m 20s (- 24m 12s) (10000 33%) loss : 5.329  accuracy : 14.5 %\n",
      "12m 28s (- 24m 5s) (10100 34%) loss : 5.198  accuracy : 15.6 %\n",
      "12m 35s (- 23m 58s) (10200 34%) loss : 5.185  accuracy : 15.8 %\n",
      "12m 43s (- 23m 50s) (10300 34%) loss : 4.994  accuracy : 16.1 %\n",
      "12m 50s (- 23m 43s) (10400 35%) loss : 5.029  accuracy : 16.6 %\n",
      "12m 58s (- 23m 36s) (10500 35%) loss : 5.210  accuracy : 15.3 %\n",
      "13m 6s (- 23m 30s) (10600 35%) loss : 5.075  accuracy : 16.5 %\n",
      "13m 14s (- 23m 23s) (10700 36%) loss : 4.983  accuracy : 18.0 %\n",
      "13m 21s (- 23m 15s) (10800 36%) loss : 5.187  accuracy : 15.9 %\n",
      "13m 28s (- 23m 8s) (10900 36%) loss : 5.047  accuracy : 18.5 %\n",
      "13m 35s (- 23m 0s) (11000 37%) loss : 4.968  accuracy : 18.3 %\n",
      "13m 42s (- 22m 52s) (11100 37%) loss : 4.814  accuracy : 20.3 %\n",
      "13m 50s (- 22m 44s) (11200 37%) loss : 4.965  accuracy : 17.5 %\n",
      "13m 58s (- 22m 38s) (11300 38%) loss : 4.952  accuracy : 19.1 %\n",
      "14m 5s (- 22m 30s) (11400 38%) loss : 4.885  accuracy : 19.8 %\n",
      "14m 12s (- 22m 21s) (11500 38%) loss : 5.043  accuracy : 17.0 %\n",
      "14m 19s (- 22m 14s) (11600 39%) loss : 4.868  accuracy : 18.4 %\n",
      "14m 27s (- 22m 7s) (11700 39%) loss : 4.816  accuracy : 19.3 %\n",
      "14m 34s (- 22m 0s) (11800 39%) loss : 4.801  accuracy : 20.0 %\n",
      "14m 42s (- 21m 53s) (11900 40%) loss : 5.007  accuracy : 18.8 %\n",
      "14m 49s (- 21m 46s) (12000 40%) loss : 4.834  accuracy : 18.9 %\n",
      "14m 58s (- 21m 39s) (12100 40%) loss : 4.782  accuracy : 19.9 %\n",
      "15m 5s (- 21m 32s) (12200 41%) loss : 4.839  accuracy : 20.0 %\n",
      "15m 12s (- 21m 23s) (12300 41%) loss : 4.849  accuracy : 18.5 %\n",
      "15m 18s (- 21m 14s) (12400 41%) loss : 4.628  accuracy : 20.8 %\n",
      "15m 26s (- 21m 8s) (12500 42%) loss : 4.764  accuracy : 20.7 %\n",
      "15m 33s (- 21m 0s) (12600 42%) loss : 4.783  accuracy : 21.0 %\n",
      "15m 40s (- 20m 52s) (12700 42%) loss : 4.782  accuracy : 21.2 %\n",
      "15m 48s (- 20m 45s) (12800 43%) loss : 4.811  accuracy : 19.4 %\n",
      "15m 56s (- 20m 39s) (12900 43%) loss : 4.604  accuracy : 22.2 %\n",
      "16m 3s (- 20m 31s) (13000 43%) loss : 4.650  accuracy : 19.9 %\n",
      "16m 11s (- 20m 24s) (13100 44%) loss : 4.670  accuracy : 19.6 %\n",
      "16m 19s (- 20m 17s) (13200 44%) loss : 4.617  accuracy : 20.8 %\n",
      "16m 26s (- 20m 9s) (13300 44%) loss : 4.712  accuracy : 20.2 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16m 35s (- 20m 3s) (13400 45%) loss : 4.690  accuracy : 22.7 %\n",
      "16m 42s (- 19m 56s) (13500 45%) loss : 4.584  accuracy : 21.9 %\n",
      "16m 49s (- 19m 48s) (13600 45%) loss : 4.666  accuracy : 20.3 %\n",
      "16m 58s (- 19m 42s) (13700 46%) loss : 4.735  accuracy : 20.8 %\n",
      "17m 6s (- 19m 36s) (13800 46%) loss : 4.742  accuracy : 19.3 %\n",
      "17m 14s (- 19m 28s) (13900 46%) loss : 4.687  accuracy : 21.3 %\n",
      "17m 21s (- 19m 20s) (14000 47%) loss : 4.570  accuracy : 20.6 %\n",
      "17m 29s (- 19m 13s) (14100 47%) loss : 4.488  accuracy : 22.1 %\n",
      "17m 36s (- 19m 6s) (14200 47%) loss : 4.469  accuracy : 23.5 %\n",
      "17m 43s (- 18m 58s) (14300 48%) loss : 4.536  accuracy : 21.8 %\n",
      "17m 51s (- 18m 51s) (14400 48%) loss : 4.639  accuracy : 19.9 %\n",
      "17m 58s (- 18m 43s) (14500 48%) loss : 4.392  accuracy : 23.6 %\n",
      "18m 5s (- 18m 36s) (14600 49%) loss : 4.414  accuracy : 23.8 %\n",
      "18m 13s (- 18m 28s) (14700 49%) loss : 4.413  accuracy : 23.4 %\n",
      "18m 19s (- 18m 20s) (14800 49%) loss : 4.416  accuracy : 24.4 %\n",
      "18m 27s (- 18m 13s) (14900 50%) loss : 4.438  accuracy : 22.5 %\n",
      "18m 34s (- 18m 5s) (15000 50%) loss : 4.496  accuracy : 23.0 %\n",
      "18m 42s (- 17m 58s) (15100 50%) loss : 4.578  accuracy : 22.1 %\n",
      "18m 48s (- 17m 49s) (15200 51%) loss : 4.367  accuracy : 23.4 %\n",
      "18m 55s (- 17m 41s) (15300 51%) loss : 4.370  accuracy : 23.3 %\n",
      "19m 3s (- 17m 35s) (15400 52%) loss : 4.526  accuracy : 23.1 %\n",
      "19m 11s (- 17m 28s) (15500 52%) loss : 4.354  accuracy : 23.6 %\n",
      "19m 20s (- 17m 22s) (15600 52%) loss : 4.577  accuracy : 22.2 %\n",
      "19m 27s (- 17m 14s) (15700 53%) loss : 4.379  accuracy : 23.2 %\n",
      "19m 34s (- 17m 6s) (15800 53%) loss : 4.466  accuracy : 24.1 %\n",
      "19m 40s (- 16m 58s) (15900 53%) loss : 4.351  accuracy : 24.2 %\n",
      "19m 48s (- 16m 51s) (16000 54%) loss : 4.307  accuracy : 23.3 %\n",
      "19m 55s (- 16m 43s) (16100 54%) loss : 4.382  accuracy : 23.5 %\n",
      "20m 3s (- 16m 35s) (16200 54%) loss : 4.412  accuracy : 24.6 %\n",
      "20m 10s (- 16m 28s) (16300 55%) loss : 4.246  accuracy : 24.3 %\n",
      "20m 17s (- 16m 20s) (16400 55%) loss : 4.281  accuracy : 23.4 %\n",
      "20m 24s (- 16m 13s) (16500 55%) loss : 4.322  accuracy : 25.8 %\n",
      "20m 32s (- 16m 5s) (16600 56%) loss : 4.281  accuracy : 25.3 %\n",
      "20m 39s (- 15m 58s) (16700 56%) loss : 4.309  accuracy : 24.8 %\n",
      "20m 46s (- 15m 50s) (16800 56%) loss : 4.266  accuracy : 24.4 %\n",
      "20m 54s (- 15m 43s) (16900 57%) loss : 4.222  accuracy : 25.3 %\n",
      "21m 2s (- 15m 36s) (17000 57%) loss : 4.130  accuracy : 26.8 %\n",
      "21m 10s (- 15m 29s) (17100 57%) loss : 4.279  accuracy : 24.6 %\n",
      "21m 17s (- 15m 21s) (17200 58%) loss : 4.307  accuracy : 25.8 %\n",
      "21m 24s (- 15m 14s) (17300 58%) loss : 4.145  accuracy : 27.4 %\n",
      "21m 31s (- 15m 6s) (17400 58%) loss : 4.212  accuracy : 26.0 %\n",
      "21m 39s (- 14m 58s) (17500 59%) loss : 4.296  accuracy : 25.4 %\n",
      "21m 46s (- 14m 51s) (17600 59%) loss : 4.193  accuracy : 25.1 %\n",
      "21m 53s (- 14m 44s) (17700 59%) loss : 4.240  accuracy : 25.5 %\n",
      "22m 1s (- 14m 37s) (17800 60%) loss : 4.191  accuracy : 26.7 %\n",
      "22m 9s (- 14m 30s) (17900 60%) loss : 4.230  accuracy : 27.0 %\n",
      "22m 16s (- 14m 21s) (18000 60%) loss : 4.164  accuracy : 25.6 %\n",
      "22m 24s (- 14m 14s) (18100 61%) loss : 4.250  accuracy : 25.6 %\n",
      "22m 30s (- 14m 6s) (18200 61%) loss : 4.135  accuracy : 28.5 %\n",
      "22m 38s (- 13m 59s) (18300 61%) loss : 4.410  accuracy : 23.9 %\n",
      "22m 45s (- 13m 51s) (18400 62%) loss : 4.111  accuracy : 25.8 %\n",
      "22m 52s (- 13m 44s) (18500 62%) loss : 4.190  accuracy : 27.9 %\n",
      "23m 0s (- 13m 37s) (18600 62%) loss : 4.176  accuracy : 26.3 %\n",
      "23m 8s (- 13m 30s) (18700 63%) loss : 4.038  accuracy : 27.9 %\n",
      "23m 16s (- 13m 22s) (18800 63%) loss : 4.151  accuracy : 25.5 %\n",
      "23m 23s (- 13m 15s) (18900 63%) loss : 4.175  accuracy : 25.7 %\n",
      "23m 30s (- 13m 7s) (19000 64%) loss : 4.050  accuracy : 27.2 %\n",
      "23m 38s (- 13m 0s) (19100 64%) loss : 4.109  accuracy : 26.4 %\n",
      "23m 45s (- 12m 52s) (19200 64%) loss : 4.006  accuracy : 27.9 %\n",
      "23m 52s (- 12m 45s) (19300 65%) loss : 3.990  accuracy : 28.2 %\n",
      "24m 0s (- 12m 38s) (19400 65%) loss : 4.092  accuracy : 28.4 %\n",
      "24m 7s (- 12m 30s) (19500 65%) loss : 4.167  accuracy : 27.7 %\n",
      "24m 15s (- 12m 23s) (19600 66%) loss : 3.990  accuracy : 27.9 %\n",
      "24m 22s (- 12m 15s) (19700 66%) loss : 4.142  accuracy : 26.8 %\n",
      "24m 29s (- 12m 8s) (19800 66%) loss : 4.098  accuracy : 27.7 %\n",
      "24m 36s (- 12m 0s) (19900 67%) loss : 4.182  accuracy : 27.8 %\n",
      "24m 43s (- 11m 52s) (20000 67%) loss : 4.062  accuracy : 27.5 %\n",
      "24m 50s (- 11m 45s) (20100 67%) loss : 3.991  accuracy : 28.3 %\n",
      "24m 57s (- 11m 37s) (20200 68%) loss : 4.041  accuracy : 26.9 %\n",
      "25m 5s (- 11m 30s) (20300 68%) loss : 4.070  accuracy : 28.7 %\n",
      "25m 12s (- 11m 22s) (20400 68%) loss : 4.114  accuracy : 28.1 %\n",
      "25m 19s (- 11m 15s) (20500 69%) loss : 4.038  accuracy : 29.5 %\n",
      "25m 27s (- 11m 8s) (20600 69%) loss : 4.170  accuracy : 26.2 %\n",
      "25m 35s (- 11m 1s) (20700 69%) loss : 3.968  accuracy : 27.0 %\n",
      "25m 43s (- 10m 53s) (20800 70%) loss : 3.777  accuracy : 29.5 %\n",
      "25m 50s (- 10m 45s) (20900 70%) loss : 3.869  accuracy : 30.1 %\n",
      "25m 58s (- 10m 38s) (21000 70%) loss : 3.887  accuracy : 30.0 %\n",
      "26m 5s (- 10m 31s) (21100 71%) loss : 4.106  accuracy : 27.3 %\n",
      "26m 12s (- 10m 23s) (21200 71%) loss : 4.008  accuracy : 27.6 %\n",
      "26m 20s (- 10m 16s) (21300 71%) loss : 4.104  accuracy : 27.3 %\n",
      "26m 28s (- 10m 9s) (21400 72%) loss : 4.082  accuracy : 27.5 %\n",
      "26m 36s (- 10m 2s) (21500 72%) loss : 4.116  accuracy : 26.8 %\n",
      "26m 44s (- 9m 54s) (21600 72%) loss : 4.039  accuracy : 28.5 %\n",
      "26m 50s (- 9m 47s) (21700 73%) loss : 3.996  accuracy : 27.2 %\n",
      "26m 58s (- 9m 39s) (21800 73%) loss : 3.983  accuracy : 30.2 %\n",
      "27m 5s (- 9m 32s) (21900 73%) loss : 3.956  accuracy : 28.6 %\n",
      "27m 12s (- 9m 24s) (22000 74%) loss : 3.778  accuracy : 32.7 %\n",
      "27m 19s (- 9m 17s) (22100 74%) loss : 3.679  accuracy : 34.4 %\n",
      "27m 25s (- 9m 9s) (22200 74%) loss : 3.946  accuracy : 29.1 %\n",
      "27m 34s (- 9m 2s) (22300 75%) loss : 3.945  accuracy : 28.9 %\n",
      "27m 41s (- 8m 54s) (22400 75%) loss : 3.978  accuracy : 28.4 %\n",
      "27m 49s (- 8m 47s) (22500 75%) loss : 4.042  accuracy : 27.8 %\n",
      "27m 56s (- 8m 40s) (22600 76%) loss : 3.917  accuracy : 30.1 %\n",
      "28m 3s (- 8m 32s) (22700 76%) loss : 3.969  accuracy : 28.1 %\n",
      "28m 10s (- 8m 24s) (22800 77%) loss : 3.848  accuracy : 30.2 %\n",
      "28m 18s (- 8m 17s) (22900 77%) loss : 3.914  accuracy : 28.8 %\n",
      "28m 24s (- 8m 9s) (23000 77%) loss : 3.901  accuracy : 28.4 %\n",
      "28m 31s (- 8m 2s) (23100 78%) loss : 3.762  accuracy : 31.1 %\n",
      "28m 39s (- 7m 55s) (23200 78%) loss : 3.910  accuracy : 30.3 %\n",
      "28m 47s (- 7m 47s) (23300 78%) loss : 3.862  accuracy : 30.0 %\n",
      "28m 53s (- 7m 40s) (23400 79%) loss : 3.892  accuracy : 28.5 %\n",
      "29m 1s (- 7m 32s) (23500 79%) loss : 3.705  accuracy : 31.8 %\n",
      "29m 8s (- 7m 25s) (23600 79%) loss : 4.094  accuracy : 27.3 %\n",
      "29m 14s (- 7m 17s) (23700 80%) loss : 4.031  accuracy : 26.9 %\n",
      "29m 22s (- 7m 10s) (23800 80%) loss : 3.881  accuracy : 29.5 %\n",
      "29m 29s (- 7m 2s) (23900 80%) loss : 3.770  accuracy : 31.0 %\n",
      "29m 37s (- 6m 55s) (24000 81%) loss : 4.091  accuracy : 28.2 %\n",
      "29m 44s (- 6m 47s) (24100 81%) loss : 3.740  accuracy : 30.6 %\n",
      "29m 52s (- 6m 40s) (24200 81%) loss : 3.943  accuracy : 29.3 %\n",
      "29m 59s (- 6m 33s) (24300 82%) loss : 3.732  accuracy : 31.3 %\n",
      "30m 8s (- 6m 26s) (24400 82%) loss : 4.003  accuracy : 29.8 %\n",
      "30m 15s (- 6m 18s) (24500 82%) loss : 3.776  accuracy : 32.1 %\n",
      "30m 22s (- 6m 11s) (24600 83%) loss : 3.788  accuracy : 30.7 %\n",
      "30m 29s (- 6m 3s) (24700 83%) loss : 3.946  accuracy : 28.8 %\n",
      "30m 36s (- 5m 56s) (24800 83%) loss : 3.816  accuracy : 30.5 %\n",
      "30m 44s (- 5m 48s) (24900 84%) loss : 3.968  accuracy : 28.0 %\n",
      "30m 50s (- 5m 41s) (25000 84%) loss : 3.696  accuracy : 32.9 %\n",
      "30m 58s (- 5m 33s) (25100 84%) loss : 3.890  accuracy : 28.6 %\n",
      "31m 5s (- 5m 26s) (25200 85%) loss : 3.839  accuracy : 29.0 %\n",
      "31m 12s (- 5m 19s) (25300 85%) loss : 3.721  accuracy : 33.1 %\n",
      "31m 19s (- 5m 11s) (25400 85%) loss : 3.681  accuracy : 32.4 %\n",
      "31m 26s (- 5m 4s) (25500 86%) loss : 3.841  accuracy : 28.4 %\n",
      "31m 34s (- 4m 56s) (25600 86%) loss : 3.812  accuracy : 28.8 %\n",
      "31m 42s (- 4m 49s) (25700 86%) loss : 3.816  accuracy : 30.6 %\n",
      "31m 49s (- 4m 42s) (25800 87%) loss : 3.760  accuracy : 32.0 %\n",
      "31m 57s (- 4m 34s) (25900 87%) loss : 3.910  accuracy : 28.8 %\n",
      "32m 5s (- 4m 27s) (26000 87%) loss : 3.901  accuracy : 29.2 %\n",
      "32m 11s (- 4m 19s) (26100 88%) loss : 3.630  accuracy : 32.4 %\n",
      "32m 19s (- 4m 12s) (26200 88%) loss : 3.668  accuracy : 32.4 %\n",
      "32m 26s (- 4m 5s) (26300 88%) loss : 3.701  accuracy : 31.7 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32m 34s (- 3m 57s) (26400 89%) loss : 3.664  accuracy : 30.3 %\n",
      "32m 41s (- 3m 50s) (26500 89%) loss : 3.725  accuracy : 29.6 %\n",
      "32m 49s (- 3m 42s) (26600 89%) loss : 3.610  accuracy : 32.6 %\n",
      "32m 55s (- 3m 35s) (26700 90%) loss : 3.594  accuracy : 33.2 %\n",
      "33m 3s (- 3m 27s) (26800 90%) loss : 3.742  accuracy : 32.0 %\n",
      "33m 11s (- 3m 20s) (26900 90%) loss : 3.703  accuracy : 33.5 %\n",
      "33m 18s (- 3m 13s) (27000 91%) loss : 3.708  accuracy : 32.2 %\n",
      "33m 26s (- 3m 5s) (27100 91%) loss : 3.917  accuracy : 30.5 %\n",
      "33m 33s (- 2m 58s) (27200 91%) loss : 3.683  accuracy : 31.5 %\n",
      "33m 40s (- 2m 50s) (27300 92%) loss : 3.822  accuracy : 31.4 %\n",
      "33m 47s (- 2m 43s) (27400 92%) loss : 3.642  accuracy : 31.7 %\n",
      "33m 54s (- 2m 36s) (27500 92%) loss : 3.738  accuracy : 31.8 %\n",
      "34m 1s (- 2m 28s) (27600 93%) loss : 3.720  accuracy : 33.0 %\n",
      "34m 8s (- 2m 21s) (27700 93%) loss : 3.581  accuracy : 32.8 %\n",
      "34m 16s (- 2m 13s) (27800 93%) loss : 3.782  accuracy : 32.0 %\n",
      "34m 23s (- 2m 6s) (27900 94%) loss : 3.801  accuracy : 30.1 %\n",
      "34m 30s (- 1m 59s) (28000 94%) loss : 3.697  accuracy : 30.5 %\n",
      "34m 38s (- 1m 51s) (28100 94%) loss : 3.698  accuracy : 31.2 %\n",
      "34m 45s (- 1m 44s) (28200 95%) loss : 3.586  accuracy : 34.2 %\n",
      "34m 53s (- 1m 36s) (28300 95%) loss : 3.626  accuracy : 32.3 %\n",
      "35m 0s (- 1m 29s) (28400 95%) loss : 3.697  accuracy : 31.1 %\n",
      "35m 8s (- 1m 22s) (28500 96%) loss : 3.777  accuracy : 29.4 %\n",
      "35m 15s (- 1m 14s) (28600 96%) loss : 3.673  accuracy : 31.9 %\n",
      "35m 23s (- 1m 7s) (28700 96%) loss : 3.739  accuracy : 32.1 %\n",
      "35m 31s (- 0m 59s) (28800 97%) loss : 3.705  accuracy : 31.9 %\n",
      "35m 38s (- 0m 52s) (28900 97%) loss : 3.842  accuracy : 31.0 %\n",
      "35m 45s (- 0m 45s) (29000 97%) loss : 3.767  accuracy : 30.4 %\n",
      "35m 53s (- 0m 37s) (29100 98%) loss : 3.583  accuracy : 33.8 %\n",
      "36m 0s (- 0m 30s) (29200 98%) loss : 3.595  accuracy : 33.1 %\n",
      "36m 7s (- 0m 22s) (29300 98%) loss : 3.548  accuracy : 35.1 %\n",
      "36m 14s (- 0m 15s) (29400 99%) loss : 3.775  accuracy : 31.5 %\n",
      "36m 22s (- 0m 8s) (29500 99%) loss : 3.505  accuracy : 36.3 %\n",
      "36m 29s (- 0m 0s) (29600 99%) loss : 3.774  accuracy : 31.4 %\n",
      "epoch 1\n",
      "0m 7s (- 36m 3s) (100 0%) loss : 3.533  accuracy : 34.3 %\n",
      "0m 15s (- 38m 45s) (200 0%) loss : 3.551  accuracy : 35.4 %\n",
      "0m 23s (- 37m 57s) (300 1%) loss : 3.367  accuracy : 36.7 %\n",
      "0m 30s (- 37m 7s) (400 1%) loss : 3.797  accuracy : 31.2 %\n",
      "0m 37s (- 36m 16s) (500 1%) loss : 3.589  accuracy : 34.7 %\n",
      "0m 44s (- 36m 14s) (600 2%) loss : 3.546  accuracy : 33.9 %\n",
      "0m 52s (- 36m 1s) (700 2%) loss : 3.470  accuracy : 35.5 %\n",
      "1m 0s (- 36m 32s) (800 2%) loss : 3.601  accuracy : 33.2 %\n",
      "1m 8s (- 36m 31s) (900 3%) loss : 3.385  accuracy : 38.1 %\n",
      "1m 16s (- 36m 21s) (1000 3%) loss : 3.535  accuracy : 34.8 %\n",
      "1m 23s (- 36m 9s) (1100 3%) loss : 3.561  accuracy : 34.8 %\n",
      "1m 31s (- 35m 59s) (1200 4%) loss : 3.370  accuracy : 36.9 %\n",
      "1m 38s (- 35m 49s) (1300 4%) loss : 3.239  accuracy : 38.3 %\n",
      "1m 51s (- 37m 22s) (1400 4%) loss : 3.384  accuracy : 36.3 %\n",
      "1m 59s (- 37m 14s) (1500 5%) loss : 3.437  accuracy : 33.8 %\n",
      "2m 7s (- 37m 4s) (1600 5%) loss : 3.552  accuracy : 34.4 %\n",
      "2m 13s (- 36m 39s) (1700 5%) loss : 3.363  accuracy : 37.1 %\n",
      "2m 21s (- 36m 27s) (1800 6%) loss : 3.559  accuracy : 33.3 %\n",
      "2m 28s (- 36m 12s) (1900 6%) loss : 3.306  accuracy : 39.3 %\n",
      "2m 36s (- 36m 3s) (2000 6%) loss : 3.414  accuracy : 35.2 %\n",
      "2m 43s (- 35m 39s) (2100 7%) loss : 3.569  accuracy : 33.1 %\n",
      "2m 50s (- 35m 18s) (2200 7%) loss : 3.368  accuracy : 36.4 %\n",
      "2m 57s (- 35m 6s) (2300 7%) loss : 3.354  accuracy : 36.7 %\n",
      "3m 5s (- 35m 0s) (2400 8%) loss : 3.600  accuracy : 34.4 %\n",
      "3m 12s (- 34m 46s) (2500 8%) loss : 3.282  accuracy : 36.5 %\n",
      "3m 19s (- 34m 32s) (2600 8%) loss : 3.409  accuracy : 35.9 %\n",
      "3m 26s (- 34m 21s) (2700 9%) loss : 3.402  accuracy : 34.9 %\n",
      "3m 34s (- 34m 13s) (2800 9%) loss : 3.566  accuracy : 33.2 %\n",
      "3m 41s (- 33m 56s) (2900 9%) loss : 3.334  accuracy : 36.5 %\n",
      "3m 47s (- 33m 37s) (3000 10%) loss : 3.364  accuracy : 36.2 %\n",
      "3m 55s (- 33m 33s) (3100 10%) loss : 3.328  accuracy : 37.6 %\n",
      "4m 3s (- 33m 25s) (3200 10%) loss : 3.342  accuracy : 36.7 %\n",
      "4m 10s (- 33m 19s) (3300 11%) loss : 3.513  accuracy : 36.2 %\n",
      "4m 18s (- 33m 15s) (3400 11%) loss : 3.458  accuracy : 36.3 %\n",
      "4m 26s (- 33m 7s) (3500 11%) loss : 3.356  accuracy : 39.5 %\n",
      "4m 33s (- 32m 55s) (3600 12%) loss : 3.390  accuracy : 37.9 %\n",
      "4m 40s (- 32m 43s) (3700 12%) loss : 3.374  accuracy : 36.2 %\n",
      "4m 47s (- 32m 33s) (3800 12%) loss : 3.497  accuracy : 34.9 %\n",
      "4m 56s (- 32m 31s) (3900 13%) loss : 3.494  accuracy : 35.7 %\n",
      "5m 3s (- 32m 24s) (4000 13%) loss : 3.349  accuracy : 35.8 %\n",
      "5m 10s (- 32m 13s) (4100 13%) loss : 3.555  accuracy : 33.7 %\n",
      "5m 17s (- 32m 2s) (4200 14%) loss : 3.522  accuracy : 34.5 %\n",
      "5m 25s (- 31m 53s) (4300 14%) loss : 3.542  accuracy : 34.1 %\n",
      "5m 32s (- 31m 43s) (4400 14%) loss : 3.279  accuracy : 39.3 %\n",
      "5m 39s (- 31m 36s) (4500 15%) loss : 3.327  accuracy : 37.6 %\n",
      "5m 47s (- 31m 26s) (4600 15%) loss : 3.358  accuracy : 37.1 %\n",
      "5m 54s (- 31m 21s) (4700 15%) loss : 3.374  accuracy : 36.0 %\n",
      "6m 2s (- 31m 13s) (4800 16%) loss : 3.480  accuracy : 35.5 %\n",
      "6m 9s (- 31m 3s) (4900 16%) loss : 3.252  accuracy : 39.3 %\n",
      "6m 16s (- 30m 53s) (5000 16%) loss : 3.396  accuracy : 35.5 %\n",
      "6m 23s (- 30m 45s) (5100 17%) loss : 3.564  accuracy : 34.3 %\n",
      "6m 31s (- 30m 36s) (5200 17%) loss : 3.337  accuracy : 39.9 %\n",
      "6m 38s (- 30m 26s) (5300 17%) loss : 3.409  accuracy : 35.5 %\n",
      "6m 45s (- 30m 18s) (5400 18%) loss : 3.407  accuracy : 36.2 %\n",
      "6m 52s (- 30m 9s) (5500 18%) loss : 3.385  accuracy : 34.3 %\n",
      "7m 0s (- 30m 3s) (5600 18%) loss : 3.427  accuracy : 35.7 %\n",
      "7m 7s (- 29m 54s) (5700 19%) loss : 3.388  accuracy : 36.3 %\n",
      "7m 15s (- 29m 48s) (5800 19%) loss : 3.425  accuracy : 36.6 %\n",
      "7m 23s (- 29m 40s) (5900 19%) loss : 3.410  accuracy : 35.1 %\n",
      "7m 30s (- 29m 31s) (6000 20%) loss : 3.607  accuracy : 32.9 %\n",
      "7m 37s (- 29m 24s) (6100 20%) loss : 3.291  accuracy : 37.7 %\n",
      "7m 45s (- 29m 17s) (6200 20%) loss : 3.434  accuracy : 36.7 %\n",
      "7m 52s (- 29m 6s) (6300 21%) loss : 3.328  accuracy : 37.8 %\n",
      "7m 58s (- 28m 56s) (6400 21%) loss : 3.461  accuracy : 36.0 %\n",
      "8m 6s (- 28m 48s) (6500 21%) loss : 3.293  accuracy : 39.4 %\n",
      "8m 13s (- 28m 39s) (6600 22%) loss : 3.533  accuracy : 33.7 %\n",
      "8m 20s (- 28m 33s) (6700 22%) loss : 3.434  accuracy : 35.6 %\n",
      "8m 28s (- 28m 26s) (6800 22%) loss : 3.416  accuracy : 36.4 %\n",
      "8m 36s (- 28m 21s) (6900 23%) loss : 3.355  accuracy : 37.2 %\n",
      "8m 43s (- 28m 12s) (7000 23%) loss : 3.325  accuracy : 37.1 %\n",
      "8m 51s (- 28m 3s) (7100 23%) loss : 3.408  accuracy : 35.8 %\n",
      "8m 57s (- 27m 54s) (7200 24%) loss : 3.409  accuracy : 35.4 %\n",
      "9m 5s (- 27m 48s) (7300 24%) loss : 3.470  accuracy : 35.0 %\n",
      "9m 13s (- 27m 40s) (7400 24%) loss : 3.482  accuracy : 34.5 %\n",
      "9m 19s (- 27m 29s) (7500 25%) loss : 3.348  accuracy : 36.5 %\n",
      "9m 26s (- 27m 21s) (7600 25%) loss : 3.404  accuracy : 34.4 %\n",
      "9m 33s (- 27m 11s) (7700 26%) loss : 3.310  accuracy : 36.8 %\n",
      "9m 40s (- 27m 4s) (7800 26%) loss : 3.228  accuracy : 39.0 %\n",
      "9m 48s (- 26m 58s) (7900 26%) loss : 3.572  accuracy : 33.9 %\n",
      "9m 55s (- 26m 49s) (8000 27%) loss : 3.424  accuracy : 34.8 %\n",
      "10m 2s (- 26m 39s) (8100 27%) loss : 3.323  accuracy : 36.3 %\n",
      "10m 9s (- 26m 31s) (8200 27%) loss : 3.400  accuracy : 35.5 %\n",
      "10m 17s (- 26m 24s) (8300 28%) loss : 3.279  accuracy : 37.5 %\n",
      "10m 23s (- 26m 14s) (8400 28%) loss : 3.242  accuracy : 37.7 %\n",
      "10m 30s (- 26m 6s) (8500 28%) loss : 3.404  accuracy : 35.8 %\n",
      "10m 37s (- 25m 58s) (8600 29%) loss : 3.384  accuracy : 34.2 %\n",
      "10m 44s (- 25m 50s) (8700 29%) loss : 3.597  accuracy : 32.0 %\n",
      "10m 51s (- 25m 40s) (8800 29%) loss : 3.473  accuracy : 33.5 %\n",
      "10m 58s (- 25m 32s) (8900 30%) loss : 3.396  accuracy : 37.1 %\n",
      "11m 6s (- 25m 26s) (9000 30%) loss : 3.396  accuracy : 36.2 %\n",
      "11m 13s (- 25m 18s) (9100 30%) loss : 3.398  accuracy : 37.0 %\n",
      "11m 21s (- 25m 11s) (9200 31%) loss : 3.589  accuracy : 32.7 %\n",
      "11m 29s (- 25m 5s) (9300 31%) loss : 3.299  accuracy : 37.7 %\n",
      "11m 36s (- 24m 58s) (9400 31%) loss : 3.290  accuracy : 37.8 %\n",
      "11m 44s (- 24m 52s) (9500 32%) loss : 3.313  accuracy : 36.2 %\n",
      "11m 52s (- 24m 45s) (9600 32%) loss : 3.456  accuracy : 34.7 %\n",
      "12m 1s (- 24m 40s) (9700 32%) loss : 3.422  accuracy : 34.9 %\n",
      "12m 9s (- 24m 34s) (9800 33%) loss : 3.390  accuracy : 34.4 %\n",
      "12m 16s (- 24m 27s) (9900 33%) loss : 3.499  accuracy : 33.7 %\n",
      "12m 23s (- 24m 18s) (10000 33%) loss : 3.340  accuracy : 37.9 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12m 31s (- 24m 12s) (10100 34%) loss : 3.384  accuracy : 35.8 %\n",
      "12m 38s (- 24m 3s) (10200 34%) loss : 3.302  accuracy : 36.7 %\n",
      "12m 46s (- 23m 56s) (10300 34%) loss : 3.236  accuracy : 38.9 %\n",
      "12m 53s (- 23m 48s) (10400 35%) loss : 3.273  accuracy : 37.6 %\n",
      "13m 0s (- 23m 40s) (10500 35%) loss : 3.298  accuracy : 36.0 %\n",
      "13m 7s (- 23m 32s) (10600 35%) loss : 3.307  accuracy : 38.4 %\n",
      "13m 15s (- 23m 25s) (10700 36%) loss : 3.425  accuracy : 36.1 %\n",
      "13m 22s (- 23m 18s) (10800 36%) loss : 3.277  accuracy : 38.4 %\n",
      "13m 29s (- 23m 10s) (10900 36%) loss : 3.416  accuracy : 34.4 %\n",
      "13m 36s (- 23m 2s) (11000 37%) loss : 3.169  accuracy : 39.2 %\n",
      "13m 43s (- 22m 52s) (11100 37%) loss : 3.352  accuracy : 36.9 %\n",
      "13m 49s (- 22m 44s) (11200 37%) loss : 3.407  accuracy : 35.8 %\n",
      "13m 57s (- 22m 36s) (11300 38%) loss : 3.321  accuracy : 37.0 %\n",
      "14m 4s (- 22m 28s) (11400 38%) loss : 3.349  accuracy : 39.2 %\n",
      "14m 11s (- 22m 20s) (11500 38%) loss : 3.387  accuracy : 34.1 %\n",
      "14m 18s (- 22m 13s) (11600 39%) loss : 3.320  accuracy : 35.9 %\n",
      "14m 26s (- 22m 6s) (11700 39%) loss : 3.354  accuracy : 36.8 %\n",
      "14m 34s (- 21m 59s) (11800 39%) loss : 3.333  accuracy : 37.2 %\n",
      "14m 42s (- 21m 52s) (11900 40%) loss : 3.398  accuracy : 35.6 %\n",
      "14m 49s (- 21m 45s) (12000 40%) loss : 3.401  accuracy : 36.3 %\n",
      "14m 57s (- 21m 39s) (12100 40%) loss : 3.332  accuracy : 37.4 %\n",
      "15m 4s (- 21m 31s) (12200 41%) loss : 3.427  accuracy : 34.7 %\n",
      "15m 13s (- 21m 26s) (12300 41%) loss : 3.271  accuracy : 38.9 %\n",
      "15m 20s (- 21m 17s) (12400 41%) loss : 3.335  accuracy : 36.9 %\n",
      "15m 27s (- 21m 10s) (12500 42%) loss : 3.370  accuracy : 35.2 %\n",
      "15m 35s (- 21m 3s) (12600 42%) loss : 3.326  accuracy : 37.9 %\n",
      "15m 43s (- 20m 56s) (12700 42%) loss : 3.217  accuracy : 38.4 %\n",
      "15m 50s (- 20m 47s) (12800 43%) loss : 3.453  accuracy : 36.0 %\n",
      "15m 57s (- 20m 40s) (12900 43%) loss : 3.363  accuracy : 37.5 %\n",
      "16m 5s (- 20m 33s) (13000 43%) loss : 3.223  accuracy : 37.9 %\n",
      "16m 13s (- 20m 27s) (13100 44%) loss : 3.373  accuracy : 36.1 %\n",
      "16m 21s (- 20m 20s) (13200 44%) loss : 3.321  accuracy : 36.6 %\n",
      "16m 28s (- 20m 12s) (13300 44%) loss : 3.271  accuracy : 37.6 %\n",
      "16m 36s (- 20m 5s) (13400 45%) loss : 3.316  accuracy : 37.6 %\n",
      "16m 43s (- 19m 57s) (13500 45%) loss : 3.283  accuracy : 37.8 %\n",
      "16m 50s (- 19m 50s) (13600 45%) loss : 3.363  accuracy : 37.0 %\n",
      "16m 58s (- 19m 42s) (13700 46%) loss : 3.284  accuracy : 38.2 %\n",
      "17m 5s (- 19m 35s) (13800 46%) loss : 3.475  accuracy : 34.8 %\n",
      "17m 13s (- 19m 28s) (13900 46%) loss : 3.243  accuracy : 37.7 %\n",
      "17m 20s (- 19m 20s) (14000 47%) loss : 3.290  accuracy : 37.3 %\n",
      "17m 27s (- 19m 12s) (14100 47%) loss : 3.305  accuracy : 38.2 %\n",
      "17m 34s (- 19m 3s) (14200 47%) loss : 3.324  accuracy : 36.6 %\n",
      "17m 40s (- 18m 55s) (14300 48%) loss : 3.383  accuracy : 36.7 %\n",
      "17m 48s (- 18m 48s) (14400 48%) loss : 3.217  accuracy : 38.4 %\n",
      "17m 55s (- 18m 41s) (14500 48%) loss : 3.389  accuracy : 36.6 %\n",
      "18m 3s (- 18m 33s) (14600 49%) loss : 3.370  accuracy : 38.0 %\n",
      "18m 9s (- 18m 25s) (14700 49%) loss : 3.192  accuracy : 39.4 %\n",
      "18m 16s (- 18m 17s) (14800 49%) loss : 3.251  accuracy : 38.2 %\n",
      "18m 24s (- 18m 10s) (14900 50%) loss : 3.340  accuracy : 36.3 %\n",
      "18m 31s (- 18m 2s) (15000 50%) loss : 3.389  accuracy : 35.6 %\n",
      "18m 38s (- 17m 54s) (15100 50%) loss : 3.314  accuracy : 37.7 %\n",
      "18m 45s (- 17m 47s) (15200 51%) loss : 3.159  accuracy : 38.9 %\n",
      "18m 53s (- 17m 39s) (15300 51%) loss : 3.267  accuracy : 38.4 %\n",
      "19m 0s (- 17m 32s) (15400 52%) loss : 3.338  accuracy : 36.0 %\n",
      "19m 8s (- 17m 25s) (15500 52%) loss : 3.378  accuracy : 35.7 %\n",
      "19m 15s (- 17m 17s) (15600 52%) loss : 3.164  accuracy : 38.1 %\n",
      "19m 21s (- 17m 9s) (15700 53%) loss : 3.314  accuracy : 36.3 %\n",
      "19m 29s (- 17m 2s) (15800 53%) loss : 3.217  accuracy : 38.4 %\n",
      "19m 37s (- 16m 55s) (15900 53%) loss : 3.286  accuracy : 37.8 %\n",
      "19m 44s (- 16m 47s) (16000 54%) loss : 3.442  accuracy : 34.0 %\n",
      "19m 51s (- 16m 40s) (16100 54%) loss : 3.131  accuracy : 39.1 %\n",
      "19m 58s (- 16m 32s) (16200 54%) loss : 3.378  accuracy : 35.7 %\n",
      "20m 5s (- 16m 24s) (16300 55%) loss : 3.266  accuracy : 38.5 %\n",
      "20m 12s (- 16m 16s) (16400 55%) loss : 3.316  accuracy : 37.0 %\n",
      "20m 20s (- 16m 9s) (16500 55%) loss : 3.167  accuracy : 40.7 %\n",
      "20m 28s (- 16m 2s) (16600 56%) loss : 3.381  accuracy : 36.0 %\n",
      "20m 36s (- 15m 55s) (16700 56%) loss : 3.330  accuracy : 36.9 %\n",
      "20m 43s (- 15m 48s) (16800 56%) loss : 3.334  accuracy : 36.7 %\n",
      "20m 51s (- 15m 41s) (16900 57%) loss : 3.464  accuracy : 34.9 %\n",
      "20m 59s (- 15m 33s) (17000 57%) loss : 3.461  accuracy : 36.1 %\n",
      "21m 6s (- 15m 26s) (17100 57%) loss : 3.227  accuracy : 37.2 %\n",
      "21m 14s (- 15m 19s) (17200 58%) loss : 3.168  accuracy : 39.6 %\n",
      "21m 22s (- 15m 12s) (17300 58%) loss : 3.387  accuracy : 37.5 %\n",
      "21m 29s (- 15m 5s) (17400 58%) loss : 3.219  accuracy : 39.0 %\n",
      "21m 36s (- 14m 57s) (17500 59%) loss : 3.141  accuracy : 38.5 %\n",
      "21m 43s (- 14m 49s) (17600 59%) loss : 3.336  accuracy : 37.1 %\n",
      "21m 49s (- 14m 41s) (17700 59%) loss : 3.326  accuracy : 36.5 %\n",
      "21m 57s (- 14m 33s) (17800 60%) loss : 3.158  accuracy : 40.3 %\n",
      "22m 5s (- 14m 27s) (17900 60%) loss : 3.368  accuracy : 36.0 %\n",
      "22m 12s (- 14m 19s) (18000 60%) loss : 3.229  accuracy : 39.1 %\n",
      "22m 19s (- 14m 11s) (18100 61%) loss : 3.325  accuracy : 36.4 %\n",
      "22m 26s (- 14m 4s) (18200 61%) loss : 3.125  accuracy : 39.2 %\n",
      "22m 33s (- 13m 56s) (18300 61%) loss : 3.330  accuracy : 38.1 %\n",
      "22m 41s (- 13m 49s) (18400 62%) loss : 3.344  accuracy : 36.9 %\n",
      "22m 48s (- 13m 41s) (18500 62%) loss : 3.418  accuracy : 35.4 %\n",
      "22m 56s (- 13m 34s) (18600 62%) loss : 3.333  accuracy : 37.3 %\n",
      "23m 4s (- 13m 27s) (18700 63%) loss : 3.241  accuracy : 38.6 %\n",
      "23m 12s (- 13m 20s) (18800 63%) loss : 3.307  accuracy : 37.7 %\n",
      "23m 18s (- 13m 12s) (18900 63%) loss : 3.237  accuracy : 38.3 %\n",
      "23m 27s (- 13m 5s) (19000 64%) loss : 3.319  accuracy : 37.1 %\n",
      "23m 34s (- 12m 58s) (19100 64%) loss : 3.322  accuracy : 37.7 %\n",
      "23m 40s (- 12m 50s) (19200 64%) loss : 3.342  accuracy : 35.9 %\n",
      "23m 49s (- 12m 43s) (19300 65%) loss : 3.368  accuracy : 36.4 %\n",
      "23m 56s (- 12m 36s) (19400 65%) loss : 3.323  accuracy : 37.6 %\n",
      "24m 4s (- 12m 28s) (19500 65%) loss : 3.263  accuracy : 38.3 %\n",
      "24m 11s (- 12m 21s) (19600 66%) loss : 3.231  accuracy : 38.6 %\n",
      "24m 17s (- 12m 13s) (19700 66%) loss : 3.199  accuracy : 38.2 %\n",
      "24m 24s (- 12m 5s) (19800 66%) loss : 3.329  accuracy : 36.2 %\n",
      "24m 32s (- 11m 58s) (19900 67%) loss : 3.403  accuracy : 35.2 %\n",
      "24m 39s (- 11m 51s) (20000 67%) loss : 3.342  accuracy : 38.0 %\n",
      "24m 47s (- 11m 43s) (20100 67%) loss : 3.353  accuracy : 34.9 %\n",
      "24m 54s (- 11m 36s) (20200 68%) loss : 3.268  accuracy : 36.1 %\n",
      "25m 2s (- 11m 28s) (20300 68%) loss : 3.241  accuracy : 37.8 %\n",
      "25m 9s (- 11m 21s) (20400 68%) loss : 3.301  accuracy : 35.8 %\n",
      "25m 16s (- 11m 13s) (20500 69%) loss : 3.286  accuracy : 36.4 %\n",
      "25m 24s (- 11m 6s) (20600 69%) loss : 3.181  accuracy : 39.1 %\n",
      "25m 31s (- 10m 59s) (20700 69%) loss : 3.269  accuracy : 38.5 %\n",
      "25m 38s (- 10m 51s) (20800 70%) loss : 3.131  accuracy : 40.6 %\n",
      "25m 45s (- 10m 44s) (20900 70%) loss : 3.269  accuracy : 37.0 %\n",
      "25m 52s (- 10m 36s) (21000 70%) loss : 3.283  accuracy : 35.6 %\n",
      "25m 59s (- 10m 28s) (21100 71%) loss : 3.325  accuracy : 36.6 %\n",
      "26m 6s (- 10m 21s) (21200 71%) loss : 3.127  accuracy : 40.3 %\n",
      "26m 14s (- 10m 14s) (21300 71%) loss : 3.293  accuracy : 37.6 %\n",
      "26m 20s (- 10m 6s) (21400 72%) loss : 3.161  accuracy : 40.2 %\n",
      "26m 27s (- 9m 58s) (21500 72%) loss : 3.143  accuracy : 39.7 %\n",
      "26m 35s (- 9m 51s) (21600 72%) loss : 3.292  accuracy : 37.3 %\n",
      "26m 41s (- 9m 43s) (21700 73%) loss : 3.224  accuracy : 38.4 %\n",
      "26m 49s (- 9m 36s) (21800 73%) loss : 3.207  accuracy : 37.8 %\n",
      "26m 55s (- 9m 28s) (21900 73%) loss : 3.163  accuracy : 39.4 %\n",
      "27m 2s (- 9m 21s) (22000 74%) loss : 3.158  accuracy : 39.2 %\n",
      "27m 10s (- 9m 13s) (22100 74%) loss : 3.308  accuracy : 36.4 %\n",
      "27m 17s (- 9m 6s) (22200 74%) loss : 3.128  accuracy : 38.7 %\n",
      "27m 24s (- 8m 59s) (22300 75%) loss : 3.187  accuracy : 38.1 %\n",
      "27m 31s (- 8m 51s) (22400 75%) loss : 2.961  accuracy : 41.7 %\n",
      "27m 39s (- 8m 44s) (22500 75%) loss : 3.318  accuracy : 37.2 %\n",
      "27m 46s (- 8m 36s) (22600 76%) loss : 3.293  accuracy : 37.0 %\n",
      "27m 53s (- 8m 29s) (22700 76%) loss : 3.172  accuracy : 40.4 %\n",
      "28m 0s (- 8m 21s) (22800 77%) loss : 3.350  accuracy : 37.0 %\n",
      "28m 7s (- 8m 14s) (22900 77%) loss : 3.353  accuracy : 37.9 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28m 15s (- 8m 7s) (23000 77%) loss : 3.205  accuracy : 37.4 %\n",
      "28m 23s (- 8m 0s) (23100 78%) loss : 3.076  accuracy : 40.6 %\n",
      "28m 30s (- 7m 52s) (23200 78%) loss : 3.176  accuracy : 38.7 %\n",
      "28m 37s (- 7m 45s) (23300 78%) loss : 3.109  accuracy : 40.6 %\n",
      "28m 45s (- 7m 38s) (23400 79%) loss : 3.218  accuracy : 38.5 %\n",
      "28m 52s (- 7m 30s) (23500 79%) loss : 3.264  accuracy : 38.1 %\n",
      "29m 0s (- 7m 23s) (23600 79%) loss : 3.174  accuracy : 38.8 %\n",
      "29m 8s (- 7m 16s) (23700 80%) loss : 3.203  accuracy : 38.5 %\n",
      "29m 16s (- 7m 8s) (23800 80%) loss : 3.338  accuracy : 37.7 %\n",
      "29m 23s (- 7m 1s) (23900 80%) loss : 3.240  accuracy : 38.6 %\n",
      "29m 29s (- 6m 53s) (24000 81%) loss : 3.185  accuracy : 39.2 %\n",
      "29m 37s (- 6m 46s) (24100 81%) loss : 3.332  accuracy : 36.0 %\n",
      "29m 44s (- 6m 38s) (24200 81%) loss : 3.173  accuracy : 38.4 %\n",
      "29m 51s (- 6m 31s) (24300 82%) loss : 3.082  accuracy : 41.9 %\n",
      "29m 58s (- 6m 24s) (24400 82%) loss : 3.091  accuracy : 40.0 %\n",
      "30m 5s (- 6m 16s) (24500 82%) loss : 3.128  accuracy : 39.1 %\n",
      "30m 13s (- 6m 9s) (24600 83%) loss : 3.126  accuracy : 39.8 %\n",
      "30m 21s (- 6m 2s) (24700 83%) loss : 3.114  accuracy : 40.1 %\n",
      "30m 29s (- 5m 54s) (24800 83%) loss : 3.249  accuracy : 38.7 %\n",
      "30m 36s (- 5m 47s) (24900 84%) loss : 3.270  accuracy : 38.5 %\n",
      "30m 43s (- 5m 39s) (25000 84%) loss : 3.168  accuracy : 39.2 %\n",
      "30m 51s (- 5m 32s) (25100 84%) loss : 3.187  accuracy : 37.6 %\n",
      "30m 58s (- 5m 25s) (25200 85%) loss : 3.289  accuracy : 37.1 %\n",
      "31m 5s (- 5m 17s) (25300 85%) loss : 3.209  accuracy : 38.5 %\n",
      "31m 13s (- 5m 10s) (25400 85%) loss : 3.096  accuracy : 39.6 %\n",
      "31m 20s (- 5m 3s) (25500 86%) loss : 3.141  accuracy : 40.1 %\n",
      "31m 27s (- 4m 55s) (25600 86%) loss : 3.307  accuracy : 37.5 %\n",
      "31m 33s (- 4m 48s) (25700 86%) loss : 3.243  accuracy : 38.6 %\n",
      "31m 40s (- 4m 40s) (25800 87%) loss : 3.131  accuracy : 39.3 %\n",
      "31m 47s (- 4m 33s) (25900 87%) loss : 3.285  accuracy : 37.9 %\n",
      "31m 55s (- 4m 25s) (26000 87%) loss : 3.263  accuracy : 37.1 %\n",
      "32m 2s (- 4m 18s) (26100 88%) loss : 3.300  accuracy : 37.4 %\n",
      "32m 9s (- 4m 11s) (26200 88%) loss : 3.288  accuracy : 37.1 %\n",
      "32m 17s (- 4m 3s) (26300 88%) loss : 3.324  accuracy : 36.4 %\n",
      "32m 25s (- 3m 56s) (26400 89%) loss : 3.114  accuracy : 40.7 %\n",
      "32m 32s (- 3m 49s) (26500 89%) loss : 3.202  accuracy : 39.3 %\n",
      "32m 39s (- 3m 41s) (26600 89%) loss : 3.231  accuracy : 37.4 %\n",
      "32m 46s (- 3m 34s) (26700 90%) loss : 3.180  accuracy : 38.6 %\n",
      "32m 52s (- 3m 26s) (26800 90%) loss : 3.430  accuracy : 36.2 %\n",
      "32m 59s (- 3m 19s) (26900 90%) loss : 3.287  accuracy : 36.1 %\n",
      "33m 7s (- 3m 12s) (27000 91%) loss : 3.333  accuracy : 37.7 %\n",
      "33m 13s (- 3m 4s) (27100 91%) loss : 3.212  accuracy : 38.1 %\n",
      "33m 20s (- 2m 57s) (27200 91%) loss : 3.282  accuracy : 37.1 %\n",
      "33m 27s (- 2m 49s) (27300 92%) loss : 3.223  accuracy : 37.5 %\n",
      "33m 35s (- 2m 42s) (27400 92%) loss : 3.216  accuracy : 39.2 %\n",
      "33m 42s (- 2m 35s) (27500 92%) loss : 3.186  accuracy : 37.5 %\n",
      "33m 49s (- 2m 27s) (27600 93%) loss : 3.238  accuracy : 39.1 %\n",
      "33m 56s (- 2m 20s) (27700 93%) loss : 3.205  accuracy : 37.8 %\n",
      "34m 3s (- 2m 13s) (27800 93%) loss : 3.211  accuracy : 37.8 %\n",
      "34m 10s (- 2m 5s) (27900 94%) loss : 3.295  accuracy : 36.1 %\n",
      "34m 17s (- 1m 58s) (28000 94%) loss : 3.188  accuracy : 38.9 %\n",
      "34m 24s (- 1m 50s) (28100 94%) loss : 3.217  accuracy : 37.3 %\n",
      "34m 32s (- 1m 43s) (28200 95%) loss : 3.166  accuracy : 40.4 %\n",
      "34m 39s (- 1m 36s) (28300 95%) loss : 3.103  accuracy : 41.5 %\n",
      "34m 46s (- 1m 28s) (28400 95%) loss : 3.154  accuracy : 38.6 %\n",
      "34m 53s (- 1m 21s) (28500 96%) loss : 3.369  accuracy : 35.7 %\n",
      "35m 1s (- 1m 14s) (28600 96%) loss : 3.095  accuracy : 39.7 %\n",
      "35m 7s (- 1m 6s) (28700 96%) loss : 3.126  accuracy : 39.5 %\n",
      "35m 14s (- 0m 59s) (28800 97%) loss : 3.013  accuracy : 40.6 %\n",
      "35m 21s (- 0m 52s) (28900 97%) loss : 3.049  accuracy : 40.8 %\n",
      "35m 28s (- 0m 44s) (29000 97%) loss : 2.979  accuracy : 43.0 %\n",
      "35m 35s (- 0m 37s) (29100 98%) loss : 3.274  accuracy : 38.9 %\n",
      "35m 43s (- 0m 30s) (29200 98%) loss : 3.322  accuracy : 36.0 %\n",
      "35m 51s (- 0m 22s) (29300 98%) loss : 3.036  accuracy : 42.0 %\n",
      "35m 58s (- 0m 15s) (29400 99%) loss : 3.414  accuracy : 34.3 %\n",
      "36m 5s (- 0m 8s) (29500 99%) loss : 3.192  accuracy : 37.7 %\n",
      "36m 12s (- 0m 0s) (29600 99%) loss : 3.020  accuracy : 40.7 %\n",
      "epoch 1\n",
      "0m 6s (- 34m 7s) (100 0%) loss : 3.113  accuracy : 39.1 %\n",
      "0m 14s (- 35m 9s) (200 0%) loss : 3.198  accuracy : 38.1 %\n",
      "0m 22s (- 35m 53s) (300 1%) loss : 2.956  accuracy : 42.8 %\n",
      "0m 29s (- 35m 47s) (400 1%) loss : 2.935  accuracy : 42.5 %\n",
      "0m 36s (- 35m 44s) (500 1%) loss : 3.141  accuracy : 39.3 %\n",
      "0m 43s (- 35m 5s) (600 2%) loss : 3.165  accuracy : 40.5 %\n",
      "0m 51s (- 35m 17s) (700 2%) loss : 3.098  accuracy : 40.8 %\n",
      "0m 58s (- 34m 58s) (800 2%) loss : 3.148  accuracy : 38.8 %\n",
      "1m 5s (- 34m 42s) (900 3%) loss : 3.004  accuracy : 42.0 %\n",
      "1m 12s (- 34m 24s) (1000 3%) loss : 3.166  accuracy : 39.8 %\n",
      "1m 18s (- 34m 5s) (1100 3%) loss : 2.936  accuracy : 41.6 %\n",
      "1m 26s (- 34m 3s) (1200 4%) loss : 3.077  accuracy : 40.8 %\n",
      "1m 33s (- 33m 48s) (1300 4%) loss : 3.088  accuracy : 41.5 %\n",
      "1m 40s (- 33m 52s) (1400 4%) loss : 2.978  accuracy : 41.7 %\n",
      "1m 48s (- 33m 45s) (1500 5%) loss : 3.117  accuracy : 41.1 %\n",
      "1m 54s (- 33m 29s) (1600 5%) loss : 3.105  accuracy : 40.6 %\n",
      "2m 1s (- 33m 16s) (1700 5%) loss : 3.161  accuracy : 38.9 %\n",
      "2m 9s (- 33m 23s) (1800 6%) loss : 3.049  accuracy : 40.9 %\n",
      "2m 17s (- 33m 19s) (1900 6%) loss : 3.020  accuracy : 42.4 %\n",
      "2m 24s (- 33m 16s) (2000 6%) loss : 3.112  accuracy : 41.2 %\n",
      "2m 32s (- 33m 16s) (2100 7%) loss : 2.892  accuracy : 43.5 %\n",
      "2m 39s (- 33m 6s) (2200 7%) loss : 3.146  accuracy : 40.5 %\n",
      "2m 46s (- 32m 51s) (2300 7%) loss : 3.166  accuracy : 37.7 %\n",
      "2m 53s (- 32m 49s) (2400 8%) loss : 3.196  accuracy : 38.6 %\n",
      "3m 1s (- 32m 43s) (2500 8%) loss : 3.030  accuracy : 41.6 %\n",
      "3m 8s (- 32m 41s) (2600 8%) loss : 3.069  accuracy : 39.6 %\n",
      "3m 15s (- 32m 28s) (2700 9%) loss : 2.997  accuracy : 41.6 %\n",
      "3m 23s (- 32m 25s) (2800 9%) loss : 3.184  accuracy : 40.3 %\n",
      "3m 30s (- 32m 20s) (2900 9%) loss : 3.152  accuracy : 39.9 %\n",
      "3m 38s (- 32m 17s) (3000 10%) loss : 3.051  accuracy : 40.8 %\n",
      "3m 46s (- 32m 15s) (3100 10%) loss : 3.142  accuracy : 40.2 %\n",
      "3m 52s (- 32m 2s) (3200 10%) loss : 3.083  accuracy : 39.4 %\n",
      "4m 0s (- 31m 57s) (3300 11%) loss : 3.403  accuracy : 36.1 %\n",
      "4m 8s (- 31m 58s) (3400 11%) loss : 3.133  accuracy : 39.8 %\n",
      "4m 15s (- 31m 47s) (3500 11%) loss : 3.032  accuracy : 41.7 %\n",
      "4m 22s (- 31m 39s) (3600 12%) loss : 3.131  accuracy : 40.7 %\n",
      "4m 30s (- 31m 33s) (3700 12%) loss : 3.123  accuracy : 38.7 %\n",
      "4m 37s (- 31m 25s) (3800 12%) loss : 3.068  accuracy : 41.8 %\n",
      "4m 45s (- 31m 19s) (3900 13%) loss : 3.097  accuracy : 41.0 %\n",
      "4m 52s (- 31m 12s) (4000 13%) loss : 3.198  accuracy : 38.0 %\n",
      "4m 58s (- 30m 59s) (4100 13%) loss : 3.145  accuracy : 40.9 %\n",
      "5m 5s (- 30m 50s) (4200 14%) loss : 3.143  accuracy : 39.2 %\n",
      "5m 13s (- 30m 45s) (4300 14%) loss : 3.072  accuracy : 40.0 %\n",
      "5m 21s (- 30m 43s) (4400 14%) loss : 3.106  accuracy : 40.7 %\n",
      "5m 29s (- 30m 37s) (4500 15%) loss : 3.098  accuracy : 40.3 %\n",
      "5m 36s (- 30m 31s) (4600 15%) loss : 3.226  accuracy : 37.1 %\n",
      "5m 43s (- 30m 19s) (4700 15%) loss : 3.013  accuracy : 42.1 %\n",
      "5m 50s (- 30m 12s) (4800 16%) loss : 3.228  accuracy : 37.8 %\n",
      "5m 57s (- 30m 5s) (4900 16%) loss : 3.095  accuracy : 40.9 %\n",
      "6m 5s (- 29m 57s) (5000 16%) loss : 3.107  accuracy : 39.3 %\n",
      "6m 12s (- 29m 50s) (5100 17%) loss : 3.127  accuracy : 39.4 %\n",
      "6m 18s (- 29m 38s) (5200 17%) loss : 3.133  accuracy : 40.5 %\n",
      "6m 26s (- 29m 31s) (5300 17%) loss : 3.084  accuracy : 40.5 %\n",
      "6m 34s (- 29m 26s) (5400 18%) loss : 3.110  accuracy : 40.4 %\n",
      "6m 42s (- 29m 23s) (5500 18%) loss : 3.173  accuracy : 39.2 %\n",
      "6m 49s (- 29m 16s) (5600 18%) loss : 2.962  accuracy : 43.2 %\n",
      "6m 56s (- 29m 6s) (5700 19%) loss : 3.075  accuracy : 40.4 %\n",
      "7m 3s (- 28m 58s) (5800 19%) loss : 3.119  accuracy : 39.8 %\n",
      "7m 11s (- 28m 54s) (5900 19%) loss : 3.060  accuracy : 41.4 %\n",
      "7m 19s (- 28m 50s) (6000 20%) loss : 3.074  accuracy : 40.7 %\n",
      "7m 26s (- 28m 42s) (6100 20%) loss : 3.160  accuracy : 39.1 %\n",
      "7m 33s (- 28m 33s) (6200 20%) loss : 3.006  accuracy : 41.9 %\n",
      "7m 40s (- 28m 25s) (6300 21%) loss : 3.029  accuracy : 40.4 %\n",
      "7m 47s (- 28m 16s) (6400 21%) loss : 3.042  accuracy : 41.4 %\n",
      "7m 54s (- 28m 8s) (6500 21%) loss : 3.106  accuracy : 41.0 %\n",
      "8m 2s (- 28m 2s) (6600 22%) loss : 3.170  accuracy : 39.7 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 10s (- 27m 56s) (6700 22%) loss : 3.120  accuracy : 38.7 %\n",
      "8m 17s (- 27m 48s) (6800 22%) loss : 3.182  accuracy : 38.6 %\n",
      "8m 25s (- 27m 43s) (6900 23%) loss : 3.070  accuracy : 39.0 %\n",
      "8m 32s (- 27m 34s) (7000 23%) loss : 3.049  accuracy : 41.6 %\n",
      "8m 41s (- 27m 31s) (7100 23%) loss : 3.179  accuracy : 39.1 %\n",
      "8m 47s (- 27m 23s) (7200 24%) loss : 3.024  accuracy : 41.4 %\n",
      "8m 55s (- 27m 16s) (7300 24%) loss : 3.006  accuracy : 41.1 %\n",
      "9m 3s (- 27m 10s) (7400 24%) loss : 3.066  accuracy : 39.7 %\n",
      "9m 10s (- 27m 2s) (7500 25%) loss : 3.142  accuracy : 40.0 %\n",
      "9m 17s (- 26m 54s) (7600 25%) loss : 3.017  accuracy : 41.4 %\n",
      "9m 25s (- 26m 48s) (7700 26%) loss : 3.150  accuracy : 38.8 %\n",
      "9m 33s (- 26m 42s) (7800 26%) loss : 3.117  accuracy : 40.4 %\n",
      "9m 40s (- 26m 35s) (7900 26%) loss : 3.212  accuracy : 37.7 %\n",
      "9m 48s (- 26m 30s) (8000 27%) loss : 3.101  accuracy : 39.5 %\n",
      "9m 55s (- 26m 22s) (8100 27%) loss : 2.975  accuracy : 41.4 %\n",
      "10m 3s (- 26m 14s) (8200 27%) loss : 2.995  accuracy : 43.3 %\n",
      "10m 9s (- 26m 6s) (8300 28%) loss : 3.209  accuracy : 39.6 %\n",
      "10m 17s (- 25m 58s) (8400 28%) loss : 2.938  accuracy : 42.8 %\n",
      "10m 24s (- 25m 50s) (8500 28%) loss : 3.090  accuracy : 41.6 %\n",
      "10m 33s (- 25m 46s) (8600 29%) loss : 2.968  accuracy : 43.1 %\n",
      "10m 39s (- 25m 37s) (8700 29%) loss : 3.123  accuracy : 39.3 %\n",
      "10m 47s (- 25m 31s) (8800 29%) loss : 3.152  accuracy : 38.4 %\n",
      "10m 54s (- 25m 24s) (8900 30%) loss : 3.243  accuracy : 37.8 %\n",
      "11m 2s (- 25m 16s) (9000 30%) loss : 3.042  accuracy : 41.7 %\n",
      "11m 9s (- 25m 7s) (9100 30%) loss : 3.145  accuracy : 38.0 %\n",
      "11m 16s (- 25m 0s) (9200 31%) loss : 3.016  accuracy : 41.9 %\n",
      "11m 23s (- 24m 53s) (9300 31%) loss : 3.163  accuracy : 38.7 %\n",
      "11m 31s (- 24m 45s) (9400 31%) loss : 3.323  accuracy : 37.2 %\n",
      "11m 38s (- 24m 38s) (9500 32%) loss : 2.958  accuracy : 41.6 %\n",
      "11m 46s (- 24m 32s) (9600 32%) loss : 2.947  accuracy : 43.7 %\n",
      "11m 53s (- 24m 25s) (9700 32%) loss : 3.200  accuracy : 37.5 %\n",
      "12m 0s (- 24m 16s) (9800 33%) loss : 3.109  accuracy : 40.3 %\n",
      "12m 7s (- 24m 8s) (9900 33%) loss : 3.163  accuracy : 37.6 %\n",
      "12m 14s (- 24m 0s) (10000 33%) loss : 3.207  accuracy : 36.8 %\n",
      "12m 21s (- 23m 52s) (10100 34%) loss : 3.266  accuracy : 36.3 %\n",
      "12m 29s (- 23m 45s) (10200 34%) loss : 3.070  accuracy : 40.3 %\n",
      "12m 35s (- 23m 36s) (10300 34%) loss : 3.164  accuracy : 38.1 %\n",
      "12m 42s (- 23m 28s) (10400 35%) loss : 3.091  accuracy : 39.7 %\n",
      "12m 51s (- 23m 23s) (10500 35%) loss : 3.121  accuracy : 40.0 %\n",
      "12m 58s (- 23m 15s) (10600 35%) loss : 2.910  accuracy : 42.5 %\n",
      "13m 5s (- 23m 7s) (10700 36%) loss : 3.072  accuracy : 40.5 %\n",
      "13m 11s (- 22m 58s) (10800 36%) loss : 2.980  accuracy : 42.8 %\n",
      "13m 18s (- 22m 51s) (10900 36%) loss : 3.133  accuracy : 39.0 %\n",
      "13m 25s (- 22m 43s) (11000 37%) loss : 3.253  accuracy : 36.4 %\n",
      "13m 33s (- 22m 36s) (11100 37%) loss : 3.116  accuracy : 40.0 %\n",
      "13m 40s (- 22m 29s) (11200 37%) loss : 3.138  accuracy : 38.5 %\n",
      "13m 47s (- 22m 21s) (11300 38%) loss : 3.190  accuracy : 38.9 %\n",
      "13m 54s (- 22m 13s) (11400 38%) loss : 3.230  accuracy : 39.2 %\n",
      "14m 2s (- 22m 6s) (11500 38%) loss : 2.990  accuracy : 42.3 %\n",
      "14m 9s (- 21m 59s) (11600 39%) loss : 3.023  accuracy : 40.4 %\n",
      "14m 17s (- 21m 52s) (11700 39%) loss : 2.878  accuracy : 43.4 %\n",
      "14m 24s (- 21m 44s) (11800 39%) loss : 3.195  accuracy : 39.0 %\n",
      "14m 31s (- 21m 36s) (11900 40%) loss : 3.098  accuracy : 39.0 %\n",
      "14m 38s (- 21m 29s) (12000 40%) loss : 3.037  accuracy : 37.3 %\n",
      "14m 46s (- 21m 22s) (12100 40%) loss : 3.020  accuracy : 41.8 %\n",
      "14m 53s (- 21m 15s) (12200 41%) loss : 3.124  accuracy : 39.6 %\n",
      "15m 1s (- 21m 8s) (12300 41%) loss : 3.048  accuracy : 40.9 %\n",
      "15m 8s (- 21m 0s) (12400 41%) loss : 3.116  accuracy : 40.2 %\n",
      "15m 15s (- 20m 52s) (12500 42%) loss : 2.982  accuracy : 41.3 %\n",
      "15m 22s (- 20m 45s) (12600 42%) loss : 2.991  accuracy : 41.3 %\n",
      "15m 30s (- 20m 38s) (12700 42%) loss : 3.083  accuracy : 41.1 %\n",
      "15m 36s (- 20m 29s) (12800 43%) loss : 3.172  accuracy : 40.4 %\n",
      "15m 44s (- 20m 23s) (12900 43%) loss : 3.085  accuracy : 39.6 %\n",
      "15m 51s (- 20m 16s) (13000 43%) loss : 3.157  accuracy : 38.9 %\n",
      "15m 58s (- 20m 8s) (13100 44%) loss : 3.149  accuracy : 39.4 %\n",
      "16m 6s (- 20m 1s) (13200 44%) loss : 3.078  accuracy : 40.7 %\n",
      "16m 13s (- 19m 53s) (13300 44%) loss : 3.094  accuracy : 40.2 %\n",
      "16m 20s (- 19m 46s) (13400 45%) loss : 3.070  accuracy : 39.0 %\n",
      "16m 27s (- 19m 38s) (13500 45%) loss : 3.170  accuracy : 38.8 %\n",
      "16m 35s (- 19m 31s) (13600 45%) loss : 3.230  accuracy : 36.6 %\n",
      "16m 42s (- 19m 24s) (13700 46%) loss : 3.012  accuracy : 41.7 %\n",
      "16m 50s (- 19m 17s) (13800 46%) loss : 3.074  accuracy : 40.9 %\n",
      "16m 56s (- 19m 9s) (13900 46%) loss : 2.915  accuracy : 42.7 %\n",
      "17m 3s (- 19m 1s) (14000 47%) loss : 3.134  accuracy : 39.5 %\n",
      "17m 10s (- 18m 53s) (14100 47%) loss : 3.118  accuracy : 41.0 %\n",
      "17m 18s (- 18m 47s) (14200 47%) loss : 3.077  accuracy : 40.0 %\n",
      "17m 25s (- 18m 39s) (14300 48%) loss : 3.051  accuracy : 41.9 %\n",
      "17m 33s (- 18m 33s) (14400 48%) loss : 3.051  accuracy : 40.1 %\n",
      "17m 41s (- 18m 26s) (14500 48%) loss : 3.097  accuracy : 39.9 %\n",
      "17m 49s (- 18m 19s) (14600 49%) loss : 3.147  accuracy : 40.3 %\n",
      "17m 58s (- 18m 13s) (14700 49%) loss : 3.195  accuracy : 38.0 %\n",
      "18m 5s (- 18m 6s) (14800 49%) loss : 3.048  accuracy : 41.5 %\n",
      "18m 12s (- 17m 58s) (14900 50%) loss : 2.970  accuracy : 43.0 %\n",
      "18m 19s (- 17m 50s) (15000 50%) loss : 3.033  accuracy : 40.9 %\n",
      "18m 26s (- 17m 43s) (15100 50%) loss : 3.054  accuracy : 40.6 %\n",
      "18m 34s (- 17m 36s) (15200 51%) loss : 3.131  accuracy : 39.2 %\n",
      "18m 40s (- 17m 27s) (15300 51%) loss : 2.982  accuracy : 40.9 %\n",
      "18m 47s (- 17m 20s) (15400 52%) loss : 2.934  accuracy : 43.7 %\n",
      "18m 54s (- 17m 12s) (15500 52%) loss : 3.205  accuracy : 38.6 %\n",
      "19m 1s (- 17m 4s) (15600 52%) loss : 2.989  accuracy : 41.4 %\n",
      "19m 7s (- 16m 56s) (15700 53%) loss : 3.070  accuracy : 39.8 %\n",
      "19m 15s (- 16m 49s) (15800 53%) loss : 3.076  accuracy : 40.2 %\n",
      "19m 22s (- 16m 42s) (15900 53%) loss : 3.046  accuracy : 40.8 %\n",
      "19m 30s (- 16m 35s) (16000 54%) loss : 3.031  accuracy : 41.1 %\n",
      "19m 38s (- 16m 28s) (16100 54%) loss : 2.967  accuracy : 41.6 %\n",
      "19m 44s (- 16m 20s) (16200 54%) loss : 3.030  accuracy : 42.2 %\n",
      "19m 52s (- 16m 13s) (16300 55%) loss : 2.966  accuracy : 41.0 %\n",
      "19m 58s (- 16m 5s) (16400 55%) loss : 3.008  accuracy : 41.2 %\n",
      "20m 5s (- 15m 58s) (16500 55%) loss : 3.002  accuracy : 39.9 %\n",
      "20m 13s (- 15m 50s) (16600 56%) loss : 3.075  accuracy : 40.3 %\n",
      "20m 20s (- 15m 43s) (16700 56%) loss : 3.182  accuracy : 38.3 %\n",
      "20m 26s (- 15m 35s) (16800 56%) loss : 3.154  accuracy : 39.1 %\n",
      "20m 34s (- 15m 28s) (16900 57%) loss : 3.038  accuracy : 41.3 %\n",
      "20m 41s (- 15m 20s) (17000 57%) loss : 3.265  accuracy : 36.5 %\n",
      "20m 48s (- 15m 13s) (17100 57%) loss : 3.255  accuracy : 38.0 %\n",
      "20m 55s (- 15m 5s) (17200 58%) loss : 3.139  accuracy : 40.1 %\n",
      "21m 2s (- 14m 58s) (17300 58%) loss : 2.988  accuracy : 42.9 %\n",
      "21m 9s (- 14m 51s) (17400 58%) loss : 3.162  accuracy : 39.5 %\n",
      "21m 16s (- 14m 43s) (17500 59%) loss : 3.109  accuracy : 40.2 %\n",
      "21m 24s (- 14m 36s) (17600 59%) loss : 3.164  accuracy : 39.0 %\n",
      "21m 31s (- 14m 29s) (17700 59%) loss : 3.303  accuracy : 35.8 %\n",
      "21m 39s (- 14m 22s) (17800 60%) loss : 3.212  accuracy : 38.0 %\n",
      "21m 47s (- 14m 15s) (17900 60%) loss : 3.081  accuracy : 39.2 %\n",
      "21m 55s (- 14m 8s) (18000 60%) loss : 3.220  accuracy : 40.4 %\n",
      "22m 2s (- 14m 1s) (18100 61%) loss : 3.192  accuracy : 38.3 %\n",
      "22m 10s (- 13m 53s) (18200 61%) loss : 3.206  accuracy : 40.5 %\n",
      "22m 17s (- 13m 46s) (18300 61%) loss : 3.151  accuracy : 39.3 %\n",
      "22m 24s (- 13m 39s) (18400 62%) loss : 2.969  accuracy : 43.3 %\n",
      "22m 31s (- 13m 31s) (18500 62%) loss : 3.137  accuracy : 37.6 %\n",
      "22m 39s (- 13m 24s) (18600 62%) loss : 3.203  accuracy : 38.6 %\n",
      "22m 47s (- 13m 17s) (18700 63%) loss : 3.073  accuracy : 39.9 %\n",
      "22m 54s (- 13m 10s) (18800 63%) loss : 2.992  accuracy : 42.5 %\n",
      "23m 2s (- 13m 3s) (18900 63%) loss : 2.863  accuracy : 45.8 %\n",
      "23m 8s (- 12m 55s) (19000 64%) loss : 3.154  accuracy : 39.5 %\n",
      "23m 15s (- 12m 48s) (19100 64%) loss : 3.186  accuracy : 40.5 %\n",
      "23m 23s (- 12m 41s) (19200 64%) loss : 3.130  accuracy : 40.3 %\n",
      "23m 30s (- 12m 33s) (19300 65%) loss : 3.120  accuracy : 39.2 %\n",
      "23m 37s (- 12m 26s) (19400 65%) loss : 3.122  accuracy : 38.7 %\n",
      "23m 44s (- 12m 18s) (19500 65%) loss : 3.145  accuracy : 39.3 %\n",
      "23m 52s (- 12m 11s) (19600 66%) loss : 3.010  accuracy : 40.6 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24m 0s (- 12m 4s) (19700 66%) loss : 3.051  accuracy : 40.4 %\n",
      "24m 6s (- 11m 56s) (19800 66%) loss : 3.194  accuracy : 37.7 %\n",
      "24m 14s (- 11m 49s) (19900 67%) loss : 3.101  accuracy : 40.1 %\n",
      "24m 21s (- 11m 42s) (20000 67%) loss : 3.183  accuracy : 38.9 %\n",
      "24m 28s (- 11m 34s) (20100 67%) loss : 3.080  accuracy : 40.5 %\n",
      "24m 36s (- 11m 27s) (20200 68%) loss : 3.080  accuracy : 39.1 %\n",
      "24m 43s (- 11m 20s) (20300 68%) loss : 2.970  accuracy : 41.1 %\n",
      "24m 50s (- 11m 13s) (20400 68%) loss : 3.116  accuracy : 39.9 %\n",
      "24m 58s (- 11m 5s) (20500 69%) loss : 2.998  accuracy : 41.9 %\n",
      "25m 4s (- 10m 58s) (20600 69%) loss : 3.039  accuracy : 40.6 %\n",
      "25m 11s (- 10m 50s) (20700 69%) loss : 2.969  accuracy : 41.2 %\n",
      "25m 19s (- 10m 43s) (20800 70%) loss : 3.152  accuracy : 39.7 %\n",
      "25m 26s (- 10m 36s) (20900 70%) loss : 3.117  accuracy : 40.1 %\n",
      "25m 34s (- 10m 29s) (21000 70%) loss : 3.148  accuracy : 40.2 %\n",
      "25m 41s (- 10m 21s) (21100 71%) loss : 3.071  accuracy : 40.4 %\n",
      "25m 49s (- 10m 14s) (21200 71%) loss : 3.209  accuracy : 40.3 %\n",
      "25m 56s (- 10m 7s) (21300 71%) loss : 3.029  accuracy : 41.4 %\n",
      "26m 4s (- 10m 0s) (21400 72%) loss : 3.111  accuracy : 40.2 %\n",
      "26m 11s (- 9m 52s) (21500 72%) loss : 3.084  accuracy : 39.6 %\n",
      "26m 19s (- 9m 45s) (21600 72%) loss : 3.077  accuracy : 40.4 %\n",
      "26m 27s (- 9m 38s) (21700 73%) loss : 3.219  accuracy : 36.9 %\n",
      "26m 35s (- 9m 31s) (21800 73%) loss : 3.012  accuracy : 41.4 %\n",
      "26m 43s (- 9m 24s) (21900 73%) loss : 3.006  accuracy : 41.7 %\n",
      "26m 50s (- 9m 16s) (22000 74%) loss : 3.263  accuracy : 36.4 %\n",
      "26m 56s (- 9m 9s) (22100 74%) loss : 3.031  accuracy : 37.5 %\n",
      "27m 3s (- 9m 1s) (22200 74%) loss : 2.863  accuracy : 43.6 %\n",
      "27m 11s (- 8m 54s) (22300 75%) loss : 3.261  accuracy : 36.9 %\n",
      "27m 18s (- 8m 47s) (22400 75%) loss : 3.080  accuracy : 40.6 %\n",
      "27m 26s (- 8m 40s) (22500 75%) loss : 3.095  accuracy : 41.2 %\n",
      "27m 33s (- 8m 32s) (22600 76%) loss : 3.103  accuracy : 39.2 %\n",
      "27m 40s (- 8m 25s) (22700 76%) loss : 3.068  accuracy : 40.6 %\n",
      "27m 47s (- 8m 18s) (22800 77%) loss : 3.164  accuracy : 39.1 %\n",
      "27m 55s (- 8m 11s) (22900 77%) loss : 3.032  accuracy : 42.2 %\n",
      "28m 2s (- 8m 3s) (23000 77%) loss : 3.244  accuracy : 36.5 %\n",
      "28m 9s (- 7m 56s) (23100 78%) loss : 3.287  accuracy : 36.2 %\n",
      "28m 16s (- 7m 48s) (23200 78%) loss : 3.145  accuracy : 40.2 %\n",
      "28m 24s (- 7m 41s) (23300 78%) loss : 3.025  accuracy : 42.2 %\n",
      "28m 32s (- 7m 34s) (23400 79%) loss : 2.928  accuracy : 43.4 %\n",
      "28m 39s (- 7m 27s) (23500 79%) loss : 3.158  accuracy : 36.9 %\n",
      "28m 46s (- 7m 19s) (23600 79%) loss : 3.175  accuracy : 39.2 %\n",
      "28m 54s (- 7m 12s) (23700 80%) loss : 3.108  accuracy : 39.6 %\n",
      "29m 2s (- 7m 5s) (23800 80%) loss : 3.207  accuracy : 39.3 %\n",
      "29m 8s (- 6m 57s) (23900 80%) loss : 3.221  accuracy : 38.0 %\n",
      "29m 15s (- 6m 50s) (24000 81%) loss : 3.069  accuracy : 41.5 %\n",
      "29m 23s (- 6m 43s) (24100 81%) loss : 3.223  accuracy : 37.1 %\n",
      "29m 31s (- 6m 35s) (24200 81%) loss : 3.111  accuracy : 40.5 %\n",
      "29m 38s (- 6m 28s) (24300 82%) loss : 3.145  accuracy : 40.4 %\n",
      "29m 46s (- 6m 21s) (24400 82%) loss : 2.995  accuracy : 42.1 %\n",
      "29m 53s (- 6m 14s) (24500 82%) loss : 3.162  accuracy : 38.9 %\n",
      "30m 1s (- 6m 6s) (24600 83%) loss : 3.074  accuracy : 41.4 %\n",
      "30m 7s (- 5m 59s) (24700 83%) loss : 2.840  accuracy : 42.9 %\n",
      "30m 15s (- 5m 52s) (24800 83%) loss : 3.046  accuracy : 41.1 %\n",
      "30m 21s (- 5m 44s) (24900 84%) loss : 3.031  accuracy : 41.6 %\n",
      "30m 29s (- 5m 37s) (25000 84%) loss : 3.094  accuracy : 40.3 %\n",
      "30m 35s (- 5m 29s) (25100 84%) loss : 3.067  accuracy : 41.4 %\n",
      "30m 43s (- 5m 22s) (25200 85%) loss : 3.103  accuracy : 40.0 %\n",
      "30m 50s (- 5m 15s) (25300 85%) loss : 3.312  accuracy : 36.5 %\n",
      "30m 58s (- 5m 7s) (25400 85%) loss : 3.250  accuracy : 37.4 %\n",
      "31m 5s (- 5m 0s) (25500 86%) loss : 3.017  accuracy : 41.6 %\n",
      "31m 13s (- 4m 53s) (25600 86%) loss : 3.107  accuracy : 40.6 %\n",
      "31m 21s (- 4m 46s) (25700 86%) loss : 2.952  accuracy : 43.3 %\n",
      "31m 28s (- 4m 38s) (25800 87%) loss : 3.172  accuracy : 39.4 %\n",
      "31m 35s (- 4m 31s) (25900 87%) loss : 3.112  accuracy : 39.8 %\n",
      "31m 42s (- 4m 24s) (26000 87%) loss : 3.180  accuracy : 39.7 %\n",
      "31m 50s (- 4m 16s) (26100 88%) loss : 3.127  accuracy : 41.9 %\n",
      "31m 57s (- 4m 9s) (26200 88%) loss : 3.193  accuracy : 39.6 %\n",
      "32m 5s (- 4m 2s) (26300 88%) loss : 3.159  accuracy : 39.0 %\n",
      "32m 12s (- 3m 54s) (26400 89%) loss : 2.923  accuracy : 42.7 %\n",
      "32m 19s (- 3m 47s) (26500 89%) loss : 3.127  accuracy : 40.5 %\n",
      "32m 26s (- 3m 40s) (26600 89%) loss : 3.108  accuracy : 40.6 %\n",
      "32m 34s (- 3m 32s) (26700 90%) loss : 3.045  accuracy : 41.2 %\n",
      "32m 41s (- 3m 25s) (26800 90%) loss : 3.080  accuracy : 42.4 %\n",
      "32m 48s (- 3m 18s) (26900 90%) loss : 3.090  accuracy : 39.8 %\n",
      "32m 57s (- 3m 11s) (27000 91%) loss : 3.198  accuracy : 38.6 %\n",
      "33m 4s (- 3m 3s) (27100 91%) loss : 3.162  accuracy : 39.6 %\n",
      "33m 11s (- 2m 56s) (27200 91%) loss : 2.980  accuracy : 42.0 %\n",
      "33m 18s (- 2m 49s) (27300 92%) loss : 2.975  accuracy : 41.6 %\n",
      "33m 27s (- 2m 41s) (27400 92%) loss : 3.043  accuracy : 40.9 %\n",
      "33m 34s (- 2m 34s) (27500 92%) loss : 2.922  accuracy : 43.8 %\n",
      "33m 42s (- 2m 27s) (27600 93%) loss : 2.951  accuracy : 42.9 %\n",
      "33m 50s (- 2m 20s) (27700 93%) loss : 3.039  accuracy : 41.9 %\n",
      "33m 57s (- 2m 12s) (27800 93%) loss : 3.060  accuracy : 40.6 %\n",
      "34m 4s (- 2m 5s) (27900 94%) loss : 3.118  accuracy : 38.3 %\n",
      "34m 11s (- 1m 57s) (28000 94%) loss : 3.162  accuracy : 38.0 %\n",
      "34m 18s (- 1m 50s) (28100 94%) loss : 3.079  accuracy : 41.2 %\n",
      "34m 25s (- 1m 43s) (28200 95%) loss : 3.155  accuracy : 38.8 %\n",
      "34m 32s (- 1m 35s) (28300 95%) loss : 3.266  accuracy : 38.0 %\n",
      "34m 41s (- 1m 28s) (28400 95%) loss : 2.992  accuracy : 43.7 %\n",
      "34m 48s (- 1m 21s) (28500 96%) loss : 3.097  accuracy : 40.3 %\n",
      "34m 54s (- 1m 13s) (28600 96%) loss : 3.123  accuracy : 40.0 %\n",
      "35m 2s (- 1m 6s) (28700 96%) loss : 3.216  accuracy : 38.3 %\n",
      "35m 10s (- 0m 59s) (28800 97%) loss : 3.009  accuracy : 40.5 %\n",
      "35m 16s (- 0m 52s) (28900 97%) loss : 3.156  accuracy : 38.0 %\n",
      "35m 24s (- 0m 44s) (29000 97%) loss : 3.083  accuracy : 39.4 %\n",
      "35m 32s (- 0m 37s) (29100 98%) loss : 3.205  accuracy : 39.3 %\n",
      "35m 39s (- 0m 30s) (29200 98%) loss : 2.989  accuracy : 42.5 %\n",
      "35m 46s (- 0m 22s) (29300 98%) loss : 2.962  accuracy : 41.2 %\n",
      "35m 54s (- 0m 15s) (29400 99%) loss : 3.103  accuracy : 39.6 %\n",
      "36m 2s (- 0m 8s) (29500 99%) loss : 3.144  accuracy : 39.3 %\n",
      "36m 9s (- 0m 0s) (29600 99%) loss : 3.179  accuracy : 39.5 %\n"
     ]
    }
   ],
   "source": [
    "denoiser.fit(batches, epochs = 1, lr = 0.01,   print_every = 100)\n",
    "denoiser.fit(batches, epochs = 1, lr = 0.0025, print_every = 100)\n",
    "denoiser.fit(batches, epochs = 1, lr = 0.0005, print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(denoiser.state_dict(), path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser_2.pth')\n",
    "\n",
    "# load\n",
    "#denoiser.load_state_dict(torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.eval()\n",
    "sentence = random.choice(corpus)\n",
    "i = random.choice(range(int(len(sentence)/2)))\n",
    "sentence = ' '.join(sentence[:i]) if i > 0 else '.'\n",
    "language_model(sentence, limit = '.', color_code = '\\x1b[48;2;255;229;217m') #  '\\x1b[48;2;255;229;217m' '\\x1b[31m'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
