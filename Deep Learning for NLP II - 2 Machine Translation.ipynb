{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part II - 2 <br><br><br>\n",
    "  Machine Translation\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. Text Classification\n",
    "\n",
    "2. <font color=red>**Machine Translation**</font>\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.3.1\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\libDL4NLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus est donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Normalisation -------------------------------\n",
    "def normalizeString(s):\n",
    "    '''Remove rare symbols from a string'''\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    " \n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9?&\\%\\-\\_]+\", r\" \", s) \n",
    "    s = re.sub(\"\\(\", r\" ( \", s)\n",
    "    s = re.sub(\"\\)\", r\" ) \", s)\n",
    "    s = re.sub(r\"\\.\", r\" . \", s)\n",
    "    s = re.sub(r\",\", r\" , \", s)\n",
    "    s = re.sub(r\"!\", r\" ! \", s)\n",
    "    s = re.sub(r\":\", r\" : \", s)\n",
    "    s = re.sub(r\"-\", r\" - \", s)\n",
    "    s = re.sub(r\"'\", r\" ' \", s)\n",
    "    s = re.sub(r\";\", r\" ; \", s)\n",
    "    s = re.sub(r' +', r' ', s).strip()\n",
    "    return s \n",
    "\n",
    "\n",
    "\n",
    "#--------------------- import des dialogues --------------------\n",
    "def importDialogues(path, limit = None):\n",
    "    '''Import a textfile containing dialogues and returns a list, each element \n",
    "       corresponding to a dialogue and also being under the form of a list, with \n",
    "       each element being a list of two elements : an element giving a user \n",
    "       utterance and another element giving the bot response. Both elements are \n",
    "       normalized strings.\n",
    "       Ex. The dialogue :\n",
    "       \n",
    "               hi    hello what can i help you with today\n",
    "               can you book a table    i m on it\n",
    "               \n",
    "       now becomes :\n",
    "       \n",
    "              [['hi', 'hello what can i help you with today'], \n",
    "               ['can you book a table', 'i m on it']]\n",
    "               \n",
    "       Lines corresponding to user utterance with no bot response are discarted.\n",
    "    '''\n",
    "    def cleanS(s):\n",
    "        cleans = normalizeString(s)\n",
    "        cleans = cleans.replace('?', ' ? ').strip()\n",
    "        return cleans\n",
    "    \n",
    "    dialogues = []\n",
    "    dialogues_import = open(path, encoding='utf-8').read().strip().split('\\n\\n')\n",
    "    for i, d in enumerate(dialogues_import):\n",
    "        dialogue = []\n",
    "        lines = d.split('\\n')\n",
    "        for l in lines:\n",
    "            if len(l.split('\\t')) == 2 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')]\n",
    "                dialogue.append(pair)\n",
    "            elif len(l.split('\\t')) == 3 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')[:2]]\n",
    "                dialogue.append(pair)\n",
    "        dialogues.append(dialogue)\n",
    "        if limit is not None and i == limit -1 : break\n",
    "    return dialogues\n",
    "\n",
    "\n",
    "def getUniqueQAs(dialogues) :\n",
    "    uniq = []\n",
    "    for qa in dialogues :\n",
    "        if qa not in uniq : uniq.append(qa)\n",
    "    return uniq\n",
    "\n",
    "\n",
    "\n",
    "#------------------ Dictionnaire des mots variables -----------------------------\n",
    "def motVar(file):\n",
    "    '''Applies to the Master's program dataset.\n",
    "       Import the collection of pairs token-content for a set of variable words.\n",
    "    '''\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "    motsVar = {}\n",
    "    for l in lines :\n",
    "        cle, valeur = l.split('\\t')\n",
    "        motsVar[cle.lower()] = valeur\n",
    "    return motsVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motsVar    = motVar(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_07\\\\chatbot-M2-DS-Variables.txt')\n",
    "dialogues  = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Train.tsv')\n",
    "dialogues_tst = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200224 20561\n"
     ]
    }
   ],
   "source": [
    "qa_trn = [qa for dialogue in dialogues for qa in dialogue] # getUniqueQAs(\n",
    "qa_tst = [qa for dialogue in dialogues_tst for qa in dialogue] # getUniqueQAs(\n",
    "\n",
    "print(len(qa_trn), len(qa_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il vaut mieux suivre quel parcours  ? \t les deux parcours sont equivalents , c ' est a vous de faire un choix .\n",
      "quand est ce que commence les cours  ? \t la rentree est le daterentree\n",
      "comment je prend contact avec la scolarite  ? \t les contacts de la scolarite sont accessibles sur : sitescolarite\n",
      "est ce que il y a des cours en anglais  ? \t plusieurs supports de cours sont en anglais\n",
      "tous les cours sont obligatoires  ? \t tous les cours sont obligatoires , il n ' existe pas d ' options .\n",
      "merci pour les renseignements \t je vous en prie\n",
      "peux tu m ' aider  ? \t je suis la pour vous renseigner sur le master 2 data science .\n",
      "le cours de data visualisation est - il en ligne  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "j ' ai envie de faire de la data science \t alors vous devriez songer a candidater a ce master !\n",
      "il y a des livres a lire en statistique  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "il y a combien de candidats  ? \t il y a plus de nbrcandidats candidats chaque annee , la selection est rude !\n",
      "combien de places sont ouvertes  ? \t souhaitez - vous suivre le parcours informatique ou mathematiques  ?\n",
      "informatique \t etes - vous un etudiant inscrit en france  ?\n",
      "non \t il y a nbreplaces_hors_france_informatique places disponibles pour les etudiants hors france en parcours informatique .\n",
      "comment je peux payer  ? \t vous pouvez payer par carte , par cheque bancaire , par virement ou en espece .\n",
      "avez - vous une maquette detaillee de ce master  ? \t les details de la formation est disponible sur la page du master parcours informatique : site_informatique\n",
      "comment ca va  ? \t je vais bien merci , en quoi puis - je vous aider  ?\n"
     ]
    }
   ],
   "source": [
    "for qa in dialogues[0] : print(qa[0], '\\t', qa[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1** : Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "#word2vec_in  = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_w2v_in_M2DS.pt')\n",
    "#word2vec_out = torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_w2v_out_M2DS.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** : Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_in  = [['SOS'] + [w for w in qa[0].split(' ')] + ['EOS'] for qa in qa_trn]\n",
    "corpus_out = [['SOS'] + [w for w in qa[1].split(' ')] + ['EOS'] for qa in qa_trn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareWord2vec(corpus, epochs) :\n",
    "    fastText_word2vec = FastText(size = 75, \n",
    "                                 window = 5, \n",
    "                                 min_count = 1, \n",
    "                                 negative = 20,\n",
    "                                 sg = 1)\n",
    "    fastText_word2vec.build_vocab(corpus)\n",
    "    print(len(fastText_word2vec.wv.vocab))\n",
    "    fastText_word2vec.train(sentences = corpus, \n",
    "                            epochs = epochs,\n",
    "                            total_examples = fastText_word2vec.corpus_count)\n",
    "    word2vec = Word2VecConnector(fastText_word2vec)\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "word2vec_in  = prepareWord2vec(corpus_in, epochs = 20)\n",
    "word2vec_out = prepareWord2vec(corpus_out, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonjour', 0.9804752469062805),\n",
       " ('mal', 0.8117103576660156),\n",
       " ('bien', 0.6764619946479797),\n",
       " ('principal', 0.672505259513855),\n",
       " ('principalement', 0.5881912112236023),\n",
       " ('english', 0.578591525554657),\n",
       " ('handle', 0.5670300722122192),\n",
       " ('coucou', 0.5658980011940002),\n",
       " ('ok', 0.5612411499023438),\n",
       " ('speak', 0.5596966743469238)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_in.word2vec.most_similar('bonjou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonjour', 0.968519926071167),\n",
       " ('accord', 0.7767391204833984),\n",
       " ('comment', 0.6192842721939087),\n",
       " ('aider', 0.5911822319030762),\n",
       " ('accordez', 0.5513397455215454),\n",
       " ('vais', 0.4964368939399719),\n",
       " ('puis', 0.4900757372379303),\n",
       " ('gardez', 0.48046615719795227),\n",
       " ('merci', 0.4791063368320465),\n",
       " ('test', 0.47400200366973877)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_out.word2vec.most_similar('bonjou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(word2vec_in, path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_w2v_in_M2DS.pt')\n",
    "#torch.save(word2vec_out, path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_w2v_out_M2DS.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "We use here a classical Attention Module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Decoder module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"decoder\"></a>\n",
    "\n",
    "#### 1.4.1 Classical Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, word2vec, hidden_dim, \n",
    "                 n_layers = 1,\n",
    "                 dropout = 0.1,\n",
    "                 bound = 25\n",
    "                ):\n",
    "        super(Decoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bound = bound\n",
    "        # modules\n",
    "        self.word2vec = word2vec\n",
    "        self.gru = nn.GRU(word2vec.output_dim, \n",
    "                          hidden_dim, \n",
    "                          n_layers, \n",
    "                          dropout = dropout, \n",
    "                          batch_first = True)\n",
    "        self.out = nn.Linear(hidden_dim, word2vec.lang.n_words)\n",
    "        self.act = F.log_softmax\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generateWord(self, hidden, embeddings, word_index):\n",
    "        # update hidden state\n",
    "        embedding = self.word2vec.embedding(word_index) # size (batch_size, 1, embedding_dim)\n",
    "        embedding = self.dropout(embedding)\n",
    "        _, hidden = self.gru(embedding, hidden)         # size (n_layers, batch_size, embedding_dim)\n",
    "        # generate next word\n",
    "        log_prob = self.out(hidden[-1])                 # size (batch_size, lang_size)\n",
    "        log_prob = self.act(log_prob, dim = 1)          # size (batch_size, lang_size)\n",
    "        return log_prob, hidden\n",
    "    \n",
    "    def forward(self, hidden, embeddings = None, device = None) :\n",
    "        answer = []\n",
    "        EOS_token  = self.word2vec.lang.getIndex('EOS')\n",
    "        word = self.word2vec.lang.getIndex('SOS')\n",
    "        word = Variable(torch.LongTensor([[word]])) # size (1)\n",
    "        hidden = hidden[-self.n_layers:]\n",
    "        for t in range(self.bound) :\n",
    "            # compute next word\n",
    "            if device is not None : word = word.to(device) # size (1)\n",
    "            log_prob, hidden = self.generateWord(hidden, embeddings, word)\n",
    "            word = log_prob.topk(1, dim = 1)[1].view(1, 1)\n",
    "            # add to output\n",
    "            if word.item() == EOS_token : break\n",
    "            else : answer.append(word.item())\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Attention Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, word2vec, attention_dim, hidden_dim,\n",
    "                 n_layers = 1,\n",
    "                 dropout = 0.1,\n",
    "                 bound = 25\n",
    "                ):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bound = bound\n",
    "        # modules\n",
    "        self.word2vec = word2vec\n",
    "        self.gru = nn.GRU(word2vec.output_dim, \n",
    "                          hidden_dim, \n",
    "                          n_layers, \n",
    "                          dropout = dropout, \n",
    "                          batch_first = True)\n",
    "        self.attn = Attention(attention_dim, hidden_dim, dropout = dropout)\n",
    "        self.out = nn.Linear(attention_dim + hidden_dim, word2vec.lang.n_words)\n",
    "        self.act = F.log_softmax\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generateWord(self, hidden, embeddings, word_index):\n",
    "        # update hidden state\n",
    "        embedding = self.word2vec.embedding(word_index) # size (batch_size, 1, embedding_dim)\n",
    "        embedding = self.dropout(embedding)\n",
    "        _, hidden = self.gru(embedding, hidden)         # size (n_layers, batch_size, embedding_dim)\n",
    "        # merge with attention\n",
    "        query = hidden[-1].unsqueeze(1)                 # size (batch_size, 1, embedding_dim)\n",
    "        attn, weights = self.attn(embeddings, query)    # size (batch_size, 1, embedding_dim)\n",
    "        merge = torch.cat([hidden[-1], attn.squeeze(1)], dim = 1) \n",
    "        merge = self.dropout(merge)                     # size (batch_size, embedding_dim + hidden_dim)\n",
    "        # generate next word\n",
    "        log_prob = self.out(merge)                      # size (batch_size, lang_size)\n",
    "        log_prob = self.act(log_prob, dim = 1)          # size (batch_size, lang_size)\n",
    "        return log_prob, hidden, weights\n",
    "    \n",
    "    def forward(self, hidden, embeddings, device = None) :\n",
    "        answer  = []\n",
    "        EOS_token  = self.word2vec.lang.getIndex('EOS')\n",
    "        word = self.word2vec.lang.getIndex('SOS')\n",
    "        word = Variable(torch.LongTensor([[word]])) # size (1)\n",
    "        hidden = hidden[-self.n_layers:]\n",
    "        for t in range(self.bound) :\n",
    "            # compute next word\n",
    "            if device is not None : word = word.to(device) # size (1)\n",
    "            log_prob, hidden, atn = self.generateWord(hidden, embeddings, word)\n",
    "            word = log_prob.topk(1, dim = 1)[1].view(1, 1)\n",
    "            # add to output\n",
    "            if word.item() == EOS_token : break\n",
    "            else : answer.append(word.item())\n",
    "            # cumulate attention weights\n",
    "            if t == 0 : weights = atn\n",
    "            else      : weights = torch.cat((weights, atn), dim = 1) # size(1, output_length, input_length)\n",
    "        return answer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of attention\n",
    "\n",
    "Taken from [this page](https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.utils import heatmap, annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# single attention head over a sequence of words\n",
    "def heatmap(data, row_labels, col_labels, ax = None, cbar_kw = {}, cbarlabel = \"\", **kwargs):\n",
    "    if not ax: ax = plt.gca()\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    return im\n",
    "\n",
    "def annotate_heatmap(im, data = None, valfmt = \"{x:.2f}\", textcolors = [\"black\", \"white\"], threshold = None, **textkw):\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Machine Translation Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec_in, word2vec_out, \n",
    "                 hidden_dim_in = 50,\n",
    "                 hidden_dim_out = 50,\n",
    "                 n_layers_in = 1,\n",
    "                 n_layers_out = 1,\n",
    "                 bound = 25,\n",
    "                 dropout = 0,\n",
    "                 decoder_warm_start = True,\n",
    "                 decoder_attention = True,\n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        #relevant quantities\n",
    "        self.decoder_warm_start = decoder_warm_start\n",
    "        \n",
    "        # modules\n",
    "        self.tokenizer    = tokenizer\n",
    "        self.word2vec_in  = word2vec_in\n",
    "        self.word2vec_out = word2vec_out\n",
    "        self.context      = RecurrentEncoder(word2vec_in.output_dim, hidden_dim_in, n_layers_in, dropout, bidirectional = True)\n",
    "        if decoder_attention : self.decoder = AttnDecoder(word2vec_out, hidden_dim_in, hidden_dim_out, n_layers_out, dropout, bound)\n",
    "        else :                 self.decoder = Decoder(word2vec_out, hidden_dim_out, n_layers_out, dropout, bound)\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index_in  = self.word2vec_in.lang.getIndex('PADDING_WORD')\n",
    "        self.ignore_index_out = self.word2vec_out.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, ignore_index = self.ignore_index_out)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def showAttention(self, words_in, words_out, attn) :\n",
    "        attn = np.array(attn[0].transpose(0, 1).data.cpu().numpy()) # size (input_length, output_length)\n",
    "        fig, ax  = plt.subplots()\n",
    "        im       = heatmap(attn,  words_in, words_out, ax=ax, cmap=\"YlGn\", cbarlabel=\"harvest [t/year]\")\n",
    "        texts    = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    def forward(self, sentence, show_attention = False):\n",
    "        # encode sentence\n",
    "        words = self.tokenizer(sentence)\n",
    "        words = [w for w in words if self.word2vec_in.lang.getIndex(w) is not None]\n",
    "        indices = [self.word2vec_in.lang.getIndex(w) for w in words]\n",
    "        embeddings = Variable(torch.LongTensor([indices])).to(self.device)\n",
    "        embeddings = self.word2vec_in.embedding(embeddings)\n",
    "        #embeddings = self.word2vec_in(words, self.device)\n",
    "        embeddings, hidden  = self.context(embeddings)\n",
    "        # prepare for decoding\n",
    "        if self.decoder_warm_start :\n",
    "            if self.context.bidirectional :\n",
    "                hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "            hidden = hidden[-self.decoder.n_layers:]\n",
    "        else : hidden = None    \n",
    "        ## compute answer\n",
    "        indices, atn = self.decoder(hidden, embeddings, self.device)\n",
    "        words_out = [self.word2vec_out.lang.index2word[i] for i in indices]\n",
    "        answer = ' '.join(words_out)\n",
    "        if show_attention : self.showAttention(words, words_out, atn)\n",
    "        return answer\n",
    "\n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) : \n",
    "        sentences.sort(key = lambda s: len(s[1]), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            # prepare input and target pack\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            pack.sort(key = lambda s: len(self.tokenizer(s[0])), reverse = True)\n",
    "            pack0 = [[self.word2vec_in.lang.getIndex(w) for w in self.tokenizer(qa[0])] for qa in pack]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack1 = [[self.word2vec_out.lang.getIndex(w) for w in self.tokenizer(qa[1]) + ['EOS']] for qa in pack]\n",
    "            pack1 = [[w for w in words if w is not None] for words in pack1]\n",
    "            lengths0 = torch.tensor([len(p) for p in pack0])           # size (batch_size) \n",
    "            lengths1 = torch.tensor([len(p) for p in pack1])           # size (batch_size) \n",
    "            # padd packs\n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index_in))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1)) # size (batch_size, max_length0) \n",
    "            pack1 = list(itertools.zip_longest(*pack1, fillvalue = self.ignore_index_out))\n",
    "            pack1 = Variable(torch.LongTensor(pack1))       # WARNING : size (max_length1, batch_size) \n",
    "            packed_data.append([pack0, lengths0, pack1, lengths1])\n",
    "        return packed_data\n",
    "    \n",
    "    def compute_accuracy(self, sentences, batch_size = 32) :\n",
    "        batches = self.generatePackedSentences(sentences, batch_size)\n",
    "        score = 0\n",
    "        for batch in batches :\n",
    "            input, input_l, target, target_l = batch\n",
    "            # encode sentences\n",
    "            embeddings = self.word2vec_in.embedding(input.to(self.device))\n",
    "            embeddings, hidden = self.context(embeddings, lengths = input_l.to(self.device)) # size (n_layers * num_directions, batch_size, hidden_dim)\n",
    "            # prepare for decoding\n",
    "            if self.decoder_warm_start :\n",
    "                if self.context.bidirectional :\n",
    "                    hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                    hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "                hidden = hidden[-self.decoder.n_layers:]\n",
    "            else : hidden = None  \n",
    "            # compute answers\n",
    "            answers = torch.zeros(target.size())\n",
    "            word_index = self.word2vec_out.lang.getIndex('SOS')\n",
    "            word_index = Variable(torch.LongTensor([word_index])) # size (1)\n",
    "            word_index = word_index.expand(target.size(1))        # size (batch_size)\n",
    "            for t in range(target.size(0)) :\n",
    "                # compute word probs\n",
    "                log_prob, hidden, atn = self.decoder.generateWord(hidden, embeddings, word_index.unsqueeze(1).to(self.device))\n",
    "                word_index = log_prob.topk(1, dim = 1)[1].view(-1) # size (batch_size)\n",
    "                answers[t] = word_index\n",
    "            # update score\n",
    "            score += sum([sum(answers[i, :l].data == target[i, :l].data) == l for i, l in enumerate(target_l.data.cpu().tolist())]).item()\n",
    "        return score * 100 / len(sentences)\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, tf_ratio = 0, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeSuccess(log_probs, targets) :\n",
    "            success = sum([self.ignore_index_out != targets[i].item() == log_probs[i].topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0))])\n",
    "            return success\n",
    "        \n",
    "        def computeLogProbs(batch, tf_ratio = 0, compute_accuracy = True) :\n",
    "            loss = 0\n",
    "            success = 0\n",
    "            forcing = (random.random() < tf_ratio)\n",
    "            input, input_l, target, target_l = batch\n",
    "            # encode sentences\n",
    "            embeddings = self.word2vec_in.embedding(input.to(self.device))\n",
    "            embeddings, hidden  = self.context(embeddings, lengths = input_l.to(self.device)) # size (n_layers * num_directions, batch_size, hidden_dim)\n",
    "            # prepare for decoding\n",
    "            if self.decoder_warm_start :\n",
    "                if self.context.bidirectional :\n",
    "                    hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                    hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "                hidden = hidden[-self.decoder.n_layers:]\n",
    "            else : hidden = None  \n",
    "            # compute answers\n",
    "            word_index = self.word2vec_out.lang.getIndex('SOS')\n",
    "            word_index = Variable(torch.LongTensor([word_index])) # size (1)\n",
    "            word_index = word_index.expand(target.size(1))        # size (batch_size)\n",
    "            for t in range(target.size(0)) :\n",
    "                # compute word probs\n",
    "                log_prob, hidden, atn = self.decoder.generateWord(hidden, embeddings, word_index.unsqueeze(1).to(self.device))\n",
    "                # compute loss\n",
    "                loss += self.criterion(log_prob, target[t])\n",
    "                if compute_accuracy : success += computeSuccess(log_prob, target[t])\n",
    "                # apply teacher forcing\n",
    "                if forcing : word_index = target[t]                             # size (batch_size) \n",
    "                else       : word_index = log_prob.topk(1, dim = 1)[1].view(-1) # size (batch_size)\n",
    "            return loss, success       \n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, tf_ratio = 0, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            total = torch.sum(batch[-1]).item()\n",
    "            loss, success = computeLogProbs(batch, tf_ratio, compute_accuracy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return float(loss.item() / total), float(success * 100 / total)\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(qa[1].split(' ')) for qa in qa_trn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601597"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = EncoderDecoder(device = torch.device(\"cpu\"),\n",
    "                         tokenizer = lambda s : normalizeString(s).split(' '),\n",
    "                         word2vec_in = word2vec_in,\n",
    "                         word2vec_out = word2vec_out,\n",
    "                         hidden_dim_in = 100,\n",
    "                         hidden_dim_out = 100,\n",
    "                         n_layers_in = 2,\n",
    "                         n_layers_out = 2,\n",
    "                         bound = 75,\n",
    "                         dropout = 0.1,\n",
    "                         decoder_warm_start = True,\n",
    "                         decoder_attention = True,\n",
    "                         optimizer = optim.SGD)\n",
    "\n",
    "chatbot.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (word2vec_in): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(784, 75)\n",
       "    )\n",
       "    (embedding): Embedding(784, 75)\n",
       "  )\n",
       "  (word2vec_out): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (embedding): Embedding(898, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (bigru): GRU(75, 100, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): AttnDecoder(\n",
       "    (word2vec): Word2VecConnector(\n",
       "      (twin): Word2Vec(\n",
       "        (embedding): Embedding(898, 75)\n",
       "      )\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (gru): GRU(75, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (attn): Attention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "      (attn_v): Linear(in_features=100, out_features=1, bias=False)\n",
       "    )\n",
       "    (out): Linear(in_features=200, out_features=897, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6257"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = chatbot.generatePackedSentences(qa_trn, batch_size = 32)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 20s (- 21m 6s) (100 1%) loss : 5.807  accuracy : 6.7 %\n",
      "0m 40s (- 20m 25s) (200 3%) loss : 5.086  accuracy : 10.2 %\n",
      "1m 0s (- 20m 1s) (300 4%) loss : 4.558  accuracy : 16.5 %\n",
      "1m 20s (- 19m 41s) (400 6%) loss : 4.209  accuracy : 24.3 %\n",
      "1m 39s (- 19m 4s) (500 7%) loss : 3.557  accuracy : 33.8 %\n",
      "1m 59s (- 18m 45s) (600 9%) loss : 3.323  accuracy : 38.9 %\n",
      "2m 19s (- 18m 31s) (700 11%) loss : 2.926  accuracy : 45.6 %\n",
      "2m 41s (- 18m 24s) (800 12%) loss : 2.683  accuracy : 51.3 %\n",
      "3m 3s (- 18m 10s) (900 14%) loss : 2.605  accuracy : 49.4 %\n",
      "3m 22s (- 17m 46s) (1000 15%) loss : 2.185  accuracy : 56.5 %\n",
      "3m 43s (- 17m 29s) (1100 17%) loss : 2.090  accuracy : 58.8 %\n",
      "4m 3s (- 17m 5s) (1200 19%) loss : 2.125  accuracy : 58.5 %\n",
      "4m 23s (- 16m 45s) (1300 20%) loss : 1.914  accuracy : 60.5 %\n",
      "4m 44s (- 16m 27s) (1400 22%) loss : 1.991  accuracy : 58.6 %\n",
      "5m 3s (- 16m 3s) (1500 23%) loss : 1.343  accuracy : 71.4 %\n",
      "5m 22s (- 15m 39s) (1600 25%) loss : 1.496  accuracy : 68.3 %\n",
      "5m 41s (- 15m 16s) (1700 27%) loss : 1.467  accuracy : 68.5 %\n",
      "6m 0s (- 14m 53s) (1800 28%) loss : 1.319  accuracy : 72.0 %\n",
      "6m 20s (- 14m 32s) (1900 30%) loss : 1.234  accuracy : 73.5 %\n",
      "6m 40s (- 14m 11s) (2000 31%) loss : 1.162  accuracy : 74.5 %\n",
      "7m 0s (- 13m 52s) (2100 33%) loss : 1.138  accuracy : 74.4 %\n",
      "7m 21s (- 13m 33s) (2200 35%) loss : 1.206  accuracy : 73.7 %\n",
      "7m 40s (- 13m 12s) (2300 36%) loss : 1.351  accuracy : 70.9 %\n",
      "8m 0s (- 12m 52s) (2400 38%) loss : 1.018  accuracy : 76.8 %\n",
      "8m 21s (- 12m 34s) (2500 39%) loss : 0.989  accuracy : 77.7 %\n",
      "8m 41s (- 12m 13s) (2600 41%) loss : 0.823  accuracy : 81.3 %\n",
      "8m 59s (- 11m 50s) (2700 43%) loss : 0.904  accuracy : 79.3 %\n",
      "9m 19s (- 11m 30s) (2800 44%) loss : 0.709  accuracy : 83.0 %\n",
      "9m 39s (- 11m 10s) (2900 46%) loss : 0.689  accuracy : 83.8 %\n",
      "10m 0s (- 10m 51s) (3000 47%) loss : 0.634  accuracy : 84.7 %\n",
      "10m 20s (- 10m 31s) (3100 49%) loss : 0.781  accuracy : 81.9 %\n",
      "10m 39s (- 10m 10s) (3200 51%) loss : 0.530  accuracy : 87.3 %\n",
      "10m 59s (- 9m 50s) (3300 52%) loss : 0.582  accuracy : 86.6 %\n",
      "11m 19s (- 9m 31s) (3400 54%) loss : 0.711  accuracy : 84.0 %\n",
      "11m 39s (- 9m 11s) (3500 55%) loss : 0.544  accuracy : 87.1 %\n",
      "12m 0s (- 8m 51s) (3600 57%) loss : 0.429  accuracy : 89.6 %\n",
      "12m 21s (- 8m 32s) (3700 59%) loss : 0.520  accuracy : 87.4 %\n",
      "12m 40s (- 8m 11s) (3800 60%) loss : 0.385  accuracy : 90.5 %\n",
      "13m 0s (- 7m 51s) (3900 62%) loss : 0.517  accuracy : 87.4 %\n",
      "13m 18s (- 7m 30s) (4000 63%) loss : 0.372  accuracy : 91.0 %\n",
      "13m 38s (- 7m 10s) (4100 65%) loss : 0.454  accuracy : 88.9 %\n",
      "13m 57s (- 6m 49s) (4200 67%) loss : 0.350  accuracy : 91.5 %\n",
      "14m 16s (- 6m 29s) (4300 68%) loss : 0.383  accuracy : 90.9 %\n",
      "14m 34s (- 6m 9s) (4400 70%) loss : 0.254  accuracy : 93.8 %\n",
      "14m 54s (- 5m 49s) (4500 71%) loss : 0.351  accuracy : 91.6 %\n",
      "15m 14s (- 5m 29s) (4600 73%) loss : 0.355  accuracy : 91.2 %\n",
      "15m 34s (- 5m 9s) (4700 75%) loss : 0.299  accuracy : 92.4 %\n",
      "15m 54s (- 4m 49s) (4800 76%) loss : 0.306  accuracy : 92.6 %\n",
      "16m 14s (- 4m 29s) (4900 78%) loss : 0.253  accuracy : 93.8 %\n",
      "16m 33s (- 4m 9s) (5000 79%) loss : 0.215  accuracy : 94.8 %\n",
      "16m 54s (- 3m 50s) (5100 81%) loss : 0.235  accuracy : 94.3 %\n",
      "17m 12s (- 3m 29s) (5200 83%) loss : 0.250  accuracy : 93.8 %\n",
      "17m 32s (- 3m 9s) (5300 84%) loss : 0.219  accuracy : 94.5 %\n",
      "17m 51s (- 2m 50s) (5400 86%) loss : 0.292  accuracy : 93.2 %\n",
      "18m 11s (- 2m 30s) (5500 87%) loss : 0.271  accuracy : 93.4 %\n",
      "18m 30s (- 2m 10s) (5600 89%) loss : 0.210  accuracy : 94.7 %\n",
      "18m 49s (- 1m 50s) (5700 91%) loss : 0.186  accuracy : 95.4 %\n",
      "19m 9s (- 1m 30s) (5800 92%) loss : 0.263  accuracy : 93.4 %\n",
      "19m 29s (- 1m 10s) (5900 94%) loss : 0.195  accuracy : 95.2 %\n",
      "19m 49s (- 0m 50s) (6000 95%) loss : 0.248  accuracy : 93.7 %\n",
      "20m 8s (- 0m 31s) (6100 97%) loss : 0.193  accuracy : 95.1 %\n",
      "20m 27s (- 0m 11s) (6200 99%) loss : 0.172  accuracy : 95.6 %\n",
      "epoch 1\n",
      "0m 20s (- 20m 38s) (100 1%) loss : 2.286  accuracy : 70.7 %\n",
      "0m 40s (- 20m 34s) (200 3%) loss : 2.313  accuracy : 63.9 %\n",
      "1m 0s (- 19m 53s) (300 4%) loss : 1.645  accuracy : 73.0 %\n",
      "1m 22s (- 20m 9s) (400 6%) loss : 1.977  accuracy : 66.3 %\n",
      "1m 42s (- 19m 41s) (500 7%) loss : 1.687  accuracy : 71.3 %\n",
      "2m 1s (- 19m 10s) (600 9%) loss : 1.465  accuracy : 73.7 %\n",
      "2m 20s (- 18m 38s) (700 11%) loss : 1.347  accuracy : 75.7 %\n",
      "2m 41s (- 18m 23s) (800 12%) loss : 1.362  accuracy : 76.1 %\n",
      "3m 1s (- 17m 57s) (900 14%) loss : 1.413  accuracy : 73.8 %\n",
      "3m 20s (- 17m 35s) (1000 15%) loss : 1.525  accuracy : 70.6 %\n",
      "3m 42s (- 17m 23s) (1100 17%) loss : 1.852  accuracy : 65.5 %\n",
      "4m 1s (- 16m 58s) (1200 19%) loss : 1.785  accuracy : 66.4 %\n",
      "4m 20s (- 16m 32s) (1300 20%) loss : 1.380  accuracy : 73.3 %\n",
      "4m 40s (- 16m 12s) (1400 22%) loss : 1.371  accuracy : 73.2 %\n",
      "5m 0s (- 15m 52s) (1500 23%) loss : 1.280  accuracy : 75.4 %\n",
      "5m 21s (- 15m 35s) (1600 25%) loss : 1.394  accuracy : 72.9 %\n",
      "5m 41s (- 15m 16s) (1700 27%) loss : 1.180  accuracy : 76.5 %\n",
      "6m 2s (- 14m 58s) (1800 28%) loss : 1.258  accuracy : 75.7 %\n",
      "6m 23s (- 14m 40s) (1900 30%) loss : 1.668  accuracy : 68.7 %\n",
      "6m 43s (- 14m 19s) (2000 31%) loss : 1.139  accuracy : 77.3 %\n",
      "7m 3s (- 13m 58s) (2100 33%) loss : 1.111  accuracy : 78.8 %\n",
      "7m 23s (- 13m 37s) (2200 35%) loss : 0.994  accuracy : 80.9 %\n",
      "7m 42s (- 13m 16s) (2300 36%) loss : 1.045  accuracy : 80.5 %\n",
      "8m 2s (- 12m 56s) (2400 38%) loss : 1.018  accuracy : 80.1 %\n",
      "8m 23s (- 12m 37s) (2500 39%) loss : 0.991  accuracy : 80.4 %\n",
      "8m 43s (- 12m 15s) (2600 41%) loss : 0.978  accuracy : 80.4 %\n",
      "9m 0s (- 11m 52s) (2700 43%) loss : 0.819  accuracy : 84.2 %\n",
      "9m 19s (- 11m 31s) (2800 44%) loss : 0.901  accuracy : 82.6 %\n",
      "9m 41s (- 11m 12s) (2900 46%) loss : 0.900  accuracy : 83.7 %\n",
      "10m 0s (- 10m 52s) (3000 47%) loss : 0.874  accuracy : 83.0 %\n",
      "10m 20s (- 10m 31s) (3100 49%) loss : 1.123  accuracy : 77.0 %\n",
      "10m 40s (- 10m 11s) (3200 51%) loss : 1.088  accuracy : 78.8 %\n",
      "10m 59s (- 9m 50s) (3300 52%) loss : 0.948  accuracy : 80.1 %\n",
      "11m 19s (- 9m 30s) (3400 54%) loss : 0.864  accuracy : 82.1 %\n",
      "11m 39s (- 9m 10s) (3500 55%) loss : 0.892  accuracy : 82.0 %\n",
      "11m 59s (- 8m 50s) (3600 57%) loss : 0.816  accuracy : 82.9 %\n",
      "12m 20s (- 8m 31s) (3700 59%) loss : 0.915  accuracy : 80.6 %\n",
      "12m 38s (- 8m 10s) (3800 60%) loss : 0.690  accuracy : 85.3 %\n",
      "12m 56s (- 7m 49s) (3900 62%) loss : 0.692  accuracy : 85.5 %\n",
      "13m 16s (- 7m 29s) (4000 63%) loss : 0.906  accuracy : 81.1 %\n",
      "13m 35s (- 7m 8s) (4100 65%) loss : 0.678  accuracy : 86.1 %\n",
      "13m 54s (- 6m 48s) (4200 67%) loss : 0.829  accuracy : 83.5 %\n",
      "14m 15s (- 6m 29s) (4300 68%) loss : 0.823  accuracy : 82.9 %\n",
      "14m 33s (- 6m 8s) (4400 70%) loss : 0.809  accuracy : 83.1 %\n",
      "14m 52s (- 5m 48s) (4500 71%) loss : 0.570  accuracy : 87.6 %\n",
      "15m 13s (- 5m 28s) (4600 73%) loss : 0.822  accuracy : 82.4 %\n",
      "15m 34s (- 5m 9s) (4700 75%) loss : 0.558  accuracy : 88.4 %\n",
      "15m 54s (- 4m 49s) (4800 76%) loss : 0.684  accuracy : 85.0 %\n",
      "16m 15s (- 4m 30s) (4900 78%) loss : 0.751  accuracy : 84.2 %\n",
      "16m 34s (- 4m 9s) (5000 79%) loss : 0.577  accuracy : 87.8 %\n",
      "16m 53s (- 3m 49s) (5100 81%) loss : 0.637  accuracy : 85.4 %\n",
      "17m 14s (- 3m 30s) (5200 83%) loss : 0.666  accuracy : 85.6 %\n",
      "17m 34s (- 3m 10s) (5300 84%) loss : 0.494  accuracy : 89.5 %\n",
      "17m 54s (- 2m 50s) (5400 86%) loss : 0.616  accuracy : 86.3 %\n",
      "18m 14s (- 2m 30s) (5500 87%) loss : 0.446  accuracy : 90.1 %\n",
      "18m 33s (- 2m 10s) (5600 89%) loss : 0.563  accuracy : 86.9 %\n",
      "18m 52s (- 1m 50s) (5700 91%) loss : 0.562  accuracy : 88.7 %\n",
      "19m 10s (- 1m 30s) (5800 92%) loss : 0.396  accuracy : 91.3 %\n",
      "19m 29s (- 1m 10s) (5900 94%) loss : 0.446  accuracy : 90.2 %\n",
      "19m 49s (- 0m 50s) (6000 95%) loss : 0.699  accuracy : 84.1 %\n",
      "20m 8s (- 0m 31s) (6100 97%) loss : 0.537  accuracy : 88.7 %\n",
      "20m 27s (- 0m 11s) (6200 99%) loss : 0.564  accuracy : 88.2 %\n",
      "epoch 1\n",
      "0m 19s (- 20m 26s) (100 1%) loss : 0.561  accuracy : 87.5 %\n",
      "0m 40s (- 20m 15s) (200 3%) loss : 0.458  accuracy : 89.7 %\n",
      "0m 58s (- 19m 23s) (300 4%) loss : 0.460  accuracy : 89.7 %\n",
      "1m 17s (- 18m 59s) (400 6%) loss : 0.473  accuracy : 89.2 %\n",
      "1m 36s (- 18m 36s) (500 7%) loss : 0.469  accuracy : 89.1 %\n",
      "1m 56s (- 18m 18s) (600 9%) loss : 0.491  accuracy : 88.8 %\n",
      "2m 14s (- 17m 50s) (700 11%) loss : 0.437  accuracy : 90.2 %\n",
      "2m 34s (- 17m 36s) (800 12%) loss : 0.472  accuracy : 89.8 %\n",
      "2m 57s (- 17m 38s) (900 14%) loss : 0.471  accuracy : 88.9 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 17s (- 17m 20s) (1000 15%) loss : 0.434  accuracy : 90.2 %\n",
      "3m 37s (- 17m 1s) (1100 17%) loss : 0.502  accuracy : 88.9 %\n",
      "3m 57s (- 16m 42s) (1200 19%) loss : 0.319  accuracy : 93.2 %\n",
      "4m 16s (- 16m 16s) (1300 20%) loss : 0.343  accuracy : 92.8 %\n",
      "4m 36s (- 15m 58s) (1400 22%) loss : 0.582  accuracy : 87.1 %\n",
      "4m 56s (- 15m 40s) (1500 23%) loss : 0.488  accuracy : 88.6 %\n",
      "5m 15s (- 15m 19s) (1600 25%) loss : 0.478  accuracy : 88.6 %\n",
      "5m 35s (- 14m 59s) (1700 27%) loss : 0.460  accuracy : 88.3 %\n",
      "5m 55s (- 14m 39s) (1800 28%) loss : 0.451  accuracy : 89.6 %\n",
      "6m 13s (- 14m 16s) (1900 30%) loss : 0.389  accuracy : 90.8 %\n",
      "6m 33s (- 13m 58s) (2000 31%) loss : 0.343  accuracy : 92.0 %\n",
      "6m 57s (- 13m 46s) (2100 33%) loss : 0.441  accuracy : 89.9 %\n",
      "7m 21s (- 13m 34s) (2200 35%) loss : 0.415  accuracy : 90.5 %\n",
      "7m 44s (- 13m 19s) (2300 36%) loss : 0.427  accuracy : 89.7 %\n",
      "8m 5s (- 13m 0s) (2400 38%) loss : 0.402  accuracy : 90.8 %\n",
      "8m 29s (- 12m 45s) (2500 39%) loss : 0.493  accuracy : 88.6 %\n",
      "8m 50s (- 12m 26s) (2600 41%) loss : 0.478  accuracy : 87.6 %\n",
      "9m 13s (- 12m 8s) (2700 43%) loss : 0.381  accuracy : 91.4 %\n",
      "9m 35s (- 11m 50s) (2800 44%) loss : 0.407  accuracy : 90.1 %\n",
      "9m 54s (- 11m 28s) (2900 46%) loss : 0.361  accuracy : 91.5 %\n",
      "10m 15s (- 11m 8s) (3000 47%) loss : 0.434  accuracy : 89.3 %\n",
      "10m 37s (- 10m 48s) (3100 49%) loss : 0.493  accuracy : 87.2 %\n"
     ]
    }
   ],
   "source": [
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 1,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 0.5,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.00025, tf_ratio = 0.5,  print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 20s (- 20m 38s) (100 1%) loss : 5.714  accuracy : 6.8 %\n",
      "0m 38s (- 19m 14s) (200 3%) loss : 5.058  accuracy : 9.5 %\n",
      "0m 57s (- 19m 4s) (300 4%) loss : 4.873  accuracy : 13.4 %\n",
      "1m 16s (- 18m 35s) (400 6%) loss : 4.103  accuracy : 23.7 %\n",
      "1m 35s (- 18m 20s) (500 7%) loss : 3.771  accuracy : 29.7 %\n",
      "1m 54s (- 18m 0s) (600 9%) loss : 3.421  accuracy : 36.8 %\n",
      "2m 12s (- 17m 32s) (700 11%) loss : 2.758  accuracy : 47.4 %\n",
      "2m 30s (- 17m 7s) (800 12%) loss : 2.626  accuracy : 50.3 %\n",
      "2m 49s (- 16m 47s) (900 14%) loss : 2.507  accuracy : 52.5 %\n",
      "3m 8s (- 16m 28s) (1000 15%) loss : 2.215  accuracy : 56.8 %\n",
      "3m 27s (- 16m 11s) (1100 17%) loss : 2.213  accuracy : 55.8 %\n",
      "3m 46s (- 15m 55s) (1200 19%) loss : 2.076  accuracy : 57.7 %\n",
      "4m 5s (- 15m 36s) (1300 20%) loss : 1.878  accuracy : 61.4 %\n",
      "4m 23s (- 15m 12s) (1400 22%) loss : 1.733  accuracy : 64.3 %\n",
      "4m 40s (- 14m 50s) (1500 23%) loss : 1.526  accuracy : 68.3 %\n",
      "4m 59s (- 14m 30s) (1600 25%) loss : 1.723  accuracy : 63.7 %\n",
      "5m 17s (- 14m 11s) (1700 27%) loss : 1.578  accuracy : 66.6 %\n",
      "5m 35s (- 13m 51s) (1800 28%) loss : 1.343  accuracy : 70.9 %\n",
      "5m 55s (- 13m 34s) (1900 30%) loss : 1.422  accuracy : 67.9 %\n",
      "6m 15s (- 13m 18s) (2000 31%) loss : 1.097  accuracy : 75.4 %\n",
      "6m 35s (- 13m 2s) (2100 33%) loss : 1.243  accuracy : 72.3 %\n",
      "6m 53s (- 12m 43s) (2200 35%) loss : 1.224  accuracy : 72.9 %\n",
      "7m 12s (- 12m 23s) (2300 36%) loss : 0.994  accuracy : 77.4 %\n",
      "7m 31s (- 12m 4s) (2400 38%) loss : 1.111  accuracy : 76.4 %\n",
      "7m 48s (- 11m 43s) (2500 39%) loss : 1.065  accuracy : 77.1 %\n",
      "8m 7s (- 11m 25s) (2600 41%) loss : 0.992  accuracy : 77.8 %\n",
      "8m 24s (- 11m 4s) (2700 43%) loss : 0.772  accuracy : 82.0 %\n",
      "8m 43s (- 10m 46s) (2800 44%) loss : 0.871  accuracy : 79.9 %\n",
      "9m 1s (- 10m 26s) (2900 46%) loss : 0.670  accuracy : 84.5 %\n",
      "9m 18s (- 10m 6s) (3000 47%) loss : 0.825  accuracy : 80.5 %\n",
      "9m 37s (- 9m 48s) (3100 49%) loss : 0.812  accuracy : 81.2 %\n",
      "9m 55s (- 9m 28s) (3200 51%) loss : 0.719  accuracy : 83.3 %\n",
      "10m 12s (- 9m 9s) (3300 52%) loss : 0.515  accuracy : 87.8 %\n",
      "10m 30s (- 8m 49s) (3400 54%) loss : 0.593  accuracy : 86.1 %\n",
      "10m 49s (- 8m 31s) (3500 55%) loss : 0.556  accuracy : 86.8 %\n",
      "11m 6s (- 8m 11s) (3600 57%) loss : 0.550  accuracy : 86.9 %\n",
      "11m 22s (- 7m 51s) (3700 59%) loss : 0.545  accuracy : 86.8 %\n",
      "11m 42s (- 7m 34s) (3800 60%) loss : 0.497  accuracy : 88.1 %\n",
      "12m 1s (- 7m 15s) (3900 62%) loss : 0.453  accuracy : 89.4 %\n",
      "12m 19s (- 6m 57s) (4000 63%) loss : 0.439  accuracy : 89.5 %\n",
      "12m 38s (- 6m 38s) (4100 65%) loss : 0.458  accuracy : 88.6 %\n",
      "12m 57s (- 6m 20s) (4200 67%) loss : 0.380  accuracy : 90.6 %\n",
      "13m 20s (- 6m 4s) (4300 68%) loss : 0.434  accuracy : 89.3 %\n",
      "13m 42s (- 5m 46s) (4400 70%) loss : 0.386  accuracy : 90.2 %\n",
      "14m 4s (- 5m 29s) (4500 71%) loss : 0.485  accuracy : 87.7 %\n",
      "14m 23s (- 5m 11s) (4600 73%) loss : 0.383  accuracy : 90.2 %\n",
      "14m 45s (- 4m 53s) (4700 75%) loss : 0.281  accuracy : 93.3 %\n",
      "15m 4s (- 4m 34s) (4800 76%) loss : 0.316  accuracy : 92.0 %\n",
      "15m 22s (- 4m 15s) (4900 78%) loss : 0.284  accuracy : 92.8 %\n",
      "15m 44s (- 3m 57s) (5000 79%) loss : 0.294  accuracy : 92.7 %\n",
      "16m 6s (- 3m 39s) (5100 81%) loss : 0.304  accuracy : 92.4 %\n",
      "16m 27s (- 3m 20s) (5200 83%) loss : 0.250  accuracy : 93.8 %\n",
      "16m 45s (- 3m 1s) (5300 84%) loss : 0.279  accuracy : 93.0 %\n",
      "17m 5s (- 2m 42s) (5400 86%) loss : 0.260  accuracy : 93.9 %\n",
      "17m 29s (- 2m 24s) (5500 87%) loss : 0.253  accuracy : 93.8 %\n",
      "17m 50s (- 2m 5s) (5600 89%) loss : 0.245  accuracy : 93.7 %\n",
      "18m 9s (- 1m 46s) (5700 91%) loss : 0.223  accuracy : 94.5 %\n",
      "18m 28s (- 1m 27s) (5800 92%) loss : 0.191  accuracy : 95.1 %\n",
      "18m 48s (- 1m 8s) (5900 94%) loss : 0.207  accuracy : 94.8 %\n",
      "19m 7s (- 0m 49s) (6000 95%) loss : 0.177  accuracy : 95.6 %\n",
      "19m 26s (- 0m 30s) (6100 97%) loss : 0.220  accuracy : 94.6 %\n",
      "19m 45s (- 0m 10s) (6200 99%) loss : 0.206  accuracy : 94.9 %\n",
      "epoch 1\n",
      "0m 17s (- 17m 52s) (100 1%) loss : 2.184  accuracy : 73.8 %\n",
      "0m 36s (- 18m 19s) (200 3%) loss : 2.458  accuracy : 64.0 %\n",
      "0m 54s (- 18m 9s) (300 4%) loss : 2.299  accuracy : 62.6 %\n",
      "1m 14s (- 18m 16s) (400 6%) loss : 2.018  accuracy : 65.9 %\n",
      "1m 35s (- 18m 23s) (500 7%) loss : 2.269  accuracy : 60.9 %\n",
      "1m 59s (- 18m 44s) (600 9%) loss : 1.795  accuracy : 68.8 %\n",
      "2m 21s (- 18m 43s) (700 11%) loss : 1.352  accuracy : 77.2 %\n",
      "2m 41s (- 18m 20s) (800 12%) loss : 1.588  accuracy : 72.8 %\n",
      "3m 3s (- 18m 11s) (900 14%) loss : 1.653  accuracy : 69.7 %\n",
      "3m 22s (- 17m 45s) (1000 15%) loss : 1.832  accuracy : 66.6 %\n",
      "3m 41s (- 17m 20s) (1100 17%) loss : 1.590  accuracy : 69.9 %\n",
      "4m 0s (- 16m 54s) (1200 19%) loss : 1.539  accuracy : 70.4 %\n",
      "4m 17s (- 16m 22s) (1300 20%) loss : 1.338  accuracy : 73.8 %\n",
      "4m 36s (- 15m 59s) (1400 22%) loss : 1.607  accuracy : 69.5 %\n",
      "4m 55s (- 15m 35s) (1500 23%) loss : 1.763  accuracy : 66.9 %\n",
      "5m 11s (- 15m 7s) (1600 25%) loss : 1.215  accuracy : 77.1 %\n",
      "5m 30s (- 14m 45s) (1700 27%) loss : 1.325  accuracy : 74.7 %\n",
      "5m 50s (- 14m 27s) (1800 28%) loss : 1.536  accuracy : 70.9 %\n",
      "6m 8s (- 14m 4s) (1900 30%) loss : 1.105  accuracy : 78.3 %\n",
      "6m 27s (- 13m 43s) (2000 31%) loss : 1.330  accuracy : 74.7 %\n",
      "6m 46s (- 13m 24s) (2100 33%) loss : 1.177  accuracy : 76.8 %\n",
      "7m 4s (- 13m 3s) (2200 35%) loss : 1.221  accuracy : 76.9 %\n",
      "7m 25s (- 12m 45s) (2300 36%) loss : 1.237  accuracy : 76.3 %\n",
      "7m 44s (- 12m 26s) (2400 38%) loss : 1.243  accuracy : 74.6 %\n",
      "8m 4s (- 12m 7s) (2500 39%) loss : 0.988  accuracy : 80.8 %\n",
      "8m 24s (- 11m 50s) (2600 41%) loss : 1.252  accuracy : 75.2 %\n",
      "8m 43s (- 11m 30s) (2700 43%) loss : 0.941  accuracy : 81.2 %\n",
      "9m 1s (- 11m 9s) (2800 44%) loss : 1.006  accuracy : 79.2 %\n",
      "9m 19s (- 10m 47s) (2900 46%) loss : 0.876  accuracy : 81.8 %\n",
      "9m 36s (- 10m 26s) (3000 47%) loss : 1.024  accuracy : 79.2 %\n",
      "9m 55s (- 10m 6s) (3100 49%) loss : 1.022  accuracy : 79.3 %\n",
      "10m 15s (- 9m 48s) (3200 51%) loss : 0.681  accuracy : 86.5 %\n",
      "10m 34s (- 9m 28s) (3300 52%) loss : 0.922  accuracy : 81.1 %\n",
      "10m 51s (- 9m 7s) (3400 54%) loss : 0.925  accuracy : 81.6 %\n",
      "11m 10s (- 8m 48s) (3500 55%) loss : 0.713  accuracy : 84.2 %\n",
      "11m 28s (- 8m 28s) (3600 57%) loss : 0.714  accuracy : 85.3 %\n",
      "11m 47s (- 8m 9s) (3700 59%) loss : 0.979  accuracy : 78.8 %\n",
      "12m 5s (- 7m 49s) (3800 60%) loss : 0.728  accuracy : 84.9 %\n",
      "12m 24s (- 7m 29s) (3900 62%) loss : 0.834  accuracy : 83.2 %\n",
      "12m 42s (- 7m 10s) (4000 63%) loss : 0.830  accuracy : 82.9 %\n",
      "13m 0s (- 6m 50s) (4100 65%) loss : 0.850  accuracy : 81.4 %\n",
      "13m 19s (- 6m 31s) (4200 67%) loss : 0.728  accuracy : 84.2 %\n",
      "13m 37s (- 6m 12s) (4300 68%) loss : 0.757  accuracy : 84.3 %\n",
      "13m 55s (- 5m 52s) (4400 70%) loss : 0.633  accuracy : 86.7 %\n",
      "14m 13s (- 5m 33s) (4500 71%) loss : 0.778  accuracy : 82.6 %\n",
      "14m 32s (- 5m 14s) (4600 73%) loss : 0.603  accuracy : 86.2 %\n",
      "14m 51s (- 4m 55s) (4700 75%) loss : 0.527  accuracy : 89.0 %\n",
      "15m 9s (- 4m 36s) (4800 76%) loss : 0.804  accuracy : 82.0 %\n",
      "15m 27s (- 4m 16s) (4900 78%) loss : 0.811  accuracy : 83.0 %\n",
      "15m 45s (- 3m 57s) (5000 79%) loss : 0.582  accuracy : 88.1 %\n",
      "16m 4s (- 3m 38s) (5100 81%) loss : 0.606  accuracy : 87.4 %\n",
      "16m 21s (- 3m 19s) (5200 83%) loss : 0.599  accuracy : 87.4 %\n",
      "16m 40s (- 3m 0s) (5300 84%) loss : 0.617  accuracy : 86.8 %\n",
      "16m 58s (- 2m 41s) (5400 86%) loss : 0.559  accuracy : 87.3 %\n",
      "17m 16s (- 2m 22s) (5500 87%) loss : 0.606  accuracy : 86.1 %\n",
      "17m 35s (- 2m 3s) (5600 89%) loss : 0.663  accuracy : 85.1 %\n",
      "17m 53s (- 1m 44s) (5700 91%) loss : 0.771  accuracy : 83.8 %\n",
      "18m 12s (- 1m 26s) (5800 92%) loss : 0.545  accuracy : 88.0 %\n",
      "18m 30s (- 1m 7s) (5900 94%) loss : 0.577  accuracy : 87.0 %\n",
      "18m 49s (- 0m 48s) (6000 95%) loss : 0.602  accuracy : 87.1 %\n",
      "19m 7s (- 0m 29s) (6100 97%) loss : 0.526  accuracy : 87.1 %\n",
      "19m 25s (- 0m 10s) (6200 99%) loss : 0.610  accuracy : 86.1 %\n",
      "epoch 1\n",
      "0m 21s (- 22m 8s) (100 1%) loss : 0.613  accuracy : 85.6 %\n",
      "0m 40s (- 20m 25s) (200 3%) loss : 0.491  accuracy : 88.5 %\n",
      "1m 0s (- 19m 59s) (300 4%) loss : 0.450  accuracy : 89.3 %\n",
      "1m 19s (- 19m 21s) (400 6%) loss : 0.475  accuracy : 89.4 %\n",
      "1m 38s (- 18m 48s) (500 7%) loss : 0.418  accuracy : 90.4 %\n",
      "1m 56s (- 18m 16s) (600 9%) loss : 0.400  accuracy : 91.2 %\n",
      "2m 14s (- 17m 50s) (700 11%) loss : 0.413  accuracy : 90.2 %\n",
      "2m 35s (- 17m 41s) (800 12%) loss : 0.364  accuracy : 92.1 %\n",
      "2m 55s (- 17m 24s) (900 14%) loss : 0.403  accuracy : 91.5 %\n",
      "3m 14s (- 17m 1s) (1000 15%) loss : 0.360  accuracy : 92.2 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 33s (- 16m 40s) (1100 17%) loss : 0.471  accuracy : 88.3 %\n",
      "3m 51s (- 16m 14s) (1200 19%) loss : 0.417  accuracy : 90.5 %\n",
      "4m 8s (- 15m 48s) (1300 20%) loss : 0.443  accuracy : 89.7 %\n",
      "4m 26s (- 15m 25s) (1400 22%) loss : 0.426  accuracy : 90.3 %\n",
      "4m 45s (- 15m 6s) (1500 23%) loss : 0.421  accuracy : 90.0 %\n",
      "5m 3s (- 14m 43s) (1600 25%) loss : 0.433  accuracy : 89.6 %\n",
      "5m 20s (- 14m 20s) (1700 27%) loss : 0.431  accuracy : 89.8 %\n",
      "5m 39s (- 14m 0s) (1800 28%) loss : 0.452  accuracy : 89.2 %\n",
      "5m 56s (- 13m 37s) (1900 30%) loss : 0.394  accuracy : 90.3 %\n",
      "6m 16s (- 13m 20s) (2000 31%) loss : 0.467  accuracy : 88.3 %\n",
      "6m 36s (- 13m 4s) (2100 33%) loss : 0.374  accuracy : 91.4 %\n",
      "6m 54s (- 12m 44s) (2200 35%) loss : 0.479  accuracy : 89.0 %\n",
      "7m 14s (- 12m 27s) (2300 36%) loss : 0.488  accuracy : 88.6 %\n",
      "7m 33s (- 12m 8s) (2400 38%) loss : 0.413  accuracy : 89.8 %\n",
      "7m 51s (- 11m 48s) (2500 39%) loss : 0.384  accuracy : 91.2 %\n",
      "8m 9s (- 11m 27s) (2600 41%) loss : 0.441  accuracy : 89.1 %\n",
      "8m 26s (- 11m 7s) (2700 43%) loss : 0.417  accuracy : 89.5 %\n",
      "8m 44s (- 10m 47s) (2800 44%) loss : 0.408  accuracy : 90.0 %\n",
      "9m 2s (- 10m 27s) (2900 46%) loss : 0.389  accuracy : 90.6 %\n",
      "9m 21s (- 10m 9s) (3000 47%) loss : 0.444  accuracy : 90.0 %\n",
      "9m 40s (- 9m 50s) (3100 49%) loss : 0.410  accuracy : 89.8 %\n",
      "10m 1s (- 9m 34s) (3200 51%) loss : 0.495  accuracy : 87.5 %\n",
      "10m 23s (- 9m 18s) (3300 52%) loss : 0.348  accuracy : 91.7 %\n",
      "10m 44s (- 9m 1s) (3400 54%) loss : 0.496  accuracy : 88.2 %\n",
      "11m 4s (- 8m 43s) (3500 55%) loss : 0.310  accuracy : 92.5 %\n",
      "11m 24s (- 8m 25s) (3600 57%) loss : 0.432  accuracy : 90.2 %\n",
      "11m 44s (- 8m 7s) (3700 59%) loss : 0.383  accuracy : 90.6 %\n",
      "12m 2s (- 7m 47s) (3800 60%) loss : 0.443  accuracy : 89.3 %\n",
      "12m 21s (- 7m 27s) (3900 62%) loss : 0.491  accuracy : 87.8 %\n",
      "12m 38s (- 7m 8s) (4000 63%) loss : 0.317  accuracy : 92.8 %\n",
      "12m 57s (- 6m 49s) (4100 65%) loss : 0.565  accuracy : 84.5 %\n",
      "13m 15s (- 6m 29s) (4200 67%) loss : 0.405  accuracy : 90.7 %\n",
      "13m 36s (- 6m 11s) (4300 68%) loss : 0.438  accuracy : 89.7 %\n",
      "13m 54s (- 5m 52s) (4400 70%) loss : 0.426  accuracy : 89.5 %\n",
      "14m 12s (- 5m 32s) (4500 71%) loss : 0.339  accuracy : 92.4 %\n",
      "14m 31s (- 5m 13s) (4600 73%) loss : 0.417  accuracy : 89.8 %\n",
      "14m 49s (- 4m 54s) (4700 75%) loss : 0.370  accuracy : 91.2 %\n",
      "15m 8s (- 4m 35s) (4800 76%) loss : 0.419  accuracy : 90.8 %\n",
      "15m 26s (- 4m 16s) (4900 78%) loss : 0.425  accuracy : 90.2 %\n",
      "15m 45s (- 3m 57s) (5000 79%) loss : 0.488  accuracy : 87.7 %\n",
      "16m 2s (- 3m 38s) (5100 81%) loss : 0.420  accuracy : 90.0 %\n",
      "16m 20s (- 3m 19s) (5200 83%) loss : 0.347  accuracy : 91.5 %\n",
      "16m 39s (- 3m 0s) (5300 84%) loss : 0.363  accuracy : 92.2 %\n",
      "16m 56s (- 2m 41s) (5400 86%) loss : 0.306  accuracy : 92.7 %\n",
      "17m 14s (- 2m 22s) (5500 87%) loss : 0.381  accuracy : 91.0 %\n",
      "17m 33s (- 2m 3s) (5600 89%) loss : 0.484  accuracy : 87.8 %\n",
      "17m 51s (- 1m 44s) (5700 91%) loss : 0.334  accuracy : 92.6 %\n",
      "18m 10s (- 1m 25s) (5800 92%) loss : 0.369  accuracy : 91.0 %\n",
      "18m 30s (- 1m 7s) (5900 94%) loss : 0.363  accuracy : 90.8 %\n",
      "18m 49s (- 0m 48s) (6000 95%) loss : 0.353  accuracy : 91.2 %\n",
      "19m 7s (- 0m 29s) (6100 97%) loss : 0.350  accuracy : 91.8 %\n",
      "19m 25s (- 0m 10s) (6200 99%) loss : 0.364  accuracy : 92.1 %\n"
     ]
    }
   ],
   "source": [
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 1,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 0.5,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.00025, tf_ratio = 0.5,  print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(chatbot.state_dict(), path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_encoder_attndecoder_M2DS.pth')\n",
    "\n",
    "# load\n",
    "#chatbot.load_state_dict(torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_II2_encoder_attndecoder_M2DS.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.compute_accuracy(qa_tst, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceMotVar(motsVar, raw_sentence):\n",
    "    sentence = []\n",
    "    word_list = raw_sentence.split(' ')\n",
    "    for word in word_list :\n",
    "        if word in motsVar.keys() :\n",
    "            sentence.append(motsVar[word])\n",
    "        else :\n",
    "            sentence.append(word)\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "\n",
    "def repair(sentence) :\n",
    "    s = re.sub(\" ' \", \"'\", sentence)\n",
    "    s = re.sub(\" - \", \"-\", s)\n",
    "    s = re.sub(\" ,\", \",\", s)\n",
    "    s = re.sub(r'(?<=\\d) \\. (?=\\d)', '.', s)\n",
    "    s = re.sub(\" \\.\", \".\", s)\n",
    "    s = re.sub(\"\\( \", \"(\", s)\n",
    "    s = re.sub(\" \\)\", \")\", s)\n",
    "    s = s[0].upper() + s[1:]\n",
    "    return s\n",
    "\n",
    "\n",
    "def InteractiveEvaluation(agent) :\n",
    "    print(\"Interactive mode (Press 'q' to exit)\")\n",
    "    agent.eval()\n",
    "    while True :\n",
    "        text = input('User : ')\n",
    "        #print('User : {}'.format(text))\n",
    "        if text == 'eoc' or text == 'q' or text == 'quit' : \n",
    "            break\n",
    "        reponse = agent(text)\n",
    "        reponse = ReplaceMotVar(motsVar, reponse)\n",
    "        reponse = repair(reponse)\n",
    "        print('Bot  : {}'.format(reponse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive mode (Press 'q' to exit)\n",
      "User : coucou\n",
      "Bot  : Bonjour, comment puis-je vous aider ?\n",
      "User : salut\n",
      "Bot  : Bonjour, comment puis-je vous aider ?\n",
      "User : tu fais quoi\n",
      "Bot  : Je suis la pour vous renseigner sur le master 2 data science.\n",
      "User : cool, sinon tu sais faire quoi\n",
      "Bot  : Je suis la pour vous renseigner sur le master 2 data science.\n",
      "User : bonjour\n",
      "Bot  : Bonjour, comment puis-je vous aider ?\n",
      "User : caca\n",
      "Bot  : Le responsable du master data science informatique est le pr. Alexandre Aussem\n",
      "User : c'est pas très gentil pour lui ça\n",
      "Bot  : Je suis la pour vous renseigner sur le master 2 data science.\n",
      "User : j'ai un diplome caca c'est ça ?\n",
      "Bot  : C'est a vous de faire un choix.\n",
      "User : hmmm je sais pas\n",
      "Bot  : D'accord, comment puis-je vous aider ?\n",
      "User : parfait mon petit horace\n",
      "Bot  : L'enseignant de statistique graphiques probabilistes est pr. Alexandre Aussem\n",
      "User : pfff tu es con\n",
      "Bot  : Je suis la pour vous renseigner sur le master 2 data science.\n",
      "User : quit\n"
     ]
    }
   ],
   "source": [
    "InteractiveEvaluation(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'le master comprend les cours de mathematiques suivant : listcoursmath'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "chatbot('quelles sont les ue de mathématiques ?', show_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.eval()\n",
    "chatbot('ou je peux trouver la liste des ue de mathématiques ?', show_attention = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
