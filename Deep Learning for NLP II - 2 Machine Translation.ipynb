{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part II - 2 <br><br><br>\n",
    "  Machine Translation\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. Text Classification\n",
    "\n",
    "2. <font color=red>**Machine Translation**</font>\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.3.1\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\libDL4NLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus est donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Normalisation -------------------------------\n",
    "def normalizeString(s):\n",
    "    '''Remove rare symbols from a string'''\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    " \n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9?&\\%\\-\\_]+\", r\" \", s) \n",
    "    s = re.sub(\"\\(\", r\" ( \", s)\n",
    "    s = re.sub(\"\\)\", r\" ) \", s)\n",
    "    s = re.sub(r\"\\.\", r\" . \", s)\n",
    "    s = re.sub(r\",\", r\" , \", s)\n",
    "    s = re.sub(r\"!\", r\" ! \", s)\n",
    "    s = re.sub(r\":\", r\" : \", s)\n",
    "    s = re.sub(r\"-\", r\" - \", s)\n",
    "    s = re.sub(r\"'\", r\" ' \", s)\n",
    "    s = re.sub(r\";\", r\" ; \", s)\n",
    "    s = re.sub(r' +', r' ', s).strip()\n",
    "    return s \n",
    "\n",
    "\n",
    "\n",
    "#--------------------- import des dialogues --------------------\n",
    "def importDialogues(path, limit = None):\n",
    "    '''Import a textfile containing dialogues and returns a list, each element \n",
    "       corresponding to a dialogue and also being under the form of a list, with \n",
    "       each element being a list of two elements : an element giving a user \n",
    "       utterance and another element giving the bot response. Both elements are \n",
    "       normalized strings.\n",
    "       Ex. The dialogue :\n",
    "       \n",
    "               hi    hello what can i help you with today\n",
    "               can you book a table    i m on it\n",
    "               \n",
    "       now becomes :\n",
    "       \n",
    "              [['hi', 'hello what can i help you with today'], \n",
    "               ['can you book a table', 'i m on it']]\n",
    "               \n",
    "       Lines corresponding to user utterance with no bot response are discarted.\n",
    "    '''\n",
    "    def cleanS(s):\n",
    "        cleans = normalizeString(s)\n",
    "        cleans = cleans.replace('?', ' ? ').strip()\n",
    "        return cleans\n",
    "    \n",
    "    dialogues = []\n",
    "    dialogues_import = open(path, encoding='utf-8').read().strip().split('\\n\\n')\n",
    "    for i, d in enumerate(dialogues_import):\n",
    "        dialogue = []\n",
    "        lines = d.split('\\n')\n",
    "        for l in lines:\n",
    "            if len(l.split('\\t')) == 2 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')]\n",
    "                dialogue.append(pair)\n",
    "            elif len(l.split('\\t')) == 3 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')[:2]]\n",
    "                dialogue.append(pair)\n",
    "        dialogues.append(dialogue)\n",
    "        if limit is not None and i == limit -1 : break\n",
    "    return dialogues\n",
    "\n",
    "\n",
    "def getUniqueQAs(dialogues) :\n",
    "    uniq = []\n",
    "    for qa in dialogues :\n",
    "        if qa not in uniq : uniq.append(qa)\n",
    "    return uniq\n",
    "\n",
    "\n",
    "\n",
    "#------------------ Dictionnaire des mots variables -----------------------------\n",
    "def motVar(file):\n",
    "    '''Applies to the Master's program dataset.\n",
    "       Import the collection of pairs token-content for a set of variable words.\n",
    "    '''\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "    motsVar = {}\n",
    "    for l in lines :\n",
    "        cle, valeur = l.split('\\t')\n",
    "        motsVar[cle.lower()] = valeur\n",
    "    return motsVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "motsVar    = motVar(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_07\\\\chatbot-M2-DS-Variables.txt')\n",
    "dialogues  = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Train.tsv')\n",
    "dialogues_tst = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200224 20561\n"
     ]
    }
   ],
   "source": [
    "qa_trn = [[qa[0], qa[1] + ' EOS'] for dialogue in dialogues for qa in dialogue] # getUniqueQAs(\n",
    "qa_tst = [[qa[0], qa[1] + ' EOS'] for dialogue in dialogues_tst for qa in dialogue] # getUniqueQAs(\n",
    "\n",
    "print(len(qa_trn), len(qa_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il vaut mieux suivre quel parcours  ? \t les deux parcours sont equivalents , c ' est a vous de faire un choix .\n",
      "quand est ce que commence les cours  ? \t la rentree est le daterentree\n",
      "comment je prend contact avec la scolarite  ? \t les contacts de la scolarite sont accessibles sur : sitescolarite\n",
      "est ce que il y a des cours en anglais  ? \t plusieurs supports de cours sont en anglais\n",
      "tous les cours sont obligatoires  ? \t tous les cours sont obligatoires , il n ' existe pas d ' options .\n",
      "merci pour les renseignements \t je vous en prie\n",
      "peux tu m ' aider  ? \t je suis la pour vous renseigner sur le master 2 data science .\n",
      "le cours de data visualisation est - il en ligne  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "j ' ai envie de faire de la data science \t alors vous devriez songer a candidater a ce master !\n",
      "il y a des livres a lire en statistique  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "il y a combien de candidats  ? \t il y a plus de nbrcandidats candidats chaque annee , la selection est rude !\n",
      "combien de places sont ouvertes  ? \t souhaitez - vous suivre le parcours informatique ou mathematiques  ?\n",
      "informatique \t etes - vous un etudiant inscrit en france  ?\n",
      "non \t il y a nbreplaces_hors_france_informatique places disponibles pour les etudiants hors france en parcours informatique .\n",
      "comment je peux payer  ? \t vous pouvez payer par carte , par cheque bancaire , par virement ou en espece .\n",
      "avez - vous une maquette detaillee de ce master  ? \t les details de la formation est disponible sur la page du master parcours informatique : site_informatique\n",
      "comment ca va  ? \t je vais bien merci , en quoi puis - je vous aider  ?\n"
     ]
    }
   ],
   "source": [
    "for qa in dialogues[0] : print(qa[0], '\\t', qa[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_in  = [['SOS'] + [w for w in qa[0].split(' ')] + ['EOS'] for qa in qa_trn]\n",
    "corpus_out = [['SOS'] + [w for w in qa[1].split(' ')]           for qa in qa_trn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareWord2vec(corpus) :\n",
    "    fastText_word2vec = FastText(size = 75, \n",
    "                                 window = 5, \n",
    "                                 min_count = 1, \n",
    "                                 negative = 20,\n",
    "                                 sg = 1)\n",
    "    fastText_word2vec.build_vocab(corpus)\n",
    "    print(len(fastText_word2vec.wv.vocab))\n",
    "    fastText_word2vec.train(sentences = corpus, \n",
    "                            epochs = 5,\n",
    "                            total_examples = fastText_word2vec.corpus_count)\n",
    "    word2vec = Word2VecConnector(fastText_word2vec)\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "word2vec_in  = prepareWord2vec(corpus_in)\n",
    "word2vec_out = prepareWord2vec(corpus_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonjour', 0.9852568507194519),\n",
       " ('mal', 0.8179829120635986),\n",
       " ('principal', 0.6931003928184509),\n",
       " ('principalement', 0.6789224147796631),\n",
       " ('bien', 0.6547073125839233),\n",
       " ('english', 0.6544337272644043),\n",
       " ('handle', 0.6447221040725708),\n",
       " ('ok', 0.6249094605445862),\n",
       " ('cordialement', 0.6209567785263062),\n",
       " ('speak', 0.618739128112793)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_in.word2vec.most_similar('bonjou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonjour', 0.9725614786148071),\n",
       " ('accord', 0.786864161491394),\n",
       " ('comment', 0.6106002330780029),\n",
       " ('aider', 0.6066528558731079),\n",
       " ('accordez', 0.5910225510597229),\n",
       " ('excusez', 0.5597412586212158),\n",
       " ('monotonie', 0.5362932682037354),\n",
       " ('puis', 0.5213144421577454),\n",
       " ('vais', 0.5169289112091064),\n",
       " ('dynamiques', 0.4986083209514618)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_out.word2vec.most_similar('bonjou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "We use here a classical Attention Module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Decoder module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"decoder\"></a>\n",
    "\n",
    "#### 1.4.1 Classical Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, word2vec, hidden_dim, \n",
    "                 n_layers = 1,\n",
    "                 dropout = 0.1,\n",
    "                 bound = 25\n",
    "                ):\n",
    "        super(Decoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bound = bound\n",
    "        # modules\n",
    "        self.word2vec = word2vec\n",
    "        self.gru = nn.GRU(word2vec.output_dim, \n",
    "                          hidden_dim, \n",
    "                          n_layers, \n",
    "                          dropout = dropout, \n",
    "                          batch_first = True)\n",
    "        self.out = nn.Linear(hidden_dim, word2vec.lang.n_words)\n",
    "        self.act = F.log_softmax\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generateWord(self, hidden, word_index):\n",
    "        # update hidden state\n",
    "        embedding = self.word2vec.embedding(word_index) # size (batch_size, 1, embedding_dim)\n",
    "        embedding = self.dropout(embedding)\n",
    "        _, hidden = self.gru(embedding, hidden)         # size (n_layers, batch_size, embedding_dim)\n",
    "        # generate next word\n",
    "        log_prob = self.out(hidden[-1])                 # size (batch_size, lang_size)\n",
    "        log_prob = self.act(log_prob, dim = 1)          # size (batch_size, lang_size)\n",
    "        return log_prob, hidden\n",
    "    \n",
    "    def forward(self, hidden, device = None) :\n",
    "        answer = []\n",
    "        word_index = self.word2vec.lang.getIndex('SOS')\n",
    "        EOS_token  = self.word2vec.lang.getIndex('EOS')\n",
    "        for t in range(self.bound) :\n",
    "            # compute next word\n",
    "            word_index = Variable(torch.LongTensor([[word_index]]))    # size (1, 1)\n",
    "            if device is not None : word_index = word_index.to(device) # size (1, 1)\n",
    "            log_prob, hidden = self.generateWord(hidden, word_index)\n",
    "            word_index = log_prob.topk(1)[1].item()\n",
    "            # add to output\n",
    "            if word_index == EOS_token : break\n",
    "            else : answer.append(word_index)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Attention Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Machine Translation Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec_in, word2vec_out, \n",
    "                 hidden_dim = 100,\n",
    "                 n_layers = 1, \n",
    "                 bound = 25,\n",
    "                 dropout = 0, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.tokenizer    = tokenizer\n",
    "        self.word2vec_in  = word2vec_in\n",
    "        self.word2vec_out = word2vec_out\n",
    "        self.context      = RecurrentEncoder(word2vec_in.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.decoder      = Decoder(word2vec_out, hidden_dim, n_layers, dropout, bound)\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index_in  = self.word2vec_in.lang.getIndex('PADDING_WORD')\n",
    "        self.ignore_index_out = self.word2vec_out.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, ignore_index = self.ignore_index_out)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def forward(self, sentence, color_code = '\\033[94m'):\n",
    "        # encode sentence\n",
    "        words  = self.tokenizer(sentence)\n",
    "        embeddings = self.word2vec_in(words, self.device)\n",
    "        _, hidden  = self.context(embeddings)\n",
    "        # sum along directions\n",
    "        if self.context.bidirectional :\n",
    "            hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "            hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "        # generate answer\n",
    "        answer = self.decoder(hidden, self.device)\n",
    "        answer = [self.word2vec_out.lang.index2word[i] for i in answer]\n",
    "        print(' '.join(words + [':', color_code] + answer + ['\\033[0m']))\n",
    "        return\n",
    "    \n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) : \n",
    "        sentences.sort(key = lambda s: len(s[1]), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            # prepare input and target pack\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            pack.sort(key = lambda s: len(self.tokenizer(s[0])), reverse = True)\n",
    "            pack0 = [[self.word2vec_in.lang.getIndex(w) for w in self.tokenizer(qa[0])] for qa in pack]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack1 = [[self.word2vec_out.lang.getIndex(w) for w in self.tokenizer(qa[1])] for qa in pack]\n",
    "            pack1 = [[w for w in words if w is not None] for words in pack1]\n",
    "            lengths = torch.tensor([len(p) for p in pack0])           # size (batch_size) \n",
    "            # padd packs\n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index_in))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1)) # size (batch_size, max_length0) \n",
    "            pack1 = list(itertools.zip_longest(*pack1, fillvalue = self.ignore_index_out))\n",
    "            pack1 = Variable(torch.LongTensor(pack1))       # WARNING : size (max_length1, batch_size) \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def compute_accuracy(self, sentences) :\n",
    "        batches = self.generatePackedSentences(sentences, batch_size = 32)\n",
    "        score = 0\n",
    "        for batch, target in batches :\n",
    "            embeddings  = self.word2vec_in.embedding(batch[0].to(self.device))\n",
    "            hiddens, _  = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended, _ = self.attention(hiddens)\n",
    "            if self.bin_mode : \n",
    "                vects  = self.out(attended).view(-1)\n",
    "                target = target.to(self.device).view(-1)\n",
    "                score += sum(torch.abs(target - self.act(vects)) < 0.5).item()\n",
    "            else : \n",
    "                log_probs = F.log_softmax(self.out(attended.squeeze(1)))\n",
    "                target    = target.to(self.device).view(-1)\n",
    "                score    += sum([target[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(target.size(0))])\n",
    "        return score * 100 / len(sentences)\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, tf_ratio = 0, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeSuccess(log_probs, targets) :\n",
    "            success = sum([self.ignore_index_out != targets[i].item() == log_probs[i].topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0))])\n",
    "            return success\n",
    "        \n",
    "        def computeLogProbs(batch, target, tf_ratio = 0, compute_accuracy = True) :\n",
    "            loss = 0\n",
    "            success = 0\n",
    "            forcing = (random.random() < tf_ratio)\n",
    "            # encode sentences\n",
    "            embeddings = self.word2vec_in.embedding(batch[0].to(self.device))\n",
    "            _, hidden  = self.context(embeddings, lengths = batch[1].to(self.device)) # size (n_layers * num_directions, batch_size, hidden_dim)\n",
    "            # sum along directions\n",
    "            if self.context.bidirectional :\n",
    "                hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                hidden = torch.sum(hidden, dim = 1)               # size (n_layers, batch_size, hidden_dim)\n",
    "            # compute answers\n",
    "            word_index = self.word2vec_out.lang.getIndex('SOS')\n",
    "            word_index = Variable(torch.LongTensor([word_index])) # size (1)\n",
    "            word_index = word_index.expand(target.size(1))        # size (batch_size)\n",
    "            for t in range(target.size(0)) :\n",
    "                # compute word probs\n",
    "                log_prob, hidden = self.decoder.generateWord(hidden, word_index.unsqueeze(1).to(self.device))\n",
    "                # compute loss\n",
    "                loss += self.criterion(log_prob, target[t])\n",
    "                if compute_accuracy : success += computeSuccess(log_prob, target[t])\n",
    "                # apply teacher forcing\n",
    "                if forcing : word_index = target[t]                             # size (batch_size) \n",
    "                else       : word_index = log_prob.topk(1, dim = 1)[1].view(-1) # size (batch_size)\n",
    "            return loss, success       \n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, tf_ratio = 0, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            target = batch[1].to(self.device)\n",
    "            total = np.sum(target.data.cpu().numpy() != self.ignore_index_out)\n",
    "            loss, success = computeLogProbs(batch[0], target, tf_ratio, compute_accuracy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return float(loss.item() / total), float(success * 100 / total)\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(qa[1].split(' ')) for qa in qa_trn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307122"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = EncoderDecoder(device = torch.device(\"cpu\"),\n",
    "                         tokenizer = lambda s : normalizeString(s).split(' '),\n",
    "                         word2vec_in = word2vec_in,\n",
    "                         word2vec_out = word2vec_out,\n",
    "                         hidden_dim = 75, \n",
    "                         n_layers = 2,\n",
    "                         bound = 75,\n",
    "                         dropout = 0.1,\n",
    "                         optimizer = optim.SGD)\n",
    "\n",
    "chatbot.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (word2vec_in): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(784, 75)\n",
       "    )\n",
       "    (embedding): Embedding(784, 75)\n",
       "  )\n",
       "  (word2vec_out): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (embedding): Embedding(898, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (bigru): GRU(75, 75, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (word2vec): Word2VecConnector(\n",
       "      (twin): Word2Vec(\n",
       "        (embedding): Embedding(898, 75)\n",
       "      )\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (gru): GRU(75, 75, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (out): Linear(in_features=75, out_features=897, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6257"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = chatbot.generatePackedSentences(qa_trn, batch_size = 32)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 15s (- 16m 10s) (100 1%) loss : 5.452  accuracy : 7.6 %\n",
      "0m 31s (- 15m 56s) (200 3%) loss : 4.851  accuracy : 10.5 %\n",
      "0m 47s (- 15m 48s) (300 4%) loss : 4.522  accuracy : 17.4 %\n",
      "1m 5s (- 15m 51s) (400 6%) loss : 4.159  accuracy : 23.2 %\n",
      "1m 21s (- 15m 43s) (500 7%) loss : 3.634  accuracy : 31.9 %\n",
      "1m 38s (- 15m 29s) (600 9%) loss : 3.188  accuracy : 38.8 %\n",
      "1m 54s (- 15m 7s) (700 11%) loss : 2.760  accuracy : 46.6 %\n",
      "2m 10s (- 14m 53s) (800 12%) loss : 2.659  accuracy : 48.6 %\n",
      "2m 28s (- 14m 41s) (900 14%) loss : 2.467  accuracy : 51.9 %\n",
      "2m 44s (- 14m 25s) (1000 15%) loss : 2.025  accuracy : 60.0 %\n",
      "3m 1s (- 14m 11s) (1100 17%) loss : 2.145  accuracy : 56.5 %\n",
      "3m 18s (- 13m 55s) (1200 19%) loss : 2.209  accuracy : 55.0 %\n",
      "3m 32s (- 13m 32s) (1300 20%) loss : 2.048  accuracy : 60.5 %\n",
      "3m 49s (- 13m 16s) (1400 22%) loss : 1.854  accuracy : 61.4 %\n",
      "4m 6s (- 13m 1s) (1500 23%) loss : 1.937  accuracy : 59.4 %\n",
      "4m 21s (- 12m 40s) (1600 25%) loss : 1.573  accuracy : 67.0 %\n",
      "4m 37s (- 12m 23s) (1700 27%) loss : 1.626  accuracy : 66.5 %\n",
      "4m 54s (- 12m 9s) (1800 28%) loss : 1.595  accuracy : 65.6 %\n",
      "5m 10s (- 11m 51s) (1900 30%) loss : 1.649  accuracy : 65.5 %\n",
      "5m 26s (- 11m 35s) (2000 31%) loss : 1.436  accuracy : 68.9 %\n",
      "5m 43s (- 11m 20s) (2100 33%) loss : 1.322  accuracy : 71.0 %\n",
      "6m 0s (- 11m 4s) (2200 35%) loss : 1.475  accuracy : 67.8 %\n",
      "6m 17s (- 10m 48s) (2300 36%) loss : 1.289  accuracy : 71.5 %\n",
      "6m 33s (- 10m 33s) (2400 38%) loss : 1.116  accuracy : 75.3 %\n",
      "6m 51s (- 10m 18s) (2500 39%) loss : 1.197  accuracy : 74.3 %\n",
      "7m 8s (- 10m 3s) (2600 41%) loss : 1.025  accuracy : 77.4 %\n",
      "7m 25s (- 9m 46s) (2700 43%) loss : 1.051  accuracy : 76.5 %\n",
      "7m 41s (- 9m 29s) (2800 44%) loss : 1.024  accuracy : 76.4 %\n",
      "7m 56s (- 9m 11s) (2900 46%) loss : 1.057  accuracy : 76.7 %\n",
      "8m 13s (- 8m 55s) (3000 47%) loss : 1.053  accuracy : 75.6 %\n",
      "8m 29s (- 8m 38s) (3100 49%) loss : 0.864  accuracy : 79.6 %\n",
      "8m 45s (- 8m 21s) (3200 51%) loss : 0.840  accuracy : 80.3 %\n",
      "9m 0s (- 8m 4s) (3300 52%) loss : 0.917  accuracy : 78.5 %\n",
      "9m 16s (- 7m 47s) (3400 54%) loss : 0.746  accuracy : 82.6 %\n",
      "9m 32s (- 7m 30s) (3500 55%) loss : 0.680  accuracy : 84.0 %\n",
      "9m 48s (- 7m 14s) (3600 57%) loss : 0.668  accuracy : 84.3 %\n",
      "10m 1s (- 6m 55s) (3700 59%) loss : 0.708  accuracy : 82.9 %\n",
      "10m 13s (- 6m 36s) (3800 60%) loss : 0.707  accuracy : 83.2 %\n",
      "10m 25s (- 6m 18s) (3900 62%) loss : 0.812  accuracy : 80.5 %\n",
      "10m 38s (- 6m 0s) (4000 63%) loss : 0.766  accuracy : 81.5 %\n",
      "10m 51s (- 5m 42s) (4100 65%) loss : 0.649  accuracy : 84.7 %\n",
      "11m 3s (- 5m 25s) (4200 67%) loss : 0.622  accuracy : 84.7 %\n",
      "11m 16s (- 5m 7s) (4300 68%) loss : 0.671  accuracy : 83.6 %\n",
      "11m 28s (- 4m 50s) (4400 70%) loss : 0.564  accuracy : 86.5 %\n",
      "11m 40s (- 4m 33s) (4500 71%) loss : 0.490  accuracy : 87.8 %\n",
      "11m 52s (- 4m 16s) (4600 73%) loss : 0.574  accuracy : 86.0 %\n",
      "12m 5s (- 4m 0s) (4700 75%) loss : 0.523  accuracy : 87.4 %\n",
      "12m 17s (- 3m 43s) (4800 76%) loss : 0.512  accuracy : 87.1 %\n",
      "12m 29s (- 3m 27s) (4900 78%) loss : 0.629  accuracy : 84.8 %\n",
      "12m 42s (- 3m 11s) (5000 79%) loss : 0.558  accuracy : 87.3 %\n",
      "12m 55s (- 2m 55s) (5100 81%) loss : 0.555  accuracy : 86.5 %\n",
      "13m 7s (- 2m 39s) (5200 83%) loss : 0.485  accuracy : 88.3 %\n",
      "13m 19s (- 2m 24s) (5300 84%) loss : 0.476  accuracy : 88.6 %\n",
      "13m 31s (- 2m 8s) (5400 86%) loss : 0.391  accuracy : 90.6 %\n",
      "13m 43s (- 1m 53s) (5500 87%) loss : 0.474  accuracy : 88.6 %\n",
      "13m 55s (- 1m 38s) (5600 89%) loss : 0.430  accuracy : 89.6 %\n",
      "14m 7s (- 1m 22s) (5700 91%) loss : 0.530  accuracy : 87.0 %\n",
      "14m 19s (- 1m 7s) (5800 92%) loss : 0.370  accuracy : 90.9 %\n",
      "14m 31s (- 0m 52s) (5900 94%) loss : 0.377  accuracy : 90.9 %\n",
      "14m 43s (- 0m 37s) (6000 95%) loss : 0.390  accuracy : 90.7 %\n",
      "14m 56s (- 0m 23s) (6100 97%) loss : 0.365  accuracy : 90.9 %\n",
      "15m 8s (- 0m 8s) (6200 99%) loss : 0.363  accuracy : 91.1 %\n",
      "epoch 1\n",
      "0m 13s (- 13m 25s) (100 1%) loss : 3.352  accuracy : 55.7 %\n",
      "0m 25s (- 12m 43s) (200 3%) loss : 2.703  accuracy : 60.0 %\n",
      "0m 37s (- 12m 23s) (300 4%) loss : 2.565  accuracy : 58.8 %\n",
      "0m 49s (- 12m 10s) (400 6%) loss : 2.589  accuracy : 59.6 %\n",
      "1m 2s (- 11m 59s) (500 7%) loss : 2.211  accuracy : 64.0 %\n",
      "1m 15s (- 11m 48s) (600 9%) loss : 2.299  accuracy : 62.6 %\n",
      "1m 27s (- 11m 36s) (700 11%) loss : 1.745  accuracy : 71.5 %\n",
      "1m 40s (- 11m 25s) (800 12%) loss : 2.316  accuracy : 60.7 %\n",
      "1m 53s (- 11m 14s) (900 14%) loss : 2.142  accuracy : 63.6 %\n",
      "2m 5s (- 10m 57s) (1000 15%) loss : 1.928  accuracy : 66.6 %\n",
      "2m 18s (- 10m 47s) (1100 17%) loss : 1.857  accuracy : 67.8 %\n",
      "2m 30s (- 10m 32s) (1200 19%) loss : 1.801  accuracy : 68.4 %\n",
      "2m 42s (- 10m 19s) (1300 20%) loss : 1.755  accuracy : 70.5 %\n",
      "2m 54s (- 10m 5s) (1400 22%) loss : 1.557  accuracy : 73.8 %\n",
      "3m 7s (- 9m 54s) (1500 23%) loss : 1.996  accuracy : 64.4 %\n",
      "3m 19s (- 9m 41s) (1600 25%) loss : 1.858  accuracy : 66.4 %\n",
      "3m 31s (- 9m 27s) (1700 27%) loss : 1.667  accuracy : 69.9 %\n",
      "3m 44s (- 9m 14s) (1800 28%) loss : 1.517  accuracy : 73.2 %\n",
      "3m 55s (- 9m 1s) (1900 30%) loss : 1.727  accuracy : 69.7 %\n",
      "4m 8s (- 8m 48s) (2000 31%) loss : 1.598  accuracy : 72.3 %\n",
      "4m 21s (- 8m 38s) (2100 33%) loss : 1.624  accuracy : 71.4 %\n",
      "4m 34s (- 8m 25s) (2200 35%) loss : 1.580  accuracy : 73.1 %\n",
      "4m 47s (- 8m 14s) (2300 36%) loss : 1.845  accuracy : 66.3 %\n",
      "5m 0s (- 8m 2s) (2400 38%) loss : 1.564  accuracy : 71.3 %\n",
      "5m 12s (- 7m 50s) (2500 39%) loss : 1.188  accuracy : 78.3 %\n",
      "5m 25s (- 7m 37s) (2600 41%) loss : 1.320  accuracy : 75.9 %\n",
      "5m 37s (- 7m 24s) (2700 43%) loss : 1.538  accuracy : 71.4 %\n",
      "5m 49s (- 7m 11s) (2800 44%) loss : 1.302  accuracy : 76.3 %\n",
      "6m 1s (- 6m 58s) (2900 46%) loss : 1.572  accuracy : 71.1 %\n",
      "6m 14s (- 6m 47s) (3000 47%) loss : 1.568  accuracy : 71.7 %\n",
      "6m 27s (- 6m 35s) (3100 49%) loss : 1.587  accuracy : 69.4 %\n",
      "6m 41s (- 6m 23s) (3200 51%) loss : 1.572  accuracy : 69.7 %\n",
      "6m 54s (- 6m 11s) (3300 52%) loss : 1.397  accuracy : 73.1 %\n",
      "7m 7s (- 5m 59s) (3400 54%) loss : 1.293  accuracy : 75.3 %\n",
      "7m 20s (- 5m 47s) (3500 55%) loss : 1.442  accuracy : 74.1 %\n",
      "7m 33s (- 5m 34s) (3600 57%) loss : 1.374  accuracy : 76.0 %\n",
      "7m 46s (- 5m 22s) (3700 59%) loss : 1.187  accuracy : 77.3 %\n",
      "7m 58s (- 5m 9s) (3800 60%) loss : 1.201  accuracy : 78.2 %\n",
      "8m 10s (- 4m 56s) (3900 62%) loss : 1.339  accuracy : 75.5 %\n",
      "8m 22s (- 4m 43s) (4000 63%) loss : 1.245  accuracy : 76.4 %\n",
      "8m 35s (- 4m 31s) (4100 65%) loss : 1.140  accuracy : 78.1 %\n",
      "8m 47s (- 4m 18s) (4200 67%) loss : 1.258  accuracy : 77.4 %\n",
      "9m 0s (- 4m 6s) (4300 68%) loss : 1.266  accuracy : 76.8 %\n",
      "9m 12s (- 3m 53s) (4400 70%) loss : 1.011  accuracy : 79.8 %\n",
      "9m 24s (- 3m 40s) (4500 71%) loss : 1.057  accuracy : 79.2 %\n",
      "9m 37s (- 3m 28s) (4600 73%) loss : 1.213  accuracy : 77.4 %\n",
      "9m 49s (- 3m 15s) (4700 75%) loss : 1.247  accuracy : 78.2 %\n",
      "10m 3s (- 3m 3s) (4800 76%) loss : 1.670  accuracy : 69.7 %\n",
      "10m 17s (- 2m 51s) (4900 78%) loss : 1.423  accuracy : 73.7 %\n",
      "10m 30s (- 2m 38s) (5000 79%) loss : 1.364  accuracy : 73.7 %\n",
      "10m 42s (- 2m 25s) (5100 81%) loss : 1.253  accuracy : 76.9 %\n",
      "10m 54s (- 2m 13s) (5200 83%) loss : 0.930  accuracy : 81.3 %\n",
      "11m 7s (- 2m 0s) (5300 84%) loss : 1.158  accuracy : 76.9 %\n",
      "11m 19s (- 1m 47s) (5400 86%) loss : 0.988  accuracy : 81.2 %\n",
      "11m 31s (- 1m 35s) (5500 87%) loss : 1.261  accuracy : 76.1 %\n",
      "11m 44s (- 1m 22s) (5600 89%) loss : 1.206  accuracy : 75.1 %\n",
      "11m 55s (- 1m 9s) (5700 91%) loss : 0.888  accuracy : 83.5 %\n",
      "12m 8s (- 0m 57s) (5800 92%) loss : 1.066  accuracy : 78.3 %\n",
      "12m 20s (- 0m 44s) (5900 94%) loss : 1.074  accuracy : 79.0 %\n",
      "12m 33s (- 0m 32s) (6000 95%) loss : 1.095  accuracy : 79.2 %\n",
      "12m 46s (- 0m 19s) (6100 97%) loss : 0.893  accuracy : 83.2 %\n",
      "12m 58s (- 0m 7s) (6200 99%) loss : 1.052  accuracy : 80.0 %\n",
      "epoch 1\n",
      "0m 12s (- 13m 0s) (100 1%) loss : 0.977  accuracy : 81.1 %\n",
      "0m 25s (- 12m 44s) (200 3%) loss : 0.852  accuracy : 83.2 %\n",
      "0m 37s (- 12m 32s) (300 4%) loss : 0.834  accuracy : 83.4 %\n",
      "0m 50s (- 12m 23s) (400 6%) loss : 0.975  accuracy : 81.9 %\n",
      "1m 2s (- 11m 59s) (500 7%) loss : 0.722  accuracy : 85.3 %\n",
      "1m 15s (- 11m 48s) (600 9%) loss : 0.840  accuracy : 84.6 %\n",
      "1m 27s (- 11m 36s) (700 11%) loss : 0.794  accuracy : 84.2 %\n",
      "1m 40s (- 11m 27s) (800 12%) loss : 0.681  accuracy : 87.3 %\n",
      "1m 54s (- 11m 19s) (900 14%) loss : 0.825  accuracy : 83.9 %\n",
      "2m 7s (- 11m 7s) (1000 15%) loss : 0.746  accuracy : 85.2 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 21s (- 11m 3s) (1100 17%) loss : 0.827  accuracy : 84.2 %\n",
      "2m 34s (- 10m 51s) (1200 19%) loss : 0.750  accuracy : 85.8 %\n"
     ]
    }
   ],
   "source": [
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 1,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.001, tf_ratio = 0.5,  print_every = 100)\n",
    "chatbot.fit(batches, epochs = 1, lr = 0.00025, tf_ratio = 0.5,  print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(denoiser.state_dict(), path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser_2.pth')\n",
    "\n",
    "# load\n",
    "#denoiser.load_state_dict(torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut ca va ? : \u001b[94m la page ecandidat est disponible sur le lien suivant : siteecandidat \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "chatbot('salut ca va ?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
