{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Deep Learning for NLP\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Part II - 2 <br><br><br>\n",
    "  Machine Translation\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "1. Word Embedding\n",
    "\n",
    "2. Sentence Classification\n",
    "\n",
    "3. Language Modeling\n",
    "\n",
    "4. Sequence Labelling\n",
    "\n",
    "\n",
    "### Part II\n",
    "\n",
    "1. Text Classification\n",
    "\n",
    "2. <font color=red>**Machine Translation**</font>\n",
    "\n",
    "\n",
    "### Part III\n",
    "\n",
    "8. Abstractive Summarization\n",
    "\n",
    "9. Question Answering\n",
    "\n",
    "10. Chatbot\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | | | |\n",
    "|------|------|------|------|\n",
    "| **Content** | [Corpus](#corpus) | [Modules](#modules) | [Model](#model) | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pytorch version : 1.3.1\n",
      "DL device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# for special math operation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# for manipulating data \n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import bcolz # see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for text processing\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "#import spacy\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)\n",
    "print('pytorch version :', torch.__version__)\n",
    "print('DL device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_NLP = 'C:\\\\Users\\\\Jb\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_NLP + '\\\\libDL4NLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "Le texte est importé et mis sous forme de liste, où chaque élément représente un texte présenté sous forme d'une liste de mots.<br> Le corpus est donc une fois importé sous le forme :<br>\n",
    "\n",
    "- corpus = [text]<br>\n",
    "- text   = [word]<br>\n",
    "- word   = str<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Normalisation -------------------------------\n",
    "def normalizeString(s):\n",
    "    '''Remove rare symbols from a string'''\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    " \n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9?&\\%\\-\\_]+\", r\" \", s) \n",
    "    s = re.sub(\"\\(\", r\" ( \", s)\n",
    "    s = re.sub(\"\\)\", r\" ) \", s)\n",
    "    s = re.sub(r\"\\.\", r\" . \", s)\n",
    "    s = re.sub(r\",\", r\" , \", s)\n",
    "    s = re.sub(r\"!\", r\" ! \", s)\n",
    "    s = re.sub(r\":\", r\" : \", s)\n",
    "    s = re.sub(r\"-\", r\" - \", s)\n",
    "    s = re.sub(r\"'\", r\" ' \", s)\n",
    "    s = re.sub(r\";\", r\" ; \", s)\n",
    "    s = re.sub(r' +', r' ', s).strip()\n",
    "    return s \n",
    "\n",
    "\n",
    "\n",
    "#--------------------- import des dialogues --------------------\n",
    "def importDialogues(path, limit = None):\n",
    "    '''Import a textfile containing dialogues and returns a list, each element \n",
    "       corresponding to a dialogue and also being under the form of a list, with \n",
    "       each element being a list of two elements : an element giving a user \n",
    "       utterance and another element giving the bot response. Both elements are \n",
    "       normalized strings.\n",
    "       Ex. The dialogue :\n",
    "       \n",
    "               hi    hello what can i help you with today\n",
    "               can you book a table    i m on it\n",
    "               \n",
    "       now becomes :\n",
    "       \n",
    "              [['hi', 'hello what can i help you with today'], \n",
    "               ['can you book a table', 'i m on it']]\n",
    "               \n",
    "       Lines corresponding to user utterance with no bot response are discarted.\n",
    "    '''\n",
    "    def cleanS(s):\n",
    "        cleans = normalizeString(s)\n",
    "        cleans = cleans.replace('?', ' ? ').strip()\n",
    "        return cleans\n",
    "    \n",
    "    dialogues = []\n",
    "    dialogues_import = open(path, encoding='utf-8').read().strip().split('\\n\\n')\n",
    "    for i, d in enumerate(dialogues_import):\n",
    "        dialogue = []\n",
    "        lines = d.split('\\n')\n",
    "        for l in lines:\n",
    "            if len(l.split('\\t')) == 2 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')]\n",
    "                dialogue.append(pair)\n",
    "            elif len(l.split('\\t')) == 3 :\n",
    "                pair = [cleanS(s) for s in l.split('\\t')[:2]]\n",
    "                dialogue.append(pair)\n",
    "        dialogues.append(dialogue)\n",
    "        if limit is not None and i == limit -1 : break\n",
    "    return dialogues\n",
    "\n",
    "\n",
    "def getUniqueQAs(dialogues) :\n",
    "    uniq = []\n",
    "    for qa in dialogues :\n",
    "        if qa not in uniq : uniq.append(qa)\n",
    "    return uniq\n",
    "\n",
    "\n",
    "\n",
    "#------------------ Dictionnaire des mots variables -----------------------------\n",
    "def motVar(file):\n",
    "    '''Applies to the Master's program dataset.\n",
    "       Import the collection of pairs token-content for a set of variable words.\n",
    "    '''\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "    motsVar = {}\n",
    "    for l in lines :\n",
    "        cle, valeur = l.split('\\t')\n",
    "        motsVar[cle.lower()] = valeur\n",
    "    return motsVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motsVar    = motVar(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_07\\\\chatbot-M2-DS-Variables.txt')\n",
    "dialogues  = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Train.tsv')\n",
    "dialogues_tst = importDialogues(path_to_NLP + '\\\\data\\\\M2DS\\\\M2DS_2019_10\\\\ChatbotDS_P_Test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668 360\n"
     ]
    }
   ],
   "source": [
    "qa_trn = getUniqueQAs([[qa[0], qa[1] + ' EOS'] for dialogue in dialogues for qa in dialogue])\n",
    "qa_tst = getUniqueQAs([[qa[0], qa[1] + ' EOS'] for dialogue in dialogues_tst for qa in dialogue])\n",
    "\n",
    "print(len(qa_trn), len(qa_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il vaut mieux suivre quel parcours  ? \t les deux parcours sont equivalents , c ' est a vous de faire un choix .\n",
      "quand est ce que commence les cours  ? \t la rentree est le daterentree\n",
      "comment je prend contact avec la scolarite  ? \t les contacts de la scolarite sont accessibles sur : sitescolarite\n",
      "est ce que il y a des cours en anglais  ? \t plusieurs supports de cours sont en anglais\n",
      "tous les cours sont obligatoires  ? \t tous les cours sont obligatoires , il n ' existe pas d ' options .\n",
      "merci pour les renseignements \t je vous en prie\n",
      "peux tu m ' aider  ? \t je suis la pour vous renseigner sur le master 2 data science .\n",
      "le cours de data visualisation est - il en ligne  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "j ' ai envie de faire de la data science \t alors vous devriez songer a candidater a ce master !\n",
      "il y a des livres a lire en statistique  ? \t vous devriez prendre contact avec l ' enseignant de l ' ue et lui demander\n",
      "il y a combien de candidats  ? \t il y a plus de nbrcandidats candidats chaque annee , la selection est rude !\n",
      "combien de places sont ouvertes  ? \t souhaitez - vous suivre le parcours informatique ou mathematiques  ?\n",
      "informatique \t etes - vous un etudiant inscrit en france  ?\n",
      "non \t il y a nbreplaces_hors_france_informatique places disponibles pour les etudiants hors france en parcours informatique .\n",
      "comment je peux payer  ? \t vous pouvez payer par carte , par cheque bancaire , par virement ou en espece .\n",
      "avez - vous une maquette detaillee de ce master  ? \t les details de la formation est disponible sur la page du master parcours informatique : site_informatique\n",
      "comment ca va  ? \t je vais bien merci , en quoi puis - je vous aider  ?\n"
     ]
    }
   ],
   "source": [
    "for qa in dialogues[0] : print(qa[0], '\\t', qa[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modules\n",
    "\n",
    "### 1.1 Word Embedding module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "All details on Word Embedding modules and their pre-training are found in **Part I - 1**. We consider here a FastText model trained following the Skip-Gram training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.models.Word_Embedding import Word2Vec as myWord2Vec\n",
    "from libDL4NLP.models.Word_Embedding import Word2VecConnector\n",
    "from libDL4NLP.utils.Lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_in  = [['SOS'] + [w for w in qa[0].split(' ')] + ['EOS'] for qa in qa_trn]\n",
    "corpus_out = [['SOS'] + [w for w in qa[1].split(' ')]           for qa in qa_trn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareWord2vec(corpus) :\n",
    "    fastText_word2vec = FastText(size = 75, \n",
    "                                 window = 5, \n",
    "                                 min_count = 1, \n",
    "                                 negative = 20,\n",
    "                                 sg = 1)\n",
    "    fastText_word2vec.build_vocab(corpus)\n",
    "    print(len(fastText_word2vec.wv.vocab))\n",
    "    fastText_word2vec.train(sentences = corpus, \n",
    "                            epochs = 50,\n",
    "                            total_examples = fastText_word2vec.corpus_count)\n",
    "    word2vec = Word2VecConnector(fastText_word2vec)\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "word2vec_in  = prepareWord2vec(corpus_in)\n",
    "word2vec_out = prepareWord2vec(corpus_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tex', 0.8783439993858337),\n",
       " ('jour', 0.8747912049293518),\n",
       " ('devra', 0.8675379753112793),\n",
       " ('!', 0.8203660249710083),\n",
       " ('va', 0.8124774098396301),\n",
       " ('ecrits', 0.8053075671195984),\n",
       " ('fort', 0.799565851688385),\n",
       " ('latex', 0.7966715097427368),\n",
       " ('monsieur', 0.7957294583320618),\n",
       " ('faudra', 0.7905347347259521)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_in.word2vec.most_similar('bonjour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accord', 0.9124477505683899),\n",
       " ('aider', 0.8670510053634644),\n",
       " ('puis', 0.8388100862503052),\n",
       " ('ravi', 0.8166019916534424),\n",
       " ('quoi', 0.8113549947738647),\n",
       " ('comment', 0.7998955249786377),\n",
       " ('courage', 0.7849225401878357),\n",
       " ('m', 0.7758355736732483),\n",
       " ('accordez', 0.7747770547866821),\n",
       " ('vais', 0.7704885601997375)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_out.word2vec.most_similar('bonjour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Contextualization module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "This module consists of a bi-directional _Gated Recurrent Unit_ (GRU) that supports packed sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import RecurrentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attention module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"attention\"></a>\n",
    "\n",
    "We use here a classical Attention Module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libDL4NLP.modules import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Decoder module\n",
    "\n",
    "[Back to top](#plan)\n",
    "\n",
    "<a id=\"decoder\"></a>\n",
    "\n",
    "#### 1.4.1 Classical Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, word2vec, hidden_dim, \n",
    "                 n_layers = 1,\n",
    "                 dropout = 0.1,\n",
    "                 bound = 25\n",
    "                ):\n",
    "        super(Decoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bound = bound\n",
    "        # modules\n",
    "        self.word2vec = word2vec\n",
    "        self.gru = nn.GRU(word2vec.output_dim, \n",
    "                          hidden_dim, \n",
    "                          n_layers, \n",
    "                          dropout = dropout, \n",
    "                          batch_first = True)\n",
    "        self.out = nn.Linear(hidden_dim, word2vec.lang.n_words)\n",
    "        self.act = F.log_softmax\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def generateWord(self, hidden, word_index):\n",
    "        # update hidden state\n",
    "        embedding = self.word2vec.embedding(word_index) # size (batch_size, 1, embedding_dim)\n",
    "        embedding = self.dropout(embedding)\n",
    "        _, hidden = self.gru(embedding, hidden)         # size (n_layers, batch_size, embedding_dim)\n",
    "        # generate next word\n",
    "        log_prob = self.out(hidden[-1])                 # size (batch_size, lang_size)\n",
    "        log_prob = self.act(log_prob, dim = 1)          # size (batch_size, lang_size)\n",
    "        return log_prob, hidden\n",
    "    \n",
    "    def forward(self, hidden, device = None) :\n",
    "        answer = []\n",
    "        word_index = self.word2vec.lang.getIndex('SOS')\n",
    "        EOS_token  = self.word2vec.lang.getIndex('EOS')\n",
    "        for t in range(self.bound) :\n",
    "            # compute next word\n",
    "            word_index = Variable(torch.LongTensor([[word_index]]))    # size (1, 1)\n",
    "            if device is not None : word_index = word_index.to(device) # size (1, 1)\n",
    "            log_prob, hidden = self.generateWord(hidden, word_index)\n",
    "            word_index = log_prob.topk(1)[1].item()\n",
    "            # add to output\n",
    "            if word_index == EOS_token : break\n",
    "            else : answer.append(word_index)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Attention Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libDL4NLP.modules import AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Machine Translation Model\n",
    "\n",
    "[Back to top](#plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module) :\n",
    "    def __init__(self, device, tokenizer, word2vec_in, word2vec_out, \n",
    "                 hidden_dim = 100,\n",
    "                 n_layers = 1, \n",
    "                 bound = 25,\n",
    "                 dropout = 0, \n",
    "                 optimizer = optim.SGD\n",
    "                 ):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # embedding\n",
    "        self.tokenizer    = tokenizer\n",
    "        self.word2vec_in  = word2vec_in\n",
    "        self.word2vec_out = word2vec_out\n",
    "        self.context      = RecurrentEncoder(word2vec_in.output_dim, hidden_dim, n_layers, dropout, bidirectional = True)\n",
    "        self.decoder      = Decoder(word2vec_out, hidden_dim, n_layers, dropout, bound)\n",
    "        \n",
    "        # optimizer\n",
    "        self.ignore_index_in  = self.word2vec_in.lang.getIndex('PADDING_WORD')\n",
    "        self.ignore_index_out = self.word2vec_out.lang.getIndex('PADDING_WORD')\n",
    "        self.criterion = nn.NLLLoss(size_average = False, ignore_index = self.ignore_index_out)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # load to device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def nbParametres(self) :\n",
    "        return sum([p.data.nelement() for p in self.parameters() if p.requires_grad == True])\n",
    "    \n",
    "    def forward(self, sentence, color_code = '\\033[94m'):\n",
    "        # encode sentence\n",
    "        words  = self.tokenizer(sentence)\n",
    "        embeddings = self.word2vec_in(words, self.device)\n",
    "        _, hidden  = self.context(embeddings)\n",
    "        # sum along directions\n",
    "        if self.context.bidirectional :\n",
    "            hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "            hidden = torch.sum(hidden, dim = 1) # size (n_layers, batch_size, hidden_dim)\n",
    "        # generate answer\n",
    "        answer = self.decoder(hidden, self.device)\n",
    "        answer = [self.word2vec_out.lang.index2word[i] for i in answer]\n",
    "        print(' '.join(words + [':', color_code] + answer + ['\\033[0m']))\n",
    "        return\n",
    "    \n",
    "    def generatePackedSentences(self, sentences, batch_size = 32) : \n",
    "        sentences.sort(key = lambda s: len(s[1]), reverse = True)\n",
    "        packed_data = []\n",
    "        for i in range(0, len(sentences), batch_size) :\n",
    "            # prepare input and target pack\n",
    "            pack = sentences[i:i + batch_size]\n",
    "            pack.sort(key = lambda s: len(self.tokenizer(s[0])), reverse = True)\n",
    "            pack0 = [[self.word2vec_in.lang.getIndex(w) for w in self.tokenizer(qa[0])] for qa in pack]\n",
    "            pack0 = [[w for w in words if w is not None] for words in pack0]\n",
    "            pack1 = [[self.word2vec_out.lang.getIndex(w) for w in self.tokenizer(qa[1])] for qa in pack]\n",
    "            pack1 = [[w for w in words if w is not None] for words in pack1]\n",
    "            lengths = torch.tensor([len(p) for p in pack0])           # size (batch_size) \n",
    "            # padd packs\n",
    "            pack0 = list(itertools.zip_longest(*pack0, fillvalue = self.ignore_index_in))\n",
    "            pack0 = Variable(torch.LongTensor(pack0).transpose(0, 1)) # size (batch_size, max_length0) \n",
    "            pack1 = list(itertools.zip_longest(*pack1, fillvalue = self.ignore_index_out))\n",
    "            pack1 = Variable(torch.LongTensor(pack1))       # WARNING : size (max_length1, batch_size) \n",
    "            packed_data.append([[pack0, lengths], pack1])\n",
    "        return packed_data\n",
    "    \n",
    "    def compute_accuracy(self, sentences) :\n",
    "        batches = self.generatePackedSentences(sentences, batch_size = 32)\n",
    "        score = 0\n",
    "        for batch, target in batches :\n",
    "            embeddings  = self.word2vec_in.embedding(batch[0].to(self.device))\n",
    "            hiddens, _  = self.context(embeddings, lengths = batch[1].to(self.device))\n",
    "            attended, _ = self.attention(hiddens)\n",
    "            if self.bin_mode : \n",
    "                vects  = self.out(attended).view(-1)\n",
    "                target = target.to(self.device).view(-1)\n",
    "                score += sum(torch.abs(target - self.act(vects)) < 0.5).item()\n",
    "            else : \n",
    "                log_probs = F.log_softmax(self.out(attended.squeeze(1)))\n",
    "                target    = target.to(self.device).view(-1)\n",
    "                score    += sum([target[i].item() == log_probs[i].data.topk(1)[1].item() for i in range(target.size(0))])\n",
    "        return score * 100 / len(sentences)\n",
    "    \n",
    "    def fit(self, batches, iters = None, epochs = None, tf_ratio = 0, lr = 0.025, random_state = 42,\n",
    "              print_every = 10, compute_accuracy = True):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops\"\"\"\n",
    "        def asMinutes(s):\n",
    "            m = math.floor(s / 60)\n",
    "            s -= m * 60\n",
    "            return '%dm %ds' % (m, s)\n",
    "\n",
    "        def timeSince(since, percent):\n",
    "            now = time.time()\n",
    "            s = now - since\n",
    "            rs = s/percent - s\n",
    "            return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "        \n",
    "        def computeSuccess(log_probs, targets) :\n",
    "            success = sum([self.ignore_index_out != targets[i].item() == log_probs[i].topk(1)[1].item() \\\n",
    "                           for i in range(targets.size(0))])\n",
    "            return success\n",
    "        \n",
    "        def computeLogProbs(batch, target, tf_ratio = 0, compute_accuracy = True) :\n",
    "            loss = 0\n",
    "            success = 0\n",
    "            forcing = (random.random() < tf_ratio)\n",
    "            # encode sentences\n",
    "            embeddings = self.word2vec_in.embedding(batch[0].to(self.device))\n",
    "            _, hidden  = self.context(embeddings, lengths = batch[1].to(self.device)) # size (n_layers * num_directions, batch_size, hidden_dim)\n",
    "            # sum along directions\n",
    "            if self.context.bidirectional :\n",
    "                hidden = hidden.view(self.context.n_layers, 2, -1, self.context.hidden_dim)\n",
    "                hidden = torch.sum(hidden, dim = 1)               # size (n_layers, batch_size, hidden_dim)\n",
    "            # compute answers\n",
    "            word_index = self.word2vec_out.lang.getIndex('SOS')\n",
    "            word_index = Variable(torch.LongTensor([word_index])) # size (1)\n",
    "            word_index = word_index.expand(target.size(1))        # size (batch_size)\n",
    "            for t in range(target.size(0)) :\n",
    "                # compute word probs\n",
    "                log_prob, hidden = self.decoder.generateWord(hidden, word_index.unsqueeze(1).to(self.device))\n",
    "                # compute loss\n",
    "                loss += self.criterion(log_prob, target[t])\n",
    "                if compute_accuracy : success += computeSuccess(log_prob, target[t])\n",
    "                # apply teacher forcing\n",
    "                if forcing : word_index = target[t]                             # size (batch_size) \n",
    "                else       : word_index = log_prob.topk(1, dim = 1)[1].view(-1) # size (batch_size)\n",
    "            return loss, success       \n",
    "\n",
    "        def printScores(start, iter, iters, tot_loss, tot_loss_words, print_every, compute_accuracy) :\n",
    "            avg_loss = tot_loss / print_every\n",
    "            avg_loss_words = tot_loss_words / print_every\n",
    "            if compute_accuracy : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}  accuracy : {:.1f} %'.format(iter, int(iter / iters * 100), avg_loss, avg_loss_words))\n",
    "            else                : print(timeSince(start, iter / iters) + ' ({} {}%) loss : {:.3f}                     '.format(iter, int(iter / iters * 100), avg_loss))\n",
    "            return 0, 0\n",
    "\n",
    "        def trainLoop(batch, optimizer, tf_ratio = 0, compute_accuracy = True):\n",
    "            \"\"\"Performs a training loop, with forward pass, backward pass and weight update.\"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            self.zero_grad()\n",
    "            target = batch[1].to(self.device)\n",
    "            total = np.sum(target.data.cpu().numpy() != self.ignore_index_out)\n",
    "            loss, success = computeLogProbs(batch[0], target, tf_ratio, compute_accuracy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return float(loss.item() / total), float(success * 100 / total)\n",
    "        \n",
    "        # --- main ---\n",
    "        self.train()\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in self.parameters() if param.requires_grad == True], lr = lr)\n",
    "        tot_loss = 0  \n",
    "        tot_acc  = 0\n",
    "        if epochs is None :\n",
    "            for iter in range(1, iters + 1):\n",
    "                batch = random.choice(batches)\n",
    "                loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                tot_loss += loss\n",
    "                tot_acc += acc      \n",
    "                if iter % print_every == 0 : \n",
    "                    tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        else :\n",
    "            iter = 0\n",
    "            iters = len(batches) * epochs\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(batches)\n",
    "                for batch in batches :\n",
    "                    loss, acc = trainLoop(batch, optimizer, tf_ratio, compute_accuracy)\n",
    "                    tot_loss += loss\n",
    "                    tot_acc += acc \n",
    "                    iter += 1\n",
    "                    if iter % print_every == 0 : \n",
    "                        tot_loss, tot_acc = printScores(start, iter, iters, tot_loss, tot_acc, print_every, compute_accuracy)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(qa[1].split(' ')) for qa in qa_trn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307122"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = EncoderDecoder(device = torch.device(\"cpu\"),\n",
    "                         tokenizer = lambda s : normalizeString(s).split(' '),\n",
    "                         word2vec_in = word2vec_in,\n",
    "                         word2vec_out = word2vec_out,\n",
    "                         hidden_dim = 75, \n",
    "                         n_layers = 2,\n",
    "                         bound = 75,\n",
    "                         dropout = 0.1,\n",
    "                         optimizer = optim.SGD)\n",
    "\n",
    "chatbot.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (word2vec_in): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(784, 75)\n",
       "    )\n",
       "    (embedding): Embedding(784, 75)\n",
       "  )\n",
       "  (word2vec_out): Word2VecConnector(\n",
       "    (twin): Word2Vec(\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (embedding): Embedding(898, 75)\n",
       "  )\n",
       "  (context): RecurrentEncoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (bigru): GRU(75, 75, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (word2vec): Word2VecConnector(\n",
       "      (twin): Word2Vec(\n",
       "        (embedding): Embedding(898, 75)\n",
       "      )\n",
       "      (embedding): Embedding(898, 75)\n",
       "    )\n",
       "    (gru): GRU(75, 75, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (out): Linear(in_features=75, out_features=897, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = chatbot.generatePackedSentences(qa_trn, batch_size = 16)\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 10s (- 3m 27s) (105 5%) loss : 0.977  accuracy : 77.6 %\n",
      "epoch 2\n",
      "0m 21s (- 3m 14s) (210 10%) loss : 0.934  accuracy : 78.6 %\n",
      "epoch 3\n",
      "0m 32s (- 3m 5s) (315 15%) loss : 0.903  accuracy : 79.6 %\n",
      "epoch 4\n",
      "0m 43s (- 2m 52s) (420 20%) loss : 0.875  accuracy : 79.7 %\n",
      "epoch 5\n",
      "0m 53s (- 2m 41s) (525 25%) loss : 0.839  accuracy : 80.5 %\n",
      "epoch 6\n",
      "1m 4s (- 2m 30s) (630 30%) loss : 0.819  accuracy : 81.0 %\n",
      "epoch 7\n",
      "1m 15s (- 2m 20s) (735 35%) loss : 0.787  accuracy : 81.4 %\n",
      "epoch 8\n",
      "1m 26s (- 2m 9s) (840 40%) loss : 0.764  accuracy : 81.9 %\n",
      "epoch 9\n",
      "1m 37s (- 1m 58s) (945 45%) loss : 0.754  accuracy : 81.9 %\n",
      "epoch 10\n",
      "1m 47s (- 1m 47s) (1050 50%) loss : 0.715  accuracy : 82.8 %\n",
      "epoch 11\n",
      "1m 58s (- 1m 37s) (1155 55%) loss : 0.691  accuracy : 83.3 %\n",
      "epoch 12\n",
      "2m 9s (- 1m 26s) (1260 60%) loss : 0.676  accuracy : 83.7 %\n",
      "epoch 13\n",
      "2m 20s (- 1m 15s) (1365 65%) loss : 0.663  accuracy : 84.0 %\n",
      "epoch 14\n",
      "2m 32s (- 1m 5s) (1470 70%) loss : 0.639  accuracy : 84.6 %\n",
      "epoch 15\n",
      "2m 43s (- 0m 54s) (1575 75%) loss : 0.633  accuracy : 84.4 %\n",
      "epoch 16\n",
      "2m 54s (- 0m 43s) (1680 80%) loss : 0.616  accuracy : 84.7 %\n",
      "epoch 17\n",
      "3m 6s (- 0m 32s) (1785 85%) loss : 0.596  accuracy : 85.4 %\n",
      "epoch 18\n",
      "3m 17s (- 0m 21s) (1890 90%) loss : 0.580  accuracy : 85.6 %\n",
      "epoch 19\n",
      "3m 28s (- 0m 10s) (1995 95%) loss : 0.568  accuracy : 85.6 %\n",
      "epoch 20\n",
      "3m 40s (- 0m 0s) (2100 100%) loss : 0.563  accuracy : 86.1 %\n"
     ]
    }
   ],
   "source": [
    "chatbot.fit(batches, epochs = 20, lr = 0.0025, tf_ratio = 1,  print_every = len(batches))\n",
    "chatbot.fit(batches, epochs = 20, lr = 0.0025, tf_ratio = 0.5,  print_every = len(batches))\n",
    "chatbot.fit(batches, epochs = 20, lr = 0.0005, tf_ratio = 0.5,  print_every = len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "0m 12s (- 3m 48s) (105 5%) loss : 1.484  accuracy : 73.2 %\n",
      "epoch 2\n",
      "0m 23s (- 3m 30s) (210 10%) loss : 1.365  accuracy : 74.9 %\n",
      "epoch 3\n",
      "0m 34s (- 3m 15s) (315 15%) loss : 1.445  accuracy : 73.2 %\n",
      "epoch 4\n",
      "0m 45s (- 3m 2s) (420 20%) loss : 1.451  accuracy : 72.8 %\n",
      "epoch 5\n",
      "0m 58s (- 2m 55s) (525 25%) loss : 1.439  accuracy : 72.3 %\n",
      "epoch 6\n",
      "1m 11s (- 2m 46s) (630 30%) loss : 1.502  accuracy : 72.6 %\n",
      "epoch 7\n",
      "1m 23s (- 2m 34s) (735 35%) loss : 1.447  accuracy : 73.2 %\n",
      "epoch 8\n",
      "1m 35s (- 2m 23s) (840 40%) loss : 1.521  accuracy : 71.7 %\n",
      "epoch 9\n",
      "1m 48s (- 2m 12s) (945 45%) loss : 1.378  accuracy : 73.8 %\n",
      "epoch 10\n",
      "2m 0s (- 2m 0s) (1050 50%) loss : 1.508  accuracy : 72.0 %\n",
      "epoch 11\n",
      "2m 11s (- 1m 47s) (1155 55%) loss : 1.484  accuracy : 71.9 %\n",
      "epoch 12\n",
      "2m 22s (- 1m 34s) (1260 60%) loss : 1.448  accuracy : 73.0 %\n",
      "epoch 13\n",
      "2m 33s (- 1m 22s) (1365 65%) loss : 1.551  accuracy : 71.7 %\n",
      "epoch 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-e771fef18154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchatbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-fb5632e75c70>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, batches, iters, epochs, tf_ratio, lr, random_state, print_every, compute_accuracy)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                     \u001b[0mtot_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[0mtot_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-fb5632e75c70>\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(batch, optimizer, tf_ratio, compute_accuracy)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeLogProbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-fb5632e75c70>\u001b[0m in \u001b[0;36mcomputeLogProbs\u001b[1;34m(batch, target, tf_ratio, compute_accuracy)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;31m# compute word probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                 \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerateWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                 \u001b[1;31m# compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-5222acef2612>\u001b[0m in \u001b[0;36mgenerateWord\u001b[1;34m(self, hidden, word_index)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# size (batch_size, 1, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# size (n_layers, batch_size, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# generate next word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;31m# size (batch_size, lang_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mrun_impl\u001b[1;34m(self, input, hx, batch_sizes)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             result = _VF.gru(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 680\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chatbot.fit(batches, epochs = 20, lr = 0.0001, tf_ratio = 0.5,  print_every = len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(denoiser.state_dict(), path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser_2.pth')\n",
    "\n",
    "# load\n",
    "#denoiser.load_state_dict(torch.load(path_to_NLP + '\\\\saves\\\\models\\\\DL4NLP_I4a_sentence_denoiser.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut ca va ? : \u001b[94m la page ecandidat est disponible sur le lien suivant : siteecandidat \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "chatbot('salut ca va ?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
