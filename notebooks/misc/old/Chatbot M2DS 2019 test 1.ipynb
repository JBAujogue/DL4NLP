{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot M2DS 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "# package a installer d'abord avec anaconda\n",
    "#import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# package a installer d'abord avec anaconda\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import unidecode\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Training data preparation\n",
    "\n",
    "### 1.1 Simple formatting of training dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- enlèvement des stopwords ---------------------------------------\n",
    "def TrimWordsSentence(sentence, stopwords):\n",
    "    '''Remove stopwords from a sentence'''\n",
    "    resultwords = [word for word in sentence if word.lower() not in stopwords]\n",
    "    return resultwords\n",
    "\n",
    "def TrimWordsDialogue(dialogue, stopwords):\n",
    "    '''Remove stopwords from user utterances in a dialogue'''\n",
    "    for pair in dialogue: \n",
    "        pair[0] = TrimWordsSentence(pair[0], stopwords)\n",
    "        #pair[1] = pair[1].strip()\n",
    "    return dialogue\n",
    "\n",
    "def TrimWords(dialogues, stopwords):\n",
    "    '''Remove stopwords from user utterances in a list of dialogues'''\n",
    "    return [TrimWordsDialogue(dialogue, stopwords) for dialogue in dialogues ]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# --------------------------- Normalisation -------------------------------\n",
    "def normalizeString(s):\n",
    "    '''Remove rare symbols from a string'''\n",
    "    def unicodeToAscii(s):\n",
    "        \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"[^a-zA-Z0-9?&\\%\\-\\_]+\", r\" \", s) \n",
    "    return s \n",
    "\n",
    "\n",
    "\n",
    "#--------------------- import des dialogues --------------------\n",
    "def importDialogues(fichier, limite = None):\n",
    "    '''Import a textfile containing dialogues and returns a list, each element \n",
    "       corresponding to a dialogue and also being under the form of a list, with \n",
    "       each element being a list of two elements : an element giving a user \n",
    "       utterance and another element giving the bot response. Both elements are \n",
    "       normalized strings.\n",
    "       Ex. The dialogue :\n",
    "       \n",
    "               hi    hello what can i help you with today\n",
    "               can you book a table    i m on it\n",
    "               \n",
    "       now becomes :\n",
    "       \n",
    "              [['hi', 'hello what can i help you with today'], \n",
    "               ['can you book a table', 'i m on it']]\n",
    "               \n",
    "       Lines corresponding to user utterance with no bot response are discarted.\n",
    "    '''\n",
    "    dialogues_import = open(fichier, encoding='utf-8').read().strip().split('\\n\\n')\n",
    "    dialogues = []\n",
    "    for i, d in enumerate(dialogues_import):\n",
    "        dialogue = []\n",
    "        lines = d.split('\\n')\n",
    "        for l in lines:\n",
    "            if len(l.split('\\t')) == 2 :\n",
    "                pair = [normalizeString(s).split(' ') for s in l.split('\\t')]\n",
    "                dialogue.append(pair)\n",
    "        dialogues.append(dialogue)\n",
    "        if limite is not None and i == limite -1 :\n",
    "            break\n",
    "\n",
    "    return dialogues\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------ Dictionnaire des mots variables -----------------------------\n",
    "def motVar(file):\n",
    "    '''Applies to the Master's program dataset.\n",
    "       Import the collection of pairs token-content for a set of variable words.\n",
    "    '''\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "    motsVar = {}\n",
    "    for l in lines :\n",
    "        cle, valeur = l.split('\\t')\n",
    "        motsVar[cle.lower()] = valeur\n",
    "    return motsVar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Création de la liste des dialogues--------------------\n",
    "def prepareData(opt):\n",
    "    '''Import dialogue from text file and apply some formatting operations,\n",
    "       as described in the functions \n",
    "               - importDialogues\n",
    "               - modify\n",
    "               - TrimWords\n",
    "               - filterDialogues\n",
    "    '''\n",
    "    dialogues = importDialogues(fichier = opt['fichier'], \n",
    "                                limite = opt['limite'])\n",
    "    dialogues = modify(dialogues) if opt['modify'] else dialogues\n",
    "    dialogues = TrimWords(dialogues, opt['stopwords']) # on enlève les stopwords de chaque question\n",
    "    print(\" %s dialogues ...\" % len(dialogues))\n",
    "    print(dialogues[0])\n",
    "    if opt['filtre'] :\n",
    "        #for pair in [pair for pair in pairs if not filterPair(pair)]:\n",
    "        #    print('%s (%d) -> %s (%d)' % (pair[0],len(pair[0].split()),pair[1],len(pair[1].split())))  \n",
    "        dialogues = filterDialogues(dialogues, opt['max_length'])\n",
    "        print('')\n",
    "        print(\"... reduced to %s dialogues\" % len(dialogues))\n",
    "\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motsVar = motVar('C:\\\\Users\\Jb\\Desktop\\Scripts\\data\\Conversations_M2DS\\\\chatbot-M2-DS-Variables.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn each dialogue of the corpus into torch variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variableFromSentence(lang, sentence, rand = 0): # sentence = [str]\n",
    "    indexes=[]\n",
    "    unknowns = 0\n",
    "    for word in sentence:\n",
    "        p = random.random()\n",
    "        if word not in lang.word2index.keys() and 'UNK' in lang.word2index.keys() :\n",
    "            #pass\n",
    "            indexes.append(lang.word2index['UNK'])\n",
    "        elif p >= rand :\n",
    "            indexes.append(lang.word2index[word])\n",
    "        elif p < rand :\n",
    "            e = random.choice([1, 2])\n",
    "            if e == 1 :  # doesn't put any word\n",
    "                pass\n",
    "            elif e == 2 and 'UNK' in lang.word2index.keys() :# hide word with UNK_Token\n",
    "                indexes.append(lang.word2index['UNK'])\n",
    "    indexes.append(lang.word2index['EOS'])                                \n",
    "    result = Variable(torch.LongTensor([[i] for i in indexes]))\n",
    "    return result\n",
    "\n",
    "def variableFromDialogue(lang, dialogue, rand = 0): # sentence = [str]\n",
    "    result = []\n",
    "    for paire in dialogue :\n",
    "        el1 = variableFromSentence(lang, paire[0], rand = rand)\n",
    "        el2 = variableFromSentence(lang, paire[1], rand = 0)\n",
    "        result.append([el1, el2])\n",
    "    return result\n",
    "\n",
    "def variableFromAllDialogues(lang, dialogues, rand = 0): # sentence = [str]\n",
    "    result = []\n",
    "    for dialogue in dialogues :\n",
    "        result.append(variableFromDialogue(lang, dialogue, rand = 0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Language class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\" : 0, \"EOS\" : 1, \"UNK\" : 2}\n",
    "        self.word2count = {\"SOS\" : 0, \"EOS\" : 0, \"UNK\" : 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\"}\n",
    "        self.n_words = 3  # Counts SOS and EOS and UNK\n",
    "\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        '''Add a word to the language'''\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        '''Add to the language all words of a sentence'''\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "            \n",
    "            \n",
    "    def addDialogues(self, dialogues, i):\n",
    "        '''Add to the language all words contained into : either all user utterances \n",
    "          (if i = 0) or all bot utterances (if i = 1), of a list of dialogues'''\n",
    "        for dialogue in dialogues :\n",
    "            for pair in dialogue:\n",
    "                try :\n",
    "                    self.addSentence(pair[i])\n",
    "                except IndexError:\n",
    "                    print(\"Problem with {}\".format(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLanguages(dialogues):\n",
    "    '''Generate three languages classes out of a list of dialogues :\n",
    "            - input_lang containing the user's vocabulary\n",
    "            - output lang containing the bot vocabulary\n",
    "            - output_sentence_lang containing the bot answers as words of a vocabulary\n",
    "    '''\n",
    "    lang = Lang('M2DS')\n",
    "    \n",
    "    lang.addDialogues(dialogues, 0)\n",
    "    lang.addDialogues(dialogues, 1)\n",
    "    print(\"Mots comptés :\")\n",
    "    print(lang.name, lang.n_words)\n",
    "    \n",
    "    return lang\n",
    "\n",
    "\n",
    "def ajout(dialogues, lang, i= 1):\n",
    "    '''addDialogues method of the Lang class with prints.'''\n",
    "    lang.addDialogues(dialogues, i)\n",
    "    print(lang.name, lang.n_words)\n",
    "    return lang \n",
    "\n",
    "\n",
    "def ajoutSentences(dialogues, sentences_lang, i = 1) :\n",
    "    '''Add sentences as words to a given language'''\n",
    "    for dialogue in dialogues :\n",
    "        for pair in dialogue :\n",
    "            try :\n",
    "                sentences_lang.addWord(pair[i])\n",
    "            except IndexError:\n",
    "                print(\"Problem with {}\".format(pair))\n",
    "                \n",
    "    return sentences_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Word encoder\n",
    "\n",
    "Le module **RecurrentWordsEncoder** encode une séquence de mots $w_1, ..., w_T$ en une séquence de vecteurs $h_1, ..., h_T$ en appliquant un plongement suivi d'une couche GRU bi-directionnelle. On peut représenter son fonctionnement par la figure suivante :\n",
    "\n",
    "\n",
    "![WordEncoder](figs/WordEncoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentWordsEncoder(nn.Module):\n",
    "    def __init__(self, device, embedding, hidden_dim, n_layers = 1, dropout = 0): \n",
    "        super(RecurrentWordsEncoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim           # dimension of hidden state of GRUs \n",
    "        self.dropout_p = dropout\n",
    "        self.n_layers = n_layers               # number of stacked GRU layers\n",
    "        self.output_dim = hidden_dim * 2       # dimension of outputed rep. of words and utterance\n",
    "        # parameters\n",
    "        self.embedding = embedding\n",
    "        for p in embedding.parameters() :\n",
    "            embedding_dim = p.data.size(1)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.bigru = nn.GRU(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            n_layers,\n",
    "                            dropout=(0 if n_layers == 1 else dropout), \n",
    "                            bidirectional=True)\n",
    "\n",
    "        \n",
    "    def initHidden(self): \n",
    "        return Variable(torch.zeros(2 * self.n_layers, 1, self.hidden_dim)).to(self.device)\n",
    "\n",
    "    def forward(self, utterance, hidden = None):\n",
    "        embeddings = self.embedding(utterance)                          # dim = (input_length, 1, embedding_dim)\n",
    "        embeddings = self.dropout(embeddings)                           # dim = (input_length, 1, embedding_dim)\n",
    "        outputs, hidden = self.bigru(embeddings, hidden)\n",
    "        outputs = self.dropout(outputs)\n",
    "        return outputs, hidden                                          # dim = (input_length, 1, hidden_dim * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Additive Attention\n",
    "\n",
    "![AttentionAdditive](figs/Attention_Additive.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, query_dim, targets_dim, n_layers = 2): \n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.n_level = 1\n",
    "        self.query_dim = query_dim\n",
    "        self.targets_dim = targets_dim\n",
    "        self.output_dim = targets_dim\n",
    "        self.n_layers = n_layers\n",
    "        # parameters\n",
    "        self.attn_layer = nn.Linear(query_dim + targets_dim, targets_dim) if n_layers >= 1 else None\n",
    "        self.attn_layer2 = nn.Linear(targets_dim, targets_dim) if n_layers >= 2 else None\n",
    "        self.attn_v = nn.Linear(targets_dim, 1, bias = False) if n_layers >= 1 else None\n",
    "        self.act = F.softmax\n",
    "\n",
    "        \n",
    "    def forward(self, query = None, targets = None):\n",
    "        '''takes as parameters : \n",
    "                a query tensor conditionning the attention,     size = (1, minibatch_size, query_dim)\n",
    "                a tensor containing attention targets           size = (targets_length, minibatch_size, targets_dim)\n",
    "           returns : \n",
    "                the resulting tensor of the attention process,  size = (1, minibatch_size, targets_dim)\n",
    "                the attention weights,                          size = (1, targets_length)\n",
    "        '''\n",
    "        if targets is not None :\n",
    "            # concat method \n",
    "            if self.n_layers >= 1 :\n",
    "                poids = torch.cat((query.expand(targets.size(0), -1, -1), targets), 2) if query is not None else targets\n",
    "                poids = self.attn_layer(poids).tanh()                 # size (targets_length, minibatch_size, targets_dim)\n",
    "                if self.n_layers >= 2 :\n",
    "                    poids = self.attn_layer2(poids).tanh()            # size (targets_length, minibatch_size, targets_dim)\n",
    "                attn_weights = self.attn_v(poids)                     # size (targets_length, minibatch_size, 1)\n",
    "                attn_weights = torch.transpose(attn_weights, 0,1)     # size (minibatch_size, targets_length, 1)\n",
    "                targets = torch.transpose(targets, 0,1)               # size (minibatch_size, targets_length, targets_dim)\n",
    "            # dot method\n",
    "            else :\n",
    "                targets = torch.transpose(targets, 0,1)               # size (minibatch_size, targets_length, targets_dim)\n",
    "                query = torch.transpose(query, 0, 1)                  # size (minibatch_size, 1, query_dim)\n",
    "                query = torch.transpose(query, 1, 2)                  # size (minibatch_size, query_dim, 1)\n",
    "                attn_weights = torch.bmm(targets, query)              # size (minibatch_size, targets_length, 1)\n",
    "                \n",
    "            attn_weights = self.act(attn_weights, dim = 1)        # size (minibatch_size, targets_length, 1)\n",
    "            attn_weights = torch.transpose(attn_weights, 1,2)     # size (minibatch_size, 1, targets_length)\n",
    "            attn_applied = torch.bmm(attn_weights, targets)       # size (minibatch_size, 1, targets_dim)\n",
    "            attn_applied = torch.transpose(attn_applied, 0,1)     # size (1, minibatch_size, targets_dim)\n",
    "\n",
    "        else :\n",
    "            attn_applied = query\n",
    "            attn_weights = None\n",
    "        return attn_applied, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Module performing additive attention over a sequence of vectors stored in\n",
    "       a memory block, conditionned by some vector. At instanciation it takes as imput :\n",
    "       \n",
    "                - query_dim : the dimension of the conditionning vector\n",
    "                - targets_dim : the dimension of vectors stored in memory\n",
    "                \n",
    "      Other ideas on Multi head attention on \n",
    "      https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/SubLayers.py\n",
    "      https://github.com/tlatkowski/multihead-siamese-nets/blob/master/layers/attention.py\n",
    "    '''\n",
    "    def __init__(self, device, n_heads, query_dim, targets_dim, n_layers = 2): \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.n_level = 1\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        # parameters\n",
    "        self.attn_modules_list = nn.ModuleList([AdditiveAttention(query_dim, targets_dim, n_layers) for i in range(n_heads)])\n",
    "\n",
    "        \n",
    "    def forward(self, query = None, targets = None):\n",
    "        '''takes as parameters : \n",
    "                a query tensor conditionning the attention,     size = (1, n_heads, query_dim)\n",
    "                a tensor containing attention targets           size = (targets_length, n_heads, targets_dim)\n",
    "           returns : \n",
    "                the resulting tensor of the attention process,  size = (1, n_heads, targets_dim)\n",
    "                the attention weights,                          size = (n_heads, 1, targets_length)\n",
    "        '''\n",
    "        print(\"multihead attention\")\n",
    "        targets_length = targets.size(0)\n",
    "        targets_dim    = targets.size(2)\n",
    "        attn_applied   = Variable(torch.zeros(1, self.n_heads, targets_dim)).to(self.device)\n",
    "        attn_weights   = torch.zeros(self.n_heads, 1, targets_length).to(self.device)\n",
    "        for i, attn in enumerate(self.attn_modules_list) :\n",
    "            que = query[:, i, :] if query is not None else None\n",
    "            print(que.size())\n",
    "            tar = targets[:, i, :].unsqueeze(1)\n",
    "            print(tar.size())\n",
    "            attn_appl, attn_wghts = attn(que, tar)\n",
    "            print(attn_appl.size())\n",
    "            print(attn_wghts.size())\n",
    "            attn_applied[:, i, :] = attn_appl.squeeze(1)\n",
    "            attn_weights[i, :, :] = attn_wghts.squeeze(0)\n",
    "        return attn_applied, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Memory tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HierarchicalAttention](figs/Hierarchical_Attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentHierarchicalAttention(nn.Module):\n",
    "    '''Ce module d'attention est :\n",
    "    \n",
    "    - hiérarchique avec bi-GRU entre chaque niveau d'attention\n",
    "    - multi-tête sur chaque niveau d'attention\n",
    "    - globalement multi-hopé, où il est possible d'effectuer plusieurs passes pour accumuler de l'information\n",
    "    '''\n",
    "\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 word_hidden_dim, \n",
    "                 sentence_hidden_dim,\n",
    "                 base_query_dim = 0, \n",
    "                 n_heads = 1,\n",
    "                 n_layers = 1,\n",
    "                 hops = 1,\n",
    "                 share = True,\n",
    "                 transf = False,\n",
    "                 dropout = 0\n",
    "                ):\n",
    "        super(RecurrentHierarchicalAttention, self).__init__()\n",
    "        \n",
    "        # dimensions\n",
    "        self.word_hidden_dim = word_hidden_dim\n",
    "        self.sentence_input_dim = self.word_hidden_dim\n",
    "        self.sentence_hidden_dim = sentence_hidden_dim\n",
    "        self.context_vector_dim = sentence_hidden_dim * 2\n",
    "        self.output_dim = sentence_hidden_dim * 2\n",
    "        self.base_query_dim = base_query_dim\n",
    "        self.hops_query_dim = self.output_dim if hops > 1 else 0\n",
    "        self.query_dim = self.base_query_dim + self.hops_query_dim\n",
    "        \n",
    "        # structural coefficients\n",
    "        self.device = device\n",
    "        self.n_level = 2\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.hops = hops\n",
    "        self.share = share\n",
    "        self.dropout_p = dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        # first attention module\n",
    "        attn1_list = []\n",
    "        if share :\n",
    "            attn1 = MultiHeadAdditiveAttention(n_heads, self.query_dim, self.word_hidden_dim) if n_heads > 1 else \\\n",
    "                    AdditiveAttention(self.query_dim, self.word_hidden_dim) \n",
    "            for hop in range(hops):\n",
    "                attn1_list.append(attn1)\n",
    "            self.attn1 = nn.ModuleList(attn1_list)\n",
    "        else :\n",
    "            for hop in range(hops):\n",
    "                qd = self.query_dim if hop > 0 else self.base_query_dim\n",
    "                attn1 = MultiHeadAdditiveAttention(n_heads, qd, self.word_hidden_dim) if n_heads > 1 else \\\n",
    "                        AdditiveAttention(qd, self.word_hidden_dim) \n",
    "                attn1_list.append(attn1)\n",
    "            self.attn1 = nn.ModuleList(attn1_list)\n",
    "        \n",
    "        # intermediate encoder module\n",
    "        self.bigru = nn.GRU(self.sentence_input_dim, \n",
    "                            self.sentence_hidden_dim, \n",
    "                            n_layers,\n",
    "                            dropout=(0 if n_layers == 1 else dropout), \n",
    "                            bidirectional=True)\n",
    "        \n",
    "        # second attention module\n",
    "        attn2_list = []\n",
    "        if share :\n",
    "            attn2 = MultiHeadAdditiveAttention(n_heads, self.query_dim, self.context_vector_dim) if n_heads > 1 else \\\n",
    "                    AdditiveAttention(self.query_dim, self.context_vector_dim) \n",
    "            for hop in range(hops):\n",
    "                attn2_list.append(attn2)\n",
    "            self.attn2 = nn.ModuleList(attn2_list)\n",
    "        else :\n",
    "            for hop in range(hops):\n",
    "                qd = self.query_dim if hop > 0 else self.base_query_dim\n",
    "                attn2 = MultiHeadAdditiveAttention(n_heads, qd, self.context_vector_dim) if n_heads > 1 else \\\n",
    "                        AdditiveAttention(qd, self.context_vector_dim) \n",
    "                attn2_list.append(attn2)\n",
    "            self.attn2 = nn.ModuleList(attn2_list)\n",
    "        \n",
    "        # accumulation step\n",
    "        self.transf = nn.GRU(self.context_vector_dim, self.context_vector_dim) if transf else None\n",
    "\n",
    "\n",
    "    def initQuery(self): \n",
    "        if self.hops_query_dim > 0 :\n",
    "            return Variable(torch.zeros(1, self.n_heads, self.hops_query_dim)).to(self.device)\n",
    "        return None\n",
    "        \n",
    "                \n",
    "    def initHidden(self): \n",
    "        return Variable(torch.zeros(2 * self.n_layers, self.n_heads, self.sentence_hidden_dim)).to(self.device)\n",
    "        \n",
    "        \n",
    "    def singlePass(self, words_memory, query, attn1, attn2): \n",
    "        L = len(words_memory)\n",
    "        attn1_weights = {}\n",
    "        bigru_inputs = Variable(torch.zeros(L, self.n_heads, self.sentence_input_dim)).to(self.device)\n",
    "        # first attention layer\n",
    "        for i in range(L) :\n",
    "            targets = words_memory[i]                              # size (N_i, 1, 2*word_hidden_dim)\n",
    "            targets = targets.repeat(1, self.n_heads, 1)           # size (N_i, n_heads, 2*word_hidden_dim)\n",
    "            attn1_output, attn1_wghts = attn1(query, targets)\n",
    "            attn1_output = self.dropout(attn1_output)\n",
    "            attn1_weights[i] = attn1_wghts\n",
    "            bigru_inputs[i] = attn1_output.squeeze(0)              # size (n_heads, 2*word_hidden_dim)\n",
    "        # intermediate biGRU\n",
    "        bigru_hidden = self.initHidden()\n",
    "        attn2_inputs, bigru_hidden = self.bigru(bigru_inputs, bigru_hidden)  # size (L, n_heads, 2*word_hidden_dim)\n",
    "        # second attention layer\n",
    "        attn2_inputs = self.dropout(attn2_inputs)\n",
    "        decision_vector, attn2_weights = attn2(query = query, targets = attn2_inputs)\n",
    "        decision_vector = self.dropout(decision_vector)\n",
    "        attn2_weights = attn2_weights.view(-1)\n",
    "        # output decision vector\n",
    "        return decision_vector, attn1_weights, attn2_weights\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, hops_query, decision_vector):\n",
    "        if self.transf is not None :\n",
    "            _ , update = self.transf(decision_vector, hops_query)\n",
    "        else :\n",
    "            update = hops_query + decision_vector\n",
    "        return update\n",
    "        \n",
    "        \n",
    "    def forward(self, words_memory, base_query = None):\n",
    "        '''takes as parameters : \n",
    "                a tensor containing words_memory vectors        dim = (words_memory_length, word_hidden_dim)\n",
    "                a tensor containing past queries                dim = (words_memory_length, query_dim)\n",
    "           returns : \n",
    "                the resulting decision vector                   dim = (1, 1, query_dim)\n",
    "                the weights of first attention layer (dict)     \n",
    "                the weights of second attention layer (dict)\n",
    "        '''\n",
    "        attn1_weights_list = []\n",
    "        attn2_weights_list = []\n",
    "        if len(words_memory) > 0 :\n",
    "            if base_query is not None :\n",
    "                base_query = base_query.repeat(1, self.n_heads, 1)\n",
    "            if self.hops > 1 and self.share :\n",
    "                hops_query = self.initQuery()\n",
    "            else :\n",
    "                hops_query = None\n",
    "\n",
    "            for hop in range(self.hops) :\n",
    "                if base_query is not None and hops_query is not None :\n",
    "                    query = torch.cat((base_query, hops_query), 2) # size (1, self.n_heads, self.query_dim)\n",
    "                elif base_query is not None :\n",
    "                    query = base_query\n",
    "                elif hops_query is not None :\n",
    "                    query = hops_query\n",
    "                else :\n",
    "                    query = None\n",
    "                decision_vector, attn1_weights, attn2_weights = self.singlePass(words_memory, \n",
    "                                                                                query, \n",
    "                                                                                self.attn1[hop], \n",
    "                                                                                self.attn2[hop])\n",
    "                attn1_weights_list.append(attn1_weights)\n",
    "                attn2_weights_list.append(attn2_weights)\n",
    "                if self.hops > 1 and hops_query is not None :\n",
    "                    hops_query = self.update(hops_query, decision_vector)  # size (L, self.n_heads, self.output_dim)\n",
    "                else :\n",
    "                    hops_query = decision_vector\n",
    "        else :\n",
    "            hops_query = base_query\n",
    "        # output decision vector\n",
    "        return hops_query, attn1_weights_list, attn2_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Word decoder\n",
    "\n",
    "$h_q$ is the vector issued from the current user utterance\n",
    "\n",
    "$h'_q$ is the decision vector obtained after memory tracking\n",
    "\n",
    "![Decoder](figs/Decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsDecoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, device, embedding, hidden_dim, dropout = 0.1):\n",
    "        super(WordsDecoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # modules\n",
    "        self.embedding = embedding\n",
    "        for p in embedding.parameters() :\n",
    "            lang_size     = p.data.size(0)\n",
    "            embedding_dim = p.data.size(1)\n",
    "        self.gru = nn.GRU(embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, lang_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def generateWord(self, decision_vector, hidden, current_word_index):\n",
    "        # update hidden state\n",
    "        current_word = self.embedding(current_word_index).view(1,1,-1)\n",
    "        embedded = torch.cat((current_word, decision_vector), dim = 2)\n",
    "        embedded = self.dropout(embedded)\n",
    "        _, hidden = self.gru(embedded, hidden)\n",
    "        # generate next word\n",
    "        vector = self.out(hidden).squeeze(0)\n",
    "        log_proba = F.log_softmax(vector, dim = 1)\n",
    "        return log_proba, hidden\n",
    "    \n",
    "    \n",
    "    def forward(self, last_words, query_vector, decision_vector, target_answer = None) :\n",
    "        bound = 25\n",
    "        log_probas = []\n",
    "        answer = []\n",
    "        di = 0\n",
    "        hidden = self.dropout(decision_vector)\n",
    "        query_vector = self.dropout(query_vector)\n",
    "        current_word_index = Variable(torch.LongTensor([[0]])).to(self.device) # SOS_token\n",
    "        for di in range(bound) :\n",
    "            log_proba, hidden = self.generateWord(query_vector, hidden, current_word_index)\n",
    "            topv, topi = log_proba.data.topk(1)\n",
    "            log_probas.append(log_proba)\n",
    "            ni = topi[0][0] # index of current generated word\n",
    "            if ni == 1 : # EOS_token\n",
    "                break\n",
    "            elif target_answer is not None : # Teacher forcing\n",
    "                answer.append(ni)\n",
    "                if di < target_answer.size(0) :\n",
    "                    current_word_index = target_answer[di].to(self.device)\n",
    "                else :\n",
    "                    break\n",
    "            else :\n",
    "                answer.append(ni)\n",
    "                current_word_index = Variable(torch.LongTensor([[ni]])).to(self.device)\n",
    "        return answer, log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnWordsDecoder(nn.Module):\n",
    "    '''Transforms a vector into a sequence of words'''\n",
    "    def __init__(self, device, embedding, hidden_dim, n_layers = 0, dropout = 0.1):\n",
    "        super(AttnWordsDecoder, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        # modules\n",
    "        self.embedding = embedding\n",
    "        for p in embedding.parameters() :\n",
    "            lang_size     = p.data.size()[0]\n",
    "            embedding_dim = p.data.size()[1]\n",
    "        self.gru = nn.GRU(embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.attn = AdditiveAttention(hidden_dim, hidden_dim, n_layers) \n",
    "        self.concat = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, lang_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def generateWord(self, last_words, decision_vector, hidden, current_word_index):\n",
    "        # update hidden state\n",
    "        current_word = self.embedding(current_word_index).view(1,1,-1)\n",
    "        #current_word = self.dropout(current_word)\n",
    "        embedded = torch.cat((current_word, decision_vector), dim = 2)\n",
    "        embedded = self.dropout(embedded)\n",
    "        _, hidden = self.gru(embedded, hidden)\n",
    "        # generate next word\n",
    "        attn, attn_weights = self.attn(hidden, last_words)\n",
    "        vector = self.concat(torch.cat((hidden, attn), dim = 2)).tanh()\n",
    "        vector = self.out(vector).squeeze(0)\n",
    "        log_proba = F.log_softmax(vector, dim = 1)\n",
    "        return log_proba, hidden\n",
    "    \n",
    "    \n",
    "    def forward(self, last_words, query_vector, decision_vector, target_answer = None) :\n",
    "        bound = 25\n",
    "        log_probas = []\n",
    "        answer = []\n",
    "        di = 0\n",
    "        decision_vector = self.dropout(decision_vector)\n",
    "        current_word_index = Variable(torch.LongTensor([[0]])).to(self.device) # SOS_token\n",
    "        last_words = self.dropout(last_words)\n",
    "        hidden = self.dropout(query_vector)\n",
    "        for di in range(bound) :\n",
    "            log_proba, hidden = self.generateWord(last_words, decision_vector, hidden, current_word_index)\n",
    "            topv, topi = log_proba.data.topk(1)\n",
    "            log_probas.append(log_proba)\n",
    "            ni = topi[0][0] # index of current generated word\n",
    "            if ni == 1 : # EOS_token\n",
    "                break\n",
    "            elif target_answer is not None : # Teacher forcing\n",
    "                answer.append(ni)\n",
    "                if di < target_answer.size(0) :\n",
    "                    current_word_index = target_answer[di].to(self.device)\n",
    "                else :\n",
    "                    break\n",
    "            else :\n",
    "                answer.append(ni)\n",
    "                current_word_index = Variable(torch.LongTensor([[ni]])).to(self.device)\n",
    "        return answer, log_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Chatbot model\n",
    "\n",
    "![Chatbot](figs/Chatbot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot(nn.Module):\n",
    "    \"\"\"Conversationnal agent with bi-GRU Encoder, taking as parameters at training time :\n",
    "    \n",
    "            -a complete dialogue of the form (with each content as string)\n",
    "    \n",
    "                    [['question 1', 'answer 1'],\n",
    "                     ['question 2', 'answer 2'],\n",
    "                             ..........\n",
    "                     ['current question', 'current answer']]\n",
    "     \n",
    "            -the current answer for teacher forcing, or None\n",
    "    \n",
    "    and at test time :\n",
    "    \n",
    "            -the current question as string\n",
    "    \n",
    "    Returns :\n",
    "     \n",
    "            -word indices of the generated answer, according to output language of the model\n",
    "            -attention weights of first attention layer, or None is no attention\n",
    "            -attention weights of second attention layer, or None is no attention\n",
    "    \"\"\"\n",
    "    def __init__(self, device, lang, encoder, attention, decoder):\n",
    "        super(Chatbot, self).__init__()\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.lang = lang \n",
    "        self.device = device\n",
    "        self.n_level = attention.n_level if attention is not None else 1\n",
    "        self.memory_dim = encoder.output_dim\n",
    "        self.memory_length = 0\n",
    "        # modules        \n",
    "        self.encoder = encoder\n",
    "        self.attention = attention\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        \n",
    "        \n",
    "    # ---------------------- Technical methods -----------------------------\n",
    "    def loadSubModule(self, encoder = None, attention = None, decoder = None) :\n",
    "        if encoder is not None :\n",
    "            self.encoder = encoder\n",
    "        if attention is not None :\n",
    "            self.attention = attention\n",
    "        if decoder is not None :\n",
    "            self.decoder = decoder\n",
    "        return\n",
    "    \n",
    "    def freezeSubModule(self, encoder = False, attention = False, decoder = False) :\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = not encoder\n",
    "        for param in self.attention.parameters():\n",
    "            param.requires_grad = not attention\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = not decoder\n",
    "        return\n",
    "    \n",
    "    def nbParametres(self) :\n",
    "        count = 0\n",
    "        for p in self.parameters():\n",
    "            if p.requires_grad == True :\n",
    "                count += p.data.nelement()\n",
    "        return count\n",
    "    \n",
    "    \n",
    "    def flatten(self, description) :\n",
    "        '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "        flatten = []\n",
    "        for line in description :\n",
    "            flatten += line\n",
    "        return flatten\n",
    "\n",
    "    \n",
    "    \n",
    "    # ------------------------ Text processing methods ---------------------------------\n",
    "    def variableFromSentence(self, sentence):\n",
    "        def normalizeString(sentence) :\n",
    "            '''Remove rare symbols from a string'''\n",
    "            def unicodeToAscii(s):\n",
    "                \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "                return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "            sentence = unicodeToAscii(sentence.lower().strip())\n",
    "            sentence = re.sub(r\"[^a-zA-Z0-9?&\\%\\-\\_]+\", r\" \", sentence) \n",
    "            return sentence\n",
    "        sentence = normalizeString(sentence).split(' ') # a raw string transformed into a list of clean words\n",
    "        indexes=[]\n",
    "        unknowns = 0\n",
    "        for word in sentence:\n",
    "            if word not in self.lang.word2index.keys() and 'UNK' in self.lang.word2index.keys() :\n",
    "                indexes.append(self.lang.word2index['UNK'])\n",
    "            else :\n",
    "                indexes.append(self.lang.word2index[word])\n",
    "        indexes.append(self.lang.word2index['EOS'])                                \n",
    "        result = Variable(torch.LongTensor([[i] for i in indexes]))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------------------------ Visualisation methods ---------------------------------\n",
    "    def flattenDialogue(self, dialogue):\n",
    "        flatten = []\n",
    "        for paire in dialogue :\n",
    "            flatten += paire\n",
    "        return [[int(word) for word in sentence.data.view(-1)] for sentence in flatten]\n",
    "    \n",
    "    def flattenWeights(self, weights) :\n",
    "        '''Baisse le nombre de niveaux de 1 dans les poids d'attention'''\n",
    "        flatten = []\n",
    "        for weight_layer in weights :\n",
    "            flatten.append(torch.cat(tuple(weight_layer.values()), dim = 2))\n",
    "        return flatten\n",
    "    \n",
    "    def formatWeights(self, dialogue, attn1_weights, attn2_weights) :\n",
    "        if self.n_level == 2 :\n",
    "            attn1_weights = self.flattenWeights(attn1_weights)\n",
    "        hops = self.attention.hops\n",
    "        l, L = len(dialogue), max([len(line) for line in dialogue])\n",
    "        Table = np.zeros((l, 1, L))\n",
    "        Liste = np.zeros((l, 1)) if attn2_weights is not None else None\n",
    "        count = 0\n",
    "        count_line = 0\n",
    "        for i, line in enumerate(dialogue) :\n",
    "            present = False\n",
    "            for j, word in enumerate(line) :\n",
    "                if word in self.lang.index2word.keys():\n",
    "                    present = True\n",
    "                    Table[i, 0, j] = sum([attn1_weights[k][0, 0, count].data for k in range(hops)])\n",
    "                    count += 1\n",
    "            if present and Liste is not None :\n",
    "                Liste[i] = sum([attn2_weights[k][count_line].data for k in range(hops)])\n",
    "                count_line += 1\n",
    "        return Table, Liste\n",
    "    \n",
    "    def showWeights(self, dialogue, attn1_weights, attn2_weights, maxi):\n",
    "        table, liste = self.formatWeights(dialogue[:-2], attn1_weights, attn2_weights)\n",
    "        l = table.shape[0]\n",
    "        L = table.shape[2]\n",
    "        fig = plt.figure(figsize = (l, L))\n",
    "        for i, line in enumerate(dialogue[:-2]):\n",
    "            ligne = [self.lang.index2word[int(word)] for word in line]\n",
    "            ax = fig.add_subplot(l, 1, i+1)\n",
    "            vals = table[i]\n",
    "            text = [' '] + ligne + [' ' for k in range(L-len(ligne))] if L>len(ligne) else [' '] + ligne\n",
    "            if liste is not None :\n",
    "                vals = np.concatenate((np.zeros((1, 1)) , vals), axis = 1)  \n",
    "                vals = np.concatenate((np.reshape(liste[i], (1, 1)) , vals), axis = 1)\n",
    "                turn = 'User' if i % 2 == 0 else 'Bot'\n",
    "                text = [turn] + [' '] + text\n",
    "            cax = ax.matshow(vals, vmin=0, vmax=maxi, cmap='YlOrBr')\n",
    "            ax.set_xticklabels(text, ha='left')\n",
    "            ax.set_yticklabels(' ')\n",
    "            ax.tick_params(axis=u'both', which=u'both',length=0, labelrotation = 30, labelright  = True)\n",
    "            ax.grid(b = False, which=\"minor\", color=\"w\", linestyle='-', linewidth=1)\n",
    "            ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "            plt.subplots_adjust(hspace=0, wspace = 0.1)\n",
    "        plt.show()\n",
    "    \n",
    "    def showAttention(self, dialogue, n_col = 1, maxi = None):\n",
    "        answer, decoder_outputs, attn1_weights, attn2_weights = self.answerTrain(dialogue)\n",
    "        dialogue = self.flattenDialogue(dialogue)\n",
    "        if len(dialogue) > 1 :\n",
    "            self.showWeights(dialogue, attn1_weights, attn2_weights, maxi)\n",
    "        print('User : ', ' '.join([self.lang.index2word[int(word)] for word in dialogue[-2][:-1]]))\n",
    "        print('target : ', ' '.join([self.lang.index2word[int(word)] for word in dialogue[-1][:-1]]))\n",
    "        print('predic : ', ' '.join([self.lang.index2word[int(word)] for word in answer]))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------------------- Process methods ------------------------\n",
    "    def initMemory(self):\n",
    "        \"\"\"Initialize memory slots\"\"\"\n",
    "        self.memory = {}\n",
    "        self.memory_queries = {}\n",
    "        self.query_hidden = self.encoder.initHidden()\n",
    "        self.memory_length = 0\n",
    "        \n",
    "    def updateMemory(self, last_words, query_hidden):\n",
    "        \"\"\"Update memory with a list of word vectors 'last_words' and the last query vector 'last_query'\"\"\"\n",
    "        self.memory[self.memory_length] = last_words\n",
    "        self.memory_queries[self.memory_length] = query_hidden\n",
    "        self.query_hidden = query_hidden\n",
    "        self.memory_length += 1\n",
    "        \n",
    "    def readSentence(self, utterance):\n",
    "        \"\"\"Perform reading of an utterance, returning created word vectors\n",
    "           and last hidden states of teh encoder bi-GRU\n",
    "        \"\"\"\n",
    "        utterance = utterance.to(self.device)\n",
    "        last_words, query_hidden = self.encoder(utterance, self.query_hidden)\n",
    "        return last_words, query_hidden\n",
    "        \n",
    "    def readDialogue(self, dialogue):\n",
    "        \"\"\"Loop of readUtterance over a whole dialogue\n",
    "        \"\"\"\n",
    "        for i in range(len(dialogue)) :\n",
    "            for j in range(2):\n",
    "                utterance = dialogue[i][j]\n",
    "                last_words, query_hidden = self.readSentence(utterance)\n",
    "                self.updateMemory(last_words, query_hidden)\n",
    "   \n",
    "    def tracking(self, query_vector):\n",
    "        \"\"\"Détermine un vecteur d'attention sur les éléments du registre de l'agent,\n",
    "        sachant un vecteur 'very_last_hidden', et l'accole à ce vecteur \"\"\"\n",
    "        decision_vector, attn1_weights, attn2_weights = self.attention(words_memory = self.memory, \n",
    "                                                                       base_query = query_vector)\n",
    "        return decision_vector, attn1_weights, attn2_weights\n",
    "\n",
    "    def generateAnswer(self,last_words, query_vector, decision_vector, target_answer = None) :\n",
    "        \"\"\"Génère une réponse à partir d'un état caché initialisant le décodeur,\n",
    "        en utilisant une réponse cible pour un mode 'teacher forcing-like' si celle-ci est fournie \"\"\"\n",
    "        answer, decoder_outputs = self.decoder(last_words, query_vector, decision_vector, target_answer)\n",
    "        return answer, decoder_outputs\n",
    "        \n",
    "        \n",
    "        \n",
    "    # ------------ 1st working mode : training mode ------------\n",
    "    def answerTrain(self, input, target_answer = None):\n",
    "        \"\"\"Parameters are a complete dialogue, containing the current query and answer, and of the form\n",
    "\n",
    "                    [['query 1', 'answer 1'],\n",
    "                     ['query 2', 'answer 2'],\n",
    "                             ..........\n",
    "                     ['current query', 'current answer']]\n",
    "\n",
    "           The model learns to generate the current answer. \n",
    "           Teacher forcing can be enabled by passing the ground answer though the 'target_answer' option. \n",
    "           Attention weights over words and past utterances can be provided with the 'provideAttention' option.\"\"\"\n",
    "        # 1) initiates memory instance\n",
    "        self.initMemory()\n",
    "        \n",
    "        # 2) reads historical part of dialogue (if applicable),\n",
    "        # word vectors and last hidden states of encoder bi-GRU are stored in memory\n",
    "        dialogue = input[:-1]\n",
    "        self.readDialogue(dialogue)\n",
    "        \n",
    "        # 3) reads current utterance,\n",
    "        # returns word vectors of query and query vector\n",
    "        query = input[-1][0]\n",
    "        last_words, query_hidden = self.readSentence(query)\n",
    "        q_hidden = query_hidden.view(1,1,-1)\n",
    "        \n",
    "        # 4) performs tracking\n",
    "        # returns decision vector\n",
    "        if self.attention is not None :\n",
    "            decision_vector, attn1_weights, attn2_weights = self.tracking(q_hidden)\n",
    "        else :\n",
    "            decision_vector = q_hidden\n",
    "            attn1_attention_weights = None\n",
    "            attn2_attention_weights = None\n",
    "            \n",
    "        # 5) response generation\n",
    "        # returns list of indices\n",
    "        answer, decoder_outputs = self.generateAnswer(last_words, q_hidden, decision_vector, target_answer)\n",
    "            \n",
    "        # 6) returns answer\n",
    "        return answer, decoder_outputs, attn1_weights, attn2_weights\n",
    "\n",
    "        \n",
    "        \n",
    "    # ------------ 2nd working mode : test mode ------------\n",
    "    def forward(self, input):\n",
    "        \"\"\"Parameters are a single current query as string, and the model learns to generate the current answer. \n",
    "           Attention weights over words and past utterances can be provided with the 'provideAttention' option.\"\"\"\n",
    "        \n",
    "        # 1) initiates memory and hidden states of encoder bi-GRU if conversation starts\n",
    "        if self.memory_length == 0 :\n",
    "            self.initMemory()\n",
    "            \n",
    "        # 2) reads current utterance,\n",
    "        # returns word vectors of query and query vector\n",
    "        sentence = self.variableFromSentence(input)\n",
    "        if sentence is None :\n",
    "            return \"Excusez-moi je n'ai pas compris\", None, None, None\n",
    "        else :\n",
    "            last_words, query_hidden = self.readSentence(sentence)\n",
    "            q_hidden = query_hidden.view(1,1,-1)\n",
    "\n",
    "            # 3) performs tracking\n",
    "            # returns decision vector\n",
    "            if self.attention is not None :\n",
    "                decision_vector, attn1_weights, attn2_weights = self.tracking(q_hidden)\n",
    "            else :\n",
    "                decision_vector = q_hidden\n",
    "                attn1_attention_weights = None\n",
    "                attn2_attention_weights = None\n",
    "\n",
    "            # 4) response generation\n",
    "            # returns list of indices\n",
    "            answer, decoder_outputs = self.generateAnswer(last_words, q_hidden, decision_vector)\n",
    "            \n",
    "            # 5) updates memory with current query and answer\n",
    "            self.updateMemory(last_words, query_hidden)\n",
    "            answer_var = Variable(torch.LongTensor([[i] for i in answer]))\n",
    "            last_words, query_hidden = self.readSentence(answer_var)\n",
    "            self.updateMemory(last_words, query_hidden)\n",
    "\n",
    "            # 6) returns answer\n",
    "            answer = ' '.join([self.lang.index2word[int(word)] for word in answer])\n",
    "            return answer, attn1_weights, attn2_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training and evaluation module\n",
    "\n",
    "Training module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBot(lang,                     ###\n",
    "              embedding_dim,              # --- Encoder options\n",
    "              hidden_dim,                 #\n",
    "              n_layers,                 ###\n",
    "\n",
    "              sentence_hidden_dim,      ###\n",
    "              hops,                       #\n",
    "              share,                      # --- Hierarchical encoder options\n",
    "              transf,                     #\n",
    "              dropout,                  ###\n",
    "              \n",
    "              attn_decoder_n_layers,    ### --- decoder options\n",
    "              \n",
    "              device\n",
    "             ):\n",
    "    '''Create an agent with specified dimensions and specificities'''\n",
    "    # 1) ----- encoding -----\n",
    "    embedding = nn.Embedding(lang.n_words, embedding_dim)\n",
    "    encoder = RecurrentWordsEncoder(device, embedding, hidden_dim, n_layers, dropout) # embedding, hidden_dim, n_layers = 1, dropout = 0\n",
    "    # 2) ----- attention -----\n",
    "    word_hidden_dim = encoder.output_dim\n",
    "    attention = RecurrentHierarchicalAttention(device,\n",
    "                                               word_hidden_dim,\n",
    "                                               sentence_hidden_dim, \n",
    "                                               base_query_dim = word_hidden_dim,\n",
    "                                               n_heads = 1,\n",
    "                                               hops = hops,\n",
    "                                               share = share,\n",
    "                                               transf = transf,\n",
    "                                               dropout = dropout)\n",
    "    # 3) ----- decoding -----\n",
    "    decoder_hidden_dim = attention.output_dim\n",
    "    if attn_decoder_n_layers >= 0 :\n",
    "        decoder = AttnWordsDecoder(device,\n",
    "                                   embedding,\n",
    "                                   decoder_hidden_dim,\n",
    "                                   dropout = dropout,\n",
    "                                   n_layers = attn_decoder_n_layers)\n",
    "    else :\n",
    "        decoder = WordsDecoder(device,\n",
    "                               embedding,\n",
    "                               decoder_hidden_dim,\n",
    "                               dropout = dropout)        \n",
    "    # 4) ----- model -----\n",
    "    chatbot = Chatbot(device, lang, encoder, attention, decoder)\n",
    "    chatbot = chatbot.to(device)\n",
    "    return chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotTrainer(object):\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 criterion= nn.NLLLoss(), \n",
    "                 optimizer = optim.SGD, \n",
    "                 clipping = 50,\n",
    "                 teacher_forcing_ratio = 0.5,  \n",
    "                 print_every=100):\n",
    "        \n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.clip = clipping\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.print_every = print_every# timer\n",
    "        \n",
    "        \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "    def timeSince(self, since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "        \n",
    "        \n",
    "    def distance(self, agent_outputs, target_answer) :\n",
    "        \"\"\" Compute cumulated error between predicted output and ground answer.\"\"\"\n",
    "        loss = 0\n",
    "        loss_diff_mots = 0\n",
    "        agent_outputs_length = len(agent_outputs)\n",
    "        target_length = len(target_answer)\n",
    "        Max = max(agent_outputs_length, target_length)\n",
    "        Min = min(agent_outputs_length, target_length)   \n",
    "        for i in range(Min):\n",
    "            agent_output = agent_outputs[i]\n",
    "            target_word = target_answer[i]\n",
    "            loss += self.criterion(agent_output, target_word)\n",
    "            topv, topi = agent_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            if ni != target_word.data[0]:\n",
    "                loss_diff_mots += 1\n",
    "        if agent_outputs_length != target_length :\n",
    "            loss_diff_mots += Max - Min\n",
    "        return loss, loss_diff_mots\n",
    "        \n",
    "        \n",
    "    def trainLoop(self, agent, dialogue, target_answer, optimizer, learning_rate):\n",
    "        \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        target_length = len(target_answer)\n",
    "        target_answer = target_answer.to(self.device)\n",
    "        tf = target_answer if random.random() < self.teacher_forcing_ratio else None\n",
    "        answer, agent_outputs, attn1_attention_weights, attn2_attention_weights =  agent.answerTrain(dialogue, tf) \n",
    "        loss, loss_diff_mots = self.distance(agent_outputs, target_answer)        \n",
    "        loss.backward()\n",
    "        _ = torch.nn.utils.clip_grad_norm_(agent.parameters(), self.clip)\n",
    "        optimizer.step()\n",
    "        return loss.data[0] / target_length , loss_diff_mots\n",
    "        \n",
    "        \n",
    "    def train(self, agent, dialogues, n_iters = 10000, learning_rate=0.01, dic = None):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops.\"\"\"\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in agent.parameters() if param.requires_grad == True], lr=learning_rate)\n",
    "        print_loss_total = 0  \n",
    "        print_loss_diff_mots_total = 0\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            if dic is not None :\n",
    "                j = int(random.choice(list(dic.keys())))\n",
    "                training_dialogue = dialogues[j]\n",
    "                i = random.choice(dic[j])\n",
    "                partie_dialogue = training_dialogue[:i+1]\n",
    "            else :\n",
    "                training_dialogue = random.choice(dialogues)\n",
    "                i = random.choice(range(len(training_dialogue)))\n",
    "                partie_dialogue = training_dialogue[:i+1]\n",
    "            #target_answer = variableFromSentence(agent.output_lang, training_dialogue[i][1])\n",
    "            target_answer = training_dialogue[i][1]\n",
    "            loss, loss_diff_mots = self.trainLoop(agent, partie_dialogue, target_answer, optimizer, learning_rate)\n",
    "            # quantité d'erreurs sur la réponse i\n",
    "            print_loss_total += loss\n",
    "            print_loss_diff_mots_total += loss_diff_mots       \n",
    "            if iter % self.print_every == 0:\n",
    "                print_loss_avg = print_loss_total / self.print_every\n",
    "                print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                print_loss_total = 0\n",
    "                print_loss_diff_mots_total = 0\n",
    "                print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg, print_loss_diff_mots_avg))\n",
    "                \n",
    "                \n",
    "    def ErrorCount(self, agent, dialogues):\n",
    "        bound = 10\n",
    "        ERRORS = [0 for i in range(bound +1)]\n",
    "        repartitionError = {}\n",
    "        for i in range(bound +1) :\n",
    "            repartitionError[i] = []\n",
    "        liste = []\n",
    "        for k, input_dialogue in enumerate(dialogues):\n",
    "            for l in range(len(input_dialogue)):\n",
    "                if len(input_dialogue[l][1])>0 :\n",
    "                    dialogue = input_dialogue[:l+1]\n",
    "                    #target_answer = variableFromSentence(agent.output_lang, input_dialogue[l][1])\n",
    "                    target_answer = input_dialogue[l][1]\n",
    "                    target_answer = target_answer.to(self.device)\n",
    "                    answer, agent_outputs, attn1_attention_weights, attn2_attention_weights = agent.answerTrain(dialogue)\n",
    "                    loss, loss_diff_mots = self.distance(agent_outputs, target_answer)\n",
    "                    if loss_diff_mots > bound :\n",
    "                        ERRORS = ERRORS + [0 for i in range(loss_diff_mots - bound)]\n",
    "                        for i in range(bound +1, loss_diff_mots +1) :\n",
    "                            repartitionError[i] = []\n",
    "                        bound  = loss_diff_mots\n",
    "                    ERRORS[loss_diff_mots] += 1\n",
    "                    if loss_diff_mots > 0 :\n",
    "                        liste.append([k, l, loss_diff_mots])\n",
    "        for triple in liste:\n",
    "            repartitionError[triple[2]].append(triple[:2])\n",
    "        print(\"The repartition of errors :\", ERRORS)\n",
    "        return repartitionError\n",
    "\n",
    "\n",
    "    def DialoguesWithErrors(self, agent, dialogues) :\n",
    "        '''Returns a dictionnary, with indices of dialogues and index of line in dialogue\n",
    "           where a mistake was made.\n",
    "        '''\n",
    "        start = time.time()\n",
    "        Sortie = {}\n",
    "        L = len(dialogues)\n",
    "        for i, dialogue in enumerate(dialogues) :\n",
    "            errs = []\n",
    "            for j in range(len(dialogue)) :\n",
    "                target_answer = dialogue[j][1]\n",
    "                target_answer = target_answer.to(self.device)\n",
    "                answer, agent_outputs, attn1_attention_weights, attn2_attention_weights = agent.answerTrain(dialogue[:j+1],\n",
    "                                                                                                            target_answer)\n",
    "                loss, loss_diff_mots = self.distance(agent_outputs, target_answer)\n",
    "                if loss_diff_mots > 0 :\n",
    "                    errs.append(j)\n",
    "            if errs != []:\n",
    "                Sortie[i] = errs\n",
    "            if (i+1) % self.print_every == 0:\n",
    "                print('%s (%d %d%%)' % (self.timeSince(start, (i+1) / L),\n",
    "                                             (i+1), (i+1) / L * 100))\n",
    "        return Sortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Some fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 Implementation\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Master's program dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4500 dialogues ...\n",
      "[[['salut'], ['bonjour']], [['quelles', 'sont', 'les', 'mentions', '?'], ['deux', 'parcours', 'sont', 'proposes', 'pour', 'le', 'master', 'data', 'science', 'le', 'parcours', 'mathematiques', 'et', 'le', 'parcours', 'informatique']], [['quelle', 'est', 'la', 'difference', 'entre', 'le', 'parcours', 'info', 'et', 'math', '?'], ['le', 'contenu', 'est', 'le', 'meme', 'seules', 'les', 'ue', 'de', 'remise', 'a', 'niveau', 'sont', 'differentes']], [['token_silence'], ['souhaitez-vous', 'connaitre', 'les', 'prerequis', 'pour', 'la', 'candidature', '?']], [['oui'], ['tres', 'bien', 'par', 'quel', 'parcours', 'etre-vous', 'interresse', '?']], [['mathematiques'], ['dans', 'ce', 'cas', 'les', 'prerequis', 'sont', 'd', 'un', 'master', '1', 'en', 'mathematiques', 'ou', 'l', 'equivalent', 'en', 'ecole', 'd', 'ingenieur']], [['c', 'est', 'tout', '?'], ['oui', 'c', 'est', 'tout']], [['on', 'peut', 'candidater', 'au', 'master', 'informatique', 'en', 'venant', 'de', 'mathematiques', '?'], ['non', 'il', 'faut', 'que', 'vous', 'candidatiez', 'pour', 'le', 'parcours', 'mathematiques']], [['comment', 'avoir', 'une', 'lettre', 'de', 'recommendation', '?'], ['il', 'faut', 'en', 'faire', 'la', 'demande', 'aupres', 'd', 'un', 'de', 'vos', 'professeurs']], [['est-ce', 'qu', 'il', 'y', 'a', 'des', 'options', 'a', 'suivre', 'en', 'master', '1', '?'], ['vous', 'devriez', 'poser', 'la', 'question', 'au', 'responsable', 'du', 'master', 'data', 'science', 'mathematiques']], [['combien', 'de', 'places', 'sont', 'disponibles', 'dans', 'ce', 'master', '?'], ['cela', 'depend', 'etes-vous', 'un', 'etudiant', 'inscrit', 'a', 'lyon1', '?']], [['non'], ['pour', 'les', 'etudiants', 'du', 'parcours', 'mathematiques', 'non-inscrits', 'a', 'lyon1', 'le', 'nombre', 'de', 'places', 'disponibles', 'est', 'de', 'nbreplaces_en_france_mathematiques']], [['cordialement'], ['cordialement']]]\n",
      " 1800 dialogues ...\n",
      "[[['comment', 'allez-vous', '?'], ['je', 'vais', 'bien', 'merci', 'et', 'vous', '?']], [['ca', 'va', 'tres', 'bien'], ['j', 'en', 'suis', 'ravi', 'en', 'quoi', 'puis-je', 'vous', 'aider', '?']], [['tu', 'as', 'un', 'nom', '?'], ['oui', 'je', 'm', 'appelle', 'nomchatbot']], [['quels', 'sont', 'les', 'cours', '?'], ['quel', 'parcours', 'souhaitez-vous', 'suivre', '?']], [['le', 'parcours', 'mathematiques'], ['la', 'liste', 'des', 'cours', 'est', 'disponible', 'sur', 'le', 'site', 'du', 'master', 'site_mathematiques']], [['il', 'y', 'a', 'beaucoup', 'de', 'cours', '?'], ['le', 'cursus', 'comprend', 'nombrecours', 'cours', 'principaux']], [['il', 'y', 'a', 'des', 'cours', 'de', 'modeles', 'de', 'regression', '?'], ['oui', 'une', 'ue', 'de', 'modeles', 'de', 'regression', 'est', 'au', 'programme']], [['comment', 's', 'appelle', 'le', 'prof', '?'], ['l', 'enseignant', 'de', 'modeles', 'de', 'regression', 'est', 'pr', 'profmr']], [['quelle', 'est', 'sa', 'page', 'web', '?'], ['vous', 'pouvez', 'simplement', 'faire', 'une', 'recherche', 'web']], [['y', 'a-t-il', 'des', 'cours', 'd', 'anglais', '?'], ['oui', 'il', 'y', 'a', 'une', 'ue', 'd', 'anglais']], [['qui', 'est', 'le', 'responsable', 'du', 'master', '?'], ['le', 'responsable', 'du', 'parcours', 'mathematiques', 'est', 'responsable_mathematiques']], [['merci', 'de', 'votre', 'aide'], ['je', 'vous', 'en', 'prie']]]\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 30\n",
    "max_length = MAX_LENGTH\n",
    "stopwords = []\n",
    "\n",
    "Master_train =   {'fichier': 'C:\\\\Users\\Jb\\Desktop\\Scripts\\data\\Conversations_M2DS\\\\Liste_Dialogues_trn.txt', #dialog-babi-task1-API-calls-trn.txt\n",
    "                   'modify' : False,\n",
    "                   'stopwords' : stopwords,\n",
    "                   'max_length' : MAX_LENGTH ,\n",
    "                   'limite' : None,\n",
    "                   'filtre' : False}\n",
    "\n",
    "dialogues_Master = prepareData(Master_train)\n",
    "\n",
    "Master_test  =   {'lang1': 'lang_client',\n",
    "                   'lang2' : 'lang_agent',\n",
    "                   'fichier': 'C:\\\\Users\\Jb\\Desktop\\Scripts\\data\\Conversations_M2DS\\\\Liste_Dialogues_tst.txt', #dialog-babi-task1-API-calls-trn.txt\n",
    "                   'modify' : False,\n",
    "                   'stopwords' : stopwords,\n",
    "                   'max_length' : MAX_LENGTH ,\n",
    "                   'limite' : None,\n",
    "                   'reverse' : False,\n",
    "                   'filtre' : False}\n",
    "\n",
    "dialogues_Master_test = prepareData(Master_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés :\n",
      "M2DS 1062\n"
     ]
    }
   ],
   "source": [
    "# compute ONCE\n",
    "lang_M2DS = generateLanguages(dialogues_Master)\n",
    "fileObject = open(r'C:\\Users\\Jb\\Desktop\\Scripts\\saves\\lang_M2DS.file', 'wb')\n",
    "pickle.dump(lang_M2DS, fileObject)\n",
    "\n",
    "# 1062 mots comptés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importLang(name, n_words):\n",
    "    lang = Lang(name)\n",
    "    lang.n_words = n_words\n",
    "    fil = open(r'C:\\Users\\Jb\\Desktop\\Scripts\\saves\\\\'+name+'.file', 'rb')\n",
    "    return pickle.load(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_M2DS = importLang('lang_M2DS', 1062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues_Master_var = variableFromAllDialogues(lang_M2DS, dialogues_Master, rand = 0)\n",
    "dialogues_Master_test_var = variableFromAllDialogues(lang_M2DS, dialogues_Master_test, rand = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BotTrainer(device = device,\n",
    "                     criterion = nn.NLLLoss(), \n",
    "                     optimizer = optim.SGD, \n",
    "                     clipping = 50,\n",
    "                     teacher_forcing_ratio = 0.5,\n",
    "                     print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357562"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1357562\n",
    "chatbot = CreateBot(  lang_M2DS,\n",
    "                      embedding_dim = 150,\n",
    "                      hidden_dim = 100,\n",
    "                      n_layers = 1, # doit être gardé à 1\n",
    "                    \n",
    "                      sentence_hidden_dim = 100,\n",
    "                      hops = 3,\n",
    "                      share = True, #False\n",
    "                      transf = False, # True\n",
    "                      dropout = 0.2,\n",
    "                    \n",
    "                      attn_decoder_n_layers = -1, # -1 : pas d'attention durant le décodage\n",
    "                    \n",
    "                     device = device\n",
    "                     )\n",
    "chatbot.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.load_state_dict(torch.load('C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chatbot(\n",
       "  (encoder): RecurrentWordsEncoder(\n",
       "    (embedding): Embedding(1062, 150)\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (bigru): GRU(150, 100, bidirectional=True)\n",
       "  )\n",
       "  (attention): RecurrentHierarchicalAttention(\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (attn1): ModuleList(\n",
       "      (0): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "      (1): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "      (2): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bigru): GRU(200, 100, bidirectional=True)\n",
       "    (attn2): ModuleList(\n",
       "      (0): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "      (1): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "      (2): AdditiveAttention(\n",
       "        (attn_layer): Linear(in_features=600, out_features=200, bias=True)\n",
       "        (attn_layer2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (attn_v): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): WordsDecoder(\n",
       "    (embedding): Embedding(1062, 150)\n",
       "    (gru): GRU(350, 200)\n",
       "    (out): Linear(in_features=200, out_features=1062, bias=True)\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# si on veut voir le pipeline du modèle\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Training\n",
    "\n",
    "### 6.3.1 Standard training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 13s (- 44m 35s) (100 0%) 4.0611 11.42\n",
      "0m 25s (- 41m 29s) (200 1%) 3.0259 10.74\n",
      "0m 37s (- 40m 58s) (300 1%) 3.1040 9.99\n",
      "0m 52s (- 42m 30s) (400 2%) 2.8464 10.99\n",
      "1m 3s (- 41m 29s) (500 2%) 2.6352 10.05\n",
      "1m 17s (- 41m 45s) (600 3%) 2.5818 10.33\n",
      "1m 31s (- 42m 0s) (700 3%) 2.6166 11.33\n",
      "1m 44s (- 41m 48s) (800 4%) 2.6838 10.29\n",
      "1m 58s (- 41m 45s) (900 4%) 3.0110 10.54\n",
      "2m 10s (- 41m 18s) (1000 5%) 2.6268 9.98\n",
      "2m 23s (- 41m 7s) (1100 5%) 2.8699 9.97\n",
      "2m 36s (- 40m 51s) (1200 6%) 2.8164 9.72\n",
      "2m 48s (- 40m 29s) (1300 6%) 2.6834 9.48\n",
      "3m 0s (- 40m 2s) (1400 7%) 2.7668 9.98\n",
      "3m 14s (- 39m 54s) (1500 7%) 2.9769 9.40\n",
      "3m 27s (- 39m 49s) (1600 8%) 2.7628 10.17\n",
      "3m 42s (- 39m 50s) (1700 8%) 2.7065 9.48\n",
      "3m 54s (- 39m 35s) (1800 9%) 2.6314 9.02\n",
      "4m 7s (- 39m 17s) (1900 9%) 2.6429 9.26\n",
      "4m 19s (- 38m 53s) (2000 10%) 2.5504 8.33\n",
      "4m 32s (- 38m 43s) (2100 10%) 2.9717 9.47\n",
      "4m 46s (- 38m 39s) (2200 11%) 2.6057 8.48\n",
      "5m 0s (- 38m 32s) (2300 11%) 3.0059 9.36\n",
      "5m 13s (- 38m 16s) (2400 12%) 2.6812 8.15\n",
      "5m 27s (- 38m 9s) (2500 12%) 2.3582 8.10\n",
      "5m 40s (- 37m 57s) (2600 13%) 2.4443 8.03\n",
      "5m 52s (- 37m 40s) (2700 13%) 2.4518 7.37\n",
      "6m 5s (- 37m 27s) (2800 14%) 2.5227 8.54\n",
      "6m 18s (- 37m 9s) (2900 14%) 2.3920 7.10\n",
      "6m 31s (- 36m 57s) (3000 15%) 2.6864 7.40\n",
      "6m 44s (- 36m 46s) (3100 15%) 2.3057 7.83\n",
      "6m 58s (- 36m 39s) (3200 16%) 2.3350 7.38\n",
      "7m 11s (- 36m 25s) (3300 16%) 2.3357 8.56\n",
      "7m 24s (- 36m 12s) (3400 17%) 2.2020 6.57\n",
      "7m 38s (- 35m 59s) (3500 17%) 2.7386 7.86\n",
      "7m 51s (- 35m 49s) (3600 18%) 2.3375 7.70\n",
      "8m 7s (- 35m 46s) (3700 18%) 2.4771 7.60\n",
      "8m 21s (- 35m 38s) (3800 19%) 1.8548 6.38\n",
      "8m 35s (- 35m 29s) (3900 19%) 1.9673 5.98\n",
      "8m 50s (- 35m 22s) (4000 20%) 2.1288 7.02\n",
      "9m 6s (- 35m 17s) (4100 20%) 2.4112 6.79\n",
      "9m 21s (- 35m 11s) (4200 21%) 2.2182 7.15\n",
      "9m 37s (- 35m 8s) (4300 21%) 2.1049 5.96\n",
      "9m 53s (- 35m 3s) (4400 22%) 2.0295 6.39\n",
      "10m 8s (- 34m 54s) (4500 22%) 2.0787 6.88\n",
      "10m 22s (- 34m 44s) (4600 23%) 2.3514 7.11\n",
      "10m 40s (- 34m 45s) (4700 23%) 2.0632 6.17\n",
      "10m 56s (- 34m 37s) (4800 24%) 2.1199 6.78\n",
      "11m 10s (- 34m 26s) (4900 24%) 1.7380 5.99\n",
      "11m 25s (- 34m 17s) (5000 25%) 2.1378 7.35\n",
      "11m 39s (- 34m 3s) (5100 25%) 2.1458 7.09\n",
      "11m 53s (- 33m 49s) (5200 26%) 1.9772 6.15\n",
      "12m 6s (- 33m 34s) (5300 26%) 1.8987 5.98\n",
      "12m 20s (- 33m 21s) (5400 27%) 1.9087 6.28\n",
      "12m 34s (- 33m 8s) (5500 27%) 1.9089 6.02\n",
      "12m 49s (- 32m 58s) (5600 28%) 2.2312 7.17\n",
      "13m 5s (- 32m 51s) (5700 28%) 2.0742 6.55\n",
      "13m 24s (- 32m 49s) (5800 28%) 1.9107 5.79\n",
      "13m 41s (- 32m 42s) (5900 29%) 1.7530 5.74\n",
      "13m 56s (- 32m 31s) (6000 30%) 1.5382 4.85\n",
      "14m 10s (- 32m 18s) (6100 30%) 1.7707 6.07\n",
      "14m 25s (- 32m 6s) (6200 31%) 1.7779 6.13\n",
      "14m 39s (- 31m 51s) (6300 31%) 1.7825 6.01\n",
      "14m 54s (- 31m 41s) (6400 32%) 1.7033 5.33\n",
      "15m 9s (- 31m 28s) (6500 32%) 1.5366 5.08\n",
      "15m 23s (- 31m 15s) (6600 33%) 1.6965 4.99\n",
      "15m 37s (- 31m 1s) (6700 33%) 1.8628 5.30\n",
      "15m 51s (- 30m 47s) (6800 34%) 1.7651 5.89\n",
      "16m 6s (- 30m 35s) (6900 34%) 1.8722 5.85\n",
      "16m 22s (- 30m 24s) (7000 35%) 1.7932 5.43\n",
      "16m 36s (- 30m 10s) (7100 35%) 1.6153 4.64\n",
      "16m 49s (- 29m 54s) (7200 36%) 1.6267 5.63\n",
      "17m 2s (- 29m 39s) (7300 36%) 1.3302 4.32\n",
      "17m 18s (- 29m 27s) (7400 37%) 1.6835 5.62\n",
      "17m 32s (- 29m 13s) (7500 37%) 1.2681 4.01\n",
      "17m 45s (- 28m 58s) (7600 38%) 1.6983 5.62\n",
      "18m 0s (- 28m 46s) (7700 38%) 1.6764 4.79\n",
      "18m 14s (- 28m 31s) (7800 39%) 1.5368 5.22\n",
      "18m 28s (- 28m 18s) (7900 39%) 1.4506 5.03\n",
      "18m 42s (- 28m 4s) (8000 40%) 1.5641 4.72\n",
      "18m 56s (- 27m 49s) (8100 40%) 1.5013 4.46\n",
      "19m 10s (- 27m 36s) (8200 41%) 1.4768 4.93\n",
      "19m 25s (- 27m 23s) (8300 41%) 1.3287 3.92\n",
      "19m 39s (- 27m 9s) (8400 42%) 1.1885 3.93\n",
      "19m 52s (- 26m 53s) (8500 42%) 1.3636 4.04\n",
      "20m 8s (- 26m 41s) (8600 43%) 1.7103 5.55\n",
      "20m 22s (- 26m 28s) (8700 43%) 1.4141 4.53\n",
      "20m 36s (- 26m 14s) (8800 44%) 1.3920 4.53\n",
      "20m 51s (- 26m 1s) (8900 44%) 1.4376 4.62\n",
      "21m 6s (- 25m 48s) (9000 45%) 1.3564 4.43\n",
      "21m 20s (- 25m 34s) (9100 45%) 1.3008 4.34\n",
      "21m 36s (- 25m 21s) (9200 46%) 1.2785 3.86\n",
      "21m 52s (- 25m 9s) (9300 46%) 1.2549 4.31\n",
      "22m 6s (- 24m 55s) (9400 47%) 1.1880 3.62\n",
      "22m 22s (- 24m 43s) (9500 47%) 1.4310 4.16\n",
      "22m 37s (- 24m 30s) (9600 48%) 1.3321 4.47\n",
      "22m 51s (- 24m 16s) (9700 48%) 1.2705 3.89\n",
      "23m 7s (- 24m 4s) (9800 49%) 0.8439 2.78\n",
      "23m 21s (- 23m 50s) (9900 49%) 1.1870 4.20\n",
      "23m 36s (- 23m 36s) (10000 50%) 1.1271 3.63\n",
      "23m 52s (- 23m 23s) (10100 50%) 1.2750 3.74\n",
      "24m 6s (- 23m 10s) (10200 51%) 1.0235 2.97\n",
      "24m 22s (- 22m 57s) (10300 51%) 1.2468 4.08\n",
      "24m 37s (- 22m 44s) (10400 52%) 1.4431 4.90\n",
      "24m 53s (- 22m 31s) (10500 52%) 1.1619 3.55\n",
      "25m 7s (- 22m 17s) (10600 53%) 1.3172 4.01\n",
      "25m 30s (- 22m 10s) (10700 53%) 1.1786 4.19\n",
      "25m 52s (- 22m 2s) (10800 54%) 1.0228 3.02\n",
      "26m 16s (- 21m 56s) (10900 54%) 1.1017 3.25\n",
      "26m 41s (- 21m 50s) (11000 55%) 1.1675 3.62\n",
      "27m 1s (- 21m 40s) (11100 55%) 1.0654 3.01\n",
      "27m 25s (- 21m 32s) (11200 56%) 1.1365 3.88\n",
      "27m 49s (- 21m 25s) (11300 56%) 1.0062 3.16\n",
      "28m 11s (- 21m 15s) (11400 56%) 1.0400 3.07\n",
      "28m 34s (- 21m 6s) (11500 57%) 1.3763 3.88\n",
      "28m 56s (- 20m 57s) (11600 57%) 1.0523 3.10\n",
      "29m 17s (- 20m 46s) (11700 58%) 1.2490 3.83\n",
      "29m 34s (- 20m 33s) (11800 59%) 1.2937 4.02\n",
      "29m 55s (- 20m 21s) (11900 59%) 0.9615 3.75\n",
      "30m 17s (- 20m 11s) (12000 60%) 1.0956 3.23\n",
      "30m 40s (- 20m 1s) (12100 60%) 0.9347 3.29\n",
      "31m 2s (- 19m 51s) (12200 61%) 0.9512 3.33\n",
      "31m 24s (- 19m 39s) (12300 61%) 1.1085 3.55\n",
      "31m 43s (- 19m 26s) (12400 62%) 1.0234 3.45\n",
      "32m 4s (- 19m 14s) (12500 62%) 0.8729 2.93\n",
      "32m 26s (- 19m 2s) (12600 63%) 1.0189 3.00\n",
      "32m 48s (- 18m 51s) (12700 63%) 1.1017 3.68\n",
      "33m 9s (- 18m 39s) (12800 64%) 0.7882 2.58\n",
      "33m 29s (- 18m 26s) (12900 64%) 0.6610 2.35\n",
      "33m 49s (- 18m 13s) (13000 65%) 0.8253 2.66\n",
      "34m 11s (- 18m 0s) (13100 65%) 0.8135 2.24\n",
      "34m 30s (- 17m 46s) (13200 66%) 1.2865 3.37\n",
      "34m 51s (- 17m 33s) (13300 66%) 1.2263 3.90\n",
      "35m 12s (- 17m 20s) (13400 67%) 1.0397 3.21\n",
      "35m 33s (- 17m 7s) (13500 67%) 1.0228 2.58\n",
      "35m 53s (- 16m 53s) (13600 68%) 0.8959 2.51\n",
      "36m 15s (- 16m 40s) (13700 68%) 0.7496 2.54\n",
      "36m 38s (- 16m 27s) (13800 69%) 0.9297 2.97\n",
      "36m 59s (- 16m 14s) (13900 69%) 0.7912 2.45\n",
      "37m 21s (- 16m 0s) (14000 70%) 1.0428 2.78\n",
      "37m 42s (- 15m 46s) (14100 70%) 0.6933 2.26\n",
      "38m 3s (- 15m 32s) (14200 71%) 0.9922 3.28\n",
      "38m 25s (- 15m 19s) (14300 71%) 0.8515 2.60\n",
      "38m 48s (- 15m 5s) (14400 72%) 0.8214 2.43\n",
      "39m 12s (- 14m 52s) (14500 72%) 0.8159 2.10\n",
      "39m 34s (- 14m 38s) (14600 73%) 0.7172 2.38\n",
      "39m 56s (- 14m 23s) (14700 73%) 0.9375 3.15\n",
      "40m 17s (- 14m 9s) (14800 74%) 0.8503 2.70\n",
      "40m 39s (- 13m 54s) (14900 74%) 0.8309 3.06\n",
      "40m 58s (- 13m 39s) (15000 75%) 0.6102 1.86\n",
      "41m 19s (- 13m 24s) (15100 75%) 0.9310 2.45\n",
      "41m 40s (- 13m 9s) (15200 76%) 0.7391 2.36\n",
      "42m 1s (- 12m 54s) (15300 76%) 0.7909 2.23\n",
      "42m 21s (- 12m 39s) (15400 77%) 0.6137 1.83\n",
      "42m 43s (- 12m 24s) (15500 77%) 1.1680 3.17\n",
      "43m 7s (- 12m 9s) (15600 78%) 0.8079 2.57\n",
      "43m 27s (- 11m 54s) (15700 78%) 0.9292 2.91\n",
      "43m 48s (- 11m 38s) (15800 79%) 0.9221 2.76\n",
      "44m 7s (- 11m 22s) (15900 79%) 0.6372 1.90\n",
      "44m 29s (- 11m 7s) (16000 80%) 0.7818 2.70\n",
      "44m 49s (- 10m 51s) (16100 80%) 0.7039 2.03\n",
      "45m 9s (- 10m 35s) (16200 81%) 1.0724 3.56\n",
      "45m 29s (- 10m 19s) (16300 81%) 0.8340 2.48\n",
      "45m 49s (- 10m 3s) (16400 82%) 0.9608 2.79\n",
      "46m 9s (- 9m 47s) (16500 82%) 0.8884 2.63\n",
      "46m 29s (- 9m 31s) (16600 83%) 0.8974 2.66\n",
      "46m 51s (- 9m 15s) (16700 83%) 0.7900 2.50\n",
      "47m 12s (- 8m 59s) (16800 84%) 0.5908 1.74\n",
      "47m 33s (- 8m 43s) (16900 84%) 0.8152 3.08\n",
      "47m 54s (- 8m 27s) (17000 85%) 0.8939 2.80\n",
      "48m 15s (- 8m 11s) (17100 85%) 0.8727 2.94\n",
      "48m 35s (- 7m 54s) (17200 86%) 0.8607 2.76\n",
      "48m 58s (- 7m 38s) (17300 86%) 0.7166 2.15\n",
      "49m 19s (- 7m 22s) (17400 87%) 0.8778 3.40\n",
      "49m 42s (- 7m 6s) (17500 87%) 1.0504 3.43\n",
      "50m 4s (- 6m 49s) (17600 88%) 0.8326 3.04\n",
      "50m 24s (- 6m 33s) (17700 88%) 0.8612 2.58\n",
      "50m 45s (- 6m 16s) (17800 89%) 0.7683 2.44\n",
      "51m 6s (- 5m 59s) (17900 89%) 0.7739 1.88\n",
      "51m 28s (- 5m 43s) (18000 90%) 0.7302 2.16\n",
      "51m 48s (- 5m 26s) (18100 90%) 0.6141 1.64\n",
      "52m 9s (- 5m 9s) (18200 91%) 0.9397 2.89\n",
      "52m 34s (- 4m 53s) (18300 91%) 0.6257 1.90\n",
      "52m 55s (- 4m 36s) (18400 92%) 0.8300 2.26\n",
      "53m 15s (- 4m 19s) (18500 92%) 0.4554 1.37\n",
      "53m 35s (- 4m 2s) (18600 93%) 0.7084 2.27\n",
      "53m 55s (- 3m 44s) (18700 93%) 0.7474 1.92\n",
      "54m 15s (- 3m 27s) (18800 94%) 0.4564 1.34\n",
      "54m 34s (- 3m 10s) (18900 94%) 0.6151 2.00\n",
      "54m 55s (- 2m 53s) (19000 95%) 0.6266 1.90\n",
      "55m 16s (- 2m 36s) (19100 95%) 0.5953 1.96\n",
      "55m 35s (- 2m 18s) (19200 96%) 0.7218 2.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55m 59s (- 2m 1s) (19300 96%) 0.3550 1.25\n",
      "56m 21s (- 1m 44s) (19400 97%) 0.6554 2.07\n",
      "56m 43s (- 1m 27s) (19500 97%) 0.7196 2.21\n",
      "57m 5s (- 1m 9s) (19600 98%) 0.8102 2.82\n",
      "57m 27s (- 0m 52s) (19700 98%) 0.8315 2.95\n",
      "57m 48s (- 0m 35s) (19800 99%) 0.6403 1.73\n",
      "58m 11s (- 0m 17s) (19900 99%) 0.7267 2.21\n",
      "58m 32s (- 0m 0s) (20000 100%) 0.5016 1.60\n"
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 21s (- 71m 57s) (100 0%) 0.5556 1.53\n",
      "0m 43s (- 71m 42s) (200 1%) 0.7855 2.72\n",
      "1m 4s (- 70m 51s) (300 1%) 0.5748 1.83\n",
      "1m 26s (- 70m 16s) (400 2%) 0.4397 1.45\n",
      "1m 47s (- 70m 6s) (500 2%) 0.5213 1.65\n",
      "2m 8s (- 69m 16s) (600 3%) 0.7909 2.33\n",
      "2m 30s (- 69m 10s) (700 3%) 0.3902 1.02\n",
      "2m 53s (- 69m 34s) (800 4%) 0.8011 2.16\n",
      "3m 17s (- 69m 57s) (900 4%) 0.6596 2.18\n",
      "3m 39s (- 69m 31s) (1000 5%) 0.5769 1.85\n",
      "4m 0s (- 68m 52s) (1100 5%) 0.4991 1.65\n",
      "4m 20s (- 68m 2s) (1200 6%) 0.6860 1.88\n",
      "4m 40s (- 67m 18s) (1300 6%) 0.3861 1.16\n",
      "5m 3s (- 67m 12s) (1400 7%) 0.7241 2.45\n",
      "5m 25s (- 66m 51s) (1500 7%) 0.5458 1.85\n",
      "5m 48s (- 66m 48s) (1600 8%) 0.6517 1.91\n",
      "6m 12s (- 66m 52s) (1700 8%) 0.4614 1.74\n",
      "6m 34s (- 66m 23s) (1800 9%) 0.2827 0.75\n",
      "6m 56s (- 66m 5s) (1900 9%) 0.5765 1.76\n",
      "7m 18s (- 65m 42s) (2000 10%) 0.4245 1.40\n",
      "7m 38s (- 65m 11s) (2100 10%) 0.7252 2.15\n",
      "8m 0s (- 64m 50s) (2200 11%) 0.4105 1.34\n",
      "8m 21s (- 64m 21s) (2300 11%) 0.6091 1.87\n",
      "8m 41s (- 63m 47s) (2400 12%) 0.5831 1.69\n",
      "9m 4s (- 63m 30s) (2500 12%) 0.7051 1.78\n",
      "9m 25s (- 63m 5s) (2600 13%) 0.4868 1.07\n",
      "9m 46s (- 62m 34s) (2700 13%) 0.5521 1.34\n",
      "10m 8s (- 62m 19s) (2800 14%) 0.3870 1.16\n",
      "10m 29s (- 61m 54s) (2900 14%) 0.6689 1.73\n",
      "10m 50s (- 61m 26s) (3000 15%) 0.4722 1.52\n",
      "11m 10s (- 60m 55s) (3100 15%) 0.5944 1.99\n",
      "11m 34s (- 60m 43s) (3200 16%) 0.5492 1.61\n",
      "11m 54s (- 60m 17s) (3300 16%) 0.4568 1.16\n",
      "12m 16s (- 59m 57s) (3400 17%) 0.4129 1.16\n",
      "12m 37s (- 59m 30s) (3500 17%) 0.6193 1.95\n",
      "12m 58s (- 59m 4s) (3600 18%) 0.3347 0.81\n",
      "13m 17s (- 58m 32s) (3700 18%) 0.3172 0.92\n",
      "13m 36s (- 57m 58s) (3800 19%) 0.5333 1.47\n",
      "13m 56s (- 57m 31s) (3900 19%) 0.3732 1.11\n",
      "14m 17s (- 57m 9s) (4000 20%) 0.5554 1.60\n",
      "14m 40s (- 56m 55s) (4100 20%) 0.3994 1.32\n",
      "15m 3s (- 56m 39s) (4200 21%) 0.6956 1.88\n",
      "15m 24s (- 56m 15s) (4300 21%) 0.5415 1.47\n",
      "15m 46s (- 55m 55s) (4400 22%) 0.3857 1.43\n",
      "16m 7s (- 55m 32s) (4500 22%) 0.3608 1.16\n",
      "16m 28s (- 55m 7s) (4600 23%) 0.6324 1.80\n",
      "16m 49s (- 54m 45s) (4700 23%) 0.5070 1.52\n",
      "17m 10s (- 54m 24s) (4800 24%) 0.3947 1.12\n",
      "17m 32s (- 54m 3s) (4900 24%) 0.6210 1.57\n",
      "17m 52s (- 53m 38s) (5000 25%) 0.5064 1.37\n",
      "18m 14s (- 53m 18s) (5100 25%) 0.7594 2.23\n",
      "18m 35s (- 52m 53s) (5200 26%) 0.5634 1.56\n",
      "18m 56s (- 52m 31s) (5300 26%) 0.4255 1.18\n",
      "19m 17s (- 52m 10s) (5400 27%) 0.5130 1.63\n",
      "19m 40s (- 51m 50s) (5500 27%) 0.4899 1.26\n",
      "20m 1s (- 51m 30s) (5600 28%) 0.4614 1.64\n",
      "20m 22s (- 51m 6s) (5700 28%) 0.3310 1.04\n",
      "20m 42s (- 50m 42s) (5800 28%) 0.4169 1.14\n",
      "21m 3s (- 50m 19s) (5900 29%) 0.4843 1.16\n",
      "21m 25s (- 49m 59s) (6000 30%) 0.4791 1.57\n",
      "21m 46s (- 49m 36s) (6100 30%) 0.3946 1.16\n",
      "22m 7s (- 49m 14s) (6200 31%) 0.7678 2.24\n",
      "22m 29s (- 48m 55s) (6300 31%) 0.3163 1.05\n",
      "22m 52s (- 48m 35s) (6400 32%) 0.5795 1.35\n",
      "23m 14s (- 48m 16s) (6500 32%) 0.3929 1.17\n",
      "23m 35s (- 47m 54s) (6600 33%) 0.3319 1.07\n",
      "23m 56s (- 47m 31s) (6700 33%) 0.3945 1.07\n",
      "24m 16s (- 47m 7s) (6800 34%) 0.5756 1.50\n",
      "24m 39s (- 46m 48s) (6900 34%) 0.5756 1.45\n",
      "25m 1s (- 46m 28s) (7000 35%) 0.3656 1.13\n",
      "25m 24s (- 46m 10s) (7100 35%) 0.4927 1.08\n",
      "25m 47s (- 45m 51s) (7200 36%) 0.4650 1.14\n",
      "26m 4s (- 45m 21s) (7300 36%) 0.5429 1.47\n",
      "26m 18s (- 44m 47s) (7400 37%) 0.3656 1.06\n",
      "26m 31s (- 44m 13s) (7500 37%) 0.3938 1.46\n",
      "26m 45s (- 43m 39s) (7600 38%) 0.7553 2.01\n",
      "26m 59s (- 43m 7s) (7700 38%) 0.4854 1.42\n",
      "27m 15s (- 42m 37s) (7800 39%) 0.5668 1.59\n",
      "27m 29s (- 42m 5s) (7900 39%) 0.3233 1.17\n",
      "27m 43s (- 41m 34s) (8000 40%) 0.4619 1.31\n",
      "27m 57s (- 41m 4s) (8100 40%) 0.3412 0.89\n",
      "28m 12s (- 40m 35s) (8200 41%) 0.4275 1.14\n",
      "28m 26s (- 40m 6s) (8300 41%) 0.3565 1.05\n",
      "28m 40s (- 39m 35s) (8400 42%) 0.4842 1.17\n",
      "28m 54s (- 39m 6s) (8500 42%) 0.3852 1.11\n",
      "29m 9s (- 38m 39s) (8600 43%) 0.4518 0.98\n",
      "29m 23s (- 38m 11s) (8700 43%) 0.4318 1.44\n",
      "29m 39s (- 37m 45s) (8800 44%) 0.4209 1.37\n",
      "29m 54s (- 37m 18s) (8900 44%) 0.3758 1.15\n",
      "30m 8s (- 36m 49s) (9000 45%) 0.3577 1.33\n",
      "30m 22s (- 36m 23s) (9100 45%) 0.5002 1.32\n",
      "30m 37s (- 35m 57s) (9200 46%) 0.3707 1.00\n",
      "30m 51s (- 35m 29s) (9300 46%) 0.3727 1.21\n",
      "31m 5s (- 35m 3s) (9400 47%) 0.3321 0.84\n",
      "31m 19s (- 34m 37s) (9500 47%) 0.3494 1.07\n",
      "31m 33s (- 34m 11s) (9600 48%) 0.4148 1.09\n",
      "31m 47s (- 33m 45s) (9700 48%) 0.4019 0.97\n",
      "32m 3s (- 33m 21s) (9800 49%) 0.4835 1.73\n",
      "32m 18s (- 32m 57s) (9900 49%) 0.4697 1.50\n",
      "32m 31s (- 32m 31s) (10000 50%) 0.2367 0.71\n",
      "32m 46s (- 32m 7s) (10100 50%) 0.5163 1.84\n",
      "33m 0s (- 31m 42s) (10200 51%) 0.3647 1.22\n",
      "33m 14s (- 31m 18s) (10300 51%) 0.5694 2.26\n",
      "33m 28s (- 30m 53s) (10400 52%) 0.5188 1.31\n",
      "33m 43s (- 30m 30s) (10500 52%) 0.3631 1.03\n",
      "33m 56s (- 30m 5s) (10600 53%) 0.2972 0.82\n",
      "34m 10s (- 29m 42s) (10700 53%) 0.3130 0.72\n",
      "34m 25s (- 29m 19s) (10800 54%) 0.4017 1.08\n",
      "34m 39s (- 28m 56s) (10900 54%) 0.3374 1.01\n",
      "34m 54s (- 28m 33s) (11000 55%) 0.4477 1.36\n",
      "35m 7s (- 28m 10s) (11100 55%) 0.2682 1.01\n",
      "35m 22s (- 27m 47s) (11200 56%) 0.5833 1.75\n",
      "35m 39s (- 27m 27s) (11300 56%) 0.3966 0.98\n",
      "35m 55s (- 27m 6s) (11400 56%) 0.5044 1.40\n",
      "36m 17s (- 26m 49s) (11500 57%) 0.6110 1.95\n",
      "36m 38s (- 26m 32s) (11600 57%) 0.5296 1.56\n",
      "37m 2s (- 26m 16s) (11700 58%) 0.5666 1.27\n",
      "37m 23s (- 25m 58s) (11800 59%) 0.4947 1.23\n",
      "37m 45s (- 25m 42s) (11900 59%) 0.3567 1.21\n",
      "38m 6s (- 25m 24s) (12000 60%) 0.5480 1.59\n",
      "38m 28s (- 25m 7s) (12100 60%) 0.3694 0.86\n",
      "38m 49s (- 24m 49s) (12200 61%) 0.2633 0.97\n",
      "39m 11s (- 24m 32s) (12300 61%) 0.2904 0.90\n",
      "39m 32s (- 24m 14s) (12400 62%) 0.3098 1.01\n",
      "39m 53s (- 23m 56s) (12500 62%) 0.4444 1.09\n",
      "40m 15s (- 23m 38s) (12600 63%) 0.4086 1.19\n",
      "40m 36s (- 23m 20s) (12700 63%) 0.4563 1.53\n",
      "40m 57s (- 23m 2s) (12800 64%) 0.3611 1.15\n",
      "41m 20s (- 22m 44s) (12900 64%) 0.3514 1.00\n",
      "41m 41s (- 22m 26s) (13000 65%) 0.5497 1.39\n",
      "42m 2s (- 22m 8s) (13100 65%) 0.3499 0.97\n",
      "42m 26s (- 21m 51s) (13200 66%) 0.4122 0.86\n",
      "42m 45s (- 21m 32s) (13300 66%) 0.3327 0.85\n",
      "43m 7s (- 21m 14s) (13400 67%) 0.1774 0.75\n",
      "43m 30s (- 20m 56s) (13500 67%) 0.4939 1.42\n",
      "43m 50s (- 20m 37s) (13600 68%) 0.2587 0.79\n",
      "44m 12s (- 20m 19s) (13700 68%) 0.1987 0.81\n",
      "44m 34s (- 20m 1s) (13800 69%) 0.3988 1.15\n",
      "44m 57s (- 19m 43s) (13900 69%) 0.1994 0.64\n",
      "45m 20s (- 19m 25s) (14000 70%) 0.2538 0.76\n",
      "45m 41s (- 19m 7s) (14100 70%) 0.3223 0.82\n",
      "46m 2s (- 18m 48s) (14200 71%) 0.3011 0.97\n",
      "46m 23s (- 18m 29s) (14300 71%) 0.2547 0.53\n",
      "46m 46s (- 18m 11s) (14400 72%) 0.4837 1.34\n",
      "47m 9s (- 17m 53s) (14500 72%) 0.2708 0.71\n",
      "47m 29s (- 17m 34s) (14600 73%) 0.3610 1.18\n",
      "47m 52s (- 17m 15s) (14700 73%) 0.2881 0.94\n",
      "48m 13s (- 16m 56s) (14800 74%) 0.4999 1.42\n",
      "48m 33s (- 16m 37s) (14900 74%) 0.5055 1.44\n",
      "48m 55s (- 16m 18s) (15000 75%) 0.3956 1.07\n",
      "49m 16s (- 15m 59s) (15100 75%) 0.4382 1.49\n",
      "49m 36s (- 15m 39s) (15200 76%) 0.2280 0.62\n",
      "49m 58s (- 15m 21s) (15300 76%) 0.4984 1.45\n",
      "50m 22s (- 15m 2s) (15400 77%) 0.5233 1.23\n",
      "50m 44s (- 14m 43s) (15500 77%) 0.3792 1.04\n",
      "51m 7s (- 14m 25s) (15600 78%) 0.5056 1.72\n",
      "51m 28s (- 14m 5s) (15700 78%) 0.3814 1.24\n",
      "51m 50s (- 13m 46s) (15800 79%) 0.3212 1.13\n",
      "52m 10s (- 13m 27s) (15900 79%) 0.3365 0.93\n",
      "52m 33s (- 13m 8s) (16000 80%) 0.3858 1.31\n",
      "52m 53s (- 12m 48s) (16100 80%) 0.2028 0.60\n",
      "53m 15s (- 12m 29s) (16200 81%) 0.2776 0.65\n",
      "53m 37s (- 12m 10s) (16300 81%) 0.1474 0.42\n",
      "53m 59s (- 11m 51s) (16400 82%) 0.2805 0.77\n",
      "54m 21s (- 11m 31s) (16500 82%) 0.2955 1.03\n",
      "54m 41s (- 11m 12s) (16600 83%) 0.3687 0.94\n",
      "55m 3s (- 10m 52s) (16700 83%) 0.2117 0.58\n",
      "55m 25s (- 10m 33s) (16800 84%) 0.3353 0.84\n",
      "55m 47s (- 10m 14s) (16900 84%) 0.3590 0.79\n",
      "56m 10s (- 9m 54s) (17000 85%) 0.3114 1.04\n",
      "56m 32s (- 9m 35s) (17100 85%) 0.1720 0.42\n",
      "56m 54s (- 9m 15s) (17200 86%) 0.5053 1.28\n",
      "57m 15s (- 8m 56s) (17300 86%) 0.3907 1.02\n",
      "57m 35s (- 8m 36s) (17400 87%) 0.2522 0.73\n",
      "57m 58s (- 8m 16s) (17500 87%) 0.3461 1.02\n",
      "58m 22s (- 7m 57s) (17600 88%) 0.2942 0.63\n",
      "58m 42s (- 7m 37s) (17700 88%) 0.4006 1.20\n",
      "59m 4s (- 7m 18s) (17800 89%) 0.3824 1.07\n",
      "59m 25s (- 6m 58s) (17900 89%) 0.3496 0.89\n",
      "59m 46s (- 6m 38s) (18000 90%) 0.3523 0.96\n",
      "60m 7s (- 6m 18s) (18100 90%) 0.3565 0.94\n",
      "60m 30s (- 5m 59s) (18200 91%) 0.4065 0.94\n",
      "60m 51s (- 5m 39s) (18300 91%) 0.2915 1.12\n",
      "61m 14s (- 5m 19s) (18400 92%) 0.4655 1.12\n",
      "61m 37s (- 4m 59s) (18500 92%) 0.4634 1.07\n",
      "62m 1s (- 4m 40s) (18600 93%) 0.3595 0.97\n",
      "62m 23s (- 4m 20s) (18700 93%) 0.3785 0.91\n",
      "62m 45s (- 4m 0s) (18800 94%) 0.3802 1.30\n",
      "63m 6s (- 3m 40s) (18900 94%) 0.3641 1.10\n",
      "63m 27s (- 3m 20s) (19000 95%) 0.4070 0.99\n",
      "63m 48s (- 3m 0s) (19100 95%) 0.2511 0.60\n",
      "64m 12s (- 2m 40s) (19200 96%) 0.3038 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64m 35s (- 2m 20s) (19300 96%) 0.3606 1.16\n",
      "64m 59s (- 2m 0s) (19400 97%) 0.3953 1.00\n",
      "65m 19s (- 1m 40s) (19500 97%) 0.1623 0.44\n",
      "65m 41s (- 1m 20s) (19600 98%) 0.2111 0.48\n",
      "66m 4s (- 1m 0s) (19700 98%) 0.2689 0.61\n",
      "66m 24s (- 0m 40s) (19800 99%) 0.4614 1.28\n",
      "66m 45s (- 0m 20s) (19900 99%) 0.2472 0.80\n",
      "67m 8s (- 0m 0s) (20000 100%) 0.3553 0.87\n",
      "0m 16s (- 54m 35s) (100 0%) 0.1278 0.38\n",
      "0m 30s (- 50m 10s) (200 1%) 0.3703 0.97\n",
      "0m 45s (- 49m 47s) (300 1%) 0.3473 1.10\n",
      "0m 58s (- 48m 1s) (400 2%) 0.2370 0.60\n",
      "1m 13s (- 47m 55s) (500 2%) 0.2157 0.63\n",
      "1m 28s (- 47m 41s) (600 3%) 0.2637 0.76\n",
      "1m 41s (- 46m 41s) (700 3%) 0.1677 0.48\n",
      "1m 58s (- 47m 31s) (800 4%) 0.4070 1.01\n",
      "2m 18s (- 48m 51s) (900 4%) 0.3657 1.13\n",
      "2m 40s (- 50m 42s) (1000 5%) 0.2116 0.65\n",
      "3m 2s (- 52m 10s) (1100 5%) 0.1725 0.38\n",
      "3m 24s (- 53m 27s) (1200 6%) 0.5205 1.23\n",
      "3m 45s (- 54m 10s) (1300 6%) 0.3887 0.86\n",
      "4m 7s (- 54m 44s) (1400 7%) 0.1981 0.47\n",
      "4m 27s (- 55m 1s) (1500 7%) 0.2278 0.72\n",
      "4m 49s (- 55m 24s) (1600 8%) 0.3703 1.09\n",
      "5m 11s (- 55m 51s) (1700 8%) 0.1786 0.57\n",
      "5m 32s (- 56m 6s) (1800 9%) 0.4401 1.08\n",
      "5m 55s (- 56m 23s) (1900 9%) 0.2917 0.75\n",
      "6m 17s (- 56m 34s) (2000 10%) 0.3827 0.94\n",
      "6m 38s (- 56m 39s) (2100 10%) 0.2610 0.79\n",
      "6m 59s (- 56m 35s) (2200 11%) 0.3656 0.80\n",
      "7m 21s (- 56m 40s) (2300 11%) 0.4248 1.14\n",
      "7m 42s (- 56m 34s) (2400 12%) 0.3264 0.77\n",
      "8m 4s (- 56m 33s) (2500 12%) 0.2637 0.46\n",
      "8m 26s (- 56m 26s) (2600 13%) 0.4178 1.14\n",
      "8m 47s (- 56m 18s) (2700 13%) 0.1545 0.26\n",
      "9m 8s (- 56m 9s) (2800 14%) 0.2082 0.44\n",
      "9m 30s (- 56m 6s) (2900 14%) 0.1984 0.47\n",
      "9m 51s (- 55m 53s) (3000 15%) 0.3728 0.99\n",
      "10m 16s (- 56m 2s) (3100 15%) 0.2426 0.56\n",
      "10m 40s (- 56m 1s) (3200 16%) 0.4152 1.10\n",
      "11m 2s (- 55m 52s) (3300 16%) 0.3068 0.90\n",
      "11m 23s (- 55m 36s) (3400 17%) 0.2786 0.95\n",
      "11m 44s (- 55m 21s) (3500 17%) 0.1843 0.40\n",
      "12m 5s (- 55m 6s) (3600 18%) 0.3409 0.86\n",
      "12m 27s (- 54m 54s) (3700 18%) 0.2260 0.73\n",
      "12m 49s (- 54m 40s) (3800 19%) 0.2705 0.65\n",
      "13m 10s (- 54m 23s) (3900 19%) 0.2727 0.66\n",
      "13m 31s (- 54m 7s) (4000 20%) 0.3251 0.93\n",
      "13m 53s (- 53m 51s) (4100 20%) 0.2716 1.04\n",
      "14m 14s (- 53m 34s) (4200 21%) 0.4090 0.98\n",
      "14m 37s (- 53m 22s) (4300 21%) 0.1028 0.22\n",
      "14m 59s (- 53m 9s) (4400 22%) 0.3632 1.24\n",
      "15m 20s (- 52m 51s) (4500 22%) 0.2040 0.60\n",
      "15m 43s (- 52m 38s) (4600 23%) 0.3821 0.94\n",
      "16m 5s (- 52m 23s) (4700 23%) 0.1714 0.39\n",
      "16m 28s (- 52m 10s) (4800 24%) 0.2627 0.67\n",
      "16m 50s (- 51m 55s) (4900 24%) 0.3040 1.12\n",
      "17m 12s (- 51m 38s) (5000 25%) 0.5368 1.57\n",
      "17m 34s (- 51m 21s) (5100 25%) 0.4041 1.36\n",
      "17m 56s (- 51m 4s) (5200 26%) 0.2481 0.82\n",
      "18m 17s (- 50m 43s) (5300 26%) 0.2335 0.51\n",
      "18m 39s (- 50m 26s) (5400 27%) 0.2798 0.97\n",
      "19m 1s (- 50m 8s) (5500 27%) 0.2605 0.61\n",
      "19m 22s (- 49m 48s) (5600 28%) 0.2246 0.71\n",
      "19m 42s (- 49m 27s) (5700 28%) 0.2372 0.77\n",
      "20m 3s (- 49m 6s) (5800 28%) 0.3105 1.00\n",
      "20m 25s (- 48m 49s) (5900 29%) 0.4090 1.27\n",
      "20m 46s (- 48m 29s) (6000 30%) 0.3628 1.10\n",
      "21m 7s (- 48m 8s) (6100 30%) 0.2442 0.69\n",
      "21m 29s (- 47m 51s) (6200 31%) 0.2479 0.72\n",
      "21m 52s (- 47m 34s) (6300 31%) 0.2108 0.60\n",
      "22m 15s (- 47m 17s) (6400 32%) 0.2628 0.91\n",
      "22m 36s (- 46m 58s) (6500 32%) 0.4628 1.20\n",
      "22m 59s (- 46m 39s) (6600 33%) 0.2177 0.61\n",
      "23m 21s (- 46m 22s) (6700 33%) 0.6076 1.53\n",
      "23m 43s (- 46m 3s) (6800 34%) 0.3539 1.15\n",
      "24m 4s (- 45m 41s) (6900 34%) 0.2415 0.67\n",
      "24m 24s (- 45m 20s) (7000 35%) 0.3520 0.79\n",
      "24m 45s (- 44m 59s) (7100 35%) 0.1595 0.43\n",
      "25m 8s (- 44m 42s) (7200 36%) 0.4728 1.32\n",
      "25m 28s (- 44m 19s) (7300 36%) 0.2674 0.82\n",
      "25m 51s (- 44m 1s) (7400 37%) 0.3175 0.64\n",
      "26m 12s (- 43m 41s) (7500 37%) 0.3639 1.32\n",
      "26m 35s (- 43m 22s) (7600 38%) 0.2974 0.82\n",
      "26m 57s (- 43m 3s) (7700 38%) 0.3629 1.01\n",
      "27m 18s (- 42m 43s) (7800 39%) 0.1302 0.32\n",
      "27m 39s (- 42m 21s) (7900 39%) 0.2559 0.87\n",
      "28m 0s (- 42m 0s) (8000 40%) 0.2194 0.67\n",
      "28m 20s (- 41m 37s) (8100 40%) 0.2081 0.50\n",
      "28m 42s (- 41m 18s) (8200 41%) 0.2734 0.98\n",
      "29m 3s (- 40m 58s) (8300 41%) 0.3035 0.80\n",
      "29m 26s (- 40m 38s) (8400 42%) 0.3082 0.70\n",
      "29m 46s (- 40m 17s) (8500 42%) 0.2923 1.09\n",
      "30m 9s (- 39m 58s) (8600 43%) 0.2310 0.78\n",
      "30m 31s (- 39m 38s) (8700 43%) 0.2959 0.69\n",
      "30m 53s (- 39m 19s) (8800 44%) 0.2993 0.95\n",
      "31m 16s (- 39m 0s) (8900 44%) 0.1514 0.44\n",
      "31m 36s (- 38m 37s) (9000 45%) 0.3203 0.70\n",
      "31m 57s (- 38m 16s) (9100 45%) 0.1480 0.53\n",
      "32m 19s (- 37m 56s) (9200 46%) 0.3593 0.80\n",
      "32m 41s (- 37m 37s) (9300 46%) 0.1404 0.52\n",
      "33m 3s (- 37m 16s) (9400 47%) 0.2907 0.86\n",
      "33m 26s (- 36m 57s) (9500 47%) 0.2512 0.81\n",
      "33m 48s (- 36m 37s) (9600 48%) 0.3260 1.12\n",
      "34m 10s (- 36m 17s) (9700 48%) 0.2170 0.85\n",
      "34m 31s (- 35m 56s) (9800 49%) 0.2270 0.77\n",
      "34m 52s (- 35m 35s) (9900 49%) 0.3162 0.92\n",
      "35m 14s (- 35m 14s) (10000 50%) 0.2468 0.80\n",
      "35m 36s (- 34m 53s) (10100 50%) 0.2982 0.78\n",
      "35m 58s (- 34m 34s) (10200 51%) 0.3476 1.08\n",
      "36m 20s (- 34m 13s) (10300 51%) 0.5741 1.52\n",
      "36m 43s (- 33m 54s) (10400 52%) 0.1478 0.34\n",
      "37m 4s (- 33m 32s) (10500 52%) 0.2471 0.55\n",
      "37m 25s (- 33m 11s) (10600 53%) 0.2562 0.56\n",
      "37m 45s (- 32m 49s) (10700 53%) 0.2053 0.56\n",
      "38m 10s (- 32m 31s) (10800 54%) 0.2993 1.09\n",
      "38m 32s (- 32m 10s) (10900 54%) 0.2217 0.63\n",
      "38m 54s (- 31m 49s) (11000 55%) 0.2717 0.79\n",
      "39m 15s (- 31m 28s) (11100 55%) 0.2297 0.57\n",
      "39m 37s (- 31m 7s) (11200 56%) 0.2757 0.75\n",
      "39m 58s (- 30m 46s) (11300 56%) 0.1686 0.62\n",
      "40m 19s (- 30m 24s) (11400 56%) 0.2509 0.75\n",
      "40m 40s (- 30m 3s) (11500 57%) 0.2118 0.79\n",
      "41m 2s (- 29m 42s) (11600 57%) 0.1402 0.40\n",
      "41m 22s (- 29m 21s) (11700 58%) 0.2336 0.61\n",
      "41m 44s (- 29m 0s) (11800 59%) 0.3720 1.15\n",
      "42m 4s (- 28m 38s) (11900 59%) 0.4309 1.17\n",
      "42m 27s (- 28m 18s) (12000 60%) 0.3740 1.21\n",
      "42m 50s (- 27m 58s) (12100 60%) 0.2306 0.41\n",
      "43m 12s (- 27m 37s) (12200 61%) 0.2216 0.68\n",
      "43m 32s (- 27m 15s) (12300 61%) 0.1347 0.44\n",
      "43m 53s (- 26m 54s) (12400 62%) 0.2058 0.66\n",
      "44m 15s (- 26m 33s) (12500 62%) 0.2407 0.68\n",
      "44m 37s (- 26m 12s) (12600 63%) 0.2941 0.89\n",
      "44m 59s (- 25m 51s) (12700 63%) 0.2521 0.58\n",
      "45m 19s (- 25m 29s) (12800 64%) 0.2019 0.48\n",
      "45m 42s (- 25m 9s) (12900 64%) 0.3242 0.75\n",
      "46m 5s (- 24m 49s) (13000 65%) 0.2446 0.60\n",
      "46m 26s (- 24m 27s) (13100 65%) 0.1982 0.85\n",
      "46m 48s (- 24m 6s) (13200 66%) 0.2505 0.53\n",
      "47m 12s (- 23m 47s) (13300 66%) 0.2063 0.64\n",
      "47m 33s (- 23m 25s) (13400 67%) 0.4370 1.03\n",
      "47m 56s (- 23m 5s) (13500 67%) 0.1126 0.22\n",
      "48m 19s (- 22m 44s) (13600 68%) 0.2781 0.66\n",
      "48m 40s (- 22m 23s) (13700 68%) 0.2213 0.53\n",
      "49m 3s (- 22m 2s) (13800 69%) 0.1984 0.53\n",
      "49m 26s (- 21m 41s) (13900 69%) 0.3096 0.92\n",
      "49m 47s (- 21m 20s) (14000 70%) 0.2667 0.82\n",
      "50m 10s (- 20m 59s) (14100 70%) 0.3989 1.27\n",
      "50m 31s (- 20m 38s) (14200 71%) 0.3335 0.99\n",
      "50m 53s (- 20m 17s) (14300 71%) 0.2109 0.54\n",
      "51m 12s (- 19m 54s) (14400 72%) 0.1788 0.59\n",
      "51m 33s (- 19m 33s) (14500 72%) 0.1692 0.51\n",
      "51m 55s (- 19m 12s) (14600 73%) 0.1905 0.50\n",
      "52m 15s (- 18m 50s) (14700 73%) 0.4555 1.33\n",
      "52m 35s (- 18m 28s) (14800 74%) 0.3558 0.98\n",
      "52m 56s (- 18m 7s) (14900 74%) 0.2898 0.67\n",
      "53m 18s (- 17m 46s) (15000 75%) 0.4042 1.11\n",
      "53m 39s (- 17m 24s) (15100 75%) 0.2112 0.70\n",
      "54m 2s (- 17m 3s) (15200 76%) 0.2263 0.55\n",
      "54m 23s (- 16m 42s) (15300 76%) 0.1571 0.51\n",
      "54m 45s (- 16m 21s) (15400 77%) 0.1909 0.51\n",
      "55m 7s (- 16m 0s) (15500 77%) 0.2579 0.77\n",
      "55m 28s (- 15m 38s) (15600 78%) 0.1752 0.45\n",
      "55m 51s (- 15m 17s) (15700 78%) 0.4126 1.30\n",
      "56m 12s (- 14m 56s) (15800 79%) 0.1972 0.59\n",
      "56m 32s (- 14m 34s) (15900 79%) 0.2410 0.99\n",
      "56m 49s (- 14m 12s) (16000 80%) 0.2481 0.74\n",
      "57m 3s (- 13m 49s) (16100 80%) 0.2213 0.52\n",
      "57m 17s (- 13m 26s) (16200 81%) 0.2048 0.45\n",
      "57m 30s (- 13m 3s) (16300 81%) 0.1937 0.50\n",
      "57m 45s (- 12m 40s) (16400 82%) 0.1525 0.32\n",
      "57m 58s (- 12m 17s) (16500 82%) 0.1637 0.54\n",
      "58m 14s (- 11m 55s) (16600 83%) 0.2551 0.54\n",
      "58m 28s (- 11m 33s) (16700 83%) 0.2728 0.99\n",
      "58m 42s (- 11m 10s) (16800 84%) 0.3145 0.97\n",
      "58m 56s (- 10m 48s) (16900 84%) 0.1297 0.44\n",
      "59m 11s (- 10m 26s) (17000 85%) 0.2894 0.58\n",
      "59m 24s (- 10m 4s) (17100 85%) 0.4051 0.83\n",
      "59m 38s (- 9m 42s) (17200 86%) 0.2767 0.69\n",
      "59m 51s (- 9m 20s) (17300 86%) 0.3469 0.95\n",
      "60m 6s (- 8m 58s) (17400 87%) 0.1903 0.52\n",
      "60m 19s (- 8m 37s) (17500 87%) 0.3044 0.63\n",
      "60m 33s (- 8m 15s) (17600 88%) 0.1204 0.42\n",
      "60m 47s (- 7m 53s) (17700 88%) 0.1873 0.54\n",
      "61m 1s (- 7m 32s) (17800 89%) 0.2899 0.80\n",
      "61m 16s (- 7m 11s) (17900 89%) 0.1982 0.51\n",
      "61m 29s (- 6m 49s) (18000 90%) 0.3073 0.81\n",
      "61m 43s (- 6m 28s) (18100 90%) 0.2199 0.46\n",
      "61m 57s (- 6m 7s) (18200 91%) 0.3054 0.87\n",
      "62m 11s (- 5m 46s) (18300 91%) 0.2689 0.80\n",
      "62m 26s (- 5m 25s) (18400 92%) 0.4398 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62m 41s (- 5m 4s) (18500 92%) 0.1027 0.23\n",
      "62m 55s (- 4m 44s) (18600 93%) 0.2624 0.50\n",
      "63m 9s (- 4m 23s) (18700 93%) 0.4336 1.05\n",
      "63m 22s (- 4m 2s) (18800 94%) 0.1775 0.49\n",
      "63m 35s (- 3m 42s) (18900 94%) 0.1751 0.68\n",
      "63m 50s (- 3m 21s) (19000 95%) 0.3688 1.01\n",
      "64m 2s (- 3m 1s) (19100 95%) 0.2970 0.88\n",
      "64m 16s (- 2m 40s) (19200 96%) 0.2569 0.74\n",
      "64m 29s (- 2m 20s) (19300 96%) 0.2618 0.82\n",
      "64m 44s (- 2m 0s) (19400 97%) 0.3638 1.13\n",
      "64m 59s (- 1m 39s) (19500 97%) 0.1182 0.45\n",
      "65m 13s (- 1m 19s) (19600 98%) 0.1319 0.47\n",
      "65m 28s (- 0m 59s) (19700 98%) 0.2022 0.55\n",
      "65m 41s (- 0m 39s) (19800 99%) 0.1935 0.42\n",
      "65m 56s (- 0m 19s) (19900 99%) 0.2852 0.83\n",
      "66m 9s (- 0m 0s) (20000 100%) 0.0897 0.29\n"
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.005)\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 9s (- 50m 40s) (100 2%)\n",
      "2m 21s (- 50m 40s) (200 4%)\n",
      "3m 34s (- 50m 1s) (300 6%)\n",
      "4m 39s (- 47m 44s) (400 8%)\n",
      "5m 49s (- 46m 33s) (500 11%)\n",
      "6m 57s (- 45m 14s) (600 13%)\n",
      "8m 10s (- 44m 24s) (700 15%)\n",
      "9m 21s (- 43m 18s) (800 17%)\n",
      "10m 33s (- 42m 14s) (900 20%)\n",
      "11m 51s (- 41m 28s) (1000 22%)\n",
      "12m 59s (- 40m 10s) (1100 24%)\n",
      "14m 9s (- 38m 54s) (1200 26%)\n",
      "15m 15s (- 37m 33s) (1300 28%)\n",
      "16m 17s (- 36m 5s) (1400 31%)\n",
      "17m 24s (- 34m 49s) (1500 33%)\n",
      "18m 28s (- 33m 28s) (1600 35%)\n",
      "19m 35s (- 32m 16s) (1700 37%)\n",
      "20m 44s (- 31m 6s) (1800 40%)\n",
      "21m 53s (- 29m 56s) (1900 42%)\n",
      "23m 2s (- 28m 47s) (2000 44%)\n",
      "24m 13s (- 27m 40s) (2100 46%)\n",
      "25m 19s (- 26m 28s) (2200 48%)\n",
      "26m 30s (- 25m 21s) (2300 51%)\n",
      "27m 38s (- 24m 10s) (2400 53%)\n",
      "28m 51s (- 23m 5s) (2500 55%)\n",
      "30m 1s (- 21m 56s) (2600 57%)\n",
      "31m 8s (- 20m 45s) (2700 60%)\n",
      "32m 16s (- 19m 35s) (2800 62%)\n",
      "33m 20s (- 18m 23s) (2900 64%)\n",
      "34m 27s (- 17m 13s) (3000 66%)\n",
      "35m 42s (- 16m 7s) (3100 68%)\n",
      "36m 53s (- 14m 59s) (3200 71%)\n",
      "38m 1s (- 13m 49s) (3300 73%)\n",
      "39m 10s (- 12m 40s) (3400 75%)\n",
      "40m 12s (- 11m 29s) (3500 77%)\n",
      "41m 25s (- 10m 21s) (3600 80%)\n",
      "42m 32s (- 9m 11s) (3700 82%)\n",
      "43m 40s (- 8m 2s) (3800 84%)\n",
      "44m 46s (- 6m 53s) (3900 86%)\n",
      "45m 56s (- 5m 44s) (4000 88%)\n",
      "47m 0s (- 4m 35s) (4100 91%)\n",
      "48m 13s (- 3m 26s) (4200 93%)\n",
      "49m 28s (- 2m 18s) (4300 95%)\n",
      "50m 40s (- 1m 9s) (4400 97%)\n",
      "51m 47s (- 0m 0s) (4500 100%)\n",
      "3063\n"
     ]
    }
   ],
   "source": [
    "#3137 / 3063\n",
    "chatbot.eval()\n",
    "dialoguesWithErrors = trainer.DialoguesWithErrors(chatbot, dialogues_Master_var)\n",
    "print(len(dialoguesWithErrors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 15s (- 51m 17s) (100 0%) 1.1138 4.24\n",
      "0m 30s (- 51m 1s) (200 1%) 1.4491 4.27\n",
      "0m 46s (- 50m 48s) (300 1%) 1.0460 3.03\n",
      "1m 2s (- 50m 56s) (400 2%) 1.1104 2.98\n",
      "1m 19s (- 51m 29s) (500 2%) 0.9772 3.22\n",
      "1m 34s (- 50m 52s) (600 3%) 0.9110 2.75\n",
      "1m 50s (- 50m 37s) (700 3%) 0.8863 2.60\n",
      "2m 5s (- 50m 13s) (800 4%) 0.8850 2.61\n",
      "2m 21s (- 50m 10s) (900 4%) 0.7978 2.36\n",
      "2m 38s (- 50m 16s) (1000 5%) 1.1326 3.42\n",
      "2m 55s (- 50m 16s) (1100 5%) 0.8478 2.45\n",
      "3m 11s (- 50m 1s) (1200 6%) 1.1146 3.08\n",
      "3m 26s (- 49m 31s) (1300 6%) 0.8757 3.17\n",
      "3m 41s (- 49m 4s) (1400 7%) 0.7859 2.20\n",
      "3m 56s (- 48m 38s) (1500 7%) 0.9147 2.96\n",
      "4m 12s (- 48m 19s) (1600 8%) 0.8670 2.40\n",
      "4m 27s (- 48m 4s) (1700 8%) 0.8536 2.35\n",
      "4m 43s (- 47m 47s) (1800 9%) 0.8544 2.51\n",
      "4m 59s (- 47m 36s) (1900 9%) 0.6867 1.93\n",
      "5m 14s (- 47m 12s) (2000 10%) 0.9761 2.44\n",
      "5m 30s (- 46m 57s) (2100 10%) 0.8314 2.24\n",
      "5m 46s (- 46m 43s) (2200 11%) 0.7596 2.17\n",
      "6m 1s (- 46m 23s) (2300 11%) 0.7426 2.20\n",
      "6m 17s (- 46m 10s) (2400 12%) 0.7943 2.18\n",
      "6m 33s (- 45m 57s) (2500 12%) 0.5551 1.66\n",
      "6m 49s (- 45m 40s) (2600 13%) 0.7055 1.94\n",
      "7m 6s (- 45m 34s) (2700 13%) 0.7190 2.00\n",
      "7m 22s (- 45m 20s) (2800 14%) 0.6167 1.84\n",
      "7m 37s (- 44m 58s) (2900 14%) 0.7692 2.54\n",
      "7m 54s (- 44m 46s) (3000 15%) 0.9620 2.80\n",
      "8m 10s (- 44m 34s) (3100 15%) 0.8839 2.65\n",
      "8m 27s (- 44m 25s) (3200 16%) 0.6422 2.37\n",
      "8m 43s (- 44m 10s) (3300 16%) 0.6783 2.08\n",
      "8m 59s (- 43m 55s) (3400 17%) 0.6212 1.92\n",
      "9m 15s (- 43m 40s) (3500 17%) 0.6798 2.05\n",
      "9m 33s (- 43m 30s) (3600 18%) 0.6625 1.96\n",
      "9m 48s (- 43m 14s) (3700 18%) 0.5718 1.43\n",
      "10m 4s (- 42m 55s) (3800 19%) 0.7789 2.50\n",
      "10m 20s (- 42m 42s) (3900 19%) 0.5533 1.53\n",
      "10m 36s (- 42m 27s) (4000 20%) 0.5447 1.53\n",
      "10m 52s (- 42m 10s) (4100 20%) 0.4775 1.37\n",
      "11m 8s (- 41m 55s) (4200 21%) 0.7009 1.96\n",
      "11m 25s (- 41m 43s) (4300 21%) 0.5637 1.75\n",
      "11m 41s (- 41m 27s) (4400 22%) 0.6497 1.84\n",
      "11m 57s (- 41m 10s) (4500 22%) 0.5881 1.70\n",
      "12m 13s (- 40m 54s) (4600 23%) 0.6392 2.17\n",
      "12m 29s (- 40m 40s) (4700 23%) 0.4295 1.22\n",
      "12m 45s (- 40m 22s) (4800 24%) 0.7075 1.98\n",
      "13m 2s (- 40m 10s) (4900 24%) 0.6797 1.86\n",
      "13m 18s (- 39m 54s) (5000 25%) 0.7143 1.76\n",
      "13m 34s (- 39m 38s) (5100 25%) 0.5051 1.59\n",
      "13m 49s (- 39m 22s) (5200 26%) 0.7320 1.98\n",
      "14m 6s (- 39m 7s) (5300 26%) 0.5708 1.50\n",
      "14m 21s (- 38m 49s) (5400 27%) 0.5550 1.58\n",
      "14m 38s (- 38m 36s) (5500 27%) 0.5460 1.43\n",
      "14m 54s (- 38m 20s) (5600 28%) 0.5964 1.87\n",
      "15m 10s (- 38m 3s) (5700 28%) 0.7753 1.92\n",
      "15m 25s (- 37m 47s) (5800 28%) 0.6598 1.61\n",
      "15m 43s (- 37m 33s) (5900 29%) 0.4974 1.32\n",
      "16m 0s (- 37m 20s) (6000 30%) 0.4198 1.19\n",
      "16m 20s (- 37m 13s) (6100 30%) 0.4261 1.26\n",
      "16m 39s (- 37m 4s) (6200 31%) 0.4122 1.28\n",
      "16m 57s (- 36m 53s) (6300 31%) 0.5763 1.54\n",
      "17m 14s (- 36m 39s) (6400 32%) 0.4808 1.18\n",
      "17m 33s (- 36m 28s) (6500 32%) 0.4136 1.41\n",
      "17m 51s (- 36m 15s) (6600 33%) 0.9705 2.71\n",
      "18m 9s (- 36m 2s) (6700 33%) 0.6573 1.88\n",
      "18m 27s (- 35m 49s) (6800 34%) 0.4228 1.17\n",
      "18m 45s (- 35m 37s) (6900 34%) 0.6289 1.84\n",
      "19m 3s (- 35m 22s) (7000 35%) 0.6247 1.68\n",
      "19m 19s (- 35m 7s) (7100 35%) 0.6398 1.75\n",
      "19m 37s (- 34m 53s) (7200 36%) 0.4269 1.22\n",
      "19m 54s (- 34m 37s) (7300 36%) 0.3940 1.15\n",
      "20m 11s (- 34m 22s) (7400 37%) 0.5537 1.48\n",
      "20m 27s (- 34m 5s) (7500 37%) 0.6339 1.92\n",
      "20m 44s (- 33m 51s) (7600 38%) 0.6744 1.97\n",
      "21m 1s (- 33m 35s) (7700 38%) 0.6076 1.96\n",
      "21m 18s (- 33m 19s) (7800 39%) 0.4316 1.32\n",
      "21m 35s (- 33m 3s) (7900 39%) 0.5270 1.50\n",
      "21m 52s (- 32m 48s) (8000 40%) 0.3978 1.33\n",
      "22m 7s (- 32m 30s) (8100 40%) 0.4424 1.35\n",
      "22m 25s (- 32m 15s) (8200 41%) 0.3149 0.86\n",
      "22m 41s (- 31m 59s) (8300 41%) 0.4375 1.18\n",
      "22m 59s (- 31m 44s) (8400 42%) 0.4832 1.30\n",
      "23m 16s (- 31m 28s) (8500 42%) 0.4563 1.46\n",
      "23m 32s (- 31m 13s) (8600 43%) 0.4615 1.58\n",
      "23m 49s (- 30m 56s) (8700 43%) 0.3460 1.01\n",
      "24m 4s (- 30m 38s) (8800 44%) 0.5097 1.49\n",
      "24m 20s (- 30m 21s) (8900 44%) 0.5302 1.45\n",
      "24m 37s (- 30m 6s) (9000 45%) 0.4134 1.21\n",
      "24m 54s (- 29m 50s) (9100 45%) 0.4206 1.23\n",
      "25m 10s (- 29m 33s) (9200 46%) 0.4135 1.27\n",
      "25m 27s (- 29m 16s) (9300 46%) 0.3026 0.93\n",
      "25m 42s (- 28m 59s) (9400 47%) 0.4958 1.48\n",
      "25m 59s (- 28m 43s) (9500 47%) 0.4660 1.34\n",
      "26m 17s (- 28m 28s) (9600 48%) 0.4106 1.38\n",
      "26m 32s (- 28m 11s) (9700 48%) 0.3667 1.23\n",
      "26m 52s (- 27m 58s) (9800 49%) 0.4736 1.34\n",
      "27m 9s (- 27m 42s) (9900 49%) 0.4814 1.46\n",
      "27m 26s (- 27m 26s) (10000 50%) 0.3243 0.93\n",
      "27m 46s (- 27m 13s) (10100 50%) 0.2545 0.65\n",
      "28m 3s (- 26m 57s) (10200 51%) 0.2859 0.92\n",
      "28m 19s (- 26m 40s) (10300 51%) 0.3171 1.03\n",
      "28m 36s (- 26m 24s) (10400 52%) 0.7066 2.17\n",
      "28m 52s (- 26m 7s) (10500 52%) 0.3816 0.99\n",
      "29m 8s (- 25m 50s) (10600 53%) 0.4917 1.28\n",
      "29m 25s (- 25m 34s) (10700 53%) 0.3635 1.03\n",
      "29m 42s (- 25m 18s) (10800 54%) 0.3344 1.09\n",
      "29m 58s (- 25m 1s) (10900 54%) 0.3227 0.98\n",
      "30m 15s (- 24m 45s) (11000 55%) 0.4064 1.47\n",
      "30m 32s (- 24m 29s) (11100 55%) 0.3864 1.00\n",
      "30m 49s (- 24m 12s) (11200 56%) 0.2461 0.75\n",
      "31m 5s (- 23m 55s) (11300 56%) 0.3206 0.77\n",
      "31m 22s (- 23m 40s) (11400 56%) 0.4144 1.27\n",
      "31m 40s (- 23m 24s) (11500 57%) 0.3809 1.12\n",
      "31m 57s (- 23m 8s) (11600 57%) 0.4381 1.07\n",
      "32m 15s (- 22m 52s) (11700 58%) 0.3249 0.99\n",
      "32m 32s (- 22m 37s) (11800 59%) 0.4647 1.23\n",
      "32m 50s (- 22m 21s) (11900 59%) 0.5082 1.27\n",
      "33m 9s (- 22m 6s) (12000 60%) 0.4713 1.11\n",
      "33m 26s (- 21m 50s) (12100 60%) 0.3559 1.09\n",
      "33m 43s (- 21m 33s) (12200 61%) 0.5473 1.36\n",
      "34m 2s (- 21m 18s) (12300 61%) 0.3102 0.90\n",
      "34m 20s (- 21m 2s) (12400 62%) 0.3530 1.01\n",
      "34m 38s (- 20m 46s) (12500 62%) 0.4156 1.26\n",
      "34m 56s (- 20m 31s) (12600 63%) 0.4409 1.42\n",
      "35m 14s (- 20m 15s) (12700 63%) 0.3231 0.82\n",
      "35m 32s (- 19m 59s) (12800 64%) 0.6501 1.54\n",
      "35m 50s (- 19m 43s) (12900 64%) 0.4556 1.22\n",
      "36m 8s (- 19m 27s) (13000 65%) 0.4842 1.30\n",
      "36m 24s (- 19m 10s) (13100 65%) 0.4653 1.22\n",
      "36m 43s (- 18m 55s) (13200 66%) 0.4243 1.28\n",
      "37m 1s (- 18m 39s) (13300 66%) 0.3272 0.89\n",
      "37m 18s (- 18m 22s) (13400 67%) 0.2099 0.54\n",
      "37m 35s (- 18m 5s) (13500 67%) 0.2702 0.89\n",
      "37m 50s (- 17m 48s) (13600 68%) 0.4215 1.21\n",
      "38m 6s (- 17m 31s) (13700 68%) 0.2241 0.73\n",
      "38m 22s (- 17m 14s) (13800 69%) 0.4092 1.30\n",
      "38m 38s (- 16m 57s) (13900 69%) 0.4085 1.26\n",
      "38m 55s (- 16m 40s) (14000 70%) 0.2918 0.83\n",
      "39m 12s (- 16m 24s) (14100 70%) 0.4388 1.17\n",
      "39m 28s (- 16m 7s) (14200 71%) 0.2671 0.79\n",
      "39m 43s (- 15m 50s) (14300 71%) 0.3284 1.01\n",
      "40m 0s (- 15m 33s) (14400 72%) 0.3498 1.02\n",
      "40m 16s (- 15m 16s) (14500 72%) 0.3109 0.89\n",
      "40m 33s (- 15m 0s) (14600 73%) 0.2972 0.94\n",
      "40m 49s (- 14m 43s) (14700 73%) 0.2477 0.56\n",
      "41m 6s (- 14m 26s) (14800 74%) 0.3201 0.95\n",
      "41m 22s (- 14m 9s) (14900 74%) 0.6178 1.68\n",
      "41m 41s (- 13m 53s) (15000 75%) 0.3781 0.84\n",
      "41m 57s (- 13m 37s) (15100 75%) 0.2811 0.74\n",
      "42m 16s (- 13m 20s) (15200 76%) 0.1677 0.55\n",
      "42m 33s (- 13m 4s) (15300 76%) 0.2878 0.95\n",
      "42m 52s (- 12m 48s) (15400 77%) 0.2688 0.69\n",
      "43m 8s (- 12m 31s) (15500 77%) 0.1890 0.46\n",
      "43m 24s (- 12m 14s) (15600 78%) 0.2863 0.85\n",
      "43m 41s (- 11m 57s) (15700 78%) 0.2910 0.66\n",
      "43m 58s (- 11m 41s) (15800 79%) 0.2552 0.71\n",
      "44m 13s (- 11m 24s) (15900 79%) 0.2638 0.77\n",
      "44m 29s (- 11m 7s) (16000 80%) 0.4672 1.61\n",
      "44m 46s (- 10m 50s) (16100 80%) 0.3678 1.09\n",
      "45m 2s (- 10m 34s) (16200 81%) 0.4181 1.08\n",
      "45m 19s (- 10m 17s) (16300 81%) 0.4228 1.13\n",
      "45m 36s (- 10m 0s) (16400 82%) 0.3169 1.09\n",
      "45m 52s (- 9m 43s) (16500 82%) 0.3770 1.01\n",
      "46m 11s (- 9m 27s) (16600 83%) 0.4153 1.05\n",
      "46m 29s (- 9m 11s) (16700 83%) 0.3045 0.83\n",
      "46m 48s (- 8m 54s) (16800 84%) 0.3074 0.98\n",
      "47m 4s (- 8m 38s) (16900 84%) 0.2905 0.82\n",
      "47m 22s (- 8m 21s) (17000 85%) 0.1526 0.44\n",
      "47m 42s (- 8m 5s) (17100 85%) 0.4759 1.57\n",
      "47m 58s (- 7m 48s) (17200 86%) 0.4221 1.38\n",
      "48m 14s (- 7m 31s) (17300 86%) 0.2757 0.89\n",
      "48m 30s (- 7m 14s) (17400 87%) 0.1937 0.39\n",
      "48m 46s (- 6m 58s) (17500 87%) 0.2066 0.62\n",
      "49m 4s (- 6m 41s) (17600 88%) 0.2871 0.77\n",
      "49m 20s (- 6m 24s) (17700 88%) 0.3906 1.17\n",
      "49m 35s (- 6m 7s) (17800 89%) 0.4993 1.15\n",
      "49m 51s (- 5m 50s) (17900 89%) 0.3594 1.04\n",
      "50m 7s (- 5m 34s) (18000 90%) 0.3136 0.80\n",
      "50m 23s (- 5m 17s) (18100 90%) 0.1515 0.39\n",
      "50m 40s (- 5m 0s) (18200 91%) 0.2921 0.97\n",
      "50m 57s (- 4m 44s) (18300 91%) 0.5191 1.38\n",
      "51m 13s (- 4m 27s) (18400 92%) 0.1801 0.44\n",
      "51m 29s (- 4m 10s) (18500 92%) 0.1795 0.53\n",
      "51m 45s (- 3m 53s) (18600 93%) 0.3537 0.95\n",
      "52m 1s (- 3m 37s) (18700 93%) 0.4451 1.36\n",
      "52m 18s (- 3m 20s) (18800 94%) 0.4568 1.46\n",
      "52m 34s (- 3m 3s) (18900 94%) 0.4431 1.10\n",
      "52m 51s (- 2m 46s) (19000 95%) 0.2966 1.00\n",
      "53m 8s (- 2m 30s) (19100 95%) 0.2918 0.69\n",
      "53m 25s (- 2m 13s) (19200 96%) 0.2894 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53m 43s (- 1m 56s) (19300 96%) 0.2141 0.56\n",
      "53m 58s (- 1m 40s) (19400 97%) 0.3008 0.77\n",
      "54m 15s (- 1m 23s) (19500 97%) 0.2463 0.61\n",
      "54m 32s (- 1m 6s) (19600 98%) 0.2288 0.52\n",
      "54m 49s (- 0m 50s) (19700 98%) 0.3099 0.83\n",
      "55m 7s (- 0m 33s) (19800 99%) 0.3245 1.07\n",
      "55m 24s (- 0m 16s) (19900 99%) 0.1852 0.48\n",
      "55m 40s (- 0m 0s) (20000 100%) 0.2904 0.93\n",
      "0m 13s (- 44m 27s) (100 0%) 0.8264 2.37\n",
      "0m 27s (- 45m 18s) (200 1%) 0.6558 1.84\n",
      "0m 42s (- 46m 6s) (300 1%) 0.5410 1.69\n",
      "0m 55s (- 45m 25s) (400 2%) 0.6722 1.88\n",
      "1m 9s (- 45m 15s) (500 2%) 0.3932 1.00\n",
      "1m 24s (- 45m 20s) (600 3%) 0.3633 0.93\n",
      "1m 38s (- 45m 2s) (700 3%) 0.5573 1.31\n",
      "1m 52s (- 45m 7s) (800 4%) 0.4429 1.17\n",
      "2m 7s (- 44m 56s) (900 4%) 0.3553 0.84\n",
      "2m 22s (- 45m 1s) (1000 5%) 0.4908 1.23\n",
      "2m 37s (- 45m 5s) (1100 5%) 0.4415 1.10\n",
      "2m 51s (- 44m 49s) (1200 6%) 0.3200 0.95\n",
      "3m 4s (- 44m 13s) (1300 6%) 0.3958 1.01\n",
      "3m 18s (- 44m 1s) (1400 7%) 0.4795 1.17\n",
      "3m 31s (- 43m 29s) (1500 7%) 0.2126 0.70\n",
      "3m 45s (- 43m 9s) (1600 8%) 0.4294 1.09\n",
      "3m 59s (- 43m 3s) (1700 8%) 0.2477 0.58\n",
      "4m 14s (- 42m 54s) (1800 9%) 0.3078 0.84\n",
      "4m 28s (- 42m 36s) (1900 9%) 0.3074 0.73\n",
      "4m 41s (- 42m 15s) (2000 10%) 0.1691 0.53\n",
      "4m 56s (- 42m 10s) (2100 10%) 0.2692 0.75\n",
      "5m 11s (- 42m 0s) (2200 11%) 0.4655 1.14\n",
      "5m 25s (- 41m 46s) (2300 11%) 0.6768 1.97\n",
      "5m 41s (- 41m 45s) (2400 12%) 0.2176 0.60\n",
      "5m 56s (- 41m 35s) (2500 12%) 0.3113 0.96\n",
      "6m 9s (- 41m 14s) (2600 13%) 0.2653 0.71\n",
      "6m 24s (- 41m 2s) (2700 13%) 0.3467 0.89\n",
      "6m 39s (- 40m 53s) (2800 14%) 0.2233 0.51\n",
      "6m 52s (- 40m 31s) (2900 14%) 0.4101 0.95\n",
      "7m 6s (- 40m 14s) (3000 15%) 0.2881 0.63\n",
      "7m 18s (- 39m 51s) (3100 15%) 0.3592 1.14\n",
      "7m 32s (- 39m 37s) (3200 16%) 0.3040 0.58\n",
      "7m 47s (- 39m 24s) (3300 16%) 0.2208 0.60\n",
      "8m 1s (- 39m 8s) (3400 17%) 0.1757 0.40\n",
      "8m 15s (- 38m 57s) (3500 17%) 0.3783 0.86\n",
      "8m 29s (- 38m 42s) (3600 18%) 0.1797 0.34\n",
      "8m 45s (- 38m 34s) (3700 18%) 0.3802 1.00\n",
      "8m 59s (- 38m 22s) (3800 19%) 0.2330 0.65\n",
      "9m 14s (- 38m 7s) (3900 19%) 0.2989 0.75\n",
      "9m 27s (- 37m 50s) (4000 20%) 0.2653 0.58\n",
      "9m 41s (- 37m 34s) (4100 20%) 0.1640 0.49\n",
      "9m 55s (- 37m 21s) (4200 21%) 0.2336 0.72\n",
      "10m 11s (- 37m 12s) (4300 21%) 0.2648 0.63\n",
      "10m 25s (- 36m 58s) (4400 22%) 0.1084 0.30\n",
      "10m 40s (- 36m 47s) (4500 22%) 0.3009 0.96\n",
      "10m 55s (- 36m 33s) (4600 23%) 0.1498 0.43\n",
      "11m 9s (- 36m 18s) (4700 23%) 0.2070 0.62\n",
      "11m 23s (- 36m 5s) (4800 24%) 0.1892 0.39\n",
      "11m 38s (- 35m 53s) (4900 24%) 0.3224 0.81\n",
      "11m 53s (- 35m 40s) (5000 25%) 0.3897 1.12\n",
      "12m 8s (- 35m 28s) (5100 25%) 0.2198 0.65\n",
      "12m 21s (- 35m 10s) (5200 26%) 0.2415 0.62\n",
      "12m 35s (- 34m 56s) (5300 26%) 0.2182 0.52\n",
      "12m 50s (- 34m 43s) (5400 27%) 0.1866 0.48\n",
      "13m 5s (- 34m 30s) (5500 27%) 0.1178 0.41\n",
      "13m 19s (- 34m 16s) (5600 28%) 0.3949 0.96\n",
      "13m 33s (- 34m 1s) (5700 28%) 0.2629 0.63\n",
      "13m 46s (- 33m 43s) (5800 28%) 0.1441 0.50\n",
      "14m 0s (- 33m 27s) (5900 29%) 0.2249 0.62\n",
      "14m 15s (- 33m 15s) (6000 30%) 0.3087 0.68\n",
      "14m 29s (- 33m 1s) (6100 30%) 0.1408 0.36\n",
      "14m 43s (- 32m 46s) (6200 31%) 0.4574 1.11\n",
      "14m 56s (- 32m 30s) (6300 31%) 0.3082 0.74\n",
      "15m 11s (- 32m 16s) (6400 32%) 0.1478 0.34\n",
      "15m 26s (- 32m 3s) (6500 32%) 0.2273 0.44\n",
      "15m 39s (- 31m 48s) (6600 33%) 0.1829 0.56\n",
      "15m 56s (- 31m 37s) (6700 33%) 0.1728 0.39\n",
      "16m 9s (- 31m 22s) (6800 34%) 0.1667 0.39\n",
      "16m 23s (- 31m 6s) (6900 34%) 0.2436 0.77\n",
      "16m 37s (- 30m 51s) (7000 35%) 0.1395 0.39\n",
      "16m 51s (- 30m 37s) (7100 35%) 0.1649 0.34\n",
      "17m 5s (- 30m 22s) (7200 36%) 0.2447 0.69\n",
      "17m 18s (- 30m 7s) (7300 36%) 0.4116 1.09\n",
      "17m 33s (- 29m 54s) (7400 37%) 0.0960 0.20\n",
      "17m 47s (- 29m 38s) (7500 37%) 0.1234 0.28\n",
      "18m 0s (- 29m 22s) (7600 38%) 0.2274 0.58\n",
      "18m 13s (- 29m 7s) (7700 38%) 0.1657 0.42\n",
      "18m 27s (- 28m 51s) (7800 39%) 0.1579 0.46\n",
      "18m 41s (- 28m 37s) (7900 39%) 0.1009 0.20\n",
      "18m 55s (- 28m 23s) (8000 40%) 0.3410 0.91\n",
      "19m 9s (- 28m 8s) (8100 40%) 0.1982 0.47\n",
      "19m 23s (- 27m 54s) (8200 41%) 0.1471 0.47\n",
      "19m 37s (- 27m 40s) (8300 41%) 0.0930 0.26\n",
      "19m 52s (- 27m 26s) (8400 42%) 0.1599 0.47\n",
      "20m 6s (- 27m 11s) (8500 42%) 0.2684 0.70\n",
      "20m 20s (- 26m 57s) (8600 43%) 0.1608 0.47\n",
      "20m 34s (- 26m 44s) (8700 43%) 0.2256 0.75\n",
      "20m 47s (- 26m 28s) (8800 44%) 0.1318 0.38\n",
      "21m 1s (- 26m 12s) (8900 44%) 0.1121 0.33\n",
      "21m 15s (- 25m 58s) (9000 45%) 0.1643 0.42\n",
      "21m 29s (- 25m 44s) (9100 45%) 0.1812 0.59\n",
      "21m 42s (- 25m 29s) (9200 46%) 0.2105 0.50\n",
      "21m 56s (- 25m 14s) (9300 46%) 0.1653 0.50\n",
      "22m 10s (- 25m 0s) (9400 47%) 0.2143 0.50\n",
      "22m 24s (- 24m 45s) (9500 47%) 0.1973 0.71\n",
      "22m 38s (- 24m 31s) (9600 48%) 0.3158 0.67\n",
      "22m 52s (- 24m 16s) (9700 48%) 0.1732 0.40\n",
      "23m 6s (- 24m 3s) (9800 49%) 0.1433 0.34\n",
      "23m 21s (- 23m 49s) (9900 49%) 0.1249 0.40\n",
      "23m 34s (- 23m 34s) (10000 50%) 0.1691 0.56\n",
      "23m 48s (- 23m 19s) (10100 50%) 0.1396 0.63\n",
      "24m 1s (- 23m 5s) (10200 51%) 0.1097 0.23\n",
      "24m 15s (- 22m 50s) (10300 51%) 0.2102 0.54\n",
      "24m 28s (- 22m 35s) (10400 52%) 0.3563 0.80\n",
      "24m 42s (- 22m 21s) (10500 52%) 0.1800 0.58\n",
      "24m 56s (- 22m 7s) (10600 53%) 0.1779 0.60\n",
      "25m 11s (- 21m 53s) (10700 53%) 0.2278 0.72\n",
      "25m 26s (- 21m 39s) (10800 54%) 0.1625 0.29\n",
      "25m 40s (- 21m 25s) (10900 54%) 0.1801 0.52\n",
      "25m 55s (- 21m 12s) (11000 55%) 0.2248 0.51\n",
      "26m 8s (- 20m 57s) (11100 55%) 0.1246 0.23\n",
      "26m 22s (- 20m 43s) (11200 56%) 0.1893 0.36\n",
      "26m 36s (- 20m 29s) (11300 56%) 0.2570 0.64\n",
      "26m 49s (- 20m 14s) (11400 56%) 0.1566 0.20\n",
      "27m 3s (- 19m 59s) (11500 57%) 0.1820 0.43\n",
      "27m 16s (- 19m 45s) (11600 57%) 0.2119 0.51\n",
      "27m 32s (- 19m 32s) (11700 58%) 0.2336 0.51\n",
      "27m 45s (- 19m 17s) (11800 59%) 0.1669 0.42\n",
      "28m 0s (- 19m 4s) (11900 59%) 0.2254 0.68\n",
      "28m 15s (- 18m 50s) (12000 60%) 0.1775 0.44\n",
      "28m 30s (- 18m 36s) (12100 60%) 0.2333 0.56\n",
      "28m 44s (- 18m 22s) (12200 61%) 0.2767 0.79\n",
      "28m 58s (- 18m 8s) (12300 61%) 0.1480 0.30\n",
      "29m 12s (- 17m 53s) (12400 62%) 0.1381 0.45\n",
      "29m 26s (- 17m 39s) (12500 62%) 0.1706 0.38\n",
      "29m 40s (- 17m 25s) (12600 63%) 0.2302 0.62\n",
      "29m 52s (- 17m 10s) (12700 63%) 0.1517 0.34\n",
      "30m 6s (- 16m 56s) (12800 64%) 0.1285 0.32\n",
      "30m 20s (- 16m 42s) (12900 64%) 0.2998 0.84\n",
      "30m 33s (- 16m 27s) (13000 65%) 0.2307 0.85\n",
      "30m 46s (- 16m 12s) (13100 65%) 0.1148 0.19\n",
      "31m 0s (- 15m 58s) (13200 66%) 0.2235 0.49\n",
      "31m 14s (- 15m 44s) (13300 66%) 0.0961 0.23\n",
      "31m 28s (- 15m 30s) (13400 67%) 0.1793 0.70\n",
      "31m 41s (- 15m 15s) (13500 67%) 0.1461 0.39\n",
      "31m 54s (- 15m 0s) (13600 68%) 0.2114 0.59\n",
      "32m 8s (- 14m 46s) (13700 68%) 0.2234 0.52\n",
      "32m 22s (- 14m 32s) (13800 69%) 0.2097 0.49\n",
      "32m 36s (- 14m 18s) (13900 69%) 0.2633 0.64\n",
      "32m 50s (- 14m 4s) (14000 70%) 0.1546 0.37\n",
      "33m 4s (- 13m 50s) (14100 70%) 0.0962 0.20\n",
      "33m 18s (- 13m 36s) (14200 71%) 0.2146 0.52\n",
      "33m 33s (- 13m 22s) (14300 71%) 0.1896 0.60\n",
      "33m 47s (- 13m 8s) (14400 72%) 0.1987 0.38\n",
      "34m 1s (- 12m 54s) (14500 72%) 0.2842 0.60\n",
      "34m 16s (- 12m 40s) (14600 73%) 0.2055 0.64\n",
      "34m 30s (- 12m 26s) (14700 73%) 0.1509 0.52\n",
      "34m 45s (- 12m 12s) (14800 74%) 0.2387 0.65\n",
      "34m 59s (- 11m 58s) (14900 74%) 0.2192 0.88\n",
      "35m 14s (- 11m 44s) (15000 75%) 0.3335 0.91\n",
      "35m 28s (- 11m 30s) (15100 75%) 0.0722 0.17\n",
      "35m 42s (- 11m 16s) (15200 76%) 0.1928 0.54\n",
      "35m 57s (- 11m 2s) (15300 76%) 0.1424 0.39\n",
      "36m 11s (- 10m 48s) (15400 77%) 0.4055 0.96\n",
      "36m 25s (- 10m 34s) (15500 77%) 0.2353 0.51\n",
      "36m 40s (- 10m 20s) (15600 78%) 0.2330 0.69\n",
      "36m 54s (- 10m 6s) (15700 78%) 0.1381 0.34\n",
      "37m 7s (- 9m 52s) (15800 79%) 0.2127 0.45\n",
      "37m 21s (- 9m 37s) (15900 79%) 0.1947 0.39\n",
      "37m 35s (- 9m 23s) (16000 80%) 0.1852 0.65\n",
      "37m 50s (- 9m 9s) (16100 80%) 0.1980 0.53\n",
      "38m 4s (- 8m 55s) (16200 81%) 0.2248 0.55\n",
      "38m 17s (- 8m 41s) (16300 81%) 0.0691 0.15\n",
      "38m 30s (- 8m 27s) (16400 82%) 0.1462 0.34\n",
      "38m 44s (- 8m 13s) (16500 82%) 0.2468 0.69\n",
      "38m 57s (- 7m 58s) (16600 83%) 0.2001 0.57\n",
      "39m 12s (- 7m 44s) (16700 83%) 0.1705 0.32\n",
      "39m 26s (- 7m 30s) (16800 84%) 0.0974 0.17\n",
      "39m 41s (- 7m 16s) (16900 84%) 0.1076 0.23\n",
      "39m 55s (- 7m 2s) (17000 85%) 0.2169 0.61\n",
      "40m 7s (- 6m 48s) (17100 85%) 0.2986 0.70\n",
      "40m 21s (- 6m 34s) (17200 86%) 0.2876 0.79\n",
      "40m 34s (- 6m 19s) (17300 86%) 0.1499 0.48\n",
      "40m 47s (- 6m 5s) (17400 87%) 0.2153 0.49\n",
      "41m 1s (- 5m 51s) (17500 87%) 0.2986 0.73\n",
      "41m 14s (- 5m 37s) (17600 88%) 0.2588 0.69\n",
      "41m 28s (- 5m 23s) (17700 88%) 0.1460 0.50\n",
      "41m 42s (- 5m 9s) (17800 89%) 0.2888 0.85\n",
      "41m 55s (- 4m 55s) (17900 89%) 0.2102 0.52\n",
      "42m 10s (- 4m 41s) (18000 90%) 0.1731 0.40\n",
      "42m 24s (- 4m 27s) (18100 90%) 0.1023 0.23\n",
      "42m 37s (- 4m 12s) (18200 91%) 0.0599 0.07\n",
      "42m 50s (- 3m 58s) (18300 91%) 0.1862 0.50\n",
      "43m 4s (- 3m 44s) (18400 92%) 0.1646 0.42\n",
      "43m 18s (- 3m 30s) (18500 92%) 0.1077 0.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43m 32s (- 3m 16s) (18600 93%) 0.1382 0.27\n",
      "43m 45s (- 3m 2s) (18700 93%) 0.1308 0.29\n",
      "43m 59s (- 2m 48s) (18800 94%) 0.2398 0.57\n",
      "44m 12s (- 2m 34s) (18900 94%) 0.1683 0.36\n",
      "44m 27s (- 2m 20s) (19000 95%) 0.3164 0.87\n",
      "44m 42s (- 2m 6s) (19100 95%) 0.1806 0.74\n",
      "44m 55s (- 1m 52s) (19200 96%) 0.3113 0.93\n",
      "45m 9s (- 1m 38s) (19300 96%) 0.1616 0.35\n",
      "45m 23s (- 1m 24s) (19400 97%) 0.1991 0.56\n",
      "45m 37s (- 1m 10s) (19500 97%) 0.1155 0.34\n",
      "45m 52s (- 0m 56s) (19600 98%) 0.1634 0.42\n",
      "46m 6s (- 0m 42s) (19700 98%) 0.1822 0.39\n",
      "46m 20s (- 0m 28s) (19800 99%) 0.2571 0.55\n",
      "46m 33s (- 0m 14s) (19900 99%) 0.1001 0.27\n",
      "46m 46s (- 0m 0s) (20000 100%) 0.0741 0.14\n"
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.0025, dic = dialoguesWithErrors)\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 15s (- 26m 15s) (100 1%) 0.5507 1.87\n",
      "0m 32s (- 26m 15s) (200 2%) 0.6083 1.95\n",
      "0m 48s (- 26m 21s) (300 3%) 0.6829 2.24\n",
      "1m 4s (- 25m 55s) (400 4%) 0.4669 1.27\n",
      "1m 21s (- 25m 41s) (500 5%) 0.2907 1.10\n",
      "1m 38s (- 25m 39s) (600 6%) 0.6921 2.21\n",
      "1m 55s (- 25m 28s) (700 7%) 0.2835 0.74\n",
      "2m 10s (- 25m 5s) (800 8%) 0.5169 1.53\n",
      "2m 27s (- 24m 47s) (900 9%) 0.3701 1.31\n",
      "2m 43s (- 24m 32s) (1000 10%) 0.4300 1.13\n",
      "3m 0s (- 24m 21s) (1100 11%) 0.2602 0.70\n",
      "3m 17s (- 24m 7s) (1200 12%) 0.5140 1.54\n",
      "3m 32s (- 23m 45s) (1300 13%) 0.4162 1.23\n",
      "3m 50s (- 23m 33s) (1400 14%) 0.3619 1.01\n",
      "4m 6s (- 23m 14s) (1500 15%) 0.4373 1.02\n",
      "4m 21s (- 22m 54s) (1600 16%) 0.4974 1.53\n",
      "4m 38s (- 22m 39s) (1700 17%) 0.3509 1.25\n",
      "4m 54s (- 22m 22s) (1800 18%) 0.5139 1.06\n",
      "5m 11s (- 22m 6s) (1900 19%) 0.5919 1.26\n",
      "5m 26s (- 21m 47s) (2000 20%) 0.4859 1.27\n",
      "5m 43s (- 21m 32s) (2100 21%) 0.3337 0.85\n",
      "5m 58s (- 21m 11s) (2200 22%) 0.3567 0.87\n",
      "6m 14s (- 20m 54s) (2300 23%) 0.2213 0.60\n",
      "6m 30s (- 20m 37s) (2400 24%) 0.4190 1.00\n",
      "6m 47s (- 20m 21s) (2500 25%) 0.5606 1.28\n",
      "7m 3s (- 20m 6s) (2600 26%) 0.4799 1.24\n",
      "7m 20s (- 19m 50s) (2700 27%) 0.3681 0.86\n",
      "7m 36s (- 19m 32s) (2800 28%) 0.3833 1.01\n",
      "7m 52s (- 19m 16s) (2900 28%) 0.2917 0.71\n",
      "8m 9s (- 19m 1s) (3000 30%) 0.2385 0.60\n",
      "8m 25s (- 18m 44s) (3100 31%) 0.2323 0.59\n",
      "8m 41s (- 18m 27s) (3200 32%) 0.2494 0.59\n",
      "8m 58s (- 18m 12s) (3300 33%) 0.1938 0.63\n",
      "9m 14s (- 17m 56s) (3400 34%) 0.3786 1.02\n",
      "9m 30s (- 17m 39s) (3500 35%) 0.2060 0.48\n",
      "9m 46s (- 17m 22s) (3600 36%) 0.3684 1.26\n",
      "10m 2s (- 17m 6s) (3700 37%) 0.2512 0.82\n",
      "10m 19s (- 16m 50s) (3800 38%) 0.2787 0.91\n",
      "10m 35s (- 16m 34s) (3900 39%) 0.3755 1.14\n",
      "10m 51s (- 16m 17s) (4000 40%) 0.3270 0.78\n",
      "11m 6s (- 15m 59s) (4100 41%) 0.3577 0.91\n",
      "11m 23s (- 15m 43s) (4200 42%) 0.2761 0.54\n",
      "11m 39s (- 15m 27s) (4300 43%) 0.3145 0.73\n",
      "11m 55s (- 15m 10s) (4400 44%) 0.2066 0.59\n",
      "12m 10s (- 14m 53s) (4500 45%) 0.2474 0.57\n",
      "12m 26s (- 14m 36s) (4600 46%) 0.4702 1.31\n",
      "12m 42s (- 14m 19s) (4700 47%) 0.2821 0.86\n",
      "12m 58s (- 14m 3s) (4800 48%) 0.3684 1.00\n",
      "13m 15s (- 13m 47s) (4900 49%) 0.3836 1.00\n",
      "13m 30s (- 13m 30s) (5000 50%) 0.2781 0.91\n",
      "13m 47s (- 13m 14s) (5100 51%) 0.3463 0.93\n",
      "14m 3s (- 12m 58s) (5200 52%) 0.2526 0.68\n",
      "14m 18s (- 12m 41s) (5300 53%) 0.3525 0.90\n",
      "14m 34s (- 12m 25s) (5400 54%) 0.2789 0.76\n",
      "14m 50s (- 12m 8s) (5500 55%) 0.3191 0.78\n",
      "15m 7s (- 11m 53s) (5600 56%) 0.3928 1.51\n",
      "15m 23s (- 11m 36s) (5700 56%) 0.5188 1.45\n",
      "15m 39s (- 11m 20s) (5800 57%) 0.4144 0.86\n",
      "15m 56s (- 11m 4s) (5900 59%) 0.1785 0.51\n",
      "16m 12s (- 10m 48s) (6000 60%) 0.2058 0.50\n",
      "16m 26s (- 10m 31s) (6100 61%) 0.3924 0.93\n",
      "16m 43s (- 10m 15s) (6200 62%) 0.2024 0.55\n",
      "16m 59s (- 9m 58s) (6300 63%) 0.3571 0.99\n",
      "17m 15s (- 9m 42s) (6400 64%) 0.3688 1.15\n",
      "17m 32s (- 9m 26s) (6500 65%) 0.2263 0.68\n",
      "17m 48s (- 9m 10s) (6600 66%) 0.2592 0.73\n",
      "18m 4s (- 8m 54s) (6700 67%) 0.2459 0.63\n",
      "18m 20s (- 8m 37s) (6800 68%) 0.2800 0.75\n",
      "18m 37s (- 8m 21s) (6900 69%) 0.0938 0.25\n",
      "18m 52s (- 8m 5s) (7000 70%) 0.3468 0.93\n",
      "19m 9s (- 7m 49s) (7100 71%) 0.2388 0.44\n",
      "19m 26s (- 7m 33s) (7200 72%) 0.3085 0.90\n",
      "19m 41s (- 7m 17s) (7300 73%) 0.1518 0.38\n",
      "19m 57s (- 7m 0s) (7400 74%) 0.2715 0.71\n",
      "20m 13s (- 6m 44s) (7500 75%) 0.2160 0.50\n",
      "20m 28s (- 6m 28s) (7600 76%) 0.2347 0.55\n",
      "20m 44s (- 6m 11s) (7700 77%) 0.2645 0.60\n",
      "21m 0s (- 5m 55s) (7800 78%) 0.4402 1.19\n",
      "21m 16s (- 5m 39s) (7900 79%) 0.2451 0.59\n",
      "21m 32s (- 5m 23s) (8000 80%) 0.3217 0.84\n",
      "21m 48s (- 5m 6s) (8100 81%) 0.2758 0.68\n",
      "22m 4s (- 4m 50s) (8200 82%) 0.2623 0.68\n",
      "22m 21s (- 4m 34s) (8300 83%) 0.1319 0.36\n",
      "22m 38s (- 4m 18s) (8400 84%) 0.2426 0.55\n",
      "22m 55s (- 4m 2s) (8500 85%) 0.1277 0.32\n",
      "23m 11s (- 3m 46s) (8600 86%) 0.3076 0.93\n",
      "23m 27s (- 3m 30s) (8700 87%) 0.1778 0.48\n",
      "23m 44s (- 3m 14s) (8800 88%) 0.3530 0.88\n",
      "24m 0s (- 2m 57s) (8900 89%) 0.3134 0.96\n",
      "24m 16s (- 2m 41s) (9000 90%) 0.2640 0.65\n",
      "24m 32s (- 2m 25s) (9100 91%) 0.2335 0.49\n",
      "24m 48s (- 2m 9s) (9200 92%) 0.3251 0.88\n",
      "25m 4s (- 1m 53s) (9300 93%) 0.3130 0.88\n",
      "25m 20s (- 1m 37s) (9400 94%) 0.3079 0.84\n",
      "25m 36s (- 1m 20s) (9500 95%) 0.2957 0.79\n",
      "25m 53s (- 1m 4s) (9600 96%) 0.2063 0.48\n",
      "26m 9s (- 0m 48s) (9700 97%) 0.2713 0.67\n",
      "26m 25s (- 0m 32s) (9800 98%) 0.3377 1.06\n",
      "26m 41s (- 0m 16s) (9900 99%) 0.4071 0.94\n",
      "26m 57s (- 0m 0s) (10000 100%) 0.3334 0.80\n",
      "0m 13s (- 45m 39s) (100 0%) 0.3832 0.86\n",
      "0m 28s (- 46m 27s) (200 1%) 0.6533 1.66\n",
      "0m 42s (- 46m 49s) (300 1%) 0.3802 1.02\n",
      "0m 56s (- 45m 57s) (400 2%) 0.3098 0.90\n",
      "1m 10s (- 45m 36s) (500 2%) 0.3450 0.92\n",
      "1m 23s (- 45m 0s) (600 3%) 0.1549 0.31\n",
      "1m 36s (- 44m 22s) (700 3%) 0.1568 0.42\n",
      "1m 50s (- 44m 9s) (800 4%) 0.2548 0.60\n",
      "2m 3s (- 43m 49s) (900 4%) 0.1953 0.43\n",
      "2m 17s (- 43m 32s) (1000 5%) 0.2809 0.67\n",
      "2m 31s (- 43m 15s) (1100 5%) 0.2973 0.89\n",
      "2m 45s (- 43m 8s) (1200 6%) 0.2859 0.93\n",
      "2m 59s (- 43m 3s) (1300 6%) 0.2249 0.44\n",
      "3m 14s (- 43m 2s) (1400 7%) 0.1758 0.44\n",
      "3m 28s (- 42m 52s) (1500 7%) 0.2367 0.73\n",
      "3m 42s (- 42m 42s) (1600 8%) 0.1817 0.39\n",
      "3m 56s (- 42m 26s) (1700 8%) 0.3883 1.05\n",
      "4m 11s (- 42m 20s) (1800 9%) 0.2697 0.76\n",
      "4m 24s (- 41m 59s) (1900 9%) 0.2966 0.82\n",
      "4m 39s (- 41m 54s) (2000 10%) 0.2183 0.46\n",
      "4m 53s (- 41m 44s) (2100 10%) 0.1581 0.39\n",
      "5m 7s (- 41m 30s) (2200 11%) 0.2611 0.59\n",
      "5m 20s (- 41m 5s) (2300 11%) 0.1533 0.23\n",
      "5m 34s (- 40m 50s) (2400 12%) 0.3088 0.77\n",
      "5m 48s (- 40m 39s) (2500 12%) 0.1053 0.48\n",
      "6m 2s (- 40m 24s) (2600 13%) 0.4630 1.15\n",
      "6m 18s (- 40m 23s) (2700 13%) 0.2007 0.50\n",
      "6m 34s (- 40m 21s) (2800 14%) 0.1796 0.48\n",
      "6m 47s (- 40m 4s) (2900 14%) 0.3391 1.07\n",
      "7m 1s (- 39m 47s) (3000 15%) 0.2092 0.45\n",
      "7m 15s (- 39m 35s) (3100 15%) 0.1450 0.29\n",
      "7m 28s (- 39m 15s) (3200 16%) 0.1113 0.39\n",
      "7m 43s (- 39m 3s) (3300 16%) 0.1429 0.41\n",
      "7m 58s (- 38m 53s) (3400 17%) 0.2134 0.44\n",
      "8m 12s (- 38m 40s) (3500 17%) 0.1436 0.49\n",
      "8m 27s (- 38m 31s) (3600 18%) 0.2338 0.60\n",
      "8m 42s (- 38m 22s) (3700 18%) 0.1118 0.26\n",
      "8m 57s (- 38m 11s) (3800 19%) 0.1568 0.36\n",
      "9m 13s (- 38m 3s) (3900 19%) 0.2106 0.53\n",
      "9m 26s (- 37m 47s) (4000 20%) 0.1673 0.53\n",
      "9m 39s (- 37m 29s) (4100 20%) 0.4073 1.07\n",
      "9m 53s (- 37m 13s) (4200 21%) 0.1300 0.30\n",
      "10m 8s (- 37m 3s) (4300 21%) 0.0836 0.15\n",
      "10m 22s (- 36m 46s) (4400 22%) 0.2137 0.66\n",
      "10m 36s (- 36m 31s) (4500 22%) 0.0909 0.21\n",
      "10m 50s (- 36m 17s) (4600 23%) 0.1014 0.20\n",
      "11m 3s (- 36m 0s) (4700 23%) 0.0748 0.13\n",
      "11m 18s (- 35m 47s) (4800 24%) 0.1484 0.46\n",
      "11m 31s (- 35m 31s) (4900 24%) 0.1887 0.54\n",
      "11m 45s (- 35m 16s) (5000 25%) 0.2036 0.58\n",
      "11m 59s (- 35m 2s) (5100 25%) 0.0920 0.15\n",
      "12m 13s (- 34m 48s) (5200 26%) 0.1771 0.58\n",
      "12m 27s (- 34m 33s) (5300 26%) 0.2287 0.68\n",
      "12m 41s (- 34m 18s) (5400 27%) 0.3809 0.92\n",
      "12m 55s (- 34m 4s) (5500 27%) 0.1107 0.23\n",
      "13m 9s (- 33m 51s) (5600 28%) 0.2183 0.47\n",
      "13m 24s (- 33m 39s) (5700 28%) 0.1988 0.48\n",
      "13m 39s (- 33m 27s) (5800 28%) 0.1532 0.34\n",
      "13m 53s (- 33m 11s) (5900 29%) 0.1341 0.39\n",
      "14m 7s (- 32m 58s) (6000 30%) 0.1152 0.31\n",
      "14m 22s (- 32m 44s) (6100 30%) 0.1148 0.43\n",
      "14m 36s (- 32m 31s) (6200 31%) 0.1994 0.58\n",
      "14m 50s (- 32m 15s) (6300 31%) 0.1774 0.42\n",
      "15m 5s (- 32m 3s) (6400 32%) 0.2274 0.62\n",
      "15m 20s (- 31m 51s) (6500 32%) 0.0944 0.21\n",
      "15m 33s (- 31m 35s) (6600 33%) 0.0995 0.24\n",
      "15m 48s (- 31m 22s) (6700 33%) 0.2154 0.46\n",
      "16m 1s (- 31m 6s) (6800 34%) 0.1218 0.42\n",
      "16m 16s (- 30m 53s) (6900 34%) 0.2778 0.72\n",
      "16m 29s (- 30m 38s) (7000 35%) 0.1588 0.49\n",
      "16m 43s (- 30m 22s) (7100 35%) 0.1572 0.52\n",
      "16m 56s (- 30m 7s) (7200 36%) 0.1121 0.29\n",
      "17m 11s (- 29m 53s) (7300 36%) 0.1790 0.46\n",
      "17m 24s (- 29m 37s) (7400 37%) 0.1993 0.57\n",
      "17m 38s (- 29m 23s) (7500 37%) 0.0985 0.20\n",
      "17m 51s (- 29m 8s) (7600 38%) 0.2942 1.00\n",
      "18m 6s (- 28m 55s) (7700 38%) 0.1012 0.24\n",
      "18m 19s (- 28m 39s) (7800 39%) 0.1976 0.59\n",
      "18m 32s (- 28m 24s) (7900 39%) 0.1288 0.51\n",
      "18m 46s (- 28m 10s) (8000 40%) 0.2445 0.59\n",
      "19m 0s (- 27m 56s) (8100 40%) 0.0598 0.12\n",
      "19m 14s (- 27m 40s) (8200 41%) 0.1637 0.30\n",
      "19m 28s (- 27m 27s) (8300 41%) 0.1063 0.19\n",
      "19m 41s (- 27m 10s) (8400 42%) 0.3692 1.22\n",
      "19m 54s (- 26m 56s) (8500 42%) 0.0575 0.18\n",
      "20m 8s (- 26m 41s) (8600 43%) 0.2581 0.56\n",
      "20m 22s (- 26m 27s) (8700 43%) 0.0520 0.08\n",
      "20m 37s (- 26m 14s) (8800 44%) 0.2153 0.89\n",
      "20m 51s (- 26m 0s) (8900 44%) 0.2102 0.54\n",
      "21m 4s (- 25m 45s) (9000 45%) 0.0692 0.13\n",
      "21m 18s (- 25m 31s) (9100 45%) 0.1293 0.31\n",
      "21m 32s (- 25m 17s) (9200 46%) 0.1338 0.29\n",
      "21m 46s (- 25m 3s) (9300 46%) 0.1047 0.23\n",
      "22m 0s (- 24m 49s) (9400 47%) 0.1773 0.35\n",
      "22m 14s (- 24m 35s) (9500 47%) 0.1021 0.26\n",
      "22m 28s (- 24m 20s) (9600 48%) 0.1069 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22m 43s (- 24m 8s) (9700 48%) 0.2074 0.59\n",
      "22m 56s (- 23m 52s) (9800 49%) 0.1863 0.47\n",
      "23m 9s (- 23m 37s) (9900 49%) 0.2059 0.44\n",
      "23m 23s (- 23m 23s) (10000 50%) 0.1921 0.38\n",
      "23m 37s (- 23m 9s) (10100 50%) 0.1006 0.18\n",
      "23m 52s (- 22m 55s) (10200 51%) 0.2383 0.50\n",
      "24m 6s (- 22m 42s) (10300 51%) 0.2404 0.65\n",
      "24m 20s (- 22m 28s) (10400 52%) 0.1746 0.44\n",
      "24m 33s (- 22m 13s) (10500 52%) 0.0782 0.12\n",
      "24m 48s (- 21m 59s) (10600 53%) 0.1699 0.40\n",
      "25m 3s (- 21m 46s) (10700 53%) 0.1364 0.32\n",
      "25m 18s (- 21m 33s) (10800 54%) 0.1862 0.45\n",
      "25m 33s (- 21m 19s) (10900 54%) 0.1597 0.40\n",
      "25m 47s (- 21m 5s) (11000 55%) 0.0809 0.15\n",
      "26m 0s (- 20m 51s) (11100 55%) 0.1559 0.25\n",
      "26m 14s (- 20m 36s) (11200 56%) 0.1423 0.39\n",
      "26m 28s (- 20m 22s) (11300 56%) 0.1004 0.20\n",
      "26m 42s (- 20m 8s) (11400 56%) 0.1773 0.57\n",
      "26m 56s (- 19m 54s) (11500 57%) 0.1280 0.39\n",
      "27m 10s (- 19m 40s) (11600 57%) 0.2116 0.42\n",
      "27m 24s (- 19m 26s) (11700 58%) 0.2692 0.62\n",
      "27m 38s (- 19m 12s) (11800 59%) 0.2012 0.37\n",
      "27m 51s (- 18m 57s) (11900 59%) 0.0696 0.17\n",
      "28m 4s (- 18m 43s) (12000 60%) 0.0526 0.07\n",
      "28m 18s (- 18m 28s) (12100 60%) 0.1937 0.58\n",
      "28m 32s (- 18m 14s) (12200 61%) 0.1446 0.38\n",
      "28m 45s (- 18m 0s) (12300 61%) 0.2867 0.83\n",
      "28m 58s (- 17m 45s) (12400 62%) 0.0649 0.08\n",
      "29m 14s (- 17m 32s) (12500 62%) 0.1744 0.39\n",
      "29m 27s (- 17m 18s) (12600 63%) 0.1039 0.28\n",
      "29m 41s (- 17m 3s) (12700 63%) 0.1483 0.57\n",
      "29m 55s (- 16m 50s) (12800 64%) 0.0711 0.14\n",
      "30m 9s (- 16m 35s) (12900 64%) 0.1075 0.24\n",
      "30m 23s (- 16m 21s) (13000 65%) 0.0583 0.15\n",
      "30m 36s (- 16m 7s) (13100 65%) 0.1874 0.39\n",
      "30m 50s (- 15m 53s) (13200 66%) 0.2243 0.57\n",
      "31m 5s (- 15m 39s) (13300 66%) 0.1479 0.22\n",
      "31m 19s (- 15m 25s) (13400 67%) 0.2025 0.67\n",
      "31m 33s (- 15m 11s) (13500 67%) 0.1060 0.19\n",
      "31m 47s (- 14m 57s) (13600 68%) 0.0481 0.08\n",
      "32m 3s (- 14m 44s) (13700 68%) 0.1383 0.30\n",
      "32m 16s (- 14m 30s) (13800 69%) 0.3272 0.91\n",
      "32m 31s (- 14m 16s) (13900 69%) 0.1839 0.54\n",
      "32m 46s (- 14m 2s) (14000 70%) 0.1410 0.31\n",
      "33m 0s (- 13m 48s) (14100 70%) 0.1382 0.39\n",
      "33m 13s (- 13m 34s) (14200 71%) 0.1508 0.31\n",
      "33m 27s (- 13m 20s) (14300 71%) 0.1721 0.54\n",
      "33m 42s (- 13m 6s) (14400 72%) 0.3210 0.69\n",
      "33m 57s (- 12m 52s) (14500 72%) 0.1167 0.31\n",
      "34m 10s (- 12m 38s) (14600 73%) 0.0601 0.16\n",
      "34m 24s (- 12m 24s) (14700 73%) 0.1014 0.33\n",
      "34m 37s (- 12m 10s) (14800 74%) 0.1685 0.56\n",
      "34m 52s (- 11m 56s) (14900 74%) 0.1080 0.38\n",
      "35m 5s (- 11m 41s) (15000 75%) 0.1699 0.47\n",
      "35m 19s (- 11m 27s) (15100 75%) 0.2015 0.57\n",
      "35m 33s (- 11m 13s) (15200 76%) 0.1174 0.35\n",
      "35m 46s (- 10m 59s) (15300 76%) 0.1287 0.39\n",
      "36m 0s (- 10m 45s) (15400 77%) 0.0944 0.27\n",
      "36m 13s (- 10m 31s) (15500 77%) 0.0627 0.08\n",
      "36m 27s (- 10m 16s) (15600 78%) 0.1505 0.37\n",
      "36m 42s (- 10m 3s) (15700 78%) 0.1870 0.59\n",
      "36m 56s (- 9m 49s) (15800 79%) 0.0956 0.15\n",
      "37m 10s (- 9m 35s) (15900 79%) 0.0917 0.27\n",
      "37m 23s (- 9m 20s) (16000 80%) 0.2573 0.66\n",
      "37m 37s (- 9m 6s) (16100 80%) 0.1139 0.39\n",
      "37m 50s (- 8m 52s) (16200 81%) 0.1342 0.30\n",
      "38m 4s (- 8m 38s) (16300 81%) 0.0606 0.12\n",
      "38m 17s (- 8m 24s) (16400 82%) 0.1976 0.33\n",
      "38m 30s (- 8m 10s) (16500 82%) 0.2021 0.50\n",
      "38m 45s (- 7m 56s) (16600 83%) 0.2093 0.44\n",
      "39m 0s (- 7m 42s) (16700 83%) 0.0900 0.17\n",
      "39m 15s (- 7m 28s) (16800 84%) 0.3380 1.22\n",
      "39m 29s (- 7m 14s) (16900 84%) 0.1020 0.22\n",
      "39m 43s (- 7m 0s) (17000 85%) 0.1161 0.22\n",
      "39m 57s (- 6m 46s) (17100 85%) 0.3371 0.91\n",
      "40m 10s (- 6m 32s) (17200 86%) 0.1905 0.47\n",
      "40m 23s (- 6m 18s) (17300 86%) 0.0588 0.12\n",
      "40m 37s (- 6m 4s) (17400 87%) 0.0476 0.05\n",
      "40m 49s (- 5m 49s) (17500 87%) 0.0649 0.30\n",
      "41m 3s (- 5m 35s) (17600 88%) 0.0626 0.13\n",
      "41m 18s (- 5m 22s) (17700 88%) 0.1376 0.22\n",
      "41m 31s (- 5m 7s) (17800 89%) 0.1366 0.34\n",
      "41m 46s (- 4m 54s) (17900 89%) 0.0819 0.30\n",
      "41m 58s (- 4m 39s) (18000 90%) 0.0581 0.07\n",
      "42m 13s (- 4m 25s) (18100 90%) 0.1927 0.53\n",
      "42m 25s (- 4m 11s) (18200 91%) 0.0991 0.12\n",
      "42m 40s (- 3m 57s) (18300 91%) 0.1359 0.23\n",
      "42m 53s (- 3m 43s) (18400 92%) 0.0851 0.18\n",
      "43m 7s (- 3m 29s) (18500 92%) 0.1438 0.47\n",
      "43m 21s (- 3m 15s) (18600 93%) 0.1623 0.61\n",
      "43m 35s (- 3m 1s) (18700 93%) 0.1751 0.39\n",
      "43m 49s (- 2m 47s) (18800 94%) 0.1525 0.46\n",
      "44m 4s (- 2m 33s) (18900 94%) 0.0617 0.13\n",
      "44m 18s (- 2m 19s) (19000 95%) 0.1489 0.33\n",
      "44m 31s (- 2m 5s) (19100 95%) 0.1405 0.38\n",
      "44m 46s (- 1m 51s) (19200 96%) 0.1585 0.31\n",
      "45m 1s (- 1m 37s) (19300 96%) 0.2632 0.52\n",
      "45m 14s (- 1m 23s) (19400 97%) 0.0991 0.13\n",
      "45m 28s (- 1m 9s) (19500 97%) 0.1425 0.27\n",
      "45m 41s (- 0m 55s) (19600 98%) 0.2316 0.63\n",
      "45m 54s (- 0m 41s) (19700 98%) 0.1348 0.45\n",
      "46m 8s (- 0m 27s) (19800 99%) 0.2250 0.82\n",
      "46m 22s (- 0m 13s) (19900 99%) 0.1423 0.33\n",
      "46m 36s (- 0m 0s) (20000 100%) 0.0765 0.19\n"
     ]
    }
   ],
   "source": [
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 10000, learning_rate=0.001, dic = dialoguesWithErrors)\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 6s (- 48m 53s) (100 2%)\n",
      "2m 18s (- 49m 31s) (200 4%)\n",
      "3m 33s (- 49m 44s) (300 6%)\n",
      "4m 39s (- 47m 46s) (400 8%)\n",
      "5m 48s (- 46m 30s) (500 11%)\n",
      "6m 58s (- 45m 20s) (600 13%)\n",
      "8m 13s (- 44m 37s) (700 15%)\n",
      "9m 26s (- 43m 37s) (800 17%)\n",
      "10m 39s (- 42m 37s) (900 20%)\n",
      "12m 0s (- 42m 2s) (1000 22%)\n",
      "13m 11s (- 40m 45s) (1100 24%)\n",
      "14m 19s (- 39m 23s) (1200 26%)\n",
      "15m 27s (- 38m 3s) (1300 28%)\n",
      "16m 31s (- 36m 35s) (1400 31%)\n",
      "17m 39s (- 35m 19s) (1500 33%)\n",
      "18m 44s (- 33m 58s) (1600 35%)\n",
      "19m 53s (- 32m 45s) (1700 37%)\n",
      "21m 3s (- 31m 34s) (1800 40%)\n",
      "22m 13s (- 30m 24s) (1900 42%)\n",
      "23m 24s (- 29m 15s) (2000 44%)\n",
      "24m 36s (- 28m 7s) (2100 46%)\n",
      "25m 44s (- 26m 54s) (2200 48%)\n",
      "26m 57s (- 25m 46s) (2300 51%)\n",
      "28m 5s (- 24m 34s) (2400 53%)\n",
      "29m 21s (- 23m 28s) (2500 55%)\n",
      "30m 31s (- 22m 18s) (2600 57%)\n",
      "31m 39s (- 21m 6s) (2700 60%)\n",
      "32m 49s (- 19m 55s) (2800 62%)\n",
      "33m 55s (- 18m 42s) (2900 64%)\n",
      "35m 3s (- 17m 31s) (3000 66%)\n",
      "36m 19s (- 16m 24s) (3100 68%)\n",
      "37m 31s (- 15m 14s) (3200 71%)\n",
      "38m 41s (- 14m 4s) (3300 73%)\n",
      "39m 52s (- 12m 53s) (3400 75%)\n",
      "40m 55s (- 11m 41s) (3500 77%)\n",
      "42m 9s (- 10m 32s) (3600 80%)\n",
      "43m 19s (- 9m 21s) (3700 82%)\n",
      "44m 27s (- 8m 11s) (3800 84%)\n",
      "45m 35s (- 7m 0s) (3900 86%)\n",
      "46m 47s (- 5m 50s) (4000 88%)\n",
      "47m 53s (- 4m 40s) (4100 91%)\n",
      "49m 7s (- 3m 30s) (4200 93%)\n",
      "50m 23s (- 2m 20s) (4300 95%)\n",
      "51m 38s (- 1m 10s) (4400 97%)\n",
      "52m 46s (- 0m 0s) (4500 100%)\n",
      "1664\n"
     ]
    }
   ],
   "source": [
    "#1345 \\ 1664\n",
    "chatbot.eval()\n",
    "dialoguesWithErrors = trainer.DialoguesWithErrors(chatbot, dialogues_Master_var)\n",
    "print(len(dialoguesWithErrors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 17s (- 57m 16s) (100 0%) 0.7168 2.55\n",
      "0m 34s (- 56m 53s) (200 1%) 0.5305 2.59\n",
      "0m 51s (- 56m 22s) (300 1%) 0.6161 2.95\n",
      "1m 8s (- 55m 49s) (400 2%) 0.7515 2.20\n",
      "1m 25s (- 55m 41s) (500 2%) 0.6215 2.15\n",
      "1m 43s (- 55m 47s) (600 3%) 0.6478 2.17\n",
      "2m 1s (- 55m 38s) (700 3%) 0.4012 1.69\n",
      "2m 18s (- 55m 25s) (800 4%) 0.3011 1.23\n",
      "2m 35s (- 55m 5s) (900 4%) 0.5369 2.06\n",
      "2m 53s (- 54m 49s) (1000 5%) 0.5977 1.94\n",
      "3m 9s (- 54m 20s) (1100 5%) 0.5424 1.94\n",
      "3m 27s (- 54m 6s) (1200 6%) 0.6544 2.06\n",
      "3m 45s (- 53m 59s) (1300 6%) 0.4910 2.07\n",
      "4m 2s (- 53m 41s) (1400 7%) 0.4817 1.99\n",
      "4m 19s (- 53m 21s) (1500 7%) 0.6436 1.97\n",
      "4m 37s (- 53m 9s) (1600 8%) 0.6551 2.55\n",
      "4m 53s (- 52m 44s) (1700 8%) 0.5664 1.62\n",
      "5m 12s (- 52m 43s) (1800 9%) 0.4834 1.61\n",
      "5m 30s (- 52m 28s) (1900 9%) 0.4311 1.55\n",
      "5m 49s (- 52m 24s) (2000 10%) 0.5377 1.82\n",
      "6m 6s (- 52m 6s) (2100 10%) 0.2947 1.25\n",
      "6m 24s (- 51m 52s) (2200 11%) 0.5190 1.66\n",
      "6m 42s (- 51m 33s) (2300 11%) 0.3592 1.31\n",
      "6m 59s (- 51m 16s) (2400 12%) 0.3297 1.32\n",
      "7m 16s (- 50m 57s) (2500 12%) 0.3387 0.96\n",
      "7m 33s (- 50m 36s) (2600 13%) 0.3896 1.26\n",
      "7m 50s (- 50m 14s) (2700 13%) 0.4101 1.71\n",
      "8m 8s (- 50m 2s) (2800 14%) 0.5481 2.16\n",
      "8m 26s (- 49m 47s) (2900 14%) 0.3376 1.34\n",
      "8m 44s (- 49m 29s) (3000 15%) 0.3357 0.89\n",
      "9m 1s (- 49m 10s) (3100 15%) 0.4069 1.61\n",
      "9m 18s (- 48m 54s) (3200 16%) 0.6486 1.95\n",
      "9m 36s (- 48m 38s) (3300 16%) 0.4031 1.13\n",
      "9m 54s (- 48m 20s) (3400 17%) 0.3399 1.35\n",
      "10m 11s (- 48m 4s) (3500 17%) 0.3295 1.38\n",
      "10m 29s (- 47m 46s) (3600 18%) 0.3111 1.16\n",
      "10m 47s (- 47m 30s) (3700 18%) 0.4021 1.28\n",
      "11m 3s (- 47m 10s) (3800 19%) 0.3890 1.63\n",
      "11m 22s (- 46m 56s) (3900 19%) 0.4984 1.91\n",
      "11m 39s (- 46m 37s) (4000 20%) 0.4851 1.85\n",
      "11m 58s (- 46m 27s) (4100 20%) 0.4854 1.53\n",
      "12m 16s (- 46m 8s) (4200 21%) 0.5375 1.49\n",
      "12m 33s (- 45m 49s) (4300 21%) 0.3492 1.36\n",
      "12m 50s (- 45m 32s) (4400 22%) 0.3919 1.35\n",
      "13m 7s (- 45m 13s) (4500 22%) 0.6570 2.34\n",
      "13m 26s (- 45m 0s) (4600 23%) 0.3771 1.45\n",
      "13m 44s (- 44m 43s) (4700 23%) 0.3604 1.50\n",
      "14m 2s (- 44m 27s) (4800 24%) 0.3048 0.86\n",
      "14m 19s (- 44m 9s) (4900 24%) 0.3302 1.79\n",
      "14m 37s (- 43m 51s) (5000 25%) 0.4727 2.05\n",
      "14m 54s (- 43m 33s) (5100 25%) 0.3635 1.31\n",
      "15m 11s (- 43m 15s) (5200 26%) 0.3929 1.17\n",
      "15m 30s (- 43m 1s) (5300 26%) 0.3444 1.14\n",
      "15m 51s (- 42m 51s) (5400 27%) 0.2977 1.19\n",
      "16m 9s (- 42m 36s) (5500 27%) 0.3087 1.01\n",
      "16m 26s (- 42m 16s) (5600 28%) 0.5878 1.97\n",
      "16m 44s (- 41m 59s) (5700 28%) 0.3544 1.31\n",
      "17m 2s (- 41m 44s) (5800 28%) 0.4099 1.74\n",
      "17m 20s (- 41m 25s) (5900 29%) 0.3141 1.41\n",
      "17m 37s (- 41m 8s) (6000 30%) 0.3221 1.12\n",
      "17m 54s (- 40m 49s) (6100 30%) 0.4178 1.27\n",
      "18m 12s (- 40m 31s) (6200 31%) 0.3575 1.18\n",
      "18m 30s (- 40m 14s) (6300 31%) 0.3706 1.33\n",
      "18m 47s (- 39m 56s) (6400 32%) 0.4581 1.43\n",
      "19m 5s (- 39m 38s) (6500 32%) 0.3461 1.02\n",
      "19m 23s (- 39m 21s) (6600 33%) 0.2939 1.50\n",
      "19m 40s (- 39m 3s) (6700 33%) 0.2973 0.99\n",
      "19m 57s (- 38m 44s) (6800 34%) 0.4038 1.47\n",
      "20m 14s (- 38m 26s) (6900 34%) 0.3870 1.29\n",
      "20m 31s (- 38m 7s) (7000 35%) 0.4365 1.61\n",
      "20m 49s (- 37m 49s) (7100 35%) 0.5886 1.89\n",
      "21m 5s (- 37m 30s) (7200 36%) 0.4070 1.43\n",
      "21m 23s (- 37m 13s) (7300 36%) 0.3584 1.28\n",
      "21m 41s (- 36m 55s) (7400 37%) 0.4039 1.55\n",
      "21m 59s (- 36m 38s) (7500 37%) 0.3458 0.95\n",
      "22m 16s (- 36m 20s) (7600 38%) 0.3317 0.97\n",
      "22m 33s (- 36m 2s) (7700 38%) 0.4497 1.70\n",
      "22m 51s (- 35m 45s) (7800 39%) 0.3470 0.98\n",
      "23m 9s (- 35m 28s) (7900 39%) 0.2784 0.84\n",
      "23m 26s (- 35m 9s) (8000 40%) 0.4908 1.68\n",
      "23m 44s (- 34m 52s) (8100 40%) 0.3225 1.15\n",
      "24m 1s (- 34m 34s) (8200 41%) 0.3330 1.23\n",
      "24m 18s (- 34m 16s) (8300 41%) 0.2782 0.83\n",
      "24m 35s (- 33m 57s) (8400 42%) 0.3114 1.40\n",
      "24m 52s (- 33m 39s) (8500 42%) 0.4451 1.71\n",
      "25m 10s (- 33m 22s) (8600 43%) 0.1296 0.37\n",
      "25m 28s (- 33m 5s) (8700 43%) 0.2115 0.59\n",
      "25m 45s (- 32m 47s) (8800 44%) 0.3551 1.49\n",
      "26m 3s (- 32m 29s) (8900 44%) 0.3720 1.26\n",
      "26m 21s (- 32m 12s) (9000 45%) 0.2162 0.82\n",
      "26m 38s (- 31m 54s) (9100 45%) 0.4135 1.53\n",
      "26m 56s (- 31m 37s) (9200 46%) 0.3274 1.29\n",
      "27m 15s (- 31m 21s) (9300 46%) 0.2595 1.15\n",
      "27m 32s (- 31m 3s) (9400 47%) 0.3981 1.49\n",
      "27m 50s (- 30m 45s) (9500 47%) 0.3031 0.93\n",
      "28m 8s (- 30m 28s) (9600 48%) 0.2782 1.07\n",
      "28m 26s (- 30m 11s) (9700 48%) 0.1923 0.46\n",
      "28m 42s (- 29m 52s) (9800 49%) 0.3834 1.14\n",
      "28m 59s (- 29m 34s) (9900 49%) 0.3661 1.15\n",
      "29m 16s (- 29m 16s) (10000 50%) 0.3091 1.12\n",
      "29m 34s (- 28m 59s) (10100 50%) 0.1570 0.43\n",
      "29m 51s (- 28m 41s) (10200 51%) 0.2481 0.91\n",
      "30m 8s (- 28m 23s) (10300 51%) 0.1824 0.57\n",
      "30m 27s (- 28m 6s) (10400 52%) 0.2032 0.84\n",
      "30m 44s (- 27m 49s) (10500 52%) 0.2257 1.03\n",
      "31m 2s (- 27m 31s) (10600 53%) 0.2806 0.95\n",
      "31m 20s (- 27m 14s) (10700 53%) 0.2748 1.12\n",
      "31m 37s (- 26m 56s) (10800 54%) 0.1669 0.61\n",
      "31m 54s (- 26m 38s) (10900 54%) 0.3771 1.38\n",
      "32m 12s (- 26m 21s) (11000 55%) 0.2180 0.94\n",
      "32m 29s (- 26m 2s) (11100 55%) 0.2863 1.15\n",
      "32m 47s (- 25m 45s) (11200 56%) 0.2948 1.03\n",
      "33m 4s (- 25m 27s) (11300 56%) 0.2446 1.11\n",
      "33m 21s (- 25m 9s) (11400 56%) 0.2227 1.11\n",
      "33m 39s (- 24m 52s) (11500 57%) 0.2346 1.08\n",
      "33m 56s (- 24m 34s) (11600 57%) 0.2971 0.89\n",
      "34m 14s (- 24m 17s) (11700 58%) 0.3494 1.66\n",
      "34m 31s (- 23m 59s) (11800 59%) 0.2230 0.85\n",
      "34m 49s (- 23m 42s) (11900 59%) 0.2508 0.70\n",
      "35m 6s (- 23m 24s) (12000 60%) 0.1972 0.83\n",
      "35m 23s (- 23m 6s) (12100 60%) 0.3133 0.88\n",
      "35m 40s (- 22m 48s) (12200 61%) 0.2706 0.86\n",
      "35m 56s (- 22m 30s) (12300 61%) 0.3546 1.14\n",
      "36m 13s (- 22m 12s) (12400 62%) 0.1946 0.54\n",
      "36m 30s (- 21m 54s) (12500 62%) 0.3182 0.94\n",
      "36m 47s (- 21m 36s) (12600 63%) 0.4088 1.01\n",
      "37m 4s (- 21m 18s) (12700 63%) 0.2277 0.77\n",
      "37m 21s (- 21m 0s) (12800 64%) 0.2170 1.01\n",
      "37m 39s (- 20m 43s) (12900 64%) 0.3944 1.49\n",
      "37m 56s (- 20m 25s) (13000 65%) 0.3475 1.11\n",
      "38m 14s (- 20m 8s) (13100 65%) 0.1324 0.55\n",
      "38m 32s (- 19m 51s) (13200 66%) 0.1336 0.53\n",
      "38m 49s (- 19m 33s) (13300 66%) 0.2887 1.22\n",
      "39m 9s (- 19m 17s) (13400 67%) 0.2361 0.84\n",
      "39m 27s (- 18m 59s) (13500 67%) 0.4020 1.58\n",
      "39m 44s (- 18m 42s) (13600 68%) 0.2723 0.95\n",
      "40m 3s (- 18m 25s) (13700 68%) 0.3639 1.19\n",
      "40m 21s (- 18m 7s) (13800 69%) 0.2014 0.81\n",
      "40m 39s (- 17m 50s) (13900 69%) 0.2195 0.62\n",
      "40m 57s (- 17m 33s) (14000 70%) 0.2526 1.13\n",
      "41m 14s (- 17m 15s) (14100 70%) 0.3131 1.40\n",
      "41m 31s (- 16m 57s) (14200 71%) 0.3895 1.80\n",
      "41m 49s (- 16m 40s) (14300 71%) 0.3526 1.29\n",
      "42m 6s (- 16m 22s) (14400 72%) 0.3149 1.00\n",
      "42m 23s (- 16m 4s) (14500 72%) 0.2022 0.93\n",
      "42m 40s (- 15m 46s) (14600 73%) 0.3032 1.04\n",
      "42m 57s (- 15m 29s) (14700 73%) 0.3240 1.24\n",
      "43m 14s (- 15m 11s) (14800 74%) 0.2042 0.46\n",
      "43m 32s (- 14m 54s) (14900 74%) 0.1799 0.53\n",
      "43m 50s (- 14m 36s) (15000 75%) 0.1904 0.50\n",
      "44m 7s (- 14m 19s) (15100 75%) 0.3007 1.38\n",
      "44m 25s (- 14m 1s) (15200 76%) 0.2137 0.87\n",
      "44m 42s (- 13m 44s) (15300 76%) 0.2515 0.95\n",
      "45m 0s (- 13m 26s) (15400 77%) 0.2874 0.79\n",
      "45m 17s (- 13m 8s) (15500 77%) 0.3354 1.31\n",
      "45m 35s (- 12m 51s) (15600 78%) 0.2015 0.86\n",
      "45m 52s (- 12m 33s) (15700 78%) 0.2299 0.81\n",
      "46m 10s (- 12m 16s) (15800 79%) 0.3236 0.90\n",
      "46m 28s (- 11m 59s) (15900 79%) 0.2208 0.98\n",
      "46m 45s (- 11m 41s) (16000 80%) 0.4075 1.50\n",
      "47m 3s (- 11m 23s) (16100 80%) 0.3250 1.10\n",
      "47m 20s (- 11m 6s) (16200 81%) 0.2834 0.74\n",
      "47m 38s (- 10m 48s) (16300 81%) 0.3270 1.31\n",
      "47m 55s (- 10m 31s) (16400 82%) 0.3809 1.57\n",
      "48m 12s (- 10m 13s) (16500 82%) 0.1287 0.63\n",
      "48m 30s (- 9m 56s) (16600 83%) 0.1968 0.70\n",
      "48m 47s (- 9m 38s) (16700 83%) 0.1605 0.61\n",
      "49m 5s (- 9m 21s) (16800 84%) 0.2004 0.82\n",
      "49m 23s (- 9m 3s) (16900 84%) 0.2636 0.84\n",
      "49m 40s (- 8m 46s) (17000 85%) 0.3282 1.05\n",
      "49m 57s (- 8m 28s) (17100 85%) 0.1679 0.82\n",
      "50m 15s (- 8m 10s) (17200 86%) 0.1883 0.71\n",
      "50m 33s (- 7m 53s) (17300 86%) 0.2205 0.70\n",
      "50m 50s (- 7m 35s) (17400 87%) 0.2479 1.06\n",
      "51m 7s (- 7m 18s) (17500 87%) 0.2903 1.22\n",
      "51m 25s (- 7m 0s) (17600 88%) 0.2813 0.77\n",
      "51m 42s (- 6m 43s) (17700 88%) 0.1574 0.81\n",
      "52m 0s (- 6m 25s) (17800 89%) 0.0976 0.38\n",
      "52m 17s (- 6m 8s) (17900 89%) 0.3270 1.37\n",
      "52m 35s (- 5m 50s) (18000 90%) 0.3025 1.18\n",
      "52m 52s (- 5m 33s) (18100 90%) 0.1826 0.80\n",
      "53m 10s (- 5m 15s) (18200 91%) 0.2275 1.08\n",
      "53m 28s (- 4m 58s) (18300 91%) 0.2339 0.85\n",
      "53m 45s (- 4m 40s) (18400 92%) 0.3752 1.35\n",
      "54m 3s (- 4m 23s) (18500 92%) 0.1965 0.81\n",
      "54m 21s (- 4m 5s) (18600 93%) 0.2056 0.56\n",
      "54m 38s (- 3m 47s) (18700 93%) 0.2440 1.09\n",
      "54m 56s (- 3m 30s) (18800 94%) 0.1772 0.77\n",
      "55m 14s (- 3m 12s) (18900 94%) 0.2362 0.78\n",
      "55m 32s (- 2m 55s) (19000 95%) 0.1256 0.34\n",
      "55m 49s (- 2m 37s) (19100 95%) 0.2277 0.97\n",
      "56m 7s (- 2m 20s) (19200 96%) 0.2623 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56m 24s (- 2m 2s) (19300 96%) 0.1322 0.35\n",
      "56m 42s (- 1m 45s) (19400 97%) 0.1571 0.49\n",
      "56m 59s (- 1m 27s) (19500 97%) 0.4074 1.14\n",
      "57m 17s (- 1m 10s) (19600 98%) 0.1533 0.67\n",
      "57m 37s (- 0m 52s) (19700 98%) 0.1726 0.61\n",
      "57m 55s (- 0m 35s) (19800 99%) 0.1678 0.55\n",
      "58m 11s (- 0m 17s) (19900 99%) 0.3822 1.14\n",
      "58m 28s (- 0m 0s) (20000 100%) 0.1687 0.57\n",
      "0m 13s (- 45m 11s) (100 0%) 0.4631 1.02\n",
      "0m 27s (- 45m 16s) (200 1%) 0.2040 0.50\n",
      "0m 41s (- 45m 27s) (300 1%) 0.4174 1.04\n",
      "0m 55s (- 45m 22s) (400 2%) 0.2286 0.78\n",
      "1m 9s (- 45m 4s) (500 2%) 0.2741 0.59\n",
      "1m 23s (- 44m 44s) (600 3%) 0.2838 0.78\n",
      "1m 37s (- 44m 54s) (700 3%) 0.1192 0.43\n",
      "1m 52s (- 45m 0s) (800 4%) 0.0714 0.09\n",
      "2m 4s (- 44m 5s) (900 4%) 0.3108 0.78\n",
      "2m 19s (- 44m 2s) (1000 5%) 0.2208 0.53\n",
      "2m 33s (- 43m 54s) (1100 5%) 0.3385 0.90\n",
      "2m 47s (- 43m 46s) (1200 6%) 0.1846 0.46\n",
      "3m 1s (- 43m 33s) (1300 6%) 0.2423 0.48\n",
      "3m 14s (- 43m 6s) (1400 7%) 0.3059 0.72\n",
      "3m 28s (- 42m 55s) (1500 7%) 0.2834 0.52\n",
      "3m 43s (- 42m 46s) (1600 8%) 0.3927 1.27\n",
      "3m 56s (- 42m 23s) (1700 8%) 0.1668 0.33\n",
      "4m 10s (- 42m 11s) (1800 9%) 0.1831 0.65\n",
      "4m 25s (- 42m 4s) (1900 9%) 0.1881 0.39\n",
      "4m 39s (- 41m 53s) (2000 10%) 0.1890 0.56\n",
      "4m 52s (- 41m 35s) (2100 10%) 0.2343 0.44\n",
      "5m 6s (- 41m 22s) (2200 11%) 0.3250 0.73\n",
      "5m 22s (- 41m 20s) (2300 11%) 0.2166 0.54\n",
      "5m 35s (- 40m 59s) (2400 12%) 0.0894 0.24\n",
      "5m 50s (- 40m 52s) (2500 12%) 0.3399 1.07\n",
      "6m 5s (- 40m 45s) (2600 13%) 0.2057 0.47\n",
      "6m 19s (- 40m 34s) (2700 13%) 0.1366 0.37\n",
      "6m 35s (- 40m 27s) (2800 14%) 0.3445 0.85\n",
      "6m 49s (- 40m 12s) (2900 14%) 0.2952 0.56\n",
      "7m 2s (- 39m 54s) (3000 15%) 0.3311 0.93\n",
      "7m 16s (- 39m 38s) (3100 15%) 0.2432 0.58\n",
      "7m 31s (- 39m 29s) (3200 16%) 0.1743 0.50\n",
      "7m 46s (- 39m 18s) (3300 16%) 0.2000 0.43\n",
      "8m 1s (- 39m 8s) (3400 17%) 0.1113 0.26\n",
      "8m 13s (- 38m 48s) (3500 17%) 0.4158 0.82\n",
      "8m 29s (- 38m 40s) (3600 18%) 0.1432 0.35\n",
      "8m 43s (- 38m 25s) (3700 18%) 0.1319 0.31\n",
      "8m 58s (- 38m 14s) (3800 19%) 0.2230 0.62\n",
      "9m 12s (- 38m 0s) (3900 19%) 0.1907 0.57\n",
      "9m 26s (- 37m 46s) (4000 20%) 0.3297 0.68\n",
      "9m 40s (- 37m 30s) (4100 20%) 0.0987 0.20\n",
      "9m 54s (- 37m 15s) (4200 21%) 0.2605 0.68\n",
      "10m 9s (- 37m 4s) (4300 21%) 0.1626 0.50\n",
      "10m 23s (- 36m 52s) (4400 22%) 0.3096 0.80\n",
      "10m 38s (- 36m 40s) (4500 22%) 0.0838 0.25\n",
      "10m 53s (- 36m 29s) (4600 23%) 0.2903 0.82\n",
      "11m 10s (- 36m 21s) (4700 23%) 0.1297 0.29\n",
      "11m 25s (- 36m 9s) (4800 24%) 0.1957 0.47\n",
      "11m 43s (- 36m 7s) (4900 24%) 0.1948 0.49\n",
      "11m 58s (- 35m 55s) (5000 25%) 0.1949 0.46\n",
      "12m 11s (- 35m 38s) (5100 25%) 0.0935 0.21\n",
      "12m 24s (- 35m 19s) (5200 26%) 0.1364 0.40\n",
      "12m 38s (- 35m 4s) (5300 26%) 0.0584 0.10\n",
      "12m 52s (- 34m 48s) (5400 27%) 0.1241 0.35\n",
      "13m 7s (- 34m 34s) (5500 27%) 0.2086 0.64\n",
      "13m 22s (- 34m 23s) (5600 28%) 0.1078 0.49\n",
      "13m 35s (- 34m 5s) (5700 28%) 0.2066 0.53\n",
      "13m 49s (- 33m 50s) (5800 28%) 0.0785 0.15\n",
      "14m 5s (- 33m 40s) (5900 29%) 0.1040 0.27\n",
      "14m 19s (- 33m 26s) (6000 30%) 0.3037 0.65\n",
      "14m 34s (- 33m 13s) (6100 30%) 0.1025 0.29\n",
      "14m 48s (- 32m 57s) (6200 31%) 0.0907 0.31\n",
      "15m 2s (- 32m 43s) (6300 31%) 0.1512 0.25\n",
      "15m 19s (- 32m 33s) (6400 32%) 0.1428 0.28\n",
      "15m 34s (- 32m 20s) (6500 32%) 0.2822 0.58\n",
      "15m 48s (- 32m 5s) (6600 33%) 0.1043 0.20\n",
      "16m 2s (- 31m 50s) (6700 33%) 0.1346 0.57\n",
      "16m 16s (- 31m 34s) (6800 34%) 0.0983 0.24\n",
      "16m 30s (- 31m 20s) (6900 34%) 0.2598 0.68\n",
      "16m 46s (- 31m 8s) (7000 35%) 0.1429 0.57\n",
      "17m 0s (- 30m 54s) (7100 35%) 0.1332 0.27\n",
      "17m 14s (- 30m 39s) (7200 36%) 0.0744 0.21\n",
      "17m 28s (- 30m 24s) (7300 36%) 0.1486 0.42\n",
      "17m 43s (- 30m 10s) (7400 37%) 0.1954 0.52\n",
      "17m 56s (- 29m 54s) (7500 37%) 0.1940 0.57\n",
      "18m 10s (- 29m 38s) (7600 38%) 0.0979 0.26\n",
      "18m 24s (- 29m 23s) (7700 38%) 0.2916 0.90\n",
      "18m 38s (- 29m 9s) (7800 39%) 0.0815 0.14\n",
      "18m 51s (- 28m 53s) (7900 39%) 0.1076 0.22\n",
      "19m 5s (- 28m 38s) (8000 40%) 0.1575 0.33\n",
      "19m 19s (- 28m 22s) (8100 40%) 0.1732 0.53\n",
      "19m 32s (- 28m 7s) (8200 41%) 0.0628 0.16\n",
      "19m 47s (- 27m 53s) (8300 41%) 0.0738 0.17\n",
      "20m 1s (- 27m 38s) (8400 42%) 0.1155 0.31\n",
      "20m 15s (- 27m 24s) (8500 42%) 0.0386 0.04\n",
      "20m 31s (- 27m 12s) (8600 43%) 0.1807 0.37\n",
      "20m 46s (- 26m 59s) (8700 43%) 0.2525 0.46\n",
      "21m 2s (- 26m 46s) (8800 44%) 0.1458 0.33\n",
      "21m 17s (- 26m 33s) (8900 44%) 0.1107 0.20\n",
      "21m 31s (- 26m 18s) (9000 45%) 0.1713 0.37\n",
      "21m 45s (- 26m 3s) (9100 45%) 0.3165 0.76\n",
      "22m 0s (- 25m 50s) (9200 46%) 0.1299 0.29\n",
      "22m 15s (- 25m 36s) (9300 46%) 0.2055 0.38\n",
      "22m 30s (- 25m 23s) (9400 47%) 0.0870 0.17\n",
      "22m 47s (- 25m 11s) (9500 47%) 0.0836 0.21\n",
      "23m 3s (- 24m 59s) (9600 48%) 0.1281 0.20\n",
      "23m 17s (- 24m 44s) (9700 48%) 0.0672 0.15\n",
      "23m 33s (- 24m 31s) (9800 49%) 0.1204 0.25\n",
      "23m 48s (- 24m 17s) (9900 49%) 0.1288 0.33\n",
      "24m 3s (- 24m 3s) (10000 50%) 0.0820 0.35\n",
      "24m 20s (- 23m 52s) (10100 50%) 0.1958 0.64\n",
      "24m 35s (- 23m 37s) (10200 51%) 0.1269 0.30\n",
      "24m 49s (- 23m 22s) (10300 51%) 0.1803 0.54\n",
      "25m 2s (- 23m 7s) (10400 52%) 0.0747 0.17\n",
      "25m 17s (- 22m 53s) (10500 52%) 0.1509 0.38\n",
      "25m 33s (- 22m 39s) (10600 53%) 0.0852 0.14\n",
      "25m 47s (- 22m 24s) (10700 53%) 0.0667 0.12\n",
      "26m 0s (- 22m 9s) (10800 54%) 0.2428 0.67\n",
      "26m 16s (- 21m 56s) (10900 54%) 0.0449 0.05\n",
      "26m 31s (- 21m 41s) (11000 55%) 0.0913 0.21\n",
      "26m 44s (- 21m 26s) (11100 55%) 0.3217 0.89\n",
      "26m 59s (- 21m 12s) (11200 56%) 0.2466 0.76\n",
      "27m 15s (- 20m 59s) (11300 56%) 0.1031 0.24\n",
      "27m 29s (- 20m 44s) (11400 56%) 0.2800 0.57\n",
      "27m 43s (- 20m 29s) (11500 57%) 0.0822 0.23\n",
      "27m 58s (- 20m 15s) (11600 57%) 0.1669 0.30\n",
      "28m 12s (- 20m 0s) (11700 58%) 0.1296 0.28\n",
      "28m 25s (- 19m 45s) (11800 59%) 0.1595 0.31\n",
      "28m 39s (- 19m 30s) (11900 59%) 0.0773 0.24\n",
      "28m 58s (- 19m 18s) (12000 60%) 0.1425 0.40\n",
      "29m 11s (- 19m 3s) (12100 60%) 0.1357 0.39\n",
      "29m 27s (- 18m 49s) (12200 61%) 0.1643 0.46\n",
      "29m 41s (- 18m 34s) (12300 61%) 0.1279 0.22\n",
      "29m 56s (- 18m 20s) (12400 62%) 0.1467 0.39\n",
      "30m 12s (- 18m 7s) (12500 62%) 0.1996 0.30\n",
      "30m 27s (- 17m 53s) (12600 63%) 0.2261 0.44\n",
      "30m 39s (- 17m 37s) (12700 63%) 0.0426 0.06\n",
      "30m 54s (- 17m 23s) (12800 64%) 0.0574 0.10\n",
      "31m 9s (- 17m 9s) (12900 64%) 0.0825 0.22\n",
      "31m 23s (- 16m 53s) (13000 65%) 0.1218 0.23\n",
      "31m 37s (- 16m 39s) (13100 65%) 0.1005 0.16\n",
      "31m 52s (- 16m 25s) (13200 66%) 0.2678 0.74\n",
      "32m 5s (- 16m 10s) (13300 66%) 0.1256 0.41\n",
      "32m 21s (- 15m 56s) (13400 67%) 0.2755 0.57\n",
      "32m 35s (- 15m 41s) (13500 67%) 0.2235 0.53\n",
      "32m 51s (- 15m 27s) (13600 68%) 0.0612 0.12\n",
      "33m 6s (- 15m 13s) (13700 68%) 0.0548 0.08\n",
      "33m 20s (- 14m 58s) (13800 69%) 0.2817 0.73\n",
      "33m 36s (- 14m 45s) (13900 69%) 0.2388 0.57\n",
      "33m 52s (- 14m 31s) (14000 70%) 0.0784 0.19\n",
      "34m 9s (- 14m 17s) (14100 70%) 0.2163 0.41\n",
      "34m 25s (- 14m 3s) (14200 71%) 0.2875 0.57\n",
      "34m 40s (- 13m 49s) (14300 71%) 0.1105 0.36\n",
      "34m 57s (- 13m 35s) (14400 72%) 0.1294 0.29\n",
      "35m 12s (- 13m 21s) (14500 72%) 0.1009 0.43\n",
      "35m 26s (- 13m 6s) (14600 73%) 0.1793 0.44\n",
      "35m 41s (- 12m 51s) (14700 73%) 0.1702 0.46\n",
      "35m 56s (- 12m 37s) (14800 74%) 0.1555 0.46\n",
      "36m 10s (- 12m 22s) (14900 74%) 0.1679 0.44\n",
      "36m 25s (- 12m 8s) (15000 75%) 0.0955 0.18\n",
      "36m 40s (- 11m 53s) (15100 75%) 0.1138 0.26\n",
      "36m 54s (- 11m 39s) (15200 76%) 0.1740 0.55\n",
      "37m 9s (- 11m 24s) (15300 76%) 0.1905 0.46\n",
      "37m 24s (- 11m 10s) (15400 77%) 0.1900 0.49\n",
      "37m 43s (- 10m 57s) (15500 77%) 0.1493 0.34\n",
      "37m 58s (- 10m 42s) (15600 78%) 0.2125 0.36\n",
      "38m 12s (- 10m 27s) (15700 78%) 0.0685 0.09\n",
      "38m 25s (- 10m 12s) (15800 79%) 0.2484 0.64\n",
      "38m 40s (- 9m 58s) (15900 79%) 0.1118 0.20\n",
      "38m 56s (- 9m 44s) (16000 80%) 0.2417 0.54\n",
      "39m 10s (- 9m 29s) (16100 80%) 0.0634 0.13\n",
      "39m 26s (- 9m 15s) (16200 81%) 0.2453 0.56\n",
      "39m 40s (- 9m 0s) (16300 81%) 0.0768 0.26\n",
      "39m 55s (- 8m 45s) (16400 82%) 0.1012 0.30\n",
      "40m 9s (- 8m 31s) (16500 82%) 0.1576 0.37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8b6228438741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mchatbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchatbot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialogues_Master_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialoguesWithErrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchatbot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialogues_Master_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-0a41f39468e1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, agent, dialogues, n_iters, learning_rate, dic)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;31m#target_answer = variableFromSentence(agent.output_lang, training_dialogue[i][1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mtarget_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dialogue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_diff_mots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartie_dialogue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_answer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;31m# quantité d'erreurs sur la réponse i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-0a41f39468e1>\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(self, agent, dialogue, target_answer, optimizer, learning_rate)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0manswer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn1_attention_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn2_attention_weights\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manswerTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_diff_mots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.001, dic = dialoguesWithErrors)\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.001, dic = dialoguesWithErrors)\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with random forgetting of words in query and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues_Master_var_015 = variableFromAllDialogues(lang_M2DS, dialogues_Master, rand = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 14s (- 23m 27s) (100 1%) 0.1902 0.51\n",
      "0m 27s (- 22m 24s) (200 2%) 0.1866 0.43\n",
      "0m 41s (- 22m 24s) (300 3%) 0.2064 0.64\n",
      "0m 54s (- 21m 43s) (400 4%) 0.0486 0.10\n",
      "1m 7s (- 21m 23s) (500 5%) 0.1039 0.38\n",
      "1m 22s (- 21m 24s) (600 6%) 0.1893 0.40\n",
      "1m 36s (- 21m 28s) (700 7%) 0.1916 0.40\n",
      "1m 51s (- 21m 23s) (800 8%) 0.1983 0.64\n",
      "2m 5s (- 21m 13s) (900 9%) 0.0592 0.17\n",
      "2m 20s (- 21m 4s) (1000 10%) 0.0624 0.09\n",
      "2m 35s (- 20m 54s) (1100 11%) 0.1474 0.50\n",
      "2m 49s (- 20m 44s) (1200 12%) 0.0807 0.19\n",
      "3m 3s (- 20m 27s) (1300 13%) 0.1076 0.23\n",
      "3m 18s (- 20m 21s) (1400 14%) 0.1343 0.33\n",
      "3m 33s (- 20m 9s) (1500 15%) 0.1981 0.48\n",
      "3m 48s (- 19m 59s) (1600 16%) 0.0699 0.15\n",
      "4m 3s (- 19m 47s) (1700 17%) 0.1758 0.47\n",
      "4m 17s (- 19m 34s) (1800 18%) 0.1311 0.29\n",
      "4m 31s (- 19m 16s) (1900 19%) 0.1465 0.44\n",
      "4m 45s (- 19m 0s) (2000 20%) 0.1014 0.28\n",
      "4m 59s (- 18m 47s) (2100 21%) 0.0590 0.09\n",
      "5m 13s (- 18m 30s) (2200 22%) 0.1035 0.25\n",
      "5m 27s (- 18m 15s) (2300 23%) 0.1101 0.26\n",
      "5m 40s (- 17m 57s) (2400 24%) 0.0884 0.24\n",
      "5m 55s (- 17m 46s) (2500 25%) 0.2452 0.87\n",
      "6m 9s (- 17m 31s) (2600 26%) 0.1299 0.21\n",
      "6m 24s (- 17m 19s) (2700 27%) 0.1182 0.29\n",
      "6m 39s (- 17m 6s) (2800 28%) 0.1771 0.57\n",
      "6m 52s (- 16m 50s) (2900 28%) 0.1243 0.46\n",
      "7m 7s (- 16m 38s) (3000 30%) 0.0619 0.14\n",
      "7m 21s (- 16m 23s) (3100 31%) 0.0895 0.23\n",
      "7m 35s (- 16m 8s) (3200 32%) 0.1709 0.53\n",
      "7m 50s (- 15m 56s) (3300 33%) 0.2319 0.42\n",
      "8m 5s (- 15m 41s) (3400 34%) 0.0913 0.23\n",
      "8m 18s (- 15m 25s) (3500 35%) 0.3035 1.01\n",
      "8m 34s (- 15m 14s) (3600 36%) 0.0657 0.12\n",
      "8m 47s (- 14m 57s) (3700 37%) 0.1143 0.27\n",
      "9m 2s (- 14m 44s) (3800 38%) 0.1752 0.50\n",
      "9m 16s (- 14m 29s) (3900 39%) 0.2876 0.74\n",
      "9m 29s (- 14m 14s) (4000 40%) 0.2675 0.81\n",
      "9m 44s (- 14m 0s) (4100 41%) 0.1166 0.41\n",
      "9m 57s (- 13m 45s) (4200 42%) 0.0492 0.11\n",
      "10m 12s (- 13m 31s) (4300 43%) 0.1723 0.55\n",
      "10m 26s (- 13m 17s) (4400 44%) 0.0993 0.25\n",
      "10m 41s (- 13m 3s) (4500 45%) 0.0730 0.16\n",
      "10m 54s (- 12m 48s) (4600 46%) 0.0393 0.04\n",
      "11m 8s (- 12m 33s) (4700 47%) 0.1913 0.47\n",
      "11m 23s (- 12m 20s) (4800 48%) 0.1303 0.31\n",
      "11m 37s (- 12m 6s) (4900 49%) 0.0843 0.19\n",
      "11m 52s (- 11m 52s) (5000 50%) 0.1568 0.45\n",
      "12m 7s (- 11m 39s) (5100 51%) 0.1044 0.20\n",
      "12m 21s (- 11m 24s) (5200 52%) 0.1325 0.29\n",
      "12m 34s (- 11m 9s) (5300 53%) 0.1306 0.35\n",
      "12m 47s (- 10m 53s) (5400 54%) 0.0636 0.21\n",
      "13m 2s (- 10m 40s) (5500 55%) 0.0549 0.06\n",
      "13m 16s (- 10m 25s) (5600 56%) 0.2917 0.82\n",
      "13m 31s (- 10m 12s) (5700 56%) 0.1864 0.55\n",
      "13m 46s (- 9m 58s) (5800 57%) 0.1573 0.25\n",
      "13m 59s (- 9m 43s) (5900 59%) 0.0521 0.05\n",
      "14m 15s (- 9m 30s) (6000 60%) 0.0900 0.26\n",
      "14m 29s (- 9m 15s) (6100 61%) 0.2104 0.58\n",
      "14m 43s (- 9m 1s) (6200 62%) 0.1044 0.27\n",
      "14m 56s (- 8m 46s) (6300 63%) 0.1058 0.19\n",
      "15m 10s (- 8m 32s) (6400 64%) 0.0410 0.07\n",
      "15m 24s (- 8m 17s) (6500 65%) 0.0819 0.21\n",
      "15m 40s (- 8m 4s) (6600 66%) 0.1416 0.28\n",
      "15m 54s (- 7m 49s) (6700 67%) 0.2048 0.55\n",
      "16m 6s (- 7m 34s) (6800 68%) 0.1045 0.31\n",
      "16m 21s (- 7m 21s) (6900 69%) 0.1618 0.41\n",
      "16m 34s (- 7m 6s) (7000 70%) 0.1353 0.27\n",
      "16m 49s (- 6m 52s) (7100 71%) 0.1015 0.17\n",
      "17m 4s (- 6m 38s) (7200 72%) 0.1802 0.59\n",
      "17m 20s (- 6m 24s) (7300 73%) 0.1186 0.18\n",
      "17m 33s (- 6m 10s) (7400 74%) 0.1061 0.17\n",
      "17m 48s (- 5m 56s) (7500 75%) 0.1629 0.49\n",
      "18m 3s (- 5m 42s) (7600 76%) 0.1188 0.29\n",
      "18m 17s (- 5m 27s) (7700 77%) 0.1957 0.52\n",
      "18m 30s (- 5m 13s) (7800 78%) 0.1882 0.45\n",
      "18m 42s (- 4m 58s) (7900 79%) 0.0574 0.12\n",
      "18m 57s (- 4m 44s) (8000 80%) 0.0697 0.14\n",
      "19m 11s (- 4m 30s) (8100 81%) 0.0876 0.21\n",
      "19m 25s (- 4m 15s) (8200 82%) 0.1319 0.27\n",
      "19m 39s (- 4m 1s) (8300 83%) 0.2237 0.51\n",
      "19m 55s (- 3m 47s) (8400 84%) 0.0897 0.18\n",
      "20m 9s (- 3m 33s) (8500 85%) 0.0844 0.19\n",
      "20m 23s (- 3m 19s) (8600 86%) 0.0400 0.07\n",
      "20m 38s (- 3m 5s) (8700 87%) 0.1350 0.29\n",
      "20m 53s (- 2m 50s) (8800 88%) 0.1140 0.36\n",
      "21m 8s (- 2m 36s) (8900 89%) 0.2386 0.59\n",
      "21m 22s (- 2m 22s) (9000 90%) 0.1528 0.32\n",
      "21m 37s (- 2m 8s) (9100 91%) 0.1950 0.38\n",
      "21m 53s (- 1m 54s) (9200 92%) 0.1040 0.39\n",
      "22m 7s (- 1m 39s) (9300 93%) 0.1567 0.47\n",
      "22m 23s (- 1m 25s) (9400 94%) 0.2145 0.62\n",
      "22m 38s (- 1m 11s) (9500 95%) 0.1563 0.37\n",
      "22m 53s (- 0m 57s) (9600 96%) 0.0480 0.09\n",
      "23m 8s (- 0m 42s) (9700 97%) 0.1421 0.29\n",
      "23m 23s (- 0m 28s) (9800 98%) 0.1394 0.24\n",
      "23m 38s (- 0m 14s) (9900 99%) 0.0880 0.11\n",
      "23m 53s (- 0m 0s) (10000 100%) 0.0682 0.20\n"
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var_015, n_iters = 10000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(chatbot.state_dict(), 'C:\\\\Users\\Jb\\Desktop\\Scripts\\saves\\chatbot.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 test\n",
    "\n",
    "### 6.4.1 Error counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repartition of errors : [22338, 101, 39, 15, 23, 5, 5, 18, 1, 14, 15, 41, 13, 9, 3, 9, 107, 0, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "z = trainer.ErrorCount(chatbot, dialogues_Master_test_var) # erreurs par réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Visualization of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x720 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User :  non\n",
      "target :  pour les etudiants du parcours mathematiques non-inscrits a lyon1 le nombre de places disponibles est de nbreplaces_en_france_mathematiques\n",
      "predic :  pour les etudiants du parcours mathematiques non-inscrits a lyon1 le nombre de places disponibles est de nbreplaces_en_france_mathematiques\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "dialogue = dialogues_Master_var[12][:4]\n",
    "chatbot.showAttention(dialogue)# (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1296 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User :  il faut coder en php ?\n",
      "target :  non aucun tp ne se fera en php\n",
      "predic :  non aucun tp ne se fera en php\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "dialogue = dialogues_Master_test_var[1][:7]\n",
    "chatbot.showAttention(dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Interactive mode\n",
    "\n",
    "write **quit** or **q** or **eoc** (end of conversation) to close conversation interface :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceMotVar(motsVar, raw_sentence):\n",
    "    sentence = []\n",
    "    word_list = raw_sentence.split(' ')\n",
    "    for word in word_list :\n",
    "        if word in motsVar.keys() :\n",
    "            sentence.append(motsVar[word])\n",
    "        else :\n",
    "            sentence.append(word)\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "def InteractiveEvaluation(agent) :\n",
    "    agent.initMemory()\n",
    "    while True :\n",
    "        text = input()\n",
    "        #print('User : {}'.format(text))\n",
    "        if text == 'eoc' or text == 'q' or text == 'quit' : \n",
    "            break\n",
    "        reponse, attn1_weights, attn2_weights = chatbot(text)\n",
    "        reponse = ReplaceMotVar(motsVar, reponse)\n",
    "        print('Bot  : {}'.format(reponse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut ma poule\n",
      "Bot  : bonjour\n",
      "comment vas tu ?\n",
      "Bot  : je vais bien merci et vous ?\n",
      "oui ca va bien\n",
      "Bot  : j en suis ravi en quoi puis-je vous aider ?\n",
      "je voudrais savoir a quel point tu sais parler\n",
      "Bot  : excellent que souhaiteriez-vous savoir ?\n",
      "c'est au top ta réponse\n",
      "Bot  : merci\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "InteractiveEvaluation(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut\n",
      "Bot  : bonjour\n",
      "tu vas bien ?\n",
      "Bot  : je m appelle Cadoc\n",
      "tres bien cadoc\n",
      "Bot  : je suis la pour vous aider ?\n",
      "c'est une question ?\n",
      "Bot  : je suis la pour vous aider\n",
      "haaa merci\n",
      "Bot  : je vous en prie\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "chatbot.eval()\n",
    "InteractiveEvaluation(chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Training with Attention decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 12s (- 40m 55s) (100 0%) 2.9270 11.84\n",
      "0m 24s (- 41m 7s) (200 1%) 2.3286 11.01\n",
      "0m 37s (- 41m 2s) (300 1%) 2.4096 11.02\n",
      "0m 51s (- 41m 42s) (400 2%) 2.2785 10.38\n",
      "1m 3s (- 41m 33s) (500 2%) 2.4305 11.40\n",
      "1m 16s (- 41m 28s) (600 3%) 2.7747 13.08\n",
      "1m 30s (- 41m 39s) (700 3%) 2.6980 9.67\n",
      "1m 44s (- 41m 38s) (800 4%) 2.5713 10.21\n",
      "1m 57s (- 41m 37s) (900 4%) 2.6310 10.58\n",
      "2m 12s (- 41m 56s) (1000 5%) 2.7061 10.13\n",
      "2m 30s (- 43m 1s) (1100 5%) 2.5968 10.97\n",
      "2m 44s (- 43m 3s) (1200 6%) 2.8367 10.14\n",
      "2m 58s (- 42m 43s) (1300 6%) 3.0008 9.93\n",
      "3m 12s (- 42m 43s) (1400 7%) 2.8631 10.41\n",
      "3m 26s (- 42m 29s) (1500 7%) 2.8545 9.91\n",
      "3m 40s (- 42m 11s) (1600 8%) 2.6098 10.52\n",
      "3m 53s (- 41m 57s) (1700 8%) 2.9465 10.08\n",
      "4m 7s (- 41m 41s) (1800 9%) 2.7973 10.50\n",
      "4m 20s (- 41m 18s) (1900 9%) 2.7764 9.94\n",
      "4m 33s (- 40m 58s) (2000 10%) 2.6915 10.01\n",
      "4m 50s (- 41m 18s) (2100 10%) 2.7661 9.57\n",
      "5m 4s (- 41m 5s) (2200 11%) 2.8064 9.82\n",
      "5m 21s (- 41m 11s) (2300 11%) 2.4426 9.79\n",
      "5m 34s (- 40m 53s) (2400 12%) 3.0416 10.08\n",
      "5m 50s (- 40m 53s) (2500 12%) 2.8618 9.20\n",
      "6m 5s (- 40m 46s) (2600 13%) 2.4874 9.34\n",
      "6m 19s (- 40m 31s) (2700 13%) 2.4461 8.26\n",
      "6m 34s (- 40m 23s) (2800 14%) 2.5676 8.49\n",
      "6m 47s (- 40m 4s) (2900 14%) 2.7720 9.22\n",
      "7m 2s (- 39m 53s) (3000 15%) 2.3568 8.32\n",
      "7m 18s (- 39m 51s) (3100 15%) 2.6342 8.21\n",
      "7m 35s (- 39m 49s) (3200 16%) 2.4949 7.66\n",
      "7m 49s (- 39m 33s) (3300 16%) 2.5369 8.44\n",
      "8m 2s (- 39m 16s) (3400 17%) 2.2561 6.88\n",
      "8m 17s (- 39m 6s) (3500 17%) 2.4883 7.75\n",
      "8m 32s (- 38m 55s) (3600 18%) 2.3082 7.40\n",
      "8m 49s (- 38m 50s) (3700 18%) 2.5832 9.17\n",
      "9m 3s (- 38m 38s) (3800 19%) 2.5510 7.48\n",
      "9m 17s (- 38m 21s) (3900 19%) 2.3735 8.31\n",
      "9m 34s (- 38m 19s) (4000 20%) 2.1467 7.68\n",
      "9m 53s (- 38m 19s) (4100 20%) 2.7847 8.51\n",
      "10m 7s (- 38m 5s) (4200 21%) 2.3515 7.62\n",
      "10m 21s (- 37m 49s) (4300 21%) 2.3921 7.48\n",
      "10m 34s (- 37m 30s) (4400 22%) 2.2307 7.75\n",
      "10m 48s (- 37m 14s) (4500 22%) 2.3466 8.29\n",
      "11m 1s (- 36m 56s) (4600 23%) 2.1258 7.21\n",
      "11m 16s (- 36m 41s) (4700 23%) 2.3005 7.60\n",
      "11m 30s (- 36m 27s) (4800 24%) 1.8487 6.80\n",
      "11m 45s (- 36m 12s) (4900 24%) 1.9354 6.64\n",
      "11m 59s (- 35m 59s) (5000 25%) 2.1612 7.45\n",
      "12m 14s (- 35m 45s) (5100 25%) 2.0751 6.43\n",
      "12m 27s (- 35m 26s) (5200 26%) 1.9405 7.02\n",
      "12m 40s (- 35m 10s) (5300 26%) 1.8658 6.27\n",
      "12m 55s (- 34m 56s) (5400 27%) 1.8059 6.12\n",
      "13m 11s (- 34m 46s) (5500 27%) 1.9882 7.31\n",
      "13m 28s (- 34m 38s) (5600 28%) 2.1424 6.79\n",
      "13m 44s (- 34m 28s) (5700 28%) 2.0922 6.29\n",
      "13m 59s (- 34m 16s) (5800 28%) 1.7860 6.28\n",
      "14m 15s (- 34m 4s) (5900 29%) 1.8056 6.23\n",
      "14m 32s (- 33m 56s) (6000 30%) 1.9904 6.17\n",
      "14m 47s (- 33m 43s) (6100 30%) 1.7875 6.51\n",
      "15m 2s (- 33m 28s) (6200 31%) 1.7121 5.96\n",
      "15m 17s (- 33m 14s) (6300 31%) 1.9003 6.51\n",
      "15m 32s (- 33m 1s) (6400 32%) 1.6019 5.71\n",
      "15m 50s (- 32m 53s) (6500 32%) 1.7449 5.43\n",
      "16m 7s (- 32m 44s) (6600 33%) 1.5625 4.87\n",
      "16m 24s (- 32m 34s) (6700 33%) 1.9510 7.07\n",
      "16m 42s (- 32m 26s) (6800 34%) 1.9326 6.70\n",
      "16m 57s (- 32m 12s) (6900 34%) 1.4859 5.51\n",
      "17m 13s (- 32m 0s) (7000 35%) 1.4996 5.11\n",
      "17m 28s (- 31m 45s) (7100 35%) 1.9178 6.60\n",
      "17m 44s (- 31m 31s) (7200 36%) 1.7370 5.83\n",
      "18m 1s (- 31m 21s) (7300 36%) 1.6098 4.70\n",
      "18m 17s (- 31m 7s) (7400 37%) 1.5240 5.24\n",
      "18m 34s (- 30m 56s) (7500 37%) 1.3578 4.37\n",
      "18m 49s (- 30m 42s) (7600 38%) 1.7569 5.50\n",
      "19m 5s (- 30m 29s) (7700 38%) 1.4968 5.18\n",
      "19m 19s (- 30m 13s) (7800 39%) 1.5403 5.20\n",
      "19m 36s (- 30m 1s) (7900 39%) 1.4759 4.75\n",
      "19m 50s (- 29m 45s) (8000 40%) 1.5598 4.64\n",
      "20m 6s (- 29m 31s) (8100 40%) 1.8119 5.71\n",
      "20m 23s (- 29m 20s) (8200 41%) 1.5193 5.46\n",
      "20m 38s (- 29m 6s) (8300 41%) 1.5278 4.78\n",
      "20m 54s (- 28m 51s) (8400 42%) 1.6178 6.05\n",
      "21m 10s (- 28m 38s) (8500 42%) 1.7537 5.07\n",
      "21m 25s (- 28m 23s) (8600 43%) 1.6082 4.66\n",
      "21m 41s (- 28m 10s) (8700 43%) 1.4741 4.30\n",
      "21m 55s (- 27m 54s) (8800 44%) 1.3730 4.50\n",
      "22m 11s (- 27m 40s) (8900 44%) 1.6374 4.53\n",
      "22m 26s (- 27m 25s) (9000 45%) 1.4022 4.39\n",
      "22m 41s (- 27m 10s) (9100 45%) 1.3762 4.90\n",
      "22m 55s (- 26m 55s) (9200 46%) 1.2161 4.46\n",
      "23m 10s (- 26m 40s) (9300 46%) 1.3923 4.51\n",
      "23m 26s (- 26m 25s) (9400 47%) 1.1899 3.56\n",
      "23m 41s (- 26m 10s) (9500 47%) 1.5013 4.45\n",
      "23m 56s (- 25m 56s) (9600 48%) 1.2791 4.20\n",
      "24m 13s (- 25m 42s) (9700 48%) 1.5050 4.85\n",
      "24m 29s (- 25m 29s) (9800 49%) 1.2663 4.03\n",
      "24m 46s (- 25m 16s) (9900 49%) 1.4220 4.72\n",
      "25m 1s (- 25m 1s) (10000 50%) 1.5659 5.34\n",
      "25m 16s (- 24m 46s) (10100 50%) 1.4103 4.14\n",
      "25m 30s (- 24m 30s) (10200 51%) 1.5976 4.83\n",
      "25m 45s (- 24m 15s) (10300 51%) 1.4223 4.19\n",
      "26m 0s (- 24m 0s) (10400 52%) 1.3650 4.13\n",
      "26m 16s (- 23m 46s) (10500 52%) 1.3640 4.22\n",
      "26m 31s (- 23m 31s) (10600 53%) 1.4265 4.30\n",
      "26m 47s (- 23m 17s) (10700 53%) 1.4062 4.56\n",
      "27m 1s (- 23m 1s) (10800 54%) 1.1312 3.48\n",
      "27m 17s (- 22m 47s) (10900 54%) 1.1482 3.72\n",
      "27m 33s (- 22m 32s) (11000 55%) 1.1394 3.99\n",
      "27m 50s (- 22m 19s) (11100 55%) 1.2453 3.35\n",
      "28m 5s (- 22m 4s) (11200 56%) 1.0950 3.54\n",
      "28m 22s (- 21m 50s) (11300 56%) 1.2733 3.80\n",
      "28m 37s (- 21m 35s) (11400 56%) 1.1799 3.79\n",
      "28m 52s (- 21m 20s) (11500 57%) 1.2058 3.58\n",
      "29m 6s (- 21m 4s) (11600 57%) 1.0323 2.80\n",
      "29m 21s (- 20m 49s) (11700 58%) 0.9799 3.30\n",
      "29m 38s (- 20m 35s) (11800 59%) 1.0997 3.63\n",
      "29m 54s (- 20m 21s) (11900 59%) 1.0626 3.33\n",
      "30m 11s (- 20m 7s) (12000 60%) 1.2025 3.91\n",
      "30m 25s (- 19m 52s) (12100 60%) 1.1498 3.95\n",
      "30m 40s (- 19m 36s) (12200 61%) 1.2629 3.81\n",
      "30m 56s (- 19m 22s) (12300 61%) 1.3327 3.90\n",
      "31m 12s (- 19m 7s) (12400 62%) 1.1992 3.35\n",
      "31m 29s (- 18m 53s) (12500 62%) 1.1578 3.75\n",
      "31m 45s (- 18m 39s) (12600 63%) 1.1162 3.59\n",
      "32m 0s (- 18m 23s) (12700 63%) 1.0339 2.59\n",
      "32m 14s (- 18m 8s) (12800 64%) 0.9981 2.77\n",
      "32m 29s (- 17m 53s) (12900 64%) 1.0414 3.16\n",
      "32m 43s (- 17m 37s) (13000 65%) 0.9526 3.43\n",
      "32m 59s (- 17m 22s) (13100 65%) 1.4346 4.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-d080955e5e21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mchatbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchatbot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialogues_Master_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.005)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.0025)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-0a41f39468e1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, agent, dialogues, n_iters, learning_rate, dic)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;31m#target_answer = variableFromSentence(agent.output_lang, training_dialogue[i][1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mtarget_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dialogue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_diff_mots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartie_dialogue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_answer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;31m# quantité d'erreurs sur la réponse i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-0a41f39468e1>\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(self, agent, dialogue, target_answer, optimizer, learning_rate)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mtarget_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_answer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_answer\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0manswer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn1_attention_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn2_attention_weights\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manswerTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_diff_mots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-135-a459d44ef8d5>\u001b[0m in \u001b[0;36manswerTrain\u001b[1;34m(self, input, target_answer)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;31m# word vectors and last hidden states of encoder bi-GRU are stored in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mdialogue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadDialogue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;31m# 3) reads current utterance,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-135-a459d44ef8d5>\u001b[0m in \u001b[0;36mreadDialogue\u001b[1;34m(self, dialogue)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mutterance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialogue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mlast_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateMemory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-135-a459d44ef8d5>\u001b[0m in \u001b[0;36mreadSentence\u001b[1;34m(self, utterance)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \"\"\"\n\u001b[0;32m    189\u001b[0m         \u001b[0mutterance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutterance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mlast_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlast_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_hidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-6a45276061ee>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, utterance, hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# dim = (input_length, 1, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m                           \u001b[1;31m# dim = (input_length, 1, embedding_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbigru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m                                          \u001b[1;31m# dim = (input_length, 1, hidden_dim * 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             dropout_ts)\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.01)\n",
    "#trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.005)\n",
    "#trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chatbot.train()\n",
    "trainer.train(chatbot, dialogues_Master_var, n_iters = 20000, learning_rate=0.005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
