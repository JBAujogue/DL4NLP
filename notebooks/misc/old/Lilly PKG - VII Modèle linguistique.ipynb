{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Dataset Lilly (pkg)\n",
    "  </div> \n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 30px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  VII. Modèle linguistique\n",
    "  </div> \n",
    "\n",
    "  <div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 20px; \n",
    "      text-align: center; \n",
    "      padding: 15px;\">\n",
    "  ALTRAN - Projet MODINS\n",
    "  </div> \n",
    "\n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Benoît COURBON  |\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> \n",
    "\n",
    "  <div style=\" display: inline-block;\n",
    "      font-family: 'Lato',\n",
    "      sans-serif;\n",
    "      font-size: 12px;\n",
    "      font-weight: bold;\n",
    "      line-height: 12px;\n",
    "      letter-spacing: 1px;\n",
    "      padding: 10px 15px 8px;\">\n",
    "  29/04/2019\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to anaconda : C:\\ProgramData\\Anaconda3\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manipulating dataframes, arrays, containers...\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "from unidecode import unidecode\n",
    "\n",
    "# equivalent of numpy for very large arrays (such as a database of pretrained word vectors)\n",
    "# optimized for SQL-like operations, not for math computations\n",
    "# see https://bcolz.readthedocs.io/en/latest/intro.html\n",
    "\n",
    "# installer avec la commande : conda install bcolz\n",
    "import bcolz\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "use_cuda = False\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NLP\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "path_to_rep = 'C:\\\\Users\\\\jbaujogue\\\\Desktop\\\\MODINS\\\\use case Lilly'\n",
    "path_to_NLP = 'C:\\\\Users\\\\jbaujogue\\\\Desktop\\\\NLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Préparation\n",
    "\n",
    "<a id=\"import\"></a>\n",
    "\n",
    "### 0.1 Import du corpus\n",
    "\n",
    "[Retour à la table des matières](#plan)\n",
    "\n",
    "Import du corpus de tickets Lilly, avec chaque ticket sous la forme d'une liste nettoyée de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3743, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Created</th>\n",
       "      <th>Problem</th>\n",
       "      <th>Resolution Code</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Description</th>\n",
       "      <th>Resolve Notes</th>\n",
       "      <th>Analyse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC2976351</td>\n",
       "      <td>2016-06-01 06:54:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>People/System use</td>\n",
       "      <td>AST : PMX-PKG : Démarrage étape de production ...</td>\n",
       "      <td>Impossible de démarrer l'étape de production s...</td>\n",
       "      <td>• [Résumé] Impossible de démarrer l'étape de p...</td>\n",
       "      <td>Hscope/Duplicate/Cslt/Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC2976936</td>\n",
       "      <td>2016-06-01 09:56:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : Alarme type 2 non vue par l'équipement</td>\n",
       "      <td>Une alarme s'est déclenchée sur le limos LPF-E...</td>\n",
       "      <td>• [Résumé]\\n\\n• [Catégorie] \\n\\n• [Résolution]...</td>\n",
       "      <td>Matrikon/Alarme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC2977191</td>\n",
       "      <td>2016-06-01 10:51:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monitoring</td>\n",
       "      <td>PMX-PKG : ticket journalier MO3524 du 01/06/2016</td>\n",
       "      <td>01/06/2016 00:00:00 =&gt;  01/06/2016 10:47:14\\n-...</td>\n",
       "      <td>• [Catégorie] Monitoring des erreurs d'interfa...</td>\n",
       "      <td>Dailyinterfacemonitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC2981590</td>\n",
       "      <td>2016-06-02 09:55:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : ref_relation = WESSTOCKREMOVAL  (LC ...</td>\n",
       "      <td>Message envoyé le 01/06/2016 12:57:07\\n\\nid = ...</td>\n",
       "      <td>• [Résumé] Message d'erreur reçu sur l'interfa...</td>\n",
       "      <td>Lcmovementerror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC2981597</td>\n",
       "      <td>2016-06-02 09:56:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMX-PKG : ref_relation = WESSTOCKREMOVAL (LC =...</td>\n",
       "      <td>Message envoyé le 01/06/2016 12:59:07\\n\\nid = ...</td>\n",
       "      <td>• [Résumé] Message d'erreur reçu sur l'interfa...</td>\n",
       "      <td>Lcmovementerror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number             Created Problem    Resolution Code  \\\n",
       "0  INC2976351 2016-06-01 06:54:32     NaN  People/System use   \n",
       "1  INC2976936 2016-06-01 09:56:53     NaN                NaN   \n",
       "2  INC2977191 2016-06-01 10:51:31     NaN         Monitoring   \n",
       "3  INC2981590 2016-06-02 09:55:10     NaN                NaN   \n",
       "4  INC2981597 2016-06-02 09:56:36     NaN                NaN   \n",
       "\n",
       "                                   Short Description  \\\n",
       "0  AST : PMX-PKG : Démarrage étape de production ...   \n",
       "1   PMX-PKG : Alarme type 2 non vue par l'équipement   \n",
       "2   PMX-PKG : ticket journalier MO3524 du 01/06/2016   \n",
       "3  PMX-PKG : ref_relation = WESSTOCKREMOVAL  (LC ...   \n",
       "4  PMX-PKG : ref_relation = WESSTOCKREMOVAL (LC =...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Impossible de démarrer l'étape de production s...   \n",
       "1  Une alarme s'est déclenchée sur le limos LPF-E...   \n",
       "2  01/06/2016 00:00:00 =>  01/06/2016 10:47:14\\n-...   \n",
       "3  Message envoyé le 01/06/2016 12:57:07\\n\\nid = ...   \n",
       "4  Message envoyé le 01/06/2016 12:59:07\\n\\nid = ...   \n",
       "\n",
       "                                       Resolve Notes  \\\n",
       "0  • [Résumé] Impossible de démarrer l'étape de p...   \n",
       "1  • [Résumé]\\n\\n• [Catégorie] \\n\\n• [Résolution]...   \n",
       "2  • [Catégorie] Monitoring des erreurs d'interfa...   \n",
       "3  • [Résumé] Message d'erreur reçu sur l'interfa...   \n",
       "4  • [Résumé] Message d'erreur reçu sur l'interfa...   \n",
       "\n",
       "                        Analyse  \n",
       "0  Hscope/Duplicate/Cslt/Action  \n",
       "1               Matrikon/Alarme  \n",
       "2      Dailyinterfacemonitoring  \n",
       "3               Lcmovementerror  \n",
       "4               Lcmovementerror  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Lilly = pd.read_excel(path_to_rep + '\\data\\Tickets_Lilly_pkg\\\\tickets_Lilly_05_03_2019.xlsx' )\n",
    "df_Lilly = df_Lilly.reset_index(drop=True)\n",
    "print(df_Lilly.shape)\n",
    "df_Lilly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(liste1, liste2):\n",
    "    return [a.lower() + ' ' + b.lower() for a,b in zip(liste2, liste1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titres = ['Short Description : ', 'Description : ', 'Resolve Notes : ']\n",
    "X_raw = [' . '.join(fusion([str(el) for el in els], titres )) \\\n",
    "            for els in zip(df_Lilly['Short Description'].values.tolist(),\n",
    "                           df_Lilly['Description'].values.tolist(),\n",
    "                           df_Lilly['Resolve Notes'].values.tolist()\n",
    "                          )]\n",
    "#X_raw = [[[word.strip() for word in sentence.split()] + ['.'] for sentence in teX_rawt.split('.')] for teX_rawt in X_raw]\n",
    "# nettoyage préalable\n",
    "X_raw = [re.sub('\\n', ' . ', teX_rawt) for teX_rawt in X_raw] # on remplace chaque retour chariot par un point espacé\n",
    "X_raw = [re.sub('arretmajeur', 'arret majeur', teX_rawt) for teX_rawt in X_raw] \n",
    "X_raw = [re.sub('=>', ' => ', teX_rawt) for teX_rawt in X_raw] \n",
    "X_raw = [re.sub('->', ' -> ', teX_rawt) for teX_rawt in X_raw] \n",
    "X_raw = [re.sub('(?P<val>\\S)\\.', '\\g<val> .', teX_rawt) for teX_rawt in X_raw] # on insere un espace à la fin de chaque hashtag\n",
    "X_raw = [re.sub('#(?P<val>[0-9]+)(?P<val2>[^0-9])', '#\\g<val> \\g<val2>', teX_rawt) for teX_rawt in X_raw] # on insere un espace à la fin de chaque hashtag\n",
    "X_raw = [teX_rawt + '.' for teX_rawt in X_raw] # on insere un point a la fin de chaque teX_rawte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanAndComputeAlignement(X, dict_sub, dict_replace) :\n",
    "    def sub2replace(dict_sub, corpus):\n",
    "        '''corpus is [str]'''\n",
    "        dict_replace = {}\n",
    "        for key in dict_sub.keys():\n",
    "            occ_list = []\n",
    "            for text in corpus : occ_list += re.findall(key, text)\n",
    "            for word in occ_list :\n",
    "                dict_replace[word] = dict_sub[key]\n",
    "        return dict_replace  \n",
    "\n",
    "\n",
    "\n",
    "    def augmentValeur(dict_replace):\n",
    "        for key, value in dict_replace.items() :\n",
    "            if len(key) > len(value) : dict_replace[key] = value + ''.join([' ']*(len(key) - len(value)))\n",
    "        return dict_replace\n",
    "\n",
    "\n",
    "\n",
    "    def applyReplace(dict_replace, corpus):\n",
    "        new_corpus = []\n",
    "        caracters_alignement_list = []\n",
    "        for text in corpus :\n",
    "            # initialisation du dictionnaire d'alignement de caractères\n",
    "            carac_dict = {}\n",
    "            for i in range(len(text)): carac_dict[i] = i\n",
    "\n",
    "            # mise à jour du dictionnaire d'alignement pour chaque mot\n",
    "            for word in dict_replace.keys():\n",
    "                diff = len(dict_replace[word]) - len(word)\n",
    "                if diff > 0 :\n",
    "                    start = text.find(word)\n",
    "                    while start != -1 :\n",
    "                        reste = start + len(word)\n",
    "                        #if '#' in word : print(word, text[start : reste], diff)\n",
    "                        for i in range(reste, len(text)) : carac_dict[i] += diff\n",
    "                        start = text.find(word, reste)\n",
    "            caracters_alignement_list.append(carac_dict)\n",
    "\n",
    "            # remplacement de chaque mot\n",
    "            for word in dict_replace.keys(): text = text.replace(word, dict_replace[word])\n",
    "            new_corpus.append(text)\n",
    "\n",
    "        return new_corpus, caracters_alignement_list\n",
    "\n",
    "\n",
    "    def removeSpecialCaracters(text):\n",
    "        def replace(c):\n",
    "            return c if unicodedata.category(c) != 'Mn' else ''\n",
    "        def unicodeToAscii(s):\n",
    "            \"\"\"Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "            return ''.join(replace(c) for c in unicodedata.normalize('NFD', s))\n",
    "        text = unicodeToAscii(text)\n",
    "        text = re.sub(r\"[^a-zA-Z\\.]\", r\" \", text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "    def cleanPoints(corpus):\n",
    "        new_corpus = []\n",
    "        for text in corpus :\n",
    "            new_text = ''\n",
    "            vu = 0\n",
    "            while vu < len(text) and (text[vu] == '.' or text[vu] == ' ') :\n",
    "                new_text += ' '\n",
    "                vu += 1\n",
    "            while vu < len(text) :\n",
    "                if text[vu] == '.' :\n",
    "                    new_text += '.'\n",
    "                    vu += 1\n",
    "                    while vu < len(text) and (text[vu] == '.' or text[vu] == ' ') :\n",
    "                        new_text += ' '\n",
    "                        vu += 1\n",
    "                else :\n",
    "                    new_text += text[vu]\n",
    "                    vu += 1\n",
    "\n",
    "            # on place correctement le point de la fin\n",
    "            #new_text = new_text[:-1] + '.'\n",
    "            #vu = len(new_text)-2\n",
    "            #while vu >=0 and (new_text[vu] == '.' or new_text[vu] == ' ') :\n",
    "            #    new_text = new_text[:vu] + ' ' + new_text[vu + 1:]\n",
    "            #    vu -= 1\n",
    "            new_corpus.append(new_text)\n",
    "        return new_corpus\n",
    "\n",
    "\n",
    "\n",
    "    def countPadding(corpus):\n",
    "        def computePadding(text, word, vu):\n",
    "            padding = 0\n",
    "            while (vu + len(word) + padding) < len(text) and text[vu + len(word) + padding] == ' ' :\n",
    "                padding += 1\n",
    "            return padding\n",
    "\n",
    "        padding_list = []\n",
    "        for text in corpus :\n",
    "            words = [word for sentence in text.split('.') for word in sentence.split() + ['.'] if len(sentence.split())>0] #text.split()\n",
    "            paddings = []\n",
    "            vu = 0\n",
    "            while text[vu] == ' ':\n",
    "                vu += 1\n",
    "            paddings.append(['SOS', vu])\n",
    "            for word in words :\n",
    "                padding = computePadding(text, word, vu)\n",
    "                paddings.append([word, padding])\n",
    "                vu += len(word) + padding\n",
    "            padding_list.append(paddings)\n",
    "        return padding_list\n",
    "\n",
    "\n",
    "\n",
    "    def car2Words(padding_list) :\n",
    "        caracter2word_dict = []\n",
    "        for paddings in padding_list :\n",
    "            text = ''.join(el[0] + ''.join([' ']*el[1]) for el in paddings)[3:]\n",
    "            carac2word = {}\n",
    "            vu = 0\n",
    "            for n, el in enumerate(paddings) :\n",
    "                length = len(el[0]) + el[1] if n > 0 else el[1]\n",
    "                for i in range(vu, vu + length) :\n",
    "                    carac2word[i] = el[0] if text[i] != ' ' else 0\n",
    "                vu += length\n",
    "            caracter2word_dict.append(carac2word)\n",
    "        return caracter2word_dict\n",
    "\n",
    "\n",
    "\n",
    "    def word2Position(caracter2word_list):\n",
    "        new_list = []\n",
    "        for car2word in caracter2word_list :\n",
    "            new_car2word = {}\n",
    "            c  = 0\n",
    "            word_count = 0\n",
    "            line_count = 0\n",
    "            while c <= max(list(car2word.keys())) :\n",
    "                w = car2word[c]\n",
    "                if w == '.' :\n",
    "                    new_car2word[c] = [line_count, word_count]\n",
    "                    line_count += 1\n",
    "                    word_count = 0\n",
    "                    c += 1\n",
    "                elif w != 0 :\n",
    "                    while c <= max(list(car2word.keys())) and car2word[c] == w :\n",
    "                        new_car2word[c] = [line_count, word_count]\n",
    "                        c += 1\n",
    "                    word_count += 1\n",
    "                else :\n",
    "                    new_car2word[c] = car2word[c]\n",
    "                    c+= 1\n",
    "            new_list.append(new_car2word)\n",
    "        return new_list  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def rawCar2Position(rawcar2car_list, car2pos_list):\n",
    "        new_list = []\n",
    "        for rawcar2car, car2pos in zip(rawcar2car_list, car2pos_list):\n",
    "            rawcar2pos = {}\n",
    "            for key, value in rawcar2car.items():\n",
    "                rawcar2pos[key] = car2pos[value]\n",
    "            new_list.append(rawcar2pos)\n",
    "        return new_list\n",
    "\n",
    "    \n",
    "    \n",
    "    dict_replace_add = sub2replace(dict_sub, X)\n",
    "    dict_replace.update(dict_replace_add)\n",
    "    #print('Il y a au total {} opération .replace à effectuer sur le corpus'.format(len(list(dict_replace.keys()))))\n",
    "    dict_replace = augmentValeur(dict_replace)\n",
    "    \n",
    "    X2, rawcar2car_list = applyReplace(dict_replace, X)\n",
    "    X3 = [removeSpecialCaracters(text) for text in X2]\n",
    "    X4 = cleanPoints(X3)\n",
    "    \n",
    "    padding_list = countPadding(X4)\n",
    "    car2word_list = car2Words(padding_list)\n",
    "    car2pos_list = word2Position(car2word_list)\n",
    "    rawcar2pos_list = rawCar2Position(rawcar2car_list, car2pos_list)\n",
    "    \n",
    "    X_final = [[sentence.split() + ['.'] for sentence in text.split('.') if len(sentence.split())>0] for text in X4]\n",
    "    return X_final, rawcar2pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sub = {'[^=-]>\\s*0' : 'positive',\n",
    "            '#[0-9]+ ' : 'hashtag ',\n",
    "            #'[0-9]+\\:[0-9]+\\:[0-9]*' : 'heurenumber',\n",
    "            #'[0-9]+\\-[0-9]+\\-[0-9]+' : 'datenumber',\n",
    "            #'[0-9]+\\/[0-9]+\\/[0-9]+' : 'datenumber',\n",
    "            #'[0-9]+\\.[0-9]+\\.[0-9]+' : 'datenumber',\n",
    "            '•' : '.'}\n",
    "\n",
    "dict_replace = {'=>' : 'donc',\n",
    "                '->' : 'donc',\n",
    "                '.zip'  : ' zip',\n",
    "                'loc.'  : 'loc ',\n",
    "                'checkliste' : 'checklist',\n",
    "                'close loop' : 'closeloop',\n",
    "                'SUPER.' : 'SUPER ',\n",
    "                'imprimente' : 'imprimante',\n",
    "                'dim.' : 'dimanche'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, rawcar2pos_list = CleanAndComputeAlignement(X_raw, dict_sub, dict_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(description) :\n",
    "    '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "    flatten = []\n",
    "    for line in description :\n",
    "        flatten += line\n",
    "    return flatten\n",
    "\n",
    "\n",
    "X_flat = [flatten(text) for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formation du language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, init = 3):\n",
    "        self.name = name\n",
    "        if init == 0 :\n",
    "            self.word2index = {}\n",
    "            self.word2count = {}\n",
    "            self.index2word = {}\n",
    "            self.n_words = 0\n",
    "        elif init == 3 :\n",
    "            self.word2index = {\"SOS\": 0, \"EOS\": 1, \"UNK\": 2}\n",
    "            self.word2count = {\"SOS\": 0, \"EOS\": 0, \"UNK\": 0}\n",
    "            self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\"}\n",
    "            self.n_words = 3\n",
    "\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        '''Add a word to the language'''\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        '''Add to the language all words of a sentence'''\n",
    "        if type(sentence) == str :\n",
    "            for word in nltk.word_tokenize(sentence): # sentence.split()\n",
    "                self.addWord(word)\n",
    "        elif type(sentence) == list :\n",
    "            for word in sentence:\n",
    "                self.addWord(word)            \n",
    "            \n",
    "            \n",
    "    def addDescriptions(self, descriptions, lvl = 1):\n",
    "        '''Add to the language all words contained into : either all user utterances \n",
    "          (if i = 0) or all bot utterances (if i = 1), of a list of dialogues'''\n",
    "        for description in descriptions :\n",
    "            \n",
    "            # si la description est une seule ligne\n",
    "            if type(description) == str :\n",
    "                    try :\n",
    "                        if lvl == 2 :\n",
    "                            for sentence in nltk.sent_tokenize(description) :\n",
    "                                self.addSentence(sentence)\n",
    "                        else :\n",
    "                            self.addSentence(description)\n",
    "                    except IndexError:\n",
    "                        print(\"Problem with {}\".format(description))\n",
    "                        \n",
    "            # si la description est une liste de lignes\n",
    "            elif type(description) == list :\n",
    "                for line in description:\n",
    "                    try :\n",
    "                        self.addSentence(line)\n",
    "                    except IndexError:\n",
    "                        print(\"Problem with {}\".format(line))\n",
    "                              \n",
    "            # sinon\n",
    "            else :\n",
    "                print(\"Problem with {}\".format(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLanguageFromWordList(liste, init = 0):\n",
    "    lang = Lang('descriptions', init)\n",
    "    lang.addSentence(liste)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang\n",
    "\n",
    "\n",
    "def generateLanguageFromNumpy(descriptions, init = 0, lvl = 1):\n",
    "    lang = Lang('descriptions', init)\n",
    "    lang.addDescriptions(descriptions)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang\n",
    "\n",
    "\n",
    "def generateLanguageFromPanda(df, i):\n",
    "    descriptions = df.ix[:, i].values\n",
    "    lang = Lang('descriptions')\n",
    "    lang.addDescriptions(descriptions)\n",
    "    print(\"Mots comptés : \", lang.n_words)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots comptés :  7238\n"
     ]
    }
   ],
   "source": [
    "lang = generateLanguageFromNumpy(X_flat, init = 3, lvl = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"embedding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Word Embedding\n",
    "\n",
    "[Retour à la table des matières](#plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.1 Modèle Skip-gram de Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gensim_skipgram = flatten(X) # ------ [[str]] : al list of list of tockens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_gensim = Word2Vec(data_gensim_skipgram, \n",
    "                           size = 100, \n",
    "                           window = 5, \n",
    "                           min_count = 1, \n",
    "                           negative = 20, \n",
    "                           iter = 500,\n",
    "                           sg = 1,\n",
    "                           workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir la table des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T est de type <class 'numpy.ndarray'> et de taille (6488, 100)\n"
     ]
    }
   ],
   "source": [
    "T = skipgram_gensim.wv.vectors\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.2 Modèle Skip-gram sur mesure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(description) :\n",
    "    '''Baisse le nombre de niveaux de 1 dans la description'''\n",
    "    flatten = []\n",
    "    for line in description :\n",
    "        flatten += line\n",
    "    return flatten\n",
    "\n",
    "\n",
    "def generateNgrams(descriptions, context_size = 5) :\n",
    "    '''descriptions = [[str]]'''\n",
    "    data = []\n",
    "    for description in descriptions :\n",
    "        line = flatten(description)\n",
    "        line = ['SOS' for i in range(context_size)] + line + ['EOS' for i in range(context_size)] \n",
    "        for i in range(context_size, len(line) - context_size):\n",
    "            context = line[i-context_size : i] + line[i+1 : i+context_size+1]\n",
    "            target = [line[i]]\n",
    "            data.append((context, target))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, device, \n",
    "                 lang, \n",
    "                 context_size, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim):\n",
    "        \n",
    "        super(SkipGram, self).__init__()\n",
    "        self.device = device\n",
    "        self.lang = lang\n",
    "        self.output_lang = copy.copy(lang)\n",
    "        self.output_lang.addDescriptions(['SOS', 'UNK', 'EOS'])\n",
    "        self.context_size = 2 * context_size\n",
    "        self.embedding = nn.Embedding(lang.n_words, embedding_dim)\n",
    "        self.linear_1 = nn.Linear(embedding_dim, 2*context_size * hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, self.output_lang.n_words)\n",
    "        \n",
    "        \n",
    "    def variableFromSentence(self, sentence):\n",
    "        '''Turn a sentence into a torch variable, containing a list of indices according\n",
    "           to a given language.'''\n",
    "        indexes = [self.lang.word2index[word] for word in sentence if word in self.lang.word2index]          \n",
    "        result = Variable(torch.LongTensor(indexes).view(1, -1)).to(self.device)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def forward(self, word):\n",
    "        input = self.variableFromSentence(word)                   # size = (1, 1)\n",
    "        embed = self.embedding(input)#.view((1, -1))              # size = (1, embedding_dim)\n",
    "        out = self.linear_1(embed).view((self.context_size, -1))  # size = (2 * context_size , hidden_dim)\n",
    "        out = F.relu(out)                                         # size = (2 * context_size , hidden_dim)\n",
    "        out = self.linear_2(out)                                  # size = (2 * context_size , lang.n_words)\n",
    "        log_probs = F.log_softmax(out)                            # size = (2 * context_size , lang.n_words)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramTrainer(object):\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 criterion = nn.NLLLoss(reduce = False), #nn.BCEWithLogitsLoss(), #nn.BCELoss(), \n",
    "                 optimizer = optim.SGD,\n",
    "                 print_every=100):\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "    \n",
    "    \n",
    "    def timeSince(self, since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "        \n",
    "        \n",
    "    def trainLoop(self, agent, context, word, weights, optimizer, learning_rate):\n",
    "        \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        agent.zero_grad()\n",
    "        \n",
    "        log_probs = agent(word)\n",
    "        context_var = agent.variableFromSentence(context).view(-1)\n",
    "        loss = self.criterion(log_probs, context_var)\n",
    "        loss = torch.sum(weights * loss)\n",
    "        loss_diff = 0\n",
    "        for i in range(agent.context_size) :\n",
    "            topv, topi = log_probs[i].data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            loss_diff = loss_diff + 1 if ni != context_var[i].data[0] else loss_diff\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        return loss.data[0], loss_diff\n",
    "        \n",
    "        \n",
    "    def train(self,\n",
    "              agent, \n",
    "              ngrams, \n",
    "              weights,\n",
    "              n_iters = 100,\n",
    "              n_epochs = None,\n",
    "              learning_rate=0.01,\n",
    "              random_state = 42\n",
    "             ):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops.\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in agent.parameters() if param.requires_grad == True], lr=learning_rate)\n",
    "        weights = Variable(torch.FloatTensor(weights)).to(self.device)\n",
    "        print_loss_total = 0  \n",
    "        print_loss_diff_mots_total = 0\n",
    "        if n_epochs is None :\n",
    "            for iter in range(1, n_iters + 1):\n",
    "                couple = random.choice(ngrams)\n",
    "                context = couple[0] \n",
    "                target = couple[1] \n",
    "                loss, loss_diff_mots = self.trainLoop(agent, context, target, weights, optimizer, learning_rate)\n",
    "                # quantité d'erreurs sur la réponse i\n",
    "                print_loss_total += loss\n",
    "                print_loss_diff_mots_total += loss_diff_mots       \n",
    "                if iter % (self.print_every) == 0:\n",
    "                    print_loss_avg = print_loss_total / self.print_every\n",
    "                    print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                    print_loss_total = 0\n",
    "                    print_loss_diff_mots_total = 0\n",
    "                    print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                                 iter, iter / n_iters * 100, \n",
    "                                                      print_loss_avg, print_loss_diff_mots_avg))\n",
    "        else :\n",
    "            for epoch in range(n_epochs):\n",
    "                print('epoch ' + str(epoch))\n",
    "                np.random.shuffle(ngrams)\n",
    "                for couple in ngrams :\n",
    "                    context = couple[0] \n",
    "                    target = couple[1] \n",
    "                    loss, loss_diff_mots = self.trainLoop(agent, context, target, weights, optimizer, learning_rate)\n",
    "\n",
    "                    # quantité d'erreurs sur la réponse i\n",
    "                    print_loss_total += loss\n",
    "                    print_loss_diff_mots_total += loss_diff_mots       \n",
    "\n",
    "                    if iter % (self.print_every) == 0:\n",
    "                        print_loss_avg = print_loss_total / self.print_every\n",
    "                        print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                        print_loss_total = 0\n",
    "                        print_loss_diff_mots_total = 0\n",
    "                        print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                                     iter, iter / n_iters * 100, \n",
    "                                                          print_loss_avg, print_loss_diff_mots_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightsList(n):\n",
    "    half = (n-1)/2\n",
    "    weights = [n**2 -(half-i)**2 for i in range(n)]\n",
    "    weights = [el/sum(weights) for el in weights]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = SkipGram(device, lang, context_size = 5, embedding_dim = 75, hidden_dim = 75)\n",
    "skipgram = skipgram.to(device)\n",
    "skipgram_trainer = SkipGramTrainer(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngrams = generateNgrams(X, context_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 8m 21s) (100 0%) 8.6615 9.31\n",
      "0m 2s (- 8m 14s) (200 0%) 8.3966 7.81\n",
      "0m 3s (- 8m 14s) (300 0%) 7.9387 7.37\n",
      "0m 4s (- 8m 11s) (400 1%) 7.6289 7.46\n",
      "0m 6s (- 8m 8s) (500 1%) 7.3045 7.53\n",
      "0m 7s (- 8m 5s) (600 1%) 7.2159 7.55\n",
      "0m 8s (- 8m 5s) (700 1%) 6.9773 7.34\n",
      "0m 9s (- 8m 4s) (800 2%) 7.3433 7.89\n",
      "0m 11s (- 8m 3s) (900 2%) 6.9874 7.49\n",
      "0m 12s (- 8m 0s) (1000 2%) 7.0193 7.57\n",
      "0m 13s (- 7m 59s) (1100 2%) 6.9350 7.46\n",
      "0m 14s (- 7m 58s) (1200 3%) 7.2537 7.85\n",
      "0m 16s (- 7m 56s) (1300 3%) 6.8125 7.40\n",
      "0m 17s (- 7m 55s) (1400 3%) 6.9897 7.67\n",
      "0m 18s (- 7m 54s) (1500 3%) 6.8655 7.45\n",
      "0m 19s (- 7m 54s) (1600 4%) 6.7800 7.33\n",
      "0m 21s (- 7m 53s) (1700 4%) 6.8878 7.56\n",
      "0m 22s (- 7m 51s) (1800 4%) 6.7829 7.45\n",
      "0m 23s (- 7m 51s) (1900 4%) 6.7094 7.43\n",
      "0m 24s (- 7m 49s) (2000 5%) 6.9370 7.81\n",
      "0m 25s (- 7m 48s) (2100 5%) 6.8034 7.65\n",
      "0m 27s (- 7m 46s) (2200 5%) 6.8269 7.61\n",
      "0m 28s (- 7m 45s) (2300 5%) 6.7266 7.65\n",
      "0m 29s (- 7m 44s) (2400 6%) 6.6305 7.67\n",
      "0m 30s (- 7m 44s) (2500 6%) 6.6411 7.53\n",
      "0m 32s (- 7m 44s) (2600 6%) 6.7969 7.77\n",
      "0m 33s (- 7m 43s) (2700 6%) 6.4996 7.40\n",
      "0m 34s (- 7m 43s) (2800 7%) 6.6406 7.72\n",
      "0m 36s (- 7m 42s) (2900 7%) 6.4595 7.54\n",
      "0m 37s (- 7m 41s) (3000 7%) 6.7789 8.05\n",
      "0m 38s (- 7m 39s) (3100 7%) 6.4581 7.45\n",
      "0m 39s (- 7m 38s) (3200 8%) 6.4712 7.42\n",
      "0m 41s (- 7m 36s) (3300 8%) 6.2887 7.31\n",
      "0m 42s (- 7m 36s) (3400 8%) 6.4758 7.65\n",
      "0m 43s (- 7m 35s) (3500 8%) 6.4377 7.71\n",
      "0m 44s (- 7m 34s) (3600 9%) 6.7320 7.91\n",
      "0m 46s (- 7m 33s) (3700 9%) 6.2127 7.36\n",
      "0m 47s (- 7m 32s) (3800 9%) 6.3204 7.80\n",
      "0m 48s (- 7m 31s) (3900 9%) 6.3081 7.82\n",
      "0m 49s (- 7m 29s) (4000 10%) 6.2571 7.57\n",
      "0m 51s (- 7m 28s) (4100 10%) 6.1123 7.61\n",
      "0m 52s (- 7m 27s) (4200 10%) 6.1270 7.80\n",
      "0m 53s (- 7m 26s) (4300 10%) 6.1603 7.53\n",
      "0m 55s (- 7m 25s) (4400 11%) 6.2320 7.56\n",
      "0m 56s (- 7m 24s) (4500 11%) 6.0913 7.46\n",
      "0m 57s (- 7m 23s) (4600 11%) 6.1502 7.46\n",
      "0m 58s (- 7m 21s) (4700 11%) 6.0450 7.68\n",
      "1m 0s (- 7m 20s) (4800 12%) 6.0461 7.50\n",
      "1m 1s (- 7m 19s) (4900 12%) 6.0230 7.55\n",
      "1m 2s (- 7m 18s) (5000 12%) 5.8940 7.48\n",
      "1m 3s (- 7m 17s) (5100 12%) 5.9454 7.45\n",
      "1m 5s (- 7m 16s) (5200 13%) 6.0896 7.65\n",
      "1m 6s (- 7m 15s) (5300 13%) 6.0536 8.03\n",
      "1m 7s (- 7m 13s) (5400 13%) 5.9529 7.63\n",
      "1m 8s (- 7m 12s) (5500 13%) 5.9795 7.79\n",
      "1m 10s (- 7m 11s) (5600 14%) 5.8034 7.27\n",
      "1m 11s (- 7m 10s) (5700 14%) 5.6314 7.29\n",
      "1m 12s (- 7m 8s) (5800 14%) 5.9909 7.70\n",
      "1m 14s (- 7m 7s) (5900 14%) 5.6876 7.49\n",
      "1m 15s (- 7m 6s) (6000 15%) 5.9289 7.71\n",
      "1m 16s (- 7m 5s) (6100 15%) 5.9352 7.61\n",
      "1m 17s (- 7m 4s) (6200 15%) 5.7304 7.55\n",
      "1m 19s (- 7m 3s) (6300 15%) 5.8627 7.51\n",
      "1m 20s (- 7m 2s) (6400 16%) 5.6568 7.25\n",
      "1m 21s (- 7m 1s) (6500 16%) 5.5978 7.44\n",
      "1m 22s (- 6m 59s) (6600 16%) 5.7787 7.54\n",
      "1m 24s (- 6m 58s) (6700 16%) 5.6524 7.46\n",
      "1m 25s (- 6m 57s) (6800 17%) 5.8222 7.52\n",
      "1m 26s (- 6m 56s) (6900 17%) 5.3473 7.41\n",
      "1m 28s (- 6m 55s) (7000 17%) 5.7781 7.54\n",
      "1m 29s (- 6m 54s) (7100 17%) 5.4405 7.23\n",
      "1m 30s (- 6m 52s) (7200 18%) 5.4687 7.32\n",
      "1m 31s (- 6m 51s) (7300 18%) 5.6587 7.35\n",
      "1m 33s (- 6m 50s) (7400 18%) 5.5639 7.32\n",
      "1m 34s (- 6m 48s) (7500 18%) 5.4366 7.44\n",
      "1m 35s (- 6m 47s) (7600 19%) 5.3753 7.21\n",
      "1m 37s (- 6m 47s) (7700 19%) 5.3746 7.12\n",
      "1m 38s (- 6m 45s) (7800 19%) 5.5866 7.44\n",
      "1m 39s (- 6m 44s) (7900 19%) 5.4486 7.33\n",
      "1m 40s (- 6m 43s) (8000 20%) 5.4179 7.28\n",
      "1m 42s (- 6m 42s) (8100 20%) 5.3389 7.36\n",
      "1m 43s (- 6m 41s) (8200 20%) 5.4015 7.48\n",
      "1m 44s (- 6m 39s) (8300 20%) 5.4010 7.12\n",
      "1m 45s (- 6m 38s) (8400 21%) 5.4561 7.29\n",
      "1m 47s (- 6m 36s) (8500 21%) 5.4579 7.38\n",
      "1m 48s (- 6m 35s) (8600 21%) 5.3677 7.26\n",
      "1m 49s (- 6m 34s) (8700 21%) 5.1098 6.98\n",
      "1m 50s (- 6m 33s) (8800 22%) 5.4772 7.52\n",
      "1m 52s (- 6m 31s) (8900 22%) 5.3877 7.46\n",
      "1m 53s (- 6m 30s) (9000 22%) 5.4684 7.50\n",
      "1m 54s (- 6m 29s) (9100 22%) 5.4269 7.38\n",
      "1m 55s (- 6m 27s) (9200 23%) 5.2360 7.30\n",
      "1m 57s (- 6m 26s) (9300 23%) 5.2803 7.30\n",
      "1m 58s (- 6m 25s) (9400 23%) 5.3237 7.29\n",
      "1m 59s (- 6m 23s) (9500 23%) 5.2267 7.15\n",
      "2m 0s (- 6m 22s) (9600 24%) 5.4281 7.60\n",
      "2m 2s (- 6m 21s) (9700 24%) 5.1467 7.23\n",
      "2m 3s (- 6m 19s) (9800 24%) 5.2421 7.14\n",
      "2m 4s (- 6m 18s) (9900 24%) 5.3248 7.35\n",
      "2m 5s (- 6m 17s) (10000 25%) 5.2930 7.41\n",
      "2m 6s (- 6m 15s) (10100 25%) 4.9638 6.98\n",
      "2m 8s (- 6m 14s) (10200 25%) 5.3523 7.34\n",
      "2m 9s (- 6m 13s) (10300 25%) 5.2235 7.28\n",
      "2m 10s (- 6m 11s) (10400 26%) 5.0621 7.18\n",
      "2m 12s (- 6m 10s) (10500 26%) 5.1619 7.39\n",
      "2m 13s (- 6m 9s) (10600 26%) 5.4741 7.68\n",
      "2m 14s (- 6m 8s) (10700 26%) 5.2377 7.31\n",
      "2m 15s (- 6m 7s) (10800 27%) 4.9845 7.07\n",
      "2m 17s (- 6m 5s) (10900 27%) 4.9064 7.06\n",
      "2m 18s (- 6m 4s) (11000 27%) 5.1082 7.19\n",
      "2m 19s (- 6m 3s) (11100 27%) 5.1458 7.21\n",
      "2m 20s (- 6m 1s) (11200 28%) 4.9755 6.87\n",
      "2m 21s (- 6m 0s) (11300 28%) 5.0334 6.94\n",
      "2m 23s (- 5m 59s) (11400 28%) 5.1123 7.07\n",
      "2m 24s (- 5m 58s) (11500 28%) 4.7213 6.85\n",
      "2m 25s (- 5m 57s) (11600 28%) 4.7854 6.92\n",
      "2m 27s (- 5m 55s) (11700 29%) 5.1332 7.17\n",
      "2m 28s (- 5m 54s) (11800 29%) 4.8181 6.99\n",
      "2m 29s (- 5m 53s) (11900 29%) 5.3340 7.43\n",
      "2m 30s (- 5m 52s) (12000 30%) 5.1068 6.96\n",
      "2m 32s (- 5m 50s) (12100 30%) 5.2971 7.27\n",
      "2m 33s (- 5m 49s) (12200 30%) 5.2583 7.24\n",
      "2m 34s (- 5m 48s) (12300 30%) 5.3455 7.23\n",
      "2m 35s (- 5m 47s) (12400 31%) 5.0182 7.08\n",
      "2m 37s (- 5m 45s) (12500 31%) 5.0647 7.23\n",
      "2m 38s (- 5m 44s) (12600 31%) 4.8601 6.97\n",
      "2m 39s (- 5m 43s) (12700 31%) 4.9414 7.25\n",
      "2m 40s (- 5m 41s) (12800 32%) 4.7077 6.80\n",
      "2m 42s (- 5m 40s) (12900 32%) 4.6766 6.68\n",
      "2m 43s (- 5m 39s) (13000 32%) 4.8761 6.86\n",
      "2m 44s (- 5m 37s) (13100 32%) 4.9557 6.85\n",
      "2m 45s (- 5m 36s) (13200 33%) 5.1301 7.32\n",
      "2m 46s (- 5m 35s) (13300 33%) 4.8423 6.88\n",
      "2m 48s (- 5m 33s) (13400 33%) 4.6477 6.97\n",
      "2m 49s (- 5m 32s) (13500 33%) 4.6952 6.95\n",
      "2m 50s (- 5m 31s) (13600 34%) 5.1718 7.10\n",
      "2m 51s (- 5m 29s) (13700 34%) 5.3300 7.38\n",
      "2m 53s (- 5m 28s) (13800 34%) 4.9257 7.02\n",
      "2m 54s (- 5m 27s) (13900 34%) 4.9727 7.07\n",
      "2m 55s (- 5m 26s) (14000 35%) 4.7509 6.77\n",
      "2m 56s (- 5m 24s) (14100 35%) 4.8065 6.89\n",
      "2m 57s (- 5m 23s) (14200 35%) 5.0161 7.09\n",
      "2m 59s (- 5m 22s) (14300 35%) 4.9967 7.06\n",
      "3m 0s (- 5m 20s) (14400 36%) 4.9203 7.05\n",
      "3m 1s (- 5m 19s) (14500 36%) 4.8846 6.92\n",
      "3m 2s (- 5m 18s) (14600 36%) 4.7685 6.83\n",
      "3m 4s (- 5m 16s) (14700 36%) 4.7403 6.70\n",
      "3m 5s (- 5m 15s) (14800 37%) 5.0226 7.01\n",
      "3m 6s (- 5m 14s) (14900 37%) 4.5484 6.65\n",
      "3m 7s (- 5m 12s) (15000 37%) 4.6288 6.85\n",
      "3m 8s (- 5m 11s) (15100 37%) 4.7514 6.96\n",
      "3m 10s (- 5m 10s) (15200 38%) 4.6314 6.60\n",
      "3m 11s (- 5m 9s) (15300 38%) 5.1724 7.22\n",
      "3m 12s (- 5m 7s) (15400 38%) 4.8281 6.80\n",
      "3m 13s (- 5m 6s) (15500 38%) 4.6910 6.78\n",
      "3m 15s (- 5m 5s) (15600 39%) 4.5898 6.95\n",
      "3m 16s (- 5m 3s) (15700 39%) 4.7492 6.99\n",
      "3m 17s (- 5m 2s) (15800 39%) 4.5130 6.69\n",
      "3m 18s (- 5m 1s) (15900 39%) 4.7340 6.88\n",
      "3m 20s (- 5m 0s) (16000 40%) 4.6538 6.97\n",
      "3m 21s (- 4m 58s) (16100 40%) 4.5473 6.60\n",
      "3m 22s (- 4m 57s) (16200 40%) 5.1426 7.19\n",
      "3m 23s (- 4m 56s) (16300 40%) 4.6600 6.96\n",
      "3m 25s (- 4m 55s) (16400 41%) 4.8737 6.96\n",
      "3m 26s (- 4m 54s) (16500 41%) 4.8335 7.14\n",
      "3m 27s (- 4m 53s) (16600 41%) 4.7090 6.87\n",
      "3m 29s (- 4m 51s) (16700 41%) 4.8957 6.90\n",
      "3m 30s (- 4m 50s) (16800 42%) 4.4751 6.66\n",
      "3m 31s (- 4m 49s) (16900 42%) 4.6948 7.21\n",
      "3m 32s (- 4m 48s) (17000 42%) 4.6068 6.80\n",
      "3m 34s (- 4m 46s) (17100 42%) 4.5375 6.97\n",
      "3m 35s (- 4m 45s) (17200 43%) 4.6702 6.85\n",
      "3m 36s (- 4m 44s) (17300 43%) 4.5682 6.88\n",
      "3m 37s (- 4m 42s) (17400 43%) 4.5205 6.89\n",
      "3m 39s (- 4m 41s) (17500 43%) 4.7004 6.78\n",
      "3m 40s (- 4m 40s) (17600 44%) 4.6068 6.93\n",
      "3m 41s (- 4m 39s) (17700 44%) 5.0208 7.04\n",
      "3m 42s (- 4m 37s) (17800 44%) 4.7240 7.00\n",
      "3m 44s (- 4m 36s) (17900 44%) 4.7389 6.97\n",
      "3m 45s (- 4m 35s) (18000 45%) 4.5729 6.68\n",
      "3m 46s (- 4m 34s) (18100 45%) 4.8204 6.98\n",
      "3m 47s (- 4m 33s) (18200 45%) 4.5097 6.82\n",
      "3m 49s (- 4m 31s) (18300 45%) 4.3035 6.53\n",
      "3m 50s (- 4m 30s) (18400 46%) 4.7357 6.81\n",
      "3m 51s (- 4m 29s) (18500 46%) 4.4850 6.80\n",
      "3m 53s (- 4m 28s) (18600 46%) 4.5312 6.76\n",
      "3m 54s (- 4m 26s) (18700 46%) 4.6273 6.70\n",
      "3m 55s (- 4m 25s) (18800 47%) 4.7272 6.84\n",
      "3m 56s (- 4m 24s) (18900 47%) 4.7503 7.03\n",
      "3m 58s (- 4m 23s) (19000 47%) 4.2807 6.65\n",
      "3m 59s (- 4m 22s) (19100 47%) 4.5920 6.85\n",
      "4m 0s (- 4m 20s) (19200 48%) 4.7035 6.82\n",
      "4m 2s (- 4m 19s) (19300 48%) 4.6812 6.97\n",
      "4m 3s (- 4m 18s) (19400 48%) 4.6291 6.69\n",
      "4m 4s (- 4m 17s) (19500 48%) 4.8805 6.98\n",
      "4m 6s (- 4m 16s) (19600 49%) 4.2814 6.50\n",
      "4m 7s (- 4m 14s) (19700 49%) 4.6863 6.87\n",
      "4m 8s (- 4m 13s) (19800 49%) 4.6272 7.00\n",
      "4m 9s (- 4m 12s) (19900 49%) 4.4543 6.70\n",
      "4m 10s (- 4m 10s) (20000 50%) 4.8064 7.12\n",
      "4m 12s (- 4m 9s) (20100 50%) 4.6447 6.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 13s (- 4m 8s) (20200 50%) 4.6532 6.74\n",
      "4m 14s (- 4m 7s) (20300 50%) 4.5873 6.68\n",
      "4m 15s (- 4m 5s) (20400 51%) 4.5567 6.74\n",
      "4m 17s (- 4m 4s) (20500 51%) 4.6774 6.89\n",
      "4m 18s (- 4m 3s) (20600 51%) 4.9188 7.06\n",
      "4m 19s (- 4m 2s) (20700 51%) 4.5559 6.77\n",
      "4m 20s (- 4m 0s) (20800 52%) 4.2201 6.46\n",
      "4m 22s (- 3m 59s) (20900 52%) 4.3170 6.56\n",
      "4m 23s (- 3m 58s) (21000 52%) 4.6413 6.99\n",
      "4m 24s (- 3m 56s) (21100 52%) 4.5372 6.83\n",
      "4m 25s (- 3m 55s) (21200 53%) 4.3307 6.49\n",
      "4m 27s (- 3m 54s) (21300 53%) 4.6840 6.79\n",
      "4m 28s (- 3m 53s) (21400 53%) 4.6583 6.91\n",
      "4m 29s (- 3m 51s) (21500 53%) 4.3774 6.50\n",
      "4m 30s (- 3m 50s) (21600 54%) 4.4222 6.63\n",
      "4m 31s (- 3m 49s) (21700 54%) 4.6390 6.85\n",
      "4m 33s (- 3m 48s) (21800 54%) 4.5037 6.67\n",
      "4m 34s (- 3m 46s) (21900 54%) 4.6484 6.85\n",
      "4m 35s (- 3m 45s) (22000 55%) 4.7608 7.11\n",
      "4m 36s (- 3m 44s) (22100 55%) 4.3271 6.68\n",
      "4m 38s (- 3m 43s) (22200 55%) 4.2208 6.14\n",
      "4m 39s (- 3m 41s) (22300 55%) 4.3677 6.53\n",
      "4m 40s (- 3m 40s) (22400 56%) 4.4364 6.70\n",
      "4m 41s (- 3m 39s) (22500 56%) 4.3389 6.66\n",
      "4m 43s (- 3m 38s) (22600 56%) 4.2643 6.40\n",
      "4m 44s (- 3m 36s) (22700 56%) 4.6718 6.77\n",
      "4m 45s (- 3m 35s) (22800 56%) 4.5573 6.95\n",
      "4m 46s (- 3m 34s) (22900 57%) 4.8544 7.03\n",
      "4m 48s (- 3m 33s) (23000 57%) 4.3664 6.62\n",
      "4m 49s (- 3m 31s) (23100 57%) 4.5247 6.87\n",
      "4m 50s (- 3m 30s) (23200 57%) 4.6444 6.76\n",
      "4m 51s (- 3m 29s) (23300 58%) 4.5618 6.94\n",
      "4m 53s (- 3m 28s) (23400 58%) 4.4939 6.75\n",
      "4m 54s (- 3m 26s) (23500 58%) 4.4788 6.67\n",
      "4m 55s (- 3m 25s) (23600 59%) 4.4773 6.74\n",
      "4m 57s (- 3m 24s) (23700 59%) 4.0622 6.33\n",
      "4m 58s (- 3m 23s) (23800 59%) 4.5983 6.98\n",
      "4m 59s (- 3m 21s) (23900 59%) 4.3066 6.49\n",
      "5m 1s (- 3m 20s) (24000 60%) 4.2329 6.50\n",
      "5m 2s (- 3m 19s) (24100 60%) 4.3951 6.62\n",
      "5m 3s (- 3m 18s) (24200 60%) 4.4839 6.56\n",
      "5m 5s (- 3m 17s) (24300 60%) 4.5320 6.90\n",
      "5m 6s (- 3m 15s) (24400 61%) 4.2525 6.51\n",
      "5m 7s (- 3m 14s) (24500 61%) 4.1467 6.29\n",
      "5m 8s (- 3m 13s) (24600 61%) 4.3831 6.55\n",
      "5m 10s (- 3m 12s) (24700 61%) 4.2864 6.37\n",
      "5m 11s (- 3m 10s) (24800 62%) 4.5371 6.74\n",
      "5m 12s (- 3m 9s) (24900 62%) 4.2982 6.49\n",
      "5m 14s (- 3m 8s) (25000 62%) 4.0665 6.38\n",
      "5m 15s (- 3m 7s) (25100 62%) 4.1604 6.27\n",
      "5m 16s (- 3m 5s) (25200 63%) 4.3044 6.73\n",
      "5m 17s (- 3m 4s) (25300 63%) 4.1787 6.36\n",
      "5m 19s (- 3m 3s) (25400 63%) 4.0593 6.43\n",
      "5m 20s (- 3m 2s) (25500 63%) 4.2617 6.56\n",
      "5m 21s (- 3m 0s) (25600 64%) 4.4368 6.72\n",
      "5m 22s (- 2m 59s) (25700 64%) 4.4442 6.65\n",
      "5m 24s (- 2m 58s) (25800 64%) 4.1990 6.34\n",
      "5m 25s (- 2m 57s) (25900 64%) 4.4259 6.61\n",
      "5m 26s (- 2m 55s) (26000 65%) 4.2331 6.52\n",
      "5m 27s (- 2m 54s) (26100 65%) 4.6255 6.98\n",
      "5m 29s (- 2m 53s) (26200 65%) 4.1342 6.42\n",
      "5m 30s (- 2m 52s) (26300 65%) 4.4609 6.67\n",
      "5m 31s (- 2m 50s) (26400 66%) 4.2900 6.58\n",
      "5m 32s (- 2m 49s) (26500 66%) 4.1857 6.52\n",
      "5m 34s (- 2m 48s) (26600 66%) 4.2039 6.43\n",
      "5m 35s (- 2m 47s) (26700 66%) 4.2168 6.51\n",
      "5m 36s (- 2m 45s) (26800 67%) 4.2556 6.24\n",
      "5m 37s (- 2m 44s) (26900 67%) 4.6089 6.88\n",
      "5m 39s (- 2m 43s) (27000 67%) 4.1298 6.15\n",
      "5m 40s (- 2m 41s) (27100 67%) 4.4494 6.55\n",
      "5m 41s (- 2m 40s) (27200 68%) 4.5697 6.58\n",
      "5m 42s (- 2m 39s) (27300 68%) 4.4742 6.51\n",
      "5m 44s (- 2m 38s) (27400 68%) 4.2806 6.45\n",
      "5m 45s (- 2m 36s) (27500 68%) 4.7221 6.85\n",
      "5m 46s (- 2m 35s) (27600 69%) 4.1584 6.58\n",
      "5m 47s (- 2m 34s) (27700 69%) 4.6061 6.93\n",
      "5m 49s (- 2m 33s) (27800 69%) 4.5746 7.03\n",
      "5m 50s (- 2m 31s) (27900 69%) 4.2203 6.25\n",
      "5m 51s (- 2m 30s) (28000 70%) 4.4881 6.66\n",
      "5m 52s (- 2m 29s) (28100 70%) 4.3475 6.80\n",
      "5m 54s (- 2m 28s) (28200 70%) 4.2761 6.52\n",
      "5m 55s (- 2m 26s) (28300 70%) 4.3251 6.62\n",
      "5m 56s (- 2m 25s) (28400 71%) 4.3100 6.56\n",
      "5m 57s (- 2m 24s) (28500 71%) 4.5457 6.80\n",
      "5m 59s (- 2m 23s) (28600 71%) 4.4359 6.51\n",
      "6m 0s (- 2m 21s) (28700 71%) 4.1099 6.45\n",
      "6m 1s (- 2m 20s) (28800 72%) 4.3431 6.72\n",
      "6m 2s (- 2m 19s) (28900 72%) 4.1208 6.38\n",
      "6m 4s (- 2m 18s) (29000 72%) 4.3721 6.55\n",
      "6m 5s (- 2m 16s) (29100 72%) 4.5035 6.81\n",
      "6m 6s (- 2m 15s) (29200 73%) 4.2416 6.52\n",
      "6m 7s (- 2m 14s) (29300 73%) 4.1407 6.20\n",
      "6m 9s (- 2m 13s) (29400 73%) 4.6266 6.88\n",
      "6m 10s (- 2m 11s) (29500 73%) 4.3134 6.46\n",
      "6m 11s (- 2m 10s) (29600 74%) 4.3262 6.37\n",
      "6m 12s (- 2m 9s) (29700 74%) 4.0470 6.14\n",
      "6m 14s (- 2m 8s) (29800 74%) 4.2983 6.25\n",
      "6m 15s (- 2m 6s) (29900 74%) 4.3766 6.88\n",
      "6m 16s (- 2m 5s) (30000 75%) 3.8438 6.14\n",
      "6m 17s (- 2m 4s) (30100 75%) 4.1475 6.45\n",
      "6m 19s (- 2m 2s) (30200 75%) 3.9964 6.38\n",
      "6m 20s (- 2m 1s) (30300 75%) 4.3674 6.52\n",
      "6m 21s (- 2m 0s) (30400 76%) 4.1256 6.27\n",
      "6m 22s (- 1m 59s) (30500 76%) 4.3484 6.60\n",
      "6m 24s (- 1m 57s) (30600 76%) 4.2855 6.46\n",
      "6m 25s (- 1m 56s) (30700 76%) 4.0798 6.28\n",
      "6m 26s (- 1m 55s) (30800 77%) 4.0512 6.19\n",
      "6m 27s (- 1m 54s) (30900 77%) 4.5616 6.93\n",
      "6m 29s (- 1m 52s) (31000 77%) 4.1151 6.21\n",
      "6m 30s (- 1m 51s) (31100 77%) 3.9579 6.42\n",
      "6m 31s (- 1m 50s) (31200 78%) 4.0843 6.38\n",
      "6m 32s (- 1m 49s) (31300 78%) 3.9186 6.25\n",
      "6m 33s (- 1m 47s) (31400 78%) 4.4506 6.51\n",
      "6m 35s (- 1m 46s) (31500 78%) 3.8950 6.30\n",
      "6m 36s (- 1m 45s) (31600 79%) 4.4801 6.57\n",
      "6m 37s (- 1m 44s) (31700 79%) 4.0745 6.29\n",
      "6m 38s (- 1m 42s) (31800 79%) 4.1540 6.34\n",
      "6m 40s (- 1m 41s) (31900 79%) 4.4328 6.54\n",
      "6m 41s (- 1m 40s) (32000 80%) 4.2692 6.62\n",
      "6m 42s (- 1m 39s) (32100 80%) 4.4915 6.59\n",
      "6m 43s (- 1m 37s) (32200 80%) 4.2676 6.88\n",
      "6m 44s (- 1m 36s) (32300 80%) 3.9861 6.25\n",
      "6m 46s (- 1m 35s) (32400 81%) 4.1451 6.24\n",
      "6m 47s (- 1m 34s) (32500 81%) 4.0784 6.20\n",
      "6m 48s (- 1m 32s) (32600 81%) 4.3523 6.64\n",
      "6m 49s (- 1m 31s) (32700 81%) 4.2260 6.51\n",
      "6m 51s (- 1m 30s) (32800 82%) 4.1524 6.49\n",
      "6m 52s (- 1m 28s) (32900 82%) 4.4271 6.60\n",
      "6m 53s (- 1m 27s) (33000 82%) 4.3793 6.29\n",
      "6m 54s (- 1m 26s) (33100 82%) 4.2101 6.48\n",
      "6m 55s (- 1m 25s) (33200 83%) 3.9859 6.28\n",
      "6m 57s (- 1m 23s) (33300 83%) 3.9911 6.27\n",
      "6m 58s (- 1m 22s) (33400 83%) 4.4280 6.50\n",
      "6m 59s (- 1m 21s) (33500 83%) 4.7104 6.86\n",
      "7m 0s (- 1m 20s) (33600 84%) 4.4293 6.34\n",
      "7m 2s (- 1m 18s) (33700 84%) 4.1958 6.32\n",
      "7m 3s (- 1m 17s) (33800 84%) 4.2401 6.61\n",
      "7m 4s (- 1m 16s) (33900 84%) 3.9486 6.15\n",
      "7m 5s (- 1m 15s) (34000 85%) 4.2100 6.23\n",
      "7m 7s (- 1m 13s) (34100 85%) 3.9183 6.21\n",
      "7m 8s (- 1m 12s) (34200 85%) 4.7845 7.00\n",
      "7m 9s (- 1m 11s) (34300 85%) 3.9436 6.15\n",
      "7m 10s (- 1m 10s) (34400 86%) 4.0240 6.17\n",
      "7m 11s (- 1m 8s) (34500 86%) 4.4394 6.69\n",
      "7m 13s (- 1m 7s) (34600 86%) 3.8413 6.36\n",
      "7m 14s (- 1m 6s) (34700 86%) 3.9813 6.37\n",
      "7m 15s (- 1m 5s) (34800 87%) 3.8133 6.17\n",
      "7m 16s (- 1m 3s) (34900 87%) 4.3022 6.65\n",
      "7m 18s (- 1m 2s) (35000 87%) 4.1764 6.45\n",
      "7m 19s (- 1m 1s) (35100 87%) 4.0796 6.38\n",
      "7m 20s (- 1m 0s) (35200 88%) 3.8825 6.12\n",
      "7m 21s (- 0m 58s) (35300 88%) 3.9314 6.34\n",
      "7m 23s (- 0m 57s) (35400 88%) 4.0677 6.28\n",
      "7m 24s (- 0m 56s) (35500 88%) 4.3054 6.42\n",
      "7m 25s (- 0m 55s) (35600 89%) 4.2190 6.66\n",
      "7m 26s (- 0m 53s) (35700 89%) 4.0831 6.61\n",
      "7m 28s (- 0m 52s) (35800 89%) 3.9551 6.17\n",
      "7m 29s (- 0m 51s) (35900 89%) 4.1056 6.59\n",
      "7m 30s (- 0m 50s) (36000 90%) 3.9213 6.25\n",
      "7m 32s (- 0m 48s) (36100 90%) 4.0232 6.17\n",
      "7m 33s (- 0m 47s) (36200 90%) 4.1694 6.40\n",
      "7m 34s (- 0m 46s) (36300 90%) 3.9631 6.32\n",
      "7m 35s (- 0m 45s) (36400 91%) 3.9264 6.32\n",
      "7m 36s (- 0m 43s) (36500 91%) 4.2825 6.56\n",
      "7m 38s (- 0m 42s) (36600 91%) 4.2654 6.56\n",
      "7m 39s (- 0m 41s) (36700 91%) 3.9529 6.44\n",
      "7m 40s (- 0m 40s) (36800 92%) 4.3374 6.74\n",
      "7m 41s (- 0m 38s) (36900 92%) 4.3523 6.61\n",
      "7m 43s (- 0m 37s) (37000 92%) 4.1978 6.53\n",
      "7m 44s (- 0m 36s) (37100 92%) 4.5809 6.74\n",
      "7m 45s (- 0m 35s) (37200 93%) 4.0607 6.57\n",
      "7m 46s (- 0m 33s) (37300 93%) 4.1622 6.42\n",
      "7m 48s (- 0m 32s) (37400 93%) 4.0756 6.38\n",
      "7m 49s (- 0m 31s) (37500 93%) 4.3793 6.75\n",
      "7m 50s (- 0m 30s) (37600 94%) 4.2124 6.25\n",
      "7m 51s (- 0m 28s) (37700 94%) 3.8324 6.13\n",
      "7m 52s (- 0m 27s) (37800 94%) 4.2614 6.41\n",
      "7m 54s (- 0m 26s) (37900 94%) 4.2611 6.73\n",
      "7m 55s (- 0m 25s) (38000 95%) 3.9651 6.21\n",
      "7m 56s (- 0m 23s) (38100 95%) 3.9939 6.45\n",
      "7m 57s (- 0m 22s) (38200 95%) 4.6553 7.05\n",
      "7m 58s (- 0m 21s) (38300 95%) 3.8918 6.10\n",
      "8m 0s (- 0m 20s) (38400 96%) 3.5280 5.94\n",
      "8m 1s (- 0m 18s) (38500 96%) 4.3399 6.45\n",
      "8m 2s (- 0m 17s) (38600 96%) 4.2899 6.50\n",
      "8m 3s (- 0m 16s) (38700 96%) 4.2993 6.48\n",
      "8m 4s (- 0m 14s) (38800 97%) 4.1558 6.46\n",
      "8m 6s (- 0m 13s) (38900 97%) 4.0600 6.32\n",
      "8m 7s (- 0m 12s) (39000 97%) 3.7686 5.96\n",
      "8m 8s (- 0m 11s) (39100 97%) 3.9890 6.20\n",
      "8m 9s (- 0m 9s) (39200 98%) 4.1660 6.30\n",
      "8m 11s (- 0m 8s) (39300 98%) 4.3302 6.47\n",
      "8m 12s (- 0m 7s) (39400 98%) 3.7819 5.88\n",
      "8m 13s (- 0m 6s) (39500 98%) 4.0634 6.48\n",
      "8m 14s (- 0m 4s) (39600 99%) 4.2792 6.23\n",
      "8m 16s (- 0m 3s) (39700 99%) 4.5700 6.67\n",
      "8m 17s (- 0m 2s) (39800 99%) 4.0768 6.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 18s (- 0m 1s) (39900 99%) 3.9669 6.40\n",
      "8m 19s (- 0m 0s) (40000 100%) 4.2651 6.35\n"
     ]
    }
   ],
   "source": [
    "skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 40000, learning_rate=0.01)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.005)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.0025)\n",
    "#skipgram_trainer.train(skipgram, Ngrams, weights = weightsList(10), n_iters = 30000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauver\n",
    "#torch.save(skipgram.state_dict(), path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_skipgram.pth')\n",
    "\n",
    "# charger\n",
    "#skipgram.load_state_dict(torch.load(path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_skipgram.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir la table des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T est de type <class 'numpy.ndarray'> et de taille (6474, 75)\n"
     ]
    }
   ],
   "source": [
    "T = skipgram.embedding.weight.cpu().detach().numpy()\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'alignement mot-indice est donné par le dictionnaire lang.word2index du language chargé dans le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2.3 Modèle Skip-gram de FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim = FT_gensim(size = 100, \n",
    "                           window = 5, \n",
    "                           min_count = 1, \n",
    "                           negative = 10,\n",
    "                           sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fasttext = [['SOS'] + text + ['EOS'] for text in X_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.build_vocab(sentences = X_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.train(sentences = X_fasttext, \n",
    "                      epochs = 500,\n",
    "                      total_examples=fastText_gensim.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_gensim.save('Lilly_pkg_modele_linguistique_fastText_bis')\n",
    "#fastText_gensim = FT_gensim.load('Lilly_pkg_modele_linguistique_fastText_bis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=7238, size=100, alpha=0.025)\n",
      "T est de type <class 'numpy.ndarray'> et de taille (7238, 100)\n"
     ]
    }
   ],
   "source": [
    "print(fastText_gensim)\n",
    "\n",
    "T = fastText_gensim.wv.vectors\n",
    "print('T est de type {} et de taille {}'.format(type(T), T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_linguistique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Modèle Linguistique\n",
    "\n",
    "Exemples d'implémentation en PyTorch :\n",
    "\n",
    "- https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n",
    "\n",
    "\n",
    "Différentes architectures sont décrites dans la litérature :\n",
    "\n",
    "- Regularizing and Optimizing LSTM Language Models - https://arxiv.org/pdf/1708.02182.pdf\n",
    "\n",
    "Un modèle linguistique est intérressant en soi, mais peut aussi servir pour le pré-entrainement de couches basses d'un modèle plus complexe :\n",
    "\n",
    "- Deep contextualized word representations - https://arxiv.org/pdf/1802.05365.pdf\n",
    "- Improving Language Understanding by Generative Pre-Training - https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\n",
    "- Language Models are Unsupervised Multitask Learners - https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Le modèle linguistique\n",
    "\n",
    "[Retour à la table des matières](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, device, \n",
    "                 lang,\n",
    "                 embedding_weights, \n",
    "                 hidden_dim,\n",
    "                 n_layers = 1, \n",
    "                 dropout = 0): \n",
    "        \n",
    "        super(LanguageModel, self).__init__()\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.lang = lang\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_p = dropout\n",
    "        self.n_layers = n_layers               # number of stacked GRU layers\n",
    "        self.output_dim = hidden_dim           # dimension of outputed rep. of words and utterance\n",
    "        # parameters\n",
    "        self.embedding = nn.Embedding(embedding_weights[0], embedding_weights[1]) if type(embedding_weights) == tuple else \\\n",
    "                         nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights), freeze=True)\n",
    "        for p in self.embedding.parameters() :\n",
    "            embedding_dim = p.data.size(1)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          self.hidden_dim, \n",
    "                          n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), \n",
    "                          bidirectional = False)\n",
    "        self.out = nn.Linear(self.hidden_dim, lang.n_words)\n",
    "        #self.out.weight = self.embedding.weight\n",
    "        \n",
    "        \n",
    "    # ------------- technical methods ------------------    \n",
    "    def nbParametres(self) :\n",
    "        count = 0\n",
    "        for p in self.parameters():\n",
    "            if p.requires_grad == True :\n",
    "                count += p.data.nelement()\n",
    "        return count\n",
    "    \n",
    "\n",
    "    def variableFromSentence(self, sentence):\n",
    "        '''Turn a sentence into a torch variable, containing a list of indices according\n",
    "           to a given language.'''\n",
    "        indexes = [self.lang.word2index[word] for word in sentence if word in self.lang.word2index]          \n",
    "        result = Variable(torch.LongTensor(indexes).view(-1, 1)).to(self.device)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def initHidden(self): \n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_dim)).to(self.device)\n",
    "    \n",
    "    \n",
    "    # ------------- main methods ------------------\n",
    "    def generateWord(self, utterance, hidden = None):\n",
    "        embeddings = self.embedding(utterance)                          # dim = (input_length, 1, embedding_dim)\n",
    "        embeddings = self.dropout(embeddings)                           # dim = (input_length, 1, embedding_dim)\n",
    "        hidden = self.initHidden() if hidden is None else hidden\n",
    "        _, hidden = self.gru(embeddings, hidden)                        # dim = (input_length, 1, hidden_dim)\n",
    "        hidden = self.dropout(hidden)\n",
    "        log_probs = F.log_softmax(self.out(hidden[-1]))         # dim = (1, lang_size)\n",
    "        return log_probs, hidden  \n",
    "\n",
    "    \n",
    "    def forward(self, sentence = ['SOS'], hidden = None, limit = 10, retain = False, color_code = '\\033[40m'):\n",
    "        result = sentence + [color_code]\n",
    "        count = 0\n",
    "        stop = False\n",
    "        utterance = self.variableFromSentence(sentence)\n",
    "        while not stop :\n",
    "            log_probs, hidden = self.generateWord(utterance, hidden)\n",
    "            topv, topi = log_probs[0].data.topk(1)\n",
    "            ni = topi.item()\n",
    "            utterance = Variable(torch.LongTensor([[ni]])).to(self.device)\n",
    "            result.append(self.lang.index2word[ni])\n",
    "            count += 1\n",
    "            if count == limit or (type(limit) == str and ni == self.lang.word2index[limit]) or count == 50 :\n",
    "                stop = True\n",
    "        if not retain :\n",
    "            phrase = ' '.join(result)\n",
    "            phrase = phrase.replace('donc', '=>')\n",
    "            phrase = re.sub(' \\.\\s*', '.\\n', phrase)\n",
    "            phrase += '\\033[0m'\n",
    "            print(phrase)\n",
    "            return\n",
    "        else :\n",
    "            return result, hidden   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelTrainer(object):\n",
    "    def __init__(self, \n",
    "                 device,\n",
    "                 criterion = nn.NLLLoss(reduce = False), #nn.BCEWithLogitsLoss(), #nn.BCELoss(), \n",
    "                 optimizer = optim.SGD,\n",
    "                 print_every=100):\n",
    "        # relevant quantities\n",
    "        self.device = device\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "    \n",
    "    \n",
    "    def timeSince(self, since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "        \n",
    "        \n",
    "    def trainLoop(self, agent, sentence, word, optimizer, learning_rate):\n",
    "        \"\"\"Performs a training loop, with forward pass and backward pass for gradient optimisation.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        agent.zero_grad()\n",
    "        word_var     = agent.variableFromSentence([word]).view(-1)\n",
    "        sentence_var = agent.variableFromSentence(sentence)\n",
    "        log_probs, _ = agent.generateWord(sentence_var)\n",
    "        \n",
    "        loss = self.criterion(log_probs, word_var)\n",
    "        topv, topi = log_probs[0].data.topk(1)\n",
    "        loss_diff = 1 if topi.item() != word_var.data.item() else 0\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        return loss.data[0], loss_diff\n",
    "        \n",
    "        \n",
    "    def train(self,\n",
    "              agent, \n",
    "              sentences,\n",
    "              n_iters = 100,\n",
    "              learning_rate=0.01,\n",
    "              random_state = 42\n",
    "             ):\n",
    "        \"\"\"Performs training over a given dataset and along a specified amount of loops.\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        start = time.time()\n",
    "        optimizer = self.optimizer([param for param in agent.parameters() if param.requires_grad == True], lr=learning_rate)\n",
    "        print_loss_total = 0  \n",
    "        print_loss_diff_mots_total = 0\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            sentence = random.choice(sentences) #--- [str]\n",
    "            i = random.choice(range(len(sentence)))\n",
    "            context = ['SOS'] + sentence[:i] \n",
    "            target = sentence[i]\n",
    "\n",
    "            loss, loss_diff_mots = self.trainLoop(agent, context, target, optimizer, learning_rate)\n",
    "            \n",
    "            # affichage\n",
    "            print_loss_total += loss\n",
    "            print_loss_diff_mots_total += loss_diff_mots       \n",
    "            if iter % (self.print_every) == 0:\n",
    "                print_loss_avg = print_loss_total / self.print_every\n",
    "                print_loss_diff_mots_avg = print_loss_diff_mots_total / self.print_every\n",
    "                print_loss_total = 0\n",
    "                print_loss_diff_mots_total = 0\n",
    "                print('%s (%d %d%%) %.4f %.2f' % (self.timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, \n",
    "                                                  print_loss_avg, print_loss_diff_mots_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipgram custom\n",
    "#T = skipgram.embedding.weight.cpu().detach().numpy()\n",
    "#lang = generateLanguageFromNumpy(X, init = 3, lvl = 2)\n",
    "\n",
    "# fastText gensim\n",
    "T = fastText_gensim.wv.vectors\n",
    "lang = generateLanguageFromWordList(list(fastText_gensim.wv.vocab.keys()), init = 0)\n",
    "lang.addDescriptions(X_flat) # pour retrouver le nombre d'occurences de chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478138"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model = LanguageModel(device = device,\n",
    "                               lang = lang,\n",
    "                               hidden_dim = 150, #100\n",
    "                               embedding_weights = T,\n",
    "                               n_layers = 3, #2\n",
    "                               dropout = 0.15)\n",
    "language_model = language_model.to(device)\n",
    "language_model.nbParametres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (embedding): Embedding(7238, 100)\n",
       "  (dropout): Dropout(p=0.15)\n",
       "  (gru): GRU(100, 150, num_layers=3, dropout=0.15)\n",
       "  (out): Linear(in_features=150, out_features=7238, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = list(lang.word2count.values())\n",
    "freqs = [1/np.log(el+1) for el in freqs]\n",
    "freqs = torch.tensor(freqs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0890, device='cuda:0') tensor(1.4427, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(min(freqs), max(freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model_trainer = LanguageModelTrainer(device = device, \n",
    "                                              criterion = nn.NLLLoss(weight = freqs), \n",
    "                                              print_every = 500\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.load_state_dict(torch.load(path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_bis.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 19s (- 25m 42s) (500 1%) 2.4809 0.42\n",
      "0m 39s (- 25m 51s) (1000 2%) 2.5120 0.43\n",
      "0m 54s (- 23m 19s) (1500 3%) 2.4712 0.44\n",
      "1m 12s (- 22m 58s) (2000 5%) 2.5622 0.44\n",
      "1m 27s (- 21m 47s) (2500 6%) 2.5426 0.42\n",
      "1m 40s (- 20m 41s) (3000 7%) 2.4138 0.40\n",
      "1m 57s (- 20m 29s) (3500 8%) 2.3096 0.40\n",
      "2m 13s (- 19m 57s) (4000 10%) 2.4725 0.42\n",
      "2m 28s (- 19m 29s) (4500 11%) 2.5369 0.43\n",
      "2m 43s (- 19m 5s) (5000 12%) 2.3827 0.40\n",
      "2m 57s (- 18m 33s) (5500 13%) 2.3754 0.40\n",
      "3m 12s (- 18m 9s) (6000 15%) 2.4467 0.40\n",
      "3m 27s (- 17m 49s) (6500 16%) 2.3025 0.40\n",
      "3m 42s (- 17m 28s) (7000 17%) 2.5415 0.45\n",
      "3m 56s (- 17m 5s) (7500 18%) 2.4088 0.44\n",
      "4m 11s (- 16m 47s) (8000 20%) 2.3833 0.41\n",
      "4m 27s (- 16m 31s) (8500 21%) 2.3885 0.40\n",
      "4m 44s (- 16m 19s) (9000 22%) 2.2055 0.41\n",
      "4m 58s (- 15m 59s) (9500 23%) 2.2989 0.40\n",
      "5m 14s (- 15m 42s) (10000 25%) 2.4319 0.41\n",
      "5m 29s (- 15m 25s) (10500 26%) 2.4844 0.43\n",
      "5m 43s (- 15m 6s) (11000 27%) 2.2588 0.40\n",
      "6m 0s (- 14m 52s) (11500 28%) 2.3465 0.42\n",
      "6m 14s (- 14m 33s) (12000 30%) 2.6662 0.45\n",
      "6m 29s (- 14m 16s) (12500 31%) 2.5799 0.43\n",
      "6m 44s (- 14m 0s) (13000 32%) 2.5084 0.42\n",
      "6m 59s (- 13m 43s) (13500 33%) 2.5223 0.44\n",
      "7m 13s (- 13m 25s) (14000 35%) 2.5548 0.43\n",
      "7m 28s (- 13m 8s) (14500 36%) 2.4897 0.41\n",
      "7m 42s (- 12m 51s) (15000 37%) 2.6753 0.46\n",
      "7m 58s (- 12m 36s) (15500 38%) 2.4903 0.46\n",
      "8m 13s (- 12m 20s) (16000 40%) 2.4741 0.44\n",
      "8m 28s (- 12m 4s) (16500 41%) 2.4513 0.42\n",
      "8m 44s (- 11m 50s) (17000 42%) 2.5690 0.44\n",
      "8m 59s (- 11m 33s) (17500 43%) 2.2238 0.42\n",
      "9m 14s (- 11m 18s) (18000 45%) 2.4685 0.41\n",
      "9m 29s (- 11m 2s) (18500 46%) 2.5511 0.42\n",
      "9m 44s (- 10m 46s) (19000 47%) 2.6814 0.45\n",
      "9m 59s (- 10m 30s) (19500 48%) 2.3184 0.40\n",
      "10m 12s (- 10m 12s) (20000 50%) 2.6582 0.45\n",
      "10m 29s (- 9m 58s) (20500 51%) 2.0685 0.37\n",
      "10m 43s (- 9m 42s) (21000 52%) 2.7005 0.46\n",
      "10m 58s (- 9m 26s) (21500 53%) 2.3167 0.40\n",
      "11m 13s (- 9m 10s) (22000 55%) 2.5446 0.42\n",
      "11m 27s (- 8m 54s) (22500 56%) 2.3966 0.43\n",
      "11m 42s (- 8m 39s) (23000 57%) 2.6527 0.47\n",
      "11m 57s (- 8m 24s) (23500 58%) 2.5381 0.42\n",
      "12m 14s (- 8m 9s) (24000 60%) 2.5169 0.45\n",
      "12m 28s (- 7m 53s) (24500 61%) 2.4424 0.44\n",
      "12m 44s (- 7m 38s) (25000 62%) 2.5159 0.45\n",
      "12m 59s (- 7m 23s) (25500 63%) 2.6216 0.45\n",
      "13m 12s (- 7m 6s) (26000 65%) 2.6754 0.44\n",
      "13m 27s (- 6m 51s) (26500 66%) 2.2006 0.39\n",
      "13m 41s (- 6m 35s) (27000 67%) 2.5902 0.42\n",
      "13m 57s (- 6m 20s) (27500 68%) 2.5143 0.44\n",
      "14m 11s (- 6m 5s) (28000 70%) 2.5817 0.46\n",
      "14m 25s (- 5m 49s) (28500 71%) 2.5225 0.43\n",
      "14m 40s (- 5m 33s) (29000 72%) 2.3577 0.40\n",
      "14m 55s (- 5m 18s) (29500 73%) 2.4475 0.44\n",
      "15m 10s (- 5m 3s) (30000 75%) 2.6610 0.43\n",
      "15m 25s (- 4m 48s) (30500 76%) 2.3213 0.41\n",
      "15m 40s (- 4m 33s) (31000 77%) 2.3648 0.40\n",
      "15m 56s (- 4m 18s) (31500 78%) 2.4274 0.42\n",
      "16m 11s (- 4m 2s) (32000 80%) 2.6810 0.48\n",
      "16m 26s (- 3m 47s) (32500 81%) 2.4734 0.40\n",
      "16m 41s (- 3m 32s) (33000 82%) 2.4126 0.43\n",
      "16m 56s (- 3m 17s) (33500 83%) 2.2849 0.39\n",
      "17m 12s (- 3m 2s) (34000 85%) 2.4882 0.41\n",
      "17m 26s (- 2m 46s) (34500 86%) 2.4541 0.40\n",
      "17m 41s (- 2m 31s) (35000 87%) 2.6562 0.44\n",
      "17m 56s (- 2m 16s) (35500 88%) 2.5096 0.41\n",
      "18m 13s (- 2m 1s) (36000 90%) 2.4258 0.40\n",
      "18m 29s (- 1m 46s) (36500 91%) 2.3313 0.42\n",
      "18m 44s (- 1m 31s) (37000 92%) 2.5810 0.43\n",
      "19m 0s (- 1m 16s) (37500 93%) 2.2300 0.38\n",
      "19m 16s (- 1m 0s) (38000 95%) 2.4060 0.43\n",
      "19m 33s (- 0m 45s) (38500 96%) 2.6339 0.47\n",
      "19m 49s (- 0m 30s) (39000 97%) 2.4808 0.45\n",
      "20m 4s (- 0m 15s) (39500 98%) 2.5002 0.43\n",
      "20m 19s (- 0m 0s) (40000 100%) 2.4703 0.43\n"
     ]
    }
   ],
   "source": [
    "language_model.train()\n",
    "#language_model_trainer.train(language_model, X_flat, n_iters = 80000, learning_rate=0.01)\n",
    "#language_model_trainer.train(language_model, X_flat, n_iters = 40000, learning_rate=0.005)\n",
    "#language_model_trainer.train(language_model, X_flat, n_iters = 40000, learning_rate=0.002)\n",
    "language_model_trainer.train(language_model, X_flat, n_iters = 40000, learning_rate=0.001)\n",
    "#language_model_trainer.train(language_model, X_flat, n_iters = 40000, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(language_model.state_dict(), path_to_rep + '\\saves\\\\Lilly_pkg_modele_linguistique_bis.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short description ast pmx pkg apollo lot impossible a demarrer attente apres signature \u001b[48;2;255;229;217m.\n",
      "description appel de l operateur pour signaler que le limos est en remote pas a signer.\n",
      "resolve notes.\n",
      "resume appel de l operateur pour signaler que le limos est en remote pas a signer.\n",
      "consequence factuelle impossible de poursuivre la checklist.\n",
      "resolution.\n",
      "verification de\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# fastText gensim, n_layers = 3, dh = 150\n",
    "language_model.eval()\n",
    "sentence = random.choice(X_flat)\n",
    "i = random.choice(range(len(sentence)))\n",
    "sentence = sentence[:i] if i > 0 else ['SOS']\n",
    "language_model(sentence, limit = 'EOS', color_code = '\\x1b[48;2;255;229;217m' ) #  '\\x1b[48;2;255;229;217m' '\\x1b[31m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recherche d'articles de language model sur les tickets d'incidents dans le contexte de \n",
    "\n",
    "- controle qualité\n",
    "- ouverture de non-conformité\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
